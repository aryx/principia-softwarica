\documentclass[twocolumn, landscape]{report}

%******************************************************************************
% Prelude
%******************************************************************************
\newif\iffinal
\newif\ifverbose
\finaltrue\verbosefalse % see also other newif in Macros.tex

%------------------------------------------------------------------------------
%history: 
%------------------------------------------------------------------------------

%thx to LP, I changed for the better a few things:
% - have a small set of cmd_xxx.ml files 
%   (dulwich has big porcelain.py and dulwich.py files, 
%    ocaml-git has just ogit.ml,
%    git has many git-xxx.c but too many; porcelain vs plumb is useless)

%thx to codemap/codegraph/scheck:
% - TODO use cg to reduce backward deps, introduce globals.c, utils.c,
%   (harder to understand non layered code)
% - TODO use scheck to remove deadcode, dead prototypes, useless export
%   or mv as forward decl
%   (harder to understand big interface files)
% - TODO use cg to reduce number of globals by moving them closer to the
%   relevant file (or even function), better cluster the code
%   (harder to understand non functional code using lots of globals)

%thx to this manual, better understand VCS (and git):
% - intuition of Torvalds for a stupid content tracker with very
%   different strategies
% - merge and MERGE_HEADS state?
% - beauty of design using SHA1 used for so many things (Graydon Hoare?)

%history LP-ization:
% * wanted to LPize camp (simplified clone of darcs, also in Haskell)
% * LPized finally dulwich (clone of git in Python)
% - skeleton, mostly copy paste of Template.nw skeleton
% - put all content of files in the Extra section, via 'pfff -lpize'
%   which also now split in chunks!
%    * function, global, struct, enum, constant, macro(actually function)
%    * [[xxx]] other fields, [[xxx]] extra fields
% - read Extra section, identify concepts, first TOC
% - distribute parts of the Extra section in the main file
% - understand main(), LP split main, improve TOC
% - understand main functions, LP split, cluster, improve TOC
% - LP split the structures, use datalog for flow to field info
% - nullify, boolify, errorify, enumify,  typeify,    scheckify, plan9ify
% - aspecify advanced features! remove useless features
% * port dulwich to OCaml thx to lpized version of dulwich
% * LPized my ocaml port of dulwich
% - TODO add figures
% - TODO add explanations

%------------------------------------------------------------------------------
% Packages
%------------------------------------------------------------------------------

\usepackage{../docs/latex/noweb}
 \noweboptions{footnotesizecode,nomargintag}
 %note: allow chunk on different pages, less white space at bottom of pages
 \def\nwendcode{\endtrivlist \endgroup}
 \let\nwdocspar=\par
\usepackage{xspace}
\usepackage{verbatim}
%note: required by noweblatexpad for the \t \l \n in this file
\usepackage{fancyvrb}
\usepackage{url}
\usepackage{hyperref}
 \hypersetup{colorlinks=true}
\usepackage[pageref]{backref}
 \def\backref{{\footnotesize cited page(s)}~}
\usepackage{booktabs} 
 \newcommand{\otoprule}{\midrule[\heavyrulewidth]}
\usepackage{graphicx}

%------------------------------------------------------------------------------
% Macros
%------------------------------------------------------------------------------
\input{../docs/latex/Macros}

%------------------------------------------------------------------------------
% Config
%------------------------------------------------------------------------------
\allcodefalse
% ifallcode is used for:
% - extra copyright 
% - file skeleton, extra signatures (stuff in Extra.nw)

\addtolength{\topmargin}{-.850in}
\addtolength{\textheight}{1.70in}

\begin{document}
%******************************************************************************
% Title
%******************************************************************************
\title{
{\Huge 
Principia Softwarica: The Version Control System (OCaml)[[git]]
}\\
{version 0.1}
}

\author{
Yoann Padioleau\\
\texttt{yoann.padioleau@gmail.com}\\
\\
with code from\\
Yoann Padioleau
}
\maketitle 

\onecolumn
\hrule
\input{../docs/latex/Copyright}
%nope: \input{../docs/latex/CopyrightPlan9}
\begin{quote}
The source code is Copyright \copyright{} 2017 Yoann Padioleau.\\
Permission is granted to copy, distribute, and/or modify the source code
under the terms of the GNU Lesser General Public License version 2.1.
\end{quote}
\hrule
\twocolumn

\begingroup
\hypersetup{linkcolor=blue}
% need to s/onecolumn/twocolumn in report.cls :) for \tableofcontents
\tableofcontents
\endgroup

%******************************************************************************
% Body
%******************************************************************************

\chapter{Introduction}

The goal of this book is to explain with full details the source code of
a {version control system}.

\section{Motivations}

Why a version control system (VCS)?
Because I think you are a better programmer if
you fully understand how things work under the hood, and
%dup: Make.nw
a VCS is one of the tools a programmer uses the most.
\n def, cos maybe not super well known term and can be confused with SCM
Indeed, a VCS manages {efficiently} changes to a file or set of files
and it is mostly used by programmers to manage the vital product of
their labour: source code.

%src: SCCS paper
A VCS allows to {store} and {retrieve} past versions of a file, and to {record}
{who} made each change, {when}, {where}, and {why}.
\l Important cos program changes all the time! bugs/features/maintenance/opti
\l need 'system' to help 'control versions' otherwise chaos.
\l introduce checkin/checkout, delta so can talk about it in next section?
\l store/retrieve/track and coordinate work of multiple people.
%
You can use a VCS not only to manage source code but also text-based
documents (e.g., the source of this book), configuration files, 
and even binaries.
\n e.g., images, but not good IMHO to store binaries.
\l Word/Excel/Google-Docs/Wikipedia have their own VCS.

For projects with a single developer, a VCS is useful
to keep track of changes; it allows the programmer to easily go back to
past versions if he messed things up.
\l also git grep, git bisect, git revert, ... (said later?)
%
For projects with multiple developers, a VCS is almost mandatory;
it allows programmers to collaborate with each other and 
even to work on and modify the same files concurrently.
\l also git blame, ... (said later?)


%dup: Make.nw
\l not as interesting as kernel/compiler, but necessary!
\l bootstrapping issues!
\l many nice algos. interesting study.

Here are a few questions I hope this book will answer:
\begin{itemize}

%dup: Make.nw
\item What are the fundamental concepts of a VCS? 
\n repo (file db), commit (changeset), branches, diff, merge
What are the core algorithms behind a VCS?
\n diff, diff3, zip/unzip, sha1, 

\item How does a VCS store efficiently multiple versions of a file?
\l store efficiently past versions of set of files
\n delta (diff), reversed-delta
%git: sha1 deduplicating (but not delta/diff really), compression,
% dedup of blob but also of (sub)trees, pack delta and compression

\item How does a VCS represent changes to a set of files?
\n changeset tree, other?
%git: does not record change but state!

\item How does a VCS allow multiple users to work on and 
modify the same files at the same time?
\l pseudo simultaneously
How can a VCS help coordinate the actions of multiple users?
\l concurrent development
\n locks, merge

\item How does a VCS allow parallel developments?
How can 
some developers work on the main release, 
some developers on experimental features, and 
some other on fixing bugs on previously shipped releases 
all at the same time?
What is a branch?
How does a VCS reconcile multiple branches?
%What are the differences between concurrent and parallel development?
%src: 7 concurrency book:
% - concurrent program has multiple logical threads of control. These threads
%   may or may not run in parallel (can interleave)
% - parallel program runs more quickly than a sequential program by
%   executing different parts of the computation simultaneously (in //).
%   It may or may not have more than one logical thread of control.

\item What is a merge algorithm? When is a merge safe? 
What is a merge conflict? How does a VCS resolve conflicts?
\n it does not resolve conflicts! it lets user, too complicated, ok to delegate

\end{itemize}

\t put in conclusion non-trivial adv algo and data structures seen? see comment
%data-structures (beyond list/hashtbl): (use lists, hashtbl)
% - crypto SHA1 DAG (authentificated from the root!) of commit
% - Merkel Trees (related to version DAG)
% - Huffman?
% - graph (DAG)

%algorithms (beyond search/sort): (appendix)
% - sha1
% - unzip (with huffman inside, adler32, lzh)
% - zip
% - diff
% - diff3 (aka merge)


%tags used in this file for different recurring themes::
 %git: %rcs: %cvs: %sccs: 
 %facebook: my facebook experience using a VCS (mostly SVN -> git -> hg)
 %
 %toc: %trans: %dup: %example: %chunks:


\section{The version control system [[git]] (and [[ocamlgit]])}
\label{sec:vcs-git-ocamlgit}

I will explain in this book the code of the VCS 
[[ocamlgit]]\furl{https://github.com/aryx/plan9-ocaml/tree/master/version_control}, which contains about 6200 lines of code (LOC).
\n [[gut]] shortand? meh, confusing. ocamlgit and git should have same UI.
%
As its name suggests, [[ocamlgit]] is written in OCaml and is a clone
of the popular VCS 
[[git]]\furl{https://git-scm.com/}, which is written in C.

As opposed to most books in \principia, I could not choose a \plan
program for this book because there is no \plan VCS.
\l (they rely on fs?) /n/sources/?
%
There are many open source \unix VCSs with different user interfaces, storage
strategies, concurrency models, features, etc. I will present
a few of those VCSs in Section~\ref{sec:other-vcs}.
%
For this book, I decided to base the presentation on [[git]] because
[[git]] is one of the most popular VCS in the open source community.
Moreover, when coupled with the hosting website 
GitHub\furl{https://github.com}, 
[[git]] makes it really easy for people to collaborate with each other.
\n mercurial has bitbucket, but still github better interface IMHO

However, [[git]] is a rather large project with more
than 200 000 LOC. It is impossible to present all this code
in a book of a reasonable size.
%
There are a few clones of [[git]] written in higher-level languages than C,
for example, [[dulwich]]\furl{https://www.dulwich.io/} written
in Python with only 16 000 LOC.
%
I could have based this book on [[dulwich]], but this would introduce
another language in the \principia book series in addition
to C (used for most of the books) 
and OCaml (used for the editor, web browser, and code generators books).
%
This would in turn require to present the code of the Python interpreter,
which contains more than 170 000 lines of C code.
\n and far more of Python code (not counting test and third-party C libs)
%
Instead, I decided to port the Python code of [[dulwich]] to OCaml, resulting
in [[ocamlgit]], and to present the code of [[ocamlgit]].
\l other ocaml clones, ocaml-git, but meh
\l not as efficient as git, not as famous as Torvalds for coding style,
\l  but not too bad (bench?) and easier entry point to then look code of git.


\section{Other version control systems}
\label{sec:other-vcs}
%me: manual backups -> RCS -> CVS -> PRCS -> git -> darcs -> SVN -> git -> hg

Here are a few VCSs that I considered for this book, but
which I ultimately discarded:
\begin{itemize}

\item The Revision Control System
(RCS)~\cite{rcs}\furl{https://www.gnu.org/software/rcs/}
was the first open source VCS.
\l really?
Like its predecessor, the Source Code Control System
(SCCS)~\cite{sccs}\furl{http://sccs.sourceforge.net/},
\n RCS closed in 1982, free in 1990 (SCCS closed in 1976, free in 2006)
\n CSSC alternative OSS version of SCCS
RCS uses {\em deltas} to store efficiently the past versions of a file. 
However, RCS improves over SCCS by using {\em reverse-deltas} to 
enable the user to also retrieve quickly the last version of a file
(a recurring operation).
\l but blaming is faster with SCCS

RCS is still a reasonable choice to manage a small project
with a single developer or a small set of developers who can 
share access to a common directory (e.g., by using NFS and symbolic links).
%
However, the use of {\em locks} in RCS to forbid multiple developers
to modify the same file and its focus on individual files make
% Mostly single file. treat files separately. Each has different version. 
%  can be used for multiple files, but abuse shell (wildcard on ,v)
%  but not really good for projects with subdirs.
RCS inadequate for large projects with many independent developers.
%
Finally, even if RCS is very limited compared to modern VCSs like [[git]],
RCS still contains more than 17 500 LOC
\n (not including testsuite, but small anyway)
\l Why? too subtle diff representation?
\n has kinda branch, and rcsmerge, and tags, but addition hacks
\l SRC wrapper from ESR? 
\l PRCS better at grouping (P = Project) http://prcs.sourceforge.net/


\item The Concurrent Versions System
CVS~\cite{cvs}\furl{http://www.nongnu.org/cvs/},
was the most popular VCS for over a decade
\n STUG award 2003
before distributed VCS (e.g., [[git]]) took over.
%
CVS introduced a few important innovations.
%
First, CVS was designed to operate on a set of files at once, 
with files possibly organized in a 
tree\footnote{RCS can operate on multiple files by using shell 
wildcards, but it was not designed for it.}.
With CVS, you can group together related changes to a set of files 
and you can easily retrieve past versions of a whole project.
\n can with RCS, with tags, or date, but again not really designed for
\l not atomic commit though (said later?)
%
Second, CVS allows multiple users to work on and modify the same
files concurrently. 
CVS relies on a {\em merge} program instead of locks.
\l  who commit first always succeeds and second need to update and merge!
%
Finally, CVS introduced later a {\em client/server} architecture 
where a {\em repository} could be stored on a remote machine.
\n TCP/IP really made took off.
When coupled with the free hosting site
Sourceforge\furl{https://sourceforge.net}, 
CVS allowed developers to easily start and collaborate on new projects.
\l but branch and parallel development is really tedious (said later?)

CVS started as a few shell scripts using RCS as a backend.
However, today CVS is a very large C program with more than
80 000 LOC.
\n not third-party libs (diff/zlib/lib/os2/NT/vms) and sanity.sh
The backend file [[src/rcs.s]] contains already 9000 LOC.
\l reputed difficult to understand, hence SVN

\n I presented a bit git before
\item [[git]]\furl{https://git-scm.com} was originally created
by Linus Torvalds around 2005 to manage the source code of the Linux kernel.
It followed a series of
{\em distributed VCSs} (e.g., Arch, Monotone, Bazaar, BitKeeper) 
designed to overcome the main limitations of CVS
(a {centralized VCS}).
%
A distributed VCS (DVCS) makes it easy and cheap to create {\em branches}
representing parallel developments, and to reconcile later
those branches.
\l also atomic, consistent checks! fast! done the right way!
Moreover, with a DVCS a developer can also work offline.
\l no need central server, peer-to-peer.

As explained in Section~\ref{sec:vcs-git-ocamlgit}, [[git]]
is a large program with more than 200 000 LOC spread over more than 400 files
(not including the tests, GUIs, and extra contributions).
%
The first version of [[git]] was small and contained only 1000 LOC\footnote{
\url{https://github.com/git/git/commit/e83c5163316f89bfbde7d9ab23ca2e25604af290}}.
However it contained only a few low-level commands that were not easy to use.
\l also libgit2, LOC? share code with git?

\item Mercurial~\cite{hgbook}\furl{https://www.mercurial-scm.org/}
is another popular DVCS started by another Linux kernel programmer
around 2005.
\l after BitKeeper fiasco
It is mostly written in Python and relies on a few C files for critical
operations. Its code is arguably easier to understand than [[git]]
but it still contains more than 100 000 LOC spread over more than 170 files
(not including the tests, extensions, and extra contributions).
\l core of 1.0 is? maybe not that bad
\l bitbucket equivalent of github

\end{itemize}

% In the end I picked a mix between git and mercurial: git, but
% implemented in the language used for mercurial (Python)
% by the guy who apparently has been involved in bazaar :)

%industry:
% - perforce
% - microsoft visual sourcesafe
% - rational clearcase
% - bitkeeper (main inspiration for git)
%history:
% - SCCS http://sccs.sourceforge.net
%   and modern version CSSC
%   https://www.gnu.org/software/cssc/
%other:
% - subversion (630 000 LOC, hmm)
%other DVCSs:
% - darcs 80 000 LOC (using literate haskell), maybe good candidate, simpler
%   model, arguably simpler than git (rebase for free?), some patch theory.
%   But code looks actually awful. Lots of boilerplate. Huge types.
% - gnu arch (aka tla 273 000 LOC) described as very complicated by many
% - bazaar (477 000 LOC) and bazaar-NG
%   https://www.jelmer.uk/pages/bzr-a-retrospective.html
% - monotone (99 000 LOC for 1.1), apparently good source of inspiration
%   for git because introduced the DAG of SHA1
% - codeville, by Bram Cohen of Bittorrent fame
% - pijul, initially in OCaml (3000 LOC), then in Rust, but seems to have 
%   a slow development
% - fossil
%git alternate porcelain:
% - gitless, a better design for git, great paper:
%   http://people.csail.mit.edu/sperezde/pre-print-oopsla16.pdf
%   (can implement this design with dulwich?)
%mini:
% - camp is a simplified version at 6300 LOC
%   a mini darcs. Simple? Elegant? Arguably more powerful. < 10 000 LOC.
%   Can be good opportunity also to read some haskell code. Maybe can then
%   port the code to OCaml.
% - http://benhoyt.com/writings/pygit/ 500 LOC to push to github,
%   with init/add/commit/push/status/diff/, very nice, but simplified
%   so only support toplevel files, no subdirs (so no subtree).
% - http://gitlet.maryrosecook.com/ mini git in Javascript, heavily
%   commented (but LP would be better)
% - gg 7000 LOC, but no locking, no push, and requires external diff.
%   http://www-cs-students.stanford.edu/~blynn/gg/
%   this guy also wrote a book on Git "Git Magic"
% - src, by raymond, wrapper around RCS
%   http://www.catb.org/esr/src/
%clones in other languages (all clones of git actually):
% - dulwich: git written in python (15000 LOC (without tests))
%   which includes some porcelain now (there is also another project
%   called gittle which is porcelain for dulwich).
%   Used by Google for some projects to provide bridge between
%   mercurial and git.
%   Originally created to offer bridge between bazaar and git by one
%   of bazaar maintainer. Based on python-git hack by James Westby.
% - git-go: git written in Go (but seems limited to archeology command)
% - JGit: git in Java
% - libgit(2): git in C, but reuse git code or new implem?
% - gat: git clone in haskell http://evan-tech.livejournal.com/254793.html
%   another one:
%   http://stefan.saasen.me/articles/git-clone-in-haskell-from-the-bottom-up/
%   pretty complete, nice figures, quite long
% - ocaml-git: 15 000 LOC, but  heavily functorized (to support unix 
%   but also mirage), many dependencies (mstructs, cstruct, topkg, logs)
%   and seems to be only an API to access data. No support
%   for diffs; no merge; limited porcelain.

%https://en.wikipedia.org/wiki/List_of_revision_control_software
%http://www.catb.org/esr/writings/version-control/version-control.html
%http://better-scm.shlomifish.org/comparison/comparison.html

%future:
% - my semantic-vcs proposal!
%   related: https://www.semanticmerge.com/
% - gitless design  http://people.csail.mit.edu/sperezde/pre-print-oopsla16.pdf
%   that uses pygit2 (a binding to libgit2)
% - CRDTs? inspired by merge in VCS?
% - use git model for more things, like in mirage and irmin?



\section{Getting started}
\label{sec:getting-started}

% Download.

% ocamlgit.
% In rest of document use 'git'. Same interface.


% get source :)

%bootstrap: need ocamlgit to get ocamlgit :) 
% or use git
% or just use tar.gz (and extra patches)

\section{Requirements}

% Because most of this book is made of OCaml source code, 
% you will need a good knowledge of the 
% OCaml programming language to understand it.
% No use of advanced features, so even book on Caml or SML
% or ML.

% No need know VCS.

% If, while reading this book, extra question, 
% read man page or Git book.

\section{About this document}
#include "../docs/latex/About.nw"

\section{Copyright}

I wrote most of the code in this document. 

<<copyright ocamlgit>>=
(* Copyright 2017 Yoann Padioleau, see copyright.txt *)
@

The code is licensed under the 
GNU Lesser General Public License version 2.1
as published by the Free Software Foundation.

I sometimes took inspiration from code written by Thomas Gazagnaire 
for [[ocaml-git]] (another clone of [[git]] in OCaml but intented to be used
as a library).
\l why not extend explained later? talk about mirage?

<<copyright ocaml-git>>=
(*
 * Copyright (c) 2013-2017 Thomas Gazagnaire <thomas@gazagnaire.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 *)
@

\ifallcode
% Also use code from ocaml libraries.

<<copyright ocaml-diff-myers>>=
(*
 * Copyright (C) 2016 OOHASHI Daichi
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 * THE SOFTWARE.
 *)
@

<<copyright ocaml-hex>>=
(*
 * Copyright (c) 2015 Trevor Summers Smith <trevorsummerssmith@gmail.com>
 * Copyright (c) 2014 Thomas Gazagnaire <thomas@gazagnaire.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 *)
@

<<copyright uuidm>>=
(*
Copyright (c) 2008 Daniel C. Bünzli

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
*)
@

<<copyright ocaml-unzip>>=
(*
 * Unzip - inflate format decompression algorithm
 * Copyright (C) 2004 Nicolas Cannasse
 * Compliant with RFC 1950 and 1951
 *
 * This library is free software; you can redistribute it and/or
 * modify it under the terms of the GNU Lesser General Public
 * License as published by the Free Software Foundation; either
 * version 2.1 of the License, or (at your option) any later version,
 * with the special exception on linking described in file LICENSE.
 *
 * This library is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public
 * License along with this library; if not, write to the Free Software
 * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
 *)
@

<<copyright camlzip>>=
(***********************************************************************)
(*                                                                     *)
(*                         The CamlZip library                         *)
(*                                                                     *)
(*            Xavier Leroy, projet Cristal, INRIA Rocquencourt         *)
(*                                                                     *)
(*  Copyright 2001 Institut National de Recherche en Informatique et   *)
(*  en Automatique.  All rights reserved.  This file is distributed    *)
(*  under the terms of the GNU Lesser General Public License, with     *)
(*  the special exception on linking described in file LICENSE.        *)
(*                                                                     *)
(***********************************************************************)
@
\fi

The prose is mine and is licensed under the \license.

\section{Acknowledgments}

I would like to acknowledge the author of [[dulwich]],
Jelmer Vernooij, for providing an easier path towards
understanding [[git]].
% I took inspiration from code from dulwich. Easier to understand than git.
% Also Thomas gazanaire.
% Finally Torvalds, for clever VCS. 



\chapter{Overview}

%trans:
Before showing the source code of [[ocamlgit]] in the following chapters, 
%toc:

\section{Version control system principles}

% nice docs:
% - ten innovations in the history of vcs:
%    http://www.flourish.org/2011/12/astonishments-ten-in-the-history-of-version-control/
% - https://betterexplained.com/articles/a-visual-guide-to-version-control/
% - Misfits paper, great summary of essential purposes.
% - git from the bottom up intro with nice glossary
% - Mercurial chapter in AOSA book.
% - Git chapter in AOSA book.
% - dulwich/docs/ but very limited.

%trans:
% how if no VCS? manual backups, tarballs, email patches?
% (\footnote{how Linux done for a long time}, human VCS) :) )
% no git blame. discipline.
%src: SCCS paper
% Code changes all the time. Bugs, experimentatl features, optims.
%  not just current version but last year's (still supported) and next year!
%  maintenance old code. Chaos if no tool, if no discipline.

% VCS, SCM?

% try be general and add %git: for git instantiation of general principles

\subsection{Storing past versions}

\subsubsection{Metadata}
% file version database
% metadata (RCS/,v, .git/objects/, CVS/CVSRoot and other dir or server, etc.)
% metadata and data in fact. past versions are really data.

% First, store past versions. Can go back in time if made a mistake.
% Could get that with copy, but need discipline, filename encoding
%  better organized, and storing deltas has efficiency implications. 
%update: actually git does not really use delta. really more a content tracker.
%update: actually can use delta, but for packfile.

% Time filesystem could do that, e.g. cd /2016/01/01/project/.
% Can even be encoded efficiently (deltas backup system, deduplication).
% But need special fs. And VCS provides additional nice services
% like commit message, and git blame!! who, when, why, where!
% (but could have a history.txt file in the project,
% and also symlinks to tag version at specific time).

% Different storage strategy.
% Some use per-file history [[,v]], flat dirs (.git/objects/), 
% Berkely DB (SVN), Sqlite (monotone), changesets (?)

\subsubsection{The repository}

\subsubsection{Working copy}
% working tree

% checkout, checkin

% So can use any editor to edit!
% (departure from Word/Excel where versions and editing are using same tool)

%rcs: checkout


\subsection{Tracking changes}

% fs could do. But which granularity? let user records
% relevant change points!

\subsubsection{The commit}

%dup: intro/motivations
% who, when, what/where, and why.

% attach note to changeset.
% incredibly useful for git blame! can help find bugs, see related
% code because related changes!

% record who made change, what change, and even why! great resource.
% git blame!

%rcs: checkin

% then commit information.
%git: again use object for that. then easy to reference
% a tree version by referencing a commit id.
% Also then can have references, symbolic references.
% Also have parents! so full history on how you got there.


\subsubsection{Version identifier}

% version, revision.

% need have different versions, different version id.
%git: use simple scheme: not v1, v2, ... but sha1 of content!
% then get for free consistency checking

% release.level
% so one way to organize set of files and have changeset by having
% all developers increment release (but then need modify every file? RCS
% does not accept empty updates)

%sccs: introduced extra lettre for different customer, so 1.2.p

% 1.1, 1.2,
%git:
%  or sha1! identified by its content! file content! but can
%  also scale to set of files! or tree! or commit!
%  has some advantages.
%Also in distributed settings, how can have global identifier?
% each user need tags its version number with its name?
% another thing where sha1 is good, they are stable across machines,
% they are global!

\subsubsection{Change granularity}

% set of logical changes as an individual group (atomic).

%cvs: not atomic?

% then need to have not just version of one file (RCS) but version
% of a tree.
%git: have tree structure which references other blob id and other trees.
% if a full subtree does not change, then share reference.

% single-file history, or whole-tree history.

% - release/level discipline, so update release for all files at certain
%   point
% - use date
% - use tag

% or simply use commit id in modern VCSs :)





\subsubsection{[[diff]]}

% cite paper

% Source code is text!

% sometimes people use commit and diff and patch interchangebly.

% diff can be used also internally in VCS to efficiently store deltas.
%git: used in pack only

% Also by having delta
% and message associated with it help explore history. Git log, git
% blame are fantastic tool, even in single-user mode. To know
% code related to a line, the message of this patch, etc.
% Also in multi-user mode good to know the author, test plan, test
% files, coupled code, etc.
% I used it a lot to understand code at Facebook.

% Usually diff at granularity line-level. So add/delete a line are 
% the primitives
% (since SCCS). Fine granularity for source code.
% Could use char, but too big then.


\subsubsection{[[patch]]}

%dual of diff. One create diff on his machine, other can apply patch on his.
% (also some fuzzy apply algorithm).

% first years of Linux was managed just with patches.
% tarballs and patches. linux-mm still use patches (quilt).

%\subsection{Revision graph}
% RCS was a tree, but then when introduce real branches get merges and a DAG!
% head, tip, branch, fork, merge, root, trunk, ... lots of graph words.
%\subsubsection{A mainline} 
%\subsubsection{A tree of branches} 
%\subsubsection{A direct-acyclic graph of merges} 

\subsection{Concurrent development}
% locks? or optimistic merging!

% When multiple developers, may modify same file, dont want one
% to overwrite change of other. Need control access to shared
% resource, the source file.
% How?

% Then when work in groups, useful to have way to work concurrently,
% to not pass his copy and wait for the "token". Concurrent
% techniques are lock, or better optimistic and later merge.

\subsubsection{Locks}

% Simple.

% but easy to forget to unlock, and really annoying for other.
% RCS.

% Locks make sense only with centralized model.

\subsubsection{Merging}
% surprisingly, it works!
% CVS.

% 3 way merge.
% cite paper?

% but need update first. 
%facebook: What if time update and time commit long
% so always another guy in the middle.

\subsubsection{Merge conflicts}

% show conflict with <<<< === >>>>

\subsection{Parallel development}

% like concurrent, but longer time-scale. Does not expect to merge
% immediately.

\subsubsection{Branch}

% Branches are also very useful. Work on different tasks, different
% branches. Can juggle between those.

% - temp fixes (never merged)
% - parallel devel for experimental feature (may be merged)
% - real fork (may be merged)

% RCS had branches, but per-file! tedious.
% CVS got it, but complicated, because was relying on RCS.
% git far easier! because every different repo/user is a branch! because
%  distributed, so had to get merge right and fast!

% Saw merge before, but merge really make sense with branching.
% Useful to branch and merge. 
% Also useful for branch and merge on a peer-to-peer basis
% (networking)

\subsubsection{Merging}

% Same, but usually bigger, and can get complicated?

\subsubsection{A direct acyclic graph}
%Again, ... as in Make.nw.


% really important. linear versions, then tree, then DAG!
% Lots of terminology about graph (HEAD, tip, ...)

% Previous VCS did not record relation between changeset (which
% requires identify changeset), and so merge could also not work good?



%\subsection{Variants}
\subsection{Centralized versus distributed}
% pulling and pushing

% but in both cases pull and push.

% github kinda centralize, but still independent repo! can work offline

% decentralized so no need access permission! Can fork, work,
% commit locally, and then ask for master to merge you.

% What brings distributed then? More convenient than centralized.
% Less imposing. Nice to have everything locally. Just more general.
% Can do centralized with distributed (e.g. "main" repo on github
% is the main thing to pull from).

% When distributed, not centralized, so no need path to shared repo
% or CVSROOT and so no need concepts such as module as in CVS.
% (actually there is concept of submodule and gitlink)
% Have different projects? Use different repo! Simple.

%\subsection{Snapshot versus changeset}
% on changesets vs snapshot-based VCS
%https://web.archive.org/web/20100327150715/sourcefrog.net/weblog/software/vc/derivatives.html
% snapshot fast to go back to previous version. No delta application.
% Just copy blob!

%\subsection{Hosting}
%\subsection{Github}
% sourceforge before.
% Finally github is fantastic. Easy to setup and start sharing work.

% Before pain create repo to collaborate. Need server, start and config
% CVS server there, password, etc. Now just create on github and clone!

%\subsection{Git}
% many more concepts: 
% index, HEAD, master, working tree, sha1
% but quite git specific.



\section{[[git]] command-line interface}

% git <cmd> [-options] <extra arguments>


\section{[[hello/.git/]]}

% See book to learn about how to use git, including internals.
% Git from the bottom-up, git for scientist, etc.
% Here just % quick session, quick tutorial.

\subsection{[[git]] concepts}

%git docs:
% - https://www.kernel.org/pub/software/scm/git/docs/user-manual.html#birdview-on-the-source-code
% - https://git-scm.com/book/en/v2/Git-Internals-Plumbing-and-Porcelain
% - git v0:
%   https://github.com/git/git/commit/e83c5163316f89bfbde7d9ab23ca2e25604af290
% - git from the bottom up (great, I read it while at FB)
% - https://building-git.launchrock.com/ 
%   learn git by building your own, an expansion of a blog on git, e.g.:
%   https://blog.jcoglan.com/2017/05/08/merging-with-diff3/
%   https://blog.jcoglan.com/2017/02/12/the-myers-diff-algorithm-part-1/
% - https://codewords.recurse.com/issues/two/git-from-the-inside-out
% - http://eagain.net/articles/git-for-computer-scientists/
% - https://stevebennett.me/2012/02/24/10-things-i-hate-about-git/
% - Bram cohen vs torvalds on deep algo in git:
%   http://www.wincent.com/a/about/wincent/weblog/archives/2007/07/a_look_back_bra.php
% - http://manishearth.github.io/blog/2017/03/05/understanding-git-filter-branch

% git does not track changes, it track states! so very different approach
% which in the end I think simplify many things.

% Stored as diffs? apparently not. Just compressed and indexed by sha.
% If same content, then same id.

% sha1! essential for consistency checking anyway!
% objects: blob, tree, commit
% sha1 graph (DAG)
% refs: HEAD, refname, refcontent
%  branch, tag, remote, master
% stage area (and index)
% working tree


% snapshot-based (so fast, at potentially cost of disk space, always
% tradeoff). No delta app.

\subsection{Repository format: [[.git/]]}

% really object store and then .git/refs/ and using sha1 can encode
% many idioms (branches, origin for push/pull, tags, stash)

% $ tree .git (after created basic command in Getting started)

% objects/!!
% refs/heads/
% refs/tags/
% refs/remote/origin/

% hooks/
% info/

% encoding UTF8 for filenames.
% https://github.com/git/git/blob/master/Documentation/i18n.txt

\subsection{A toy session}

%dup: 
% use git below, but really ocamlgit, try compatible UI.

% maybe show how certain commands modify .git/
% but should say better docs:
% - http://eagain.net/articles/git-for-computer-scientists/
% - git from the bottom up (great, I read it while at FB)

% git init
% git add
%%git rm
% git commit

% git show
% git log

% git branch foo
% git checkout foo
% ...
% git checkout master
% git merge foo

% git status
% git diff

% git clone
% git pull
% git push

\section{Code organization}

% requires also:
% - zlib

% style: Xxx.t, match () with _ when ... ->, Common.


\section{Software architecture}

% plumbing vs porcelain in original git version,
% because Linus started with very low-level commands for
% essentially a content addressable storage engine
% but not very important here. 

% pretty simple: 
% Main -> cmds -> cmd_xxx -> cmd | repository -> objects -> 
%   blob|Commit(User)|Tree|Index|Refs...
% and then client/server on the side of repo too with different clients
% and then compression|unzip|zlib, IO, diff_myers, hexsha, sha1

\section{Book structure}

%###############################################################################

\chapter{Core Data Structures}

\section{Secure Hash Algorithm (SHA1) hashes}
\n Secure, not Simple.

% used for 
%  - identifying (and versioning), 
%  - consistency checking, 
%  - indexing (and also for folders), 
%  - deduplicating (good for rename detection too)
% SHA1 underlies lots of things in git.

%sccs: used checksum (as opposed to RCS) to detect corrupted history files

\subsection{Binary hashes}

% sha1 is large number of 20 bytes.

<<type Sha1.t>>=
(* a 20 bytes number (really a string of length 20) *)
type t = bytes
@


<<signature Sha1.sha1>>=
(* computes SHA1 of a series of bytes *) 
val sha1: bytes -> t
@
% See appendix for code for sha1().
% bytes to bytes in the end, but first bytes is arbitrary length
% and final bytes are just 20 bytes.

%for more information on SHA1:
% http://www-cs-students.stanford.edu/~blynn/gitmagic/ch08.html


<<signature Sha1.is_sha>>=
val is_sha: t -> bool
@
<<function Sha1.is_sha>>=
let is_sha x =
  Bytes.length x = 20
@
\n extra checks? forbidden bytes? I dont think so.


\subsection{Hexadecimal hashes}

% SHA1 used in git to identify things (e.g., commit).
% Not easy enter binary data. Enter Hexsha, can be input
% easily.

% Given that 1 byte can be encoded by 2 hex (e.g. 255 = 0xFF),
% then you need 40 hex number to represent a sha1.
% hexsha type! 40 bytes number as number in hexa.
% (each byte is actually encoding only 16 values, an hexadecimal number)
% Easier format for user to enter or read sha.


<<type Hexsha.t>>=
(* a 40 characters string, e.g. "d670460b4b4aece5915caf5c68d12f560a9fe3e4" *)
type t = string
@

<<signature Hexsha.is_hexsha>>=
val is_hexsha: t -> bool
@
<<function Hexsha.is_hexsha>>=
let is_hexsha x =
 String.length x = 40 && x =~ "^[0-9a-fA-F]+$"
@
%$

% git should internally use always binsha, except when need
% read or write to user (and when need access loose object).
% (actually commit file format contains hexsha).



<<signature Hexsha.of_sha>>=
val of_sha: Sha1.t -> t
@
<<function Hexsha.of_sha>>=
let of_sha x =
  assert (Sha1.is_sha x);
  of_string_fast x
@

<<function Hexsha.of_string_fast>>=
let of_string_fast s =
  let len = String.length s in
  let buf = Bytes.create (len * 2) in
  for i = 0 to len - 1 do
    Bytes.unsafe_set buf (i * 2)
      (String.unsafe_get hexa1 (Char.code (String.unsafe_get s i)));
    Bytes.unsafe_set buf (succ (i * 2))
      (String.unsafe_get hexa2 (Char.code (String.unsafe_get s i)));
  done;
  (*pad:`Hex*) buf
@
\l unsafe_get opti useful?


<<signature Hexsha.to_sha>>=
val to_sha: t -> Sha1.t
@
<<function Hexsha.to_sha>>=
let to_sha x =
  assert (is_hexsha x);
  to_string x
@

<<function Hexsha.to_string>>=
let to_string ((*`Hex*) s) =
  if s = "" 
  then ""
  else
    let n = String.length s in
    let buf = Bytes.create (n/2) in
    let rec aux i j =
      if i >= n 
      then ()
      else if j >= n 
           then raise (Invalid_argument "hex conversion: invalid hex string")
      else (
        Bytes.set buf (i/2) (to_char s.[i] s.[j]);
        aux (j+1) (j+2)
      )
    in
    aux 0 1;
    buf
@
%old:
%<<function Hexsha.to_string>>=
%let to_string hex =
%  to_helper ~empty_return:"" ~create:Bytes.create ~set:Bytes.set hex
%@

<<function Hexsha.to_char>>=
let to_char x y =
  let code c = 
    match c with
    | '0'..'9' -> Char.code c - 48 (* Char.code '0' *)
    | 'A'..'F' -> Char.code c - 55 (* Char.code 'A' + 10 *)
    | 'a'..'f' -> Char.code c - 87 (* Char.code 'a' + 10 *)
    | _ -> 
      raise (Invalid_argument 
              (spf "Hex.to_char: %d is an invalid char" (Char.code c)))
  in
  Char.chr (code x lsl 4 + code y)
@
%old:
% <<function Hexsha.invalid_arg>>=
% let invalid_arg fmt =
%   Printf.ksprintf (fun str -> raise (Invalid_argument str)) fmt
% @



\section{[[Repository.t]]}

% a repo is really a set of commits,
% and also set of names of commits (branches, tags, HEAD).
% But represented in subtle way in git.
% set of objects, and then refs of this object, where some objects can
% be commit.

% worktree and metadata (dotgit)

<<type Repository.t>>=
type t = {
  (* less: on bare repo, this could be None *)
  worktree: Common.filename;
  (* less: on bare repo this could be the toplevel dir *)
  dotgit: Common.filename;

  <<[[Repository.t]] other fields>>
  (* less: compression level config field? *)
}
@
\n dotgit could be called commondir or controldir when have bare repo.

% Hooks later.
% info?? useful for grafts and?

% Most operations will take repo as first argument.

%trans:
% Repo contains objects and refs (see next 2 sections).
%python: [] accessors for repo.object_store and repo.refs
% (and even [] for repo itself for objectish)

\section{[[Objects.t]]}

%https://git-scm.com/book/en/v2/Git-Internals-Git-Objects

<<type Objects.t>>=
type t = 
  | Blob   of Blob.t
  | Commit of Commit.t
  | Tree   of Tree.t
  <<[[Objects.t]] cases>>
@

\subsection{Object store}

% git really is a content addressable storage engine.

% internal functions not exposed in repository.mli
<<function Repository.hexsha_to_filename>>=
(* for loose objects *)
let hexsha_to_filename r hexsha =
  let dir = String.sub hexsha 0 2 in
  let file = String.sub hexsha 2 (String.length hexsha - 2) in
  r.dotgit / "objects" / dir / file
@
%python: nice syntax for string access like hex[:2] and hex[2:]

<<function Repository.hexsha_to_dirname>>=
let hexsha_to_dirname r hexsha =
  let dir = String.sub hexsha 0 2 in
  r.dotgit / "objects" / dir
@

% Regular files!

% encode stuff? should aspectize, confusing.

%python: nice overloading of [] (but bad to abuse it) to access object
% store.

% will see open_() later.


\subsection{[[Blob.t]]}
% =~ file content (but no name, name is in tree)

<<type Blob.t>>=
type t = bytes
@

<<type Blob.hash>>=
type hash = Sha1.t
@
% Later will want to specify that sha1 corresponds to a blob, so
% use type alias for readability (but not really typechecked)


% But no interleave deltas (SCCS), reverse deltas (RCS).
% Each modif generates new blob! disk is cheap now!
% But dedup!
% deduplicating! empty file! copy of file.
% And will see soon compressed on disk!
% And will see later more optim with pack files and deltas.

\subsection{[[Tree.t]]}
% =~ directories =~ project content.

%"It doesn't bother trying to store per-file histories;
%it instead stores the history at the tree level. When you perform a
%diff you are comparing two trees, not two files."

<<type Tree.t>>=
(* todo: entries must be sorted! and each name must be unique *)
type t = entry list
@

<<type Tree.hash>>=
type hash = Sha1.t
@

<<type Tree.entry>>=
type entry = {
  (* relative to tree, so does not contain any '/', or '.' or '..' *)
  name: string;
  (* Blob.hash or Tree.hash *)
  id: Sha1.t;
  perm: perm;
}
@
%old: use id instead of node, so more consistent with Index.entry.id

% Name can contain space, utf8, whatever! 
% (seemed to be a pb in many other SCMs)

<<type Tree.perm>>=
(* very similar to Index.mode, but with also a 'Dir' *)
type perm = 
  | Normal
  | Exec
  | Link
  | Dir
  <<[[Tree.perm]] cases>>
@
% Nice simplification :) just needs that!
% Dont care about permission, time, inode-id, etc. 

% deduplicating! share subdir if no change.

%alt: flat list of revision number for each file? how retrive file?
% if renamed? if removed?

% Merkel trees?
% Can reference entire tree with just hash of root tree! because
% This tree itself is hashed by its content.

\subsection{[[Commit.t]]}

% =~ history
% each commit has a tree and a parent, so can trace history of full project.

<<type Commit.t>>=
type t = {
  tree     : Tree.hash;
  (* first commit has no parent, and merge commits have 2 parents *)
  parents  : hash list;
  (* note that User.t contains a time *)
  author   : User.t;
  committer: User.t;

  message  : string;

  (* less: encoding, gpgsig, mergetag, extra *)
}
@

<<type Commit.hash>>=
and hash = Sha1.t
@


<<type User.t>>=
type t = {
  name : string;
  email: string;
  date : int64 * tz_offset(*option*);
}
@

%rcs: %sccs: had 2 digits for the year for a long time and was
% using local time

<<type User.tz_offset>>=
type tz_offset = {
  sign: sign;
  hours: int;
  min: int;
}
@

<<type User.sign>>=
type sign = Plus | Minus
@


% Fast checkout. Give me commit and I can grab
% all files from object store (looking firs tree and then
% going recursively grabbing blobs on the way).
%rcs: innovated over slow sccs by storing diffs in reverse! fast checkout.

\section{References}

% kinda correspond to branch name.
% .git/refs/heads/xxx are branches.
% .git/HEAD is current branch (usually point to .git/refs/heads/master
%  but 'master' is really just a convention could be 'trunk' or whatever)
% then this simple model allow to encode many idioms:
% - remote push/pull .git/refs/remote/origin/master
% - tags (refs/tags/xxx)
% - stash
% - ?

\l when stuff under refs/... contain indirect ref? HEAD is indirect
\l ref, but when need indirect ref under refs/?

% then can even save history of those refs (the reflog).

%https://git-scm.com/book/en/v2/Git-Internals-Git-References
%references vs symbolic references.

\subsection{Reference names}

<<type Refs.refname>>=
(* should always start with "refs/", see is_valid_refname() later *)
type refname = string (* e.g. "refs/heads/master" *)
@

<<signature Refs.is_valid_refname>>=
val is_valid_refname: refname -> bool
@
<<function Refs.is_valid_refname>>=
let is_valid_refname str =
  str =~ "^refs/"
  (* todo: git-check-ref-format *)
@

\subsection{[[HEAD]]}

<<type Refs.t>>=
type t =
  | Head
  | Ref of refname
@

% used for? dumper?
<<signature Refs.string_of_ref>>=
val string_of_ref: t -> string
@
<<function Refs.string_of_ref>>=
let string_of_ref = function
  | Head -> "HEAD"
  | Ref x -> x
@


\subsection{Reference store}
%similar to Object store, indeed .git/ is mostly objects and refs (and index)

% disk!
<<function Repository.ref_to_filename>>=
let ref_to_filename r aref =
  match aref with
  | Refs.Head -> r.dotgit / "HEAD"
  (* less: win32: should actually replace '/' in name *)
  | Refs.Ref name -> r.dotgit / name
@

\subsection{Reference content}

<<type Refs.ref_content>>=
type ref_content =
  (* the final value when follow all the pointers *)
  | Hash of Commit.hash
  (* pointer (may contain sha1 or another pointer again) *)
  | OtherRef of refname
@

<<signature Refs.default_head_content>>=
val default_head_content: ref_content
@
<<constant Refs.default_head_content>>=
let default_head_content = 
  OtherRef "refs/heads/master"
@


\subsection{Objectish references}

<<type Repository.objectish>>=
(* todo: handle ^ like HEAD^, so need more complex objectish parser *)
type objectish =
  | ObjByRef of Refs.t
  | ObjByHex of Hexsha.t
  <<[[Repository.objectish]] cases>>
@

<<[[Repository.objectish]] cases>>=
(* todo:
 *  ObjByBranch
 *  ObjByShortHex
 *)
@
%branch is shorter name than Refs.


\section{[[Index.t]]}
% Staging area.

% To know diff between working tree and HEAD.
% (misfit paper says that you do not need staging area and that in fact
%  it causes misfits)

<<[[Repository.t]] other fields>>=
mutable index: Index.t;
@

<<function Repository.index_to_filename>>=
let index_to_filename r =
  r.dotgit / "index"
@


<<type Index.t>>=
(* the entries are sorted (see compare_entries below) *)
type t = entry list
@

<<type Index.entry>>=
(** The type for a Git index entry. *)
type entry = {
  (* relative path *)
  name  : Common.filename;
  id    : Blob.hash;
  stats : stat_info;
}
@
%old: stage : int; (*?? *)


% Here id can refer only to a Blob. No subtree like for Tree.
% An index is a flat list of files (sorted).

% Index.stats vs Tree.perm.

<<type Index.stat_info>>=
(** The type for file-system stat information. *)
type stat_info = {
  mode : mode;

  ctime: time;
  mtime: time;

  dev  : Int32.t;
  inode: Int32.t;

  uid  : Int32.t;
  gid  : Int32.t;

  size : Int32.t;
}
@
% all those info disappear once in Tree.entry.

<<type Index.mode>>=
and mode =
  (* no directory here *)
  | Normal
  | Exec
  | Link
  <<[[Index.mode]] cases>>
@

<<type Index.time>>=
(** The type for a time represented by its [lsb32] and [nsec] parts. *)
and time = {
  lsb32: Int32.t;
  nsec : Int32.t;
}
@


<<signature Index.empty>>=
val empty: t
@
<<constant Index.empty>>=
let empty = []
@

<<signature Index.mk_entry>>=
val mk_entry: Common.filename -> Sha1.t -> Unix.stats -> entry
@
<<function Index.mk_entry>>=
let mk_entry relpath sha stats =
  { name = relpath;
    id = sha;
    stats = stat_info_of_lstats stats;
  }
@
%old:    stage = 0; (* ?? *)


<<signature Index.stat_info_of_lstats>>=
val stat_info_of_lstats: Unix.stats -> stat_info
@
<<function Index.stat_info_of_lstats>>=
let stat_info_of_lstats stats = 
    { ctime = { lsb32 = Int32.of_float stats.Unix.st_ctime; nsec = 0l };
      mtime = { lsb32 = Int32.of_float stats.Unix.st_mtime; nsec = 0l };
      dev = Int32.of_int stats.Unix.st_dev;
      inode = Int32.of_int stats.Unix.st_ino;
      mode = 
        (match stats.Unix.st_kind, stats.Unix.st_perm with
        | Unix.S_REG, p -> 
          if p land 0o100 = 0o100 
          then Exec 
          else Normal
        | Unix.S_LNK, _ -> Link
        | _ -> failwith ("unsupported file type")
        );
      uid = Int32.of_int stats.Unix.st_uid;
      gid = Int32.of_int stats.Unix.st_gid;
      size = Int32.of_int stats.Unix.st_size;
    }
@


\section{Pack files}

% pack objects, pack refs, pack-idx.

% adv topics, but referenced many times (especially in Networking chapter).

\section{Networking}

% for git://, ssh://, but also for local.
% Abstracted behind Client interface.

\subsection{[[Client.t]]}

<<type Client.t>>=
type t = {
  (* path to remote (e.g., /path/other/repo, or git://github.com/foo/bar) *)
  url: string;
  (* less: more parameters:
   *  - determine_refs_wanted. for now grabs everything from remote HEAD 
   *  - return set of remote refs, not just the one for HEAD
   * Note that fetch will modify the target repository by side effect.
   *)
  fetch: Repository.t -> Commit.hash;
  (* less: progress *)
}
@
\t will get send method too?

% Repo param of fetch is dst repo, not remote repo.

<<signature Clients.client_of_url>>=
val client_of_url: string -> Client.t
@
<<function Clients.client_of_url>>=
(* old: was called get_transport_and_path (and xxx_from_url) in dulwich *)
let client_of_url url =
  match url with
  <<[[Clients.client_of_url()]] match url cases>>
  | s -> 
    if Sys.file_exists s
    then Client_local.mk_client url
    else failwith (spf "remote repository URL not supported: %s" url)
@

% Will see Client_local.mk_client later and match url cases later too.

\subsection{[[Server.t]]}






\chapter{Main Functions}

%trans: before main(), important type.
% git works with commands, git cmd args
% where each command have own options and actions.

\section{Main commands}

\subsection{[[Cmd.t]]}

<<type Cmd.t>>=
type t = {
  name: string;
  help: string;
  options: (Arg.key * Arg.spec * Arg.doc) list;

  (* the command! *)
  f: string list -> unit;
  (* less: man: when do git -help get short help, and with --help man page *)
}
@
%alt: use of 'Term.()' and '$' to not require globals for flags (src: ocaml-git)
% but not worth it. With split cmd_xxx.ml can have different globals in
% those different files.

%cvs: the one who introduced cvs xxx style instead of many programs? 
% (ci/co/...)

\subsection{[[Cmds.main_commands]]}

<<constant Cmds.main_commands>>=
let main_commands = [
  (* creating *)
  Cmd_init.cmd;
  Cmd_add.cmd;
  Cmd_rm.cmd;
  Cmd_commit.cmd;

  (* branching *)
  Cmd_branch.cmd;
  Cmd_checkout.cmd;
  Cmd_reset.cmd;
  
  (* inspecting *)
  Cmd_show.cmd;
  Cmd_diff.cmd;
  Cmd_log.cmd;
  Cmd_status.cmd;

  (* networking *)
  Cmd_pull.cmd;
  Cmd_push.cmd;
  Cmd_clone.cmd;
]
@
%todo: no merge 
%less: rebase

%chunks:
% will see in next chapters code for each of those commands.

% There is also extra_commands (for debugging) and Cmd_help.cmd (for help).

\section{[[Main.main()]]}

<<toplevel Main._1>>=
let _ =
  main ()
@


<<function Main.main>>=
let main () =
  <<[[Main.main()]] sanity check arguments>>
  else begin
    let cmd = 
      try 
        Hashtbl.find hcommands Sys.argv.(1) 
      with Not_found ->
        <<[[Main.main()]] print usage and exit>>
    in
    <<[[Main.main()]] execute [[cmd]]>>
  end
@


<<constant Main.hcommands>>=
let hcommands = 
  commands |> List.map (fun cmd -> cmd.Cmd.name, cmd) |> Hashtbl_.of_list
@

<<constant Main.commands>>=
let commands = List.flatten [
  Cmds.main_commands;
  Cmds.extra_commands;
  [Cmd_help.cmd];
]
@

<<[[Main.main()]] sanity check arguments>>=
if Array.length Sys.argv < 2
then begin
  <<[[Main.main()]] print usage and exit>>
end
@
% git cmd xxx so at least 2.

<<[[Main.main()]] print usage and exit>>=
pr2 (usage ());
exit 1
@

<<function Main.usage>>=
let usage () =
  spf "usage: ocamlgit <%s> [options]"
    (String.concat "|" (commands |> List.map (fun cmd -> cmd.Cmd.name)))
@




<<[[Main.main()]] execute [[cmd]]>>=
let argv = Array.sub Sys.argv 1 (Array.length Sys.argv -1) in
let usage_msg_cmd = spf "usage: %s %s%s"
  (Filename.basename Sys.argv.(0))
  cmd.Cmd.name
  cmd.Cmd.help
in
let remaining_args = ref [] in
<<[[Main.main()]] parse [[argv]] for [[cmd]] options and remaining args>>
(* finally! *)
try 
  cmd.Cmd.f (List.rev !remaining_args)
with 
  | Cmd.ShowUsage ->
    Arg.usage (Arg.align cmd.Cmd.options) usage_msg_cmd;
    exit 1
@

<<exception Cmd.ShowUsage>>=
(* f can raise ShowUsage which will be catched by caller in main.ml *)
exception ShowUsage
@


<<[[Main.main()]] parse [[argv]] for [[cmd]] options and remaining args>>=
(try 
 (* todo: look if --help and factorize treatment of usage for subcmds *)
   Arg.parse_argv argv (Arg.align cmd.Cmd.options) 
     (fun arg -> Common.push arg remaining_args) usage_msg_cmd;
 with Arg.Bad str | Arg.Help str->  
   prerr_string str;
   exit 1
);
@




\section{Getting help: [[git help]]}

<<constant Cmd_help.list_extra>>=
let list_extra = ref false
@

<<constant Cmd_help.cmd>>=
let rec cmd = { Cmd.
  name = "help";
  help = "";
  options = ["-a", Arg.Set list_extra, " see all commands"];
  f = (fun args ->
    let xs = 
      if !list_extra
      then Cmds.main_commands @ Cmds.extra_commands @ [cmd]
      else Cmds.main_commands
    in
    pr ("Available commands: ");
    xs |> List.iter (fun cmd ->
      pr (spf "  %s" cmd.Cmd.name);
    );
  );
}
@
% let rec, subtle! not a function but still!


% will have also 'git cmd --help' later.


\chapter{Creating a Repository}
\n Initializing? reserved for 'creating empty', so would match only git init

\section{Initializing a repository: [[git init]]}
% Creating a fresh repository

<<constant Cmd_init.cmd>>=
let cmd = { Cmd.
  name = "init";
  help = " [directory]";
  options = [
   (* less: -bare, --quiet *)
  ];
  f = (fun args ->
    match args with
    | []    -> Repository.init "."
    | [dir] -> Repository.init dir
    | _ -> raise Cmd.ShowUsage
  );
}
@

<<signature Repository.init>>=
val init: Common.filename -> unit
@
<<function Repository.init>>=
let init root =
  if not (Sys.file_exists root)
  then Unix.mkdir root dirperm;

  (* less: bare argument? so no .git/ prefix? *)
  let dirs = [
    ".git";
    ".git/objects";
    ".git/refs";
    ".git/refs/heads";
    ".git/refs/tags";
    ".git/refs/remote";
    ".git/refs/remote/origin";
    ".git/hooks";
    ".git/info";
  ] in
  dirs |> List.iter (fun dir ->
    (* less: exn if already there? *)
    Unix.mkdir (root / dir) dirperm;
  );
  let r = {
    worktree = root;
    dotgit = root / ".git";
    index = Index.empty;
  } in
  add_ref_if_new r Refs.Head Refs.default_head_content |> ignore;

  (* less: config file, description, hooks, etc *)
  pr (spf "Initialized empty Git repository in %s" (root / ".git"))
@

% will see add_ref_if_new later.

<<constant Repository.TODOOPERATOR>>=
let (/) = Filename.concat
@

<<constant Repository.dirperm>>=
(* rwxr-x--- *)
let dirperm = 0o750
@


%\subsection{Common directory}
% To abstract diff between bare and normal repository

%\subsection{Named files}

\section{Cloning a repository: [[git clone]]}

% Other common way to initialize a repo is clone! Copy from
% network location (or local too, but less useful).

% Will see clone also later

\section{Copying a repository: [[cp -r]]}

% well, can just do cp :) 
% Can also use branch, see later.
% actually at FB some people (Ola?) were prefering copy to
% branch cos git was not scaling enough when lots of files
% so switching branch was too slow (but doing cd /other/repo was fast)

% will see clone later, but useful more in networking context
% (and even there cp would be better thx to NFS)

% clone creates a connexion to original repo. cp does not.
% no remote and push/pull.


\section{Opening a repository}
% will see later most op need a Repository.t structure representing
% an existing repo.

<<signature Repository.open_>>=
val open_: Common.filename -> t
@
% not open cos conflict with ocaml keyword
<<function Repository.open_>>=
let open_ root = 
  let path = root / ".git" in
  if Sys.file_exists path &&
     (Unix.stat path).Unix.st_kind = Unix.S_DIR
  then 
    { worktree = root;
      dotgit = path;
      (* less: grafts, hooks *)
      index = 
        if Sys.file_exists (path / "index")
        then 
          (path / "index") |> Common.with_file_in (fun ch ->
            ch |> IO.input_channel |> Index.read)
        else Index.empty
    }
  else failwith (spf "Not a git repository at %s" root)
@
%todo: bar repo, 
\l cant used index_to_filename cos no repo yet, sad.

% See appendix for IO.xxx, Common.with_file_in
% Will see Index.read later.

<<signature Repository.find_dotgit_root_and_open>>=
val find_root_open_and_adjust_paths: 
 Common.filename list -> t * Common.filename list
@
<<function Repository.find_dotgit_root_and_open>>=
let find_root_open_and_adjust_paths paths = 
  (* todo: allow git from different location *)
  let r = open_ "." in
  (* todo: support also absolute paths and transform in relpaths *)
  let relpaths = paths |> List.map (fun path ->
    if Filename.is_relative path
    then 
      (* todo: may have to adjust if root was not pwd *)
      path
    else failwith (spf "TODO: Not a relative path: %s" path)
    )
  in
  r, relpaths
@


%\section{Checking out a repository: [[git checkout]]}
% if cp -a just .git, then can checkout by doing git checkout.

%\section{Fast Import/Export}
%adv topics



\chapter{Reading from a Repository}
\t should enforce that read every bytes

\section{Objects}

% repo * sha -> path -> (channel -> IO.input) -> decompress -> deserialize

<<signature Repository.read_obj>>=
val read_obj: t -> Sha1.t -> Objects.t
@
<<function Repository.read_obj>>=
let read_obj r h =
  (* todo: look for packed obj *)
  let path = h |> Hexsha.of_sha |> hexsha_to_filename r in
  path |> Common.with_file_in (fun ch ->
    (* less: check read everything from channel? *)
    (* todo: check if sha consistent? *)
    ch |> IO.input_channel |> Compression.decompress |> Objects.read
  )
@
\l loose vs pack objects

% when reading no need lock, so simply with_file_in.


<<signature Objects.read>>=
(* assumes input is in decompressed form *)
val read: IO.input -> t
@
<<function Objects.read>>=
let read ch =
  let str = IO_.read_string_and_stop_char ch ' ' in
  let n = IO_.read_int_and_nullbyte ch in
  let raw = IO.really_nread ch n in
  (* less: assert finished ch? use IO.pos_in? *)
  let ch2 = IO.input_bytes raw in
  (* less: just reuse ch so avoid use of intermediate strings? *)
  match str with
  <<[[Objects.read()]] match str cases>>
  (* less: assert finished ch2? *)
  | str -> failwith (spf "Objects.read: invalid header: %s" str)
@

\subsection{Decompression}

<<signature Compression.decompress>>=
val decompress: 
  IO.input -> IO.input
@
<<function Compression.decompress>>=
let decompress ch = 
  Unzip.inflate ch
@
% See appendix for Unzip.inflate().



\subsection{Reading a blob}

<<[[Objects.read()]] match str cases>>=
| "blob"   -> Blob   (Blob.read ch2)
@
<<signature Blob.read>>=
(* assumes have already read the 'blob <size>\000' header from unzipped input *)
val read: IO.input -> t
@
<<function Blob.read>>=
let read ch =
  IO.read_all ch
@


<<signature Repository.read_blob>>=
val read_blob: t -> Sha1.t -> Blob.t
@
<<function Repository.read_blob>>=
let read_blob r h =
  match read_obj r h with
  | Objects.Blob x -> x
  | _ -> failwith "read_commit: was expecting a blob"
@

\subsection{Reading a tree}

<<[[Objects.read()]] match str cases>>=
| "tree"   -> Tree   (Tree.read ch2)
@

<<signature Tree.read>>=
(* assumes have already read the 'tree <size>\000' header from unzipped input *)
val read: IO.input -> t
@

<<function Tree.read>>=
let read ch =
  let rec aux acc =
    try 
      (* todo: how diffentiate no more input from wrong input ?
       * pass size ch and use IO.pos_in ?
       *)
      let e = read_entry ch in
      aux (e::acc)
    with IO.No_more_input ->
      List.rev acc
  in
  aux []
@

<<function Tree.read_entry>>=
(* todo: should transform some No_more_input exn in something bad,
 * on first one it's ok, but after it means incomplete entry.
 *)
let read_entry ch =
  let perm = IO_.read_string_and_stop_char ch ' ' in
  (* todo: handle escape char in filenames? encode/decode *)
  let name = IO_.read_string_and_stop_char ch '\000' in
  let hash = Sha1.read ch in
  { perm = perm_of_string perm; name = name; id = hash }
@

<<signature Sha1.read>>=
val read: IO.input -> t
@
<<function Sha1.read>>=
let read ch =
  let s = IO.really_nread ch 20 in
  assert (is_sha s);
  s
@

<<function Tree.perm_of_string>>=
let perm_of_string = function
  | "44"
  | "100644" -> Normal
  | "100755" -> Exec
  | "120000" -> Link
  | "40000"  -> Dir
  <<[[Tree.perm_of_string()]] match str cases>>
  | x        -> failwith (spf "Tree.perm_of_string: %s is not a valid perm." x)
@


<<signature Repository.read_tree>>=
val read_tree: t -> Sha1.t -> Tree.t
@
<<function Repository.read_tree>>=
let read_tree r h =
  match read_obj r h with
  | Objects.Tree x -> x
  | _ -> failwith "read_commit: was expecting a tree"
@

\subsection{Reading a commit}

<<[[Objects.read()]] match str cases>>=
| "commit" -> Commit (Commit.read ch2)
@

<<signature Commit.read>>=
(* assumes have already read the 'commit <size>\000' hdr from unzipped input *)
val read: IO.input -> t
@

<<function Commit.read>>=
let read ch =
  let tree = 
    IO_.read_key_space_value_newline ch "tree" Hexsha.read in
  (* todo: read "parent" or "author", because first commit has no parent *)
  let parents, author = 
    let rec loop parents =
      let str = IO_.read_string_and_stop_char ch ' ' in
      match str with
      | "parent" -> 
        let v = Hexsha.read ch in
        let c = IO.read ch in
        if c <> '\n'
        then failwith "Commit.read: missing newline after parent";
        loop (v::parents)
      | "author" ->
        let v = User.read ch in
        let c = IO.read ch in
        if c <> '\n'
        then failwith "Commit.read: missing newline after author";
        List.rev parents, v
      | _ -> failwith (spf "Commit.read: was expecting parent or author not %s"
                         str)
    in
    loop []
  in
  let committer = 
    IO_.read_key_space_value_newline ch "committer" User.read in
  let c = IO.read ch in
  if c <> '\n'
  then failwith "Commit.read: missing newline before message";
  let msg = IO.read_all ch in
  { tree = Hexsha.to_sha tree; 
    parents = parents |> List.map Hexsha.to_sha; 
    author = author; committer = committer;
    message = msg;
  }
@

% As opposed to Tree, the Commit contains sha in Hexsha form
<<signature Hexsha.read>>=
val read: IO.input -> t
@
<<function Hexsha.read>>=
let read ch =
  let s = IO.really_nread ch 40 in
  assert (is_hexsha s);
  s
@



<<signature User.read>>=
val read: IO.input -> t
@

<<function User.read>>=
let read ch =
  let name = IO_.read_string_and_stop_char ch '<' in
  let email = IO_.read_string_and_stop_char ch '>' in
  let c = IO.read ch in
  if c <> ' ' then failwith "User.read: wrong format, missing space";

  let seconds = IO_.read_string_and_stop_char ch ' ' in
  let sign = IO.read ch in
  let hours = IO.nread_string ch 2 in
  let mins = IO.nread_string ch 2 in
  { name = String.sub name 0 (String.length name - 1);
    email = email;
    date = (Int64.of_string seconds,
            {
              sign = sign_of_char sign;
              hours = int_of_string hours;
              min = int_of_string mins;
            });
  }
@

<<function User.sign_of_char>>=
let sign_of_char = function
  | '+' -> Plus
  | '-' -> Minus
  | c -> failwith (spf "User.sign_of_string: not a sign, got %c" c)
@

<<signature Repository.read_commit>>=
val read_commit: t -> Sha1.t -> Commit.t
@
<<function Repository.read_commit>>=
let read_commit r h =
  match read_obj r h with
  | Objects.Commit x -> x
  | _ -> failwith "read_commit: was expecting a commit"
@

%\section{[[git show]]}
%here?


\section{References}

<<signature Repository.read_ref>>=
val read_ref: t -> Refs.t -> Refs.ref_content
@
<<function Repository.read_ref>>=
let read_ref r aref =
  (* less: packed refs *)
  let file = ref_to_filename r aref in
  file |> Common.with_file_in (fun ch ->
    ch |> IO.input_channel |> Refs.read
  )
@
\l loose vs pack refs

<<signature Refs.read>>=
val read: IO.input -> ref_content
@
<<function Refs.read>>=
let read ch =
  let str = IO.read_all ch in
  (* less: check finish by newline? *)
  match str with
  | _ when str =~ "^ref: \\(.*\\)$" -> OtherRef (Regexp_.matched1 str)
  | _ -> Hash (str |> IO.input_string |> Hexsha.read |> Hexsha.to_sha)
@
%$



% useful function, used at many places (not just read_objectish)
<<signature Repository.follow_ref>>=
val follow_ref: t -> Refs.t -> Refs.t list * Commit.hash option
@
<<function Repository.follow_ref>>=
let rec follow_ref r aref =
  (* less: check if depth > 5? *)
  try (
  let content = read_ref r aref in
  match content with
  | Refs.Hash sha -> [aref], Some sha
  | Refs.OtherRef refname ->
    let (xs, shaopt) = follow_ref r (Refs.Ref refname) in
    aref::xs, shaopt
  ) 
  (* inexistent ref file, can happen at the beginning when have .git/HEAD
   * pointing to an inexistent .git/refs/heads/master
   *)
  with Sys_error _ (* no such file or directory *) -> [aref], None
@

% In some code we assume there is one, otherwise would be internal error
\l but should still be fault tolerant and have nice error msg?
<<signature Repository.follow_ref_some>>=
val follow_ref_some: t -> Refs.t -> Commit.hash
@
<<function Repository.follow_ref_some>>=
let follow_ref_some r aref =
  match follow_ref r aref |> snd with
  | Some sha -> sha
  | None -> failwith (spf "could not follow %s" (Refs.string_of_ref aref))
@



%\section{Objectish}

<<signature Repository.read_objectish>>=
val read_objectish: t -> objectish -> Objects.t
@
<<function Repository.read_objectish>>=
let read_objectish r objectish =
  match objectish with
  | ObjByRef aref -> 
    (match follow_ref r aref |> snd with
    | None -> failwith (spf "could not resolve %s" (Refs.string_of_ref aref))
    | Some sha -> 
      read_obj r sha
    )
  | ObjByHex hexsha ->
    let sha = Hexsha.to_sha hexsha in
    read_obj r sha
@



\section{Index}

<<signature Repository.read_index>>=
val read_index: t -> Index.t
@
<<function Repository.read_index>>=
let read_index r =
  r.index
@
% initialized when open_ a repo (possibly to Index.empty if no index file)

<<signature Index.read>>=
val read: IO.input -> t
@
<<function Index.read>>=
let read ch =
  let header = IO.really_nread_string ch 4 in
  if header <> "DIRC"
  then failwith "Index.read: expecting DIRC header";
  let version = IO.BigEndian.read_i32 ch in
  if version <> 2
  then failwith "Index.read: expecting version 2";
  let entries = read_entries ch in
  (* todo: read_extensions but need know when reach last 20 bytes *)
  (* todo: check hash correctly stored in last 20 bytes *)
  entries
@

<<function Index.read_entries>>=
let read_entries ch =
  let n = IO.BigEndian.read_i32 ch in
  let rec loop acc n =
    if n = 0 
    then List.rev acc
    else
      let entry = read_entry ch in
      loop (entry :: acc) (n - 1) in
  loop [] n
@

<<function Index.read_entry>>=
let read_entry ch =
  let stats = read_stat_info ch in
  let id = Sha1.read ch in
  let stage, len =
    let i = IO.BigEndian.read_ui16 ch in
    (i land 0x3000) lsr 12,
    (i land 0x0FFF)
  in
  if (stage <> 0)
  then failwith (spf "stage is not 0: %d" stage);
  let name = IO.really_nread_string ch len in
  let c = IO.read ch in
  if c <> '\000'
  then failwith "Index.read_entry: expecting null char after name";
  let len = 63 + String.length name in
  let pad = 
    match len mod 8 with
    | 0 -> 0
    | n -> 8-n 
  in
  let _zeros = IO.really_nread ch pad in
  (* less: assert zeros *)
  { stats; id; name }
@
%old: was using stage

<<function Index.read_stat_info>>=
let read_stat_info ch =
  let ctime = read_time ch in
  let mtime = read_time ch in
  (* less: unsigned again *)
  let dev = IO.BigEndian.read_real_i32 ch in
  let inode = IO.BigEndian.read_real_i32 ch in
  let mode = read_mode ch in
  let uid = IO.BigEndian.read_real_i32 ch in
  let gid = IO.BigEndian.read_real_i32 ch in
  let size = IO.BigEndian.read_real_i32 ch in
  { mtime; ctime; dev; inode; mode; uid; gid; size }
@


<<function Index.read_time>>=
let read_time ch =
  (* less: unsigned actually *)
  let lsb32 = IO.BigEndian.read_real_i32 ch in
  let nsec = IO.BigEndian.read_real_i32 ch in
  { lsb32; nsec }
@

<<function Index.read_mode>>=
let read_mode ch =
  let _zero = IO.BigEndian.read_ui16 ch in
  let n = IO.BigEndian.read_ui16 ch in
  match n lsr 12 with
  | 0b1010 -> Link
  <<[[Index.read_mode()]] match [[n lsr 12]] cases>>
  | 0b1000 ->
    (match n land 0x1FF with
    | 0o755 -> Exec
    | 0o644 -> Normal
    | d     -> failwith (spf "Index.mode: invalid permission (%d)" d)
    )
  | m -> failwith (spf "Index.mode: invalid (%d)" m)
@


\chapter{Writing to a Repository}

% dual.

\section{Objects}

<<signature Repository.add_obj>>=
val add_obj: t -> Objects.t -> Sha1.t
@
<<function Repository.add_obj>>=
let add_obj r obj =
  let bytes = 
    IO.output_bytes () |> IO_.with_close_out (Objects.write obj) in
  let sha = Sha1.sha1 bytes in
  let hexsha = Hexsha.of_sha sha in
  let dir = hexsha_to_dirname r hexsha in
  if not (Sys.file_exists dir)
  then Unix.mkdir dir dirperm;
  let file = hexsha_to_filename r hexsha in
  if (Sys.file_exists file)
  then sha (* deduplication! nothing to write, can share objects *)
  else begin
    file |> with_file_out_with_lock (fun ch ->
      let ic = IO.input_bytes bytes in
      let oc = IO.output_channel ch in
      Compression.compress ic oc;
      IO.close_out oc;
    );
    sha
  end
@

% should warn if add obj already there?
% No! deduplication! if you add a file that hash to content of already
% existing file, then great


<<signature Objects.write>>=
(* will not compress, will return unserialized content for sha1 computation *)
val write: t -> bytes IO.output -> unit
@
<<function Objects.write>>=
let write obj ch =
  let body = 
    IO.output_bytes () |> IO_.with_close_out (fun ch ->
      match obj with
      | Blob x   -> Blob.write x ch
      | Commit x -> Commit.write x ch
      | Tree x   -> Tree.write x ch
      <<[[Objects.write()]] match obj cases>>
    )
  in
  let header = 
    spf "%s %d\000"
      (match obj with
      | Blob _   -> "blob"
      | Commit _ -> "commit"
      | Tree  _  ->  "tree"
      <<[[Objects.write()]] return header, match obj cases>>
      ) 
      (Bytes.length body)
  in
  IO.nwrite ch header;
  IO.nwrite ch body
@



% because when write object, write its size.


\subsection{Compression}

<<signature Compression.compress>>=
val compress: 
  IO.input -> 'a IO.output -> unit
@
<<function Compression.compress>>=
let compress ic oc =
  Zlib.compress 
    (fun buf -> 
      try IO.input ic buf 0 (Bytes.length buf)
      with IO.No_more_input -> 0
    )
    (fun buf len -> 
      IO.output oc buf 0 len |> ignore)
@
% See appendix for Zlib.compress

% So bench? what overhead over working copy uses git to
% store all past versions?

\subsection{Locking}

% Locking here is different from lock on files.
% Concurrent updates to same .git file are not permitted
% (anyway less a pb with git because objects are immutable,
% but still need to modify reference files! especially HEAD)

<<function Repository.with_file_out_with_lock>>=
(* todo: see code of _Gitfile.__init__ O_EXCL ... *)
let with_file_out_with_lock f file =
  (* todo: create .lock file and then rename *)
  Common.with_file_out f file
@
% but really need that for objects?


\subsection{Writing a blob}

<<signature Blob.write>>=
(* does not write the header, does not compress *)
val write: t -> bytes IO.output -> unit
@
<<function Blob.write>>=
let write blob ch =
  IO.nwrite ch blob
@


\subsection{Writing a tree}

<<signature Tree.write>>=
(* does not write the header, does not compress *)
val write: t -> bytes IO.output -> unit
@
<<function Tree.write>>=
let write t ch =
  t |> List.iter (write_entry ch)
@

<<function Tree.write_entry>>=
let write_entry ch e =
  IO.nwrite ch (string_of_perm e.perm);
  IO.write ch ' ';
  (* todo: handle escape char in filenames? encode/decode *)
  IO.nwrite ch e.name;
  IO.write ch '\000';
  Sha1.write ch e.id
@

<<signature Sha1.write>>=
val write: 'a IO.output -> t -> unit
@
<<function Sha1.write>>=
let write ch x =
  IO.nwrite ch x
@

<<function Tree.string_of_perm>>=
let string_of_perm = function
  | Normal -> "100644"
  | Exec   -> "100755"
  | Link   -> "120000"
  | Dir    -> "40000"
  <<[[Tree.string_of_perm()]] match perm cases>>
@


\subsection{Writing a commit}

<<signature Commit.write>>=
(* does not write the header, does not compress *)
val write: t -> 'a IO.output -> unit
@
<<function Commit.write>>=
let write commit ch =
  IO.nwrite ch "tree ";
  Hexsha.write ch (Hexsha.of_sha commit.tree);
  IO.write ch '\n';
  commit.parents |> List.iter (fun parent ->
    IO.nwrite ch "parent ";
    Hexsha.write ch (Hexsha.of_sha parent);
    IO.write ch '\n';
  );
  IO.nwrite ch "author ";
  User.write ch commit.author;
  IO.write ch '\n';
  IO.nwrite ch "committer ";
  User.write ch commit.committer;
  IO.write ch '\n';

  IO.write ch '\n';
  IO.nwrite ch commit.message
@


<<signature Hexsha.write>>=
val write: 'a IO.output -> t -> unit
@
<<function Hexsha.write>>=
let write ch x =
  IO.nwrite ch x
@

<<signature User.write>>=
val write: 'a IO.output -> t -> unit
@
<<function User.write>>=
let write ch user =
  IO.nwrite ch (spf "%s <%s> " user.name user.email);
  write_date ch user.date
@

<<function User.write_date>>=
let write_date ch (date, tz) =
  IO.nwrite ch (Int64.to_string date);
  IO.write ch ' ';
  let sign = match tz.sign with Plus -> "+" | Minus -> "-" in
  IO.nwrite ch (spf "%s%02d%02d" sign tz.hours tz.min)
@

\section{References}

<<signature Repository.write_ref>>=
val write_ref: t -> Refs.t -> Refs.ref_content -> unit
@
<<function Repository.write_ref>>=
(* low-level *)
let write_ref r aref content =
  let file = ref_to_filename r aref in
  file |> with_file_out_with_lock (fun ch ->
    ch |> IO.output_channel |> IO_.with_close_out (Refs.write content))
@
\l check_refname? git-check-ref-format
%    [1] http://www.kernel.org/pub/software/scm/git/docs/git-check-ref-format.html

<<signature Refs.write>>=
val write: ref_content -> unit IO.output -> unit
@
<<function Refs.write>>=
let write content ch =
  match content with
  | Hash h -> 
    IO.nwrite_string ch (Hexsha.of_sha h ^ "\n")
  | OtherRef name ->
    IO.nwrite_string ch ("ref: " ^ name ^ "\n")
@



\section{Index}

<<signature Repository.write_index>>=
val write_index: t -> unit
@
<<function Repository.write_index>>=
let write_index r =
  let path = index_to_filename r in
  path |> with_file_out_with_lock (fun ch ->
    ch |> IO.output_channel |> IO_.with_close_out (Index.write r.index)
  )
@


<<signature Index.write>>=
(* will write the header, and sha checksum at the end *)
val write: t -> unit IO.output -> unit
@
<<function Index.write>>=
let write idx ch =
  let n = List.length idx in
  let body =
    IO.output_bytes () |> IO_.with_close_out (fun ch ->
      IO.nwrite ch "DIRC";
      IO.BigEndian.write_i32 ch 2;
      IO.BigEndian.write_i32 ch n;
      idx |> List.iter (write_entry ch)
    )
  in
  let sha = Sha1.sha1 body in
  IO.nwrite ch body;
  Sha1.write ch sha
@

<<function Index.write_entry>>=
let write_entry ch e =
  write_stat_info ch e.stats;
  Sha1.write ch e.id;
  let flags = (0 lsl 12 + String.length e.name) land 0x3FFF in
  IO.BigEndian.write_ui16 ch flags;
  IO.nwrite ch e.name;
  let len = 63 + String.length e.name in
  let pad = 
    match len mod 8 with
    | 0 -> 0
    | n -> 8-n 
  in
  IO.nwrite ch (Bytes.make pad '\000');
  IO.write ch '\000'
@
%old: was using e.stage

<<function Index.write_stat_info>>=
let write_stat_info ch stats =
  write_time ch stats.ctime;
  write_time ch stats.mtime;
  IO.BigEndian.write_real_i32 ch stats.dev;
  IO.BigEndian.write_real_i32 ch stats.inode;
  write_mode ch stats.mode;
  IO.BigEndian.write_real_i32 ch stats.uid;
  IO.BigEndian.write_real_i32 ch stats.gid;
  IO.BigEndian.write_real_i32 ch stats.size;
  ()
@


<<function Index.write_mode>>=
let write_mode ch mode =
  IO.BigEndian.write_ui16 ch 0;
  let n = 
    match mode with
    | Exec    -> 0b1000__000__111_101_101
    | Normal  -> 0b1000__000__110_100_100
    | Link    -> 0b1010__000__000_000_000
    <<[[Index.write_mode()]] match mode cases>>
  in
  IO.BigEndian.write_ui16 ch n
@


<<function Index.write_time>>=
let write_time ch time =
  IO.BigEndian.write_real_i32 ch time.lsb32;
  IO.BigEndian.write_real_i32 ch time.nsec
@



%\chapter{Walking a Repository}

\chapter{Staging a Diff}

%trans:
% Ok enough introduction. Now ready for real commands again!

% gitless says staging is not necessary.
% But if modified a b c and want different commits, then can!
% (can even use magit-status and pick each changes!)

\section{Adding files: [[git add]]}
% Adding and modifying

<<constant Cmd_add.cmd>>=
let cmd = { Cmd.
  name = "add";
  help = " <file>..."; (* less: pathspec? *)
  options = [
    (* todo: --interactive, --patch for picking, --force (if ignored) 
     * --all
     *)
  ];
  f = (fun args ->
    match args with
    | [] -> pr2 "Nothing specified, nothing added."
    | xs ->
      let r, relpaths = Repository.find_root_open_and_adjust_paths xs in
      (* less: support directories *)
      add r relpaths
  );
}
@

<<function Cmd_add.add>>=
let add r relpaths = 
  (* this will also add some blobs to the object store *)
  Repository.add_in_index r relpaths
@

% build a series of tree objects if different from last one?
% No, commit does that. Here we just add blobs.

% Note that git add is to add new file to repo but also
% to add existing file to the commit!

\section{Creating a blob from a file}

<<signature Repository.add_in_index>>=
val add_in_index: t -> Common.filename list -> unit
@

% create blob and add object! so 'git add' add object to repo.
% if git add again same file then old object is useless (git gc).

<<function Repository.add_in_index>>=
(* old: was called stage() in dulwich *)
let add_in_index r relpaths =
  assert (relpaths |> List.for_all Filename.is_relative);
  relpaths |> List.iter (fun relpath ->
    let full_path = r.worktree / relpath in
    let stat = 
      try Unix.lstat full_path 
      with Unix.Unix_error _ ->
        failwith (spf "Repository.add_in_index: %s does not exist anymore"
                    relpath)
    in
    let blob = Objects.Blob (content_from_path_and_unix_stat full_path stat) in
    let sha = add_obj r blob in
    let entry = Index.mk_entry relpath sha stat in
    r.index <- Index.add_entry r.index entry;
  );
  write_index r
@
\l sanitize fs_path (win32)

<<signature Index.add_entry>>=
val add_entry: t -> entry -> t
@
<<function Index.add_entry>>=
let rec add_entry idx entry =
  match idx with
  | [] -> [entry]
  | x::xs ->
    (match entry.name <=> x.name with
    | Sup -> x::(add_entry xs entry)
    (* replacing old entry is ok *)
    | Equal -> entry::xs
    (* the entries are sorted *)
    | Inf -> entry::x::xs
    )
@

<<function Repository.content_from_path_and_unix_stat>>=
let content_from_path_and_unix_stat full_path stat =
  match stat.Unix.st_kind with
  | Unix.S_LNK ->
    Unix.readlink full_path
  | Unix.S_REG -> 
    full_path |> Common.with_file_in (fun ch ->
      ch |> IO.input_channel |> IO.read_all
    )
  | _ -> failwith (spf "Repository.add_in_index: %s kind not handled" 
                     full_path)
@

% blob can be a symlink! git allows to store symlinks.

% Order of operation is important. Always in a consistent state.
% Will add index entry only if blob has been added! if failure after
% blob created, no pb!

\section{Removing files: [[git rm]]}

<<constant Cmd_rm.cmd>>=
let cmd = { Cmd.
  name = "rm";
  help = " [options] <file>...";
  options = [
  (* less: -f force, -r recursive, --quiet *)
  ];
  f = (fun args ->
    match args with
    | [] -> raise Cmd.ShowUsage
    | xs ->
      let r, relpaths = Repository.find_root_open_and_adjust_paths xs in
      rm r relpaths
  );
}
@

<<function Cmd_rm.rm>>=
let rm r relpaths =
  (* removing is simpler than adding; no need to add blobs in
   * the object store, so can just use functions from Index
   *)
  (* less: not super efficient, could use hashes to speedup things *)
  r.Repository.index <-
    relpaths |> List.fold_left (fun idx relpath ->
          (* todo: -f? remove also file *)
      Index.remove_entry idx relpath
    ) r.Repository.index;
  Repository.write_index r
@


<<signature Index.remove_entry>>=
val remove_entry: t -> Common.filename -> t
@
<<function Index.remove_entry>>=
let rec remove_entry idx name =
  match idx with
  | [] -> failwith (spf "The file %s is not in the index" name)
  | x::xs ->
    (match name <=> x.name with
    | Sup -> x::(remove_entry xs name)
    | Equal -> xs
    (* the entries are sorted *)
    | Inf -> failwith (spf "The file %s is not in the index" name)
    )
@

% when rm, we just want to build from index a tree without
% this entry. Simple.

\section{Renaming files: [[git mv]]}

% huge debate. How to track rename of files and dirs.
%cvs: was terrible at renaming

%git: Just add and rm.
% Note that same sha1 when rename, because same content, so no space lost.
% Also can be used to quickly detect renames when explore history.

\chapter{Committing a Diff}

\section{Committing the index: [[git commit]]}
%snapshotting the index?

<<constant Cmd_commit.cmd>>=
let cmd = { Cmd.
  name = "commit";
  help = " [options]"; (* less: <pathspec>... *)
  options = [
    "-m",        Arg.Set_string message, " commit message";
    "--message", Arg.Set_string message, " commit message";
    "--author", Arg.Set_string author, " <author> override author";
    "--committer", Arg.Set_string author, " ";
    (* less: commit mesg option: --file, --date, --signoff *)
    (* less: commit content options: -a, --interactive, --patch *)
    (* todo: --amend *)
  ];
  f = (fun args ->
    match args with
    | [] -> 
      let r, _ = Repository.find_root_open_and_adjust_paths [] in
      <<[[Cmd_commit.cmd]] compute [[today]]>>
      <<[[Cmd_commit.cmd]] compute [[author]]>>
      <<[[Cmd_commit.cmd]] compute [[comitter]]>>
      commit r author committer !message

    | xs -> raise Cmd.ShowUsage
  );
}
@

<<constant Cmd_commit.message>>=
let message = ref ""
@

<<function Cmd_commit.commit>>=
let commit r author committer message =
  (* todo: imitate git output
   *   [master 0b50159] xxx
   *   1 file changed, 0 insertions(+), 0 deletions(-)
   *   create mode 100644 foobar.txt
   *)
  (* todo: nothing to commit, working directory clean *)
  Repository.commit_index r author committer message
@


<<signature Repository.commit_index>>=
val commit_index: 
  t -> User.t (* author *) -> User.t (* committer *) -> string (* msg *) -> unit
@
<<function Repository.commit_index>>=
let commit_index r author committer message =
  let aref = Refs.Head in
  let tree = Index.tree_of_index r.index 
    (fun t -> add_obj r (Objects.Tree t)) 
  in
  (* todo: execute pre-commit hook *)

  (* less: Try to read commit message from .git/MERGE_MSG *)
  let message = message in
  (* todo: execute commit-msg hook *)

  let commit = { Commit. parents = []; tree; author; committer; message } in

  let ok =
    match follow_ref r aref |> snd with
    | Some old_head ->
      (* less: merge_heads from .git/MERGE_HEADS *)
      let merge_heads = [] in
      let commit = { commit with Commit.parents = old_head :: merge_heads } in
      let sha = add_obj r (Objects.Commit commit) in
      set_ref_if_same_old r aref old_head sha
    | None ->
      (* maybe first commit so refs/heads/master may not even exist yet *)
      let commit = { commit with Commit.parents = [] } in
      let sha = add_obj r (Objects.Commit commit) in
      add_ref_if_new r aref (Refs.Hash sha)
  in
  if not ok
  then failwith (spf "%s changed during commit" (Refs.string_of_ref aref));
  (* todo: execute post-commit hook *)
  ()
@



\section{Computing the tree from an index}

% FIGURE, flat index to tree.

<<type Index.dirs>>=
type dirs = (string (* full relpath of dir *), dir) Hashtbl.t
@

<<type Index.dir>>=
type dir = dir_entry list ref
@
<<type Index.dir_entry>>=
  and dir_entry =
    | Subdir of string (* basename *)
    | File of string (* basename *) * entry
@



<<signature Index.tree_of_index>>=
val tree_of_index: t -> (* add_obj *)(Tree.t -> Tree.hash) -> Tree.hash
@
<<function Index.tree_of_index>>=
let tree_of_index idx add_tree_obj =
  let (dirs: dirs) = Hashtbl.create 11 in
  Hashtbl.add dirs "." (ref []);
  (* populate dirs *)
  idx |> List.iter (fun entry ->
    let relpath = entry.name in
    let (dir, base) = Filename.dirname relpath, Filename.basename relpath in
    let dir = add_dir dirs dir in
    dir := (File (base, entry))::!dir
  );
  (* build trees *)
  build_trees dirs "." add_tree_obj
@

<<function Index.add_dir>>=
let rec add_dir dirs dirpath =
  try 
    Hashtbl.find dirs dirpath
  with Not_found ->
    let newdir = ref [] in
    Hashtbl.add dirs dirpath newdir;
    let (parent, base) = 
      Filename.dirname dirpath, Filename.basename dirpath in
    (* !recursive call! should stop at some point because "." is in dirs *)
    let dir = add_dir dirs parent in
    dir := Subdir (base)::!dir;
    newdir
@


% FIGURE for trees.
% It maps relative path of dir to dir content



<<function Index.build_trees>>=
let rec build_trees dirs dirpath add_tree_obj =
  let dir = Hashtbl.find dirs dirpath in
  (* entries of a Tree.t must be sorted, but entries of an index too,
   * so we can assume add_dir was called in sorted order
   *)
  let xs = List.rev !dir in
  let tree = 
    xs |> List.map (function
      | File (base, entry) ->
        {Tree.
         name = base; 
         id = entry.id; 
         perm = perm_of_mode entry.stats.mode;
        }
      | Subdir base ->
        let sha = 
          build_trees dirs (Filename.concat dirpath base) add_tree_obj in
        {Tree. perm = Tree.Dir; name = base; id = sha }
    )
  in
  add_tree_obj tree
@

<<signature Index.perm_of_mode>>=
val perm_of_mode: mode -> Tree.perm
@
<<function Index.perm_of_mode>>=
let perm_of_mode mode = 
  match mode with
  | Normal -> Tree.Normal
  | Exec -> Tree.Exec
  | Link -> Tree.Link
  <<[[Index.perm_of_mode()]] match mode cases>>
@


\section{Storing the author and committer}

<<[[Cmd_commit.cmd]] compute [[today]]>>=
let today = 
  (Int64.of_float (Unix.time ()),
   { User.
 (* todo: use localtime vs gmtime? *)
     sign = User.Minus;
     hours = 7; (* SF *)
     min = 0;
   })
in
@


<<constant Cmd_commit.author>>=
let author = ref ""
@
<<constant Cmd_commit.committer>>=
let committer = ref ""
@

<<[[Cmd_commit.cmd]] compute [[author]]>>=
(* todo: read from .git/config or ~/.gitconfig *)
let author = 
  if !author = ""
  then { User.
         name = Unix.getlogin ();
         email = "todo@todo";
         date = today;
       }
  else raise Todo (* need parse author string *)
in
@
<<[[Cmd_commit.cmd]] compute [[comitter]]>>=
let committer =
  if !committer = ""
  then author
  else raise Todo
in
@



% Use config for default, see adv topics.

\section{Recording the message}


\section{Updating [[HEAD]]}

% HEAD by default

%concurrency:
% need atomic operations for updating the refs, because
% push/pull will modify other repos that may be concurrently
% accessed by another user at the same time.

% why important atomic? because when push, you will write to another
% repo, and you will modify refs possibly? so need atomic?

%cvs: CVS was first to consider a set of files, but it was not atomic!

\subsection{Updating an existing reference}


<<signature Repository.set_ref_if_same_old>>=
val set_ref_if_same_old: t -> Refs.t -> Sha1.t -> Sha1.t -> bool
@
<<function Repository.set_ref_if_same_old>>=
let set_ref_if_same_old r aref oldh newh =
  let (refs, _) = follow_ref r aref in
  let lastref = List.hd (List.rev refs) in
  let file = ref_to_filename r lastref in
  try 
    file |> with_file_out_with_lock (fun ch ->
      (* TODO generate some IO.No_more_input 
      let prev = read_ref r lastref in
      if prev <> (Refs.Hash oldh)
      then raise Not_found
      else 
      *)
        ch |> IO.output_channel |> IO_.with_close_out 
            (Refs.write (Refs.Hash newh))
    );
    true
  with Not_found -> false
@

\subsection{Creating a new reference (first commit)}

<<signature Repository.add_ref_if_new>>=
val add_ref_if_new: t -> Refs.t -> Refs.ref_content -> bool
@
<<function Repository.add_ref_if_new>>=
let add_ref_if_new r aref refval =
  let (refs, shaopt) = follow_ref r aref in
  if shaopt <> None
  then false
  else begin
    let lastref = List.hd (List.rev refs) in
    let file = ref_to_filename r lastref in
    (* todo: ensure dirname exists *)
    file |> with_file_out_with_lock (fun ch ->
      (* todo: check file does not exist aleady *)
      ch |> IO.output_channel |> IO_.with_close_out (Refs.write refval)
    );
    true
  end
@


\chapter{Branching}
% fork

% purpose: parallel development (!= concurrent development)
% gitless records working version of files, so can easily switch branch!
% no problem if got uncommitted stuff in current dir or untracked file
% that conflicts with tracked file in another branch, it will be saved!
% in gitless, it really is like you had 2 separate dirs with 2
%  separate working versions!

% Again can simply use cp and create another repo :)

% Branch operations are very simple. Just list/create/delete
% entries under refs/.

<<constant Cmd_branch.cmd>>=
let cmd = { Cmd.
  name = "branch";
  help = " [options]
   or: ocamlgit branch [options] <branchname>
   or: ocamlgit branch [options] (-d | -D) <branchname>
";
  options = [
    "-d",       Arg.Set del_flag, " delete fully merged branch";
    "--delete", Arg.Set del_flag, " delete fully merged branch";
    "-D",       Arg.Set del_force, " delete branch (even if not merged)";
    (* less: --merged, --no-merged, --all for listing 
     *  --move to rename branch
     *  --force (force creation, deletion, rename)
    *)
  ];
  f = (fun args ->
    let r, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> list_branches r
    | [name] ->
      (match () with
      | _ when !del_flag  -> delete_branch r name false
      | _ when !del_force -> delete_branch r name true
      | _ -> create_branch r name
      )
    | [name;objectish] ->
      raise Todo
    | _ -> raise Cmd.ShowUsage
  );
}
@

<<constant Cmd_branch.del_flag>>=
let del_flag = ref false
@
<<constant Cmd_branch.del_force>>=
let del_force = ref false
@


\section{Listing branches: [[git branch]]}

<<function Cmd_branch.list_branches>>=
(* less: remote_flag set with --all to also list remote refs *)
let list_branches r =
  let head_branch = Repository.read_ref r (Refs.Head) in
  let all_refs = Repository.all_refs r in
  all_refs |> List.iter (fun refname ->
    if refname =~ "^refs/heads/\\(.*\\)"
    then 
      let short = Regexp_.matched1 refname in
      let prefix = 
        if (Refs.OtherRef refname = head_branch)
        then " * "
        else "   "
      in
      pr (spf "%s%s" prefix short)
  )
@

<<signature Repository.all_refs>>=
val all_refs: t -> Refs.refname list
@
<<function Repository.all_refs>>=
let all_refs r =
  let root = r.dotgit ^ "/" in
  let rootlen = String.length root in
  let res = ref [] in
  (root / "refs") |> walk_dir (fun path dirs files ->
    files |> List.iter (fun file ->
      (* less: replace os.path.sep *)
      let dir = String.sub path rootlen (String.length path - rootlen) in
      let refname = dir / file in
      Common.push refname res
    );
   );
  List.rev !res
@

% all_refs | ?? -> <>
<<signature Repository.walk_dir>>=
val walk_dir: 
  (Common.filename -> Common.filename list -> Common.filename list -> unit) ->
  Common.filename ->
  unit
@
<<function Repository.walk_dir>>=
(* inspired from os.path.walk in Python *)
let rec walk_dir f dir =
  dir |> with_opendir (fun handle ->
    let dirs = ref [] in
    let files = ref [] in
    try 
      while true do
        let s = Unix.readdir handle in
        (* git specific here *)
        if s <> "." && s <> ".." && s <> ".git" then begin
          let path = Filename.concat dir s in
          let st = Unix.lstat path in
          (match st.Unix.st_kind with
          | Unix.S_DIR -> Common.push s dirs
          | _ -> Common.push s files
          )
        end
      done
    with End_of_file ->
      let dirs = List.rev !dirs in
      let files = List.rev !files in
      f dir dirs files;
      dirs |> List.iter (fun s ->
        walk_dir f (Filename.concat dir s)
      )
  )
@

<<function Repository.with_opendir>>=
(* less: use finalize *)
let with_opendir f dir =
  let handle = Unix.opendir dir in
  let res = f handle in
  Unix.closedir handle;
  res
@

\section{Creating a branch: [[git branch <name>]]}

<<function Cmd_branch.create_branch>>=
let create_branch r name (* sha *) =
  let all_refs = Repository.all_refs r in
  let refname = "refs/heads/" ^ name in
  <<[[Cmd_branch.create_branch()]] sanity check refname>>
  let sha = Repository.follow_ref_some r (Refs.Head) in
  let ok = Repository.add_ref_if_new r (Refs.Ref refname) (Refs.Hash sha) in
  if not ok
  then failwith (spf "could not create branch '%s'" name)
@

% cheap! (ok checkout takes time)
% and then usually checkout!

<<[[Cmd_branch.create_branch()]] sanity check refname>>=
if List.mem refname all_refs
(* less: unless -force *)
then failwith (spf "A branch named '%s' already exists." name);
@

\section{Deleting a branch: [[git branch -d <name>]]}

<<function Cmd_branch.delete_branch>>=
let delete_branch r name force =
  let refname = "refs/heads/" ^ name in
  let aref = Refs.Ref refname in
  let sha = Repository.follow_ref_some r aref in
  if not force
  (* todo: detect if fully merged branch! *)    
  then ();
  Repository.del_ref r aref;
  pr (spf "Deleted branch %s (was %s)" name (Hexsha.of_sha sha))
@

<<signature Repository.del_ref>>=
val del_ref: t -> Refs.t -> unit
@
<<function Repository.del_ref>>=
let del_ref r aref =
  let file = ref_to_filename r aref in
  Unix.unlink file
@

% git gc

\section{Checking out a branch: [[git checkout]]}

<<constant Cmd_checkout.cmd>>=
let cmd = { Cmd.
  name = "checkout";
  help = " [options] <branch>
   or: ocamlgit checkout [options] <commitid>
   or: ocamlgit checkout [options]
";
  options = [
    (* less: --detach, --patch?
     * -b create and checkout a branch
     *)
  ];
  f = (fun args ->
    let r, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> update r
    | [str] -> checkout r str
    | _ -> raise Cmd.ShowUsage
  );
}
@

<<function Cmd_checkout.checkout>>=
let checkout r str =
  let all_refs = Repository.all_refs r in
  let refname = "refs/heads/" ^ str in

  match () with
  | _ when List.mem refname all_refs ->
    let commitid = Repository.follow_ref_some r (Refs.Ref refname) in
    let commit = Repository.read_commit r commitid in
    let treeid = commit.Commit.tree in
    let tree = Repository.read_tree r treeid in
    (* todo: order of operation? set ref before index? reverse? *)
    Repository.write_ref r (Refs.Head) (Refs.OtherRef refname);
    Repository.set_worktree_and_index_to_tree r tree;
    pr (spf "Switched to branch '%s'" str);
    (* less: if master, then check if up-to-date with origin/master *)
  <<[[Cmd_checkout.checkout()]] cases>>
  | _ -> raise Cmd.ShowUsage
@


% reset_index use for checkout!

% build_index and also set worktree from tree.



<<function Cmd_checkout.update>>=
(* Your branch is up-to-date with 'origin/master'. *)
let update r =
  raise Todo
@

\subsection{Computing the index (and worktree) from a tree}
% opposite of what we saw before for git commit.

<<signature Repository.set_worktree_and_index_to_tree>>=
val set_worktree_and_index_to_tree:
  t -> Tree.t -> unit
@
<<function Repository.set_worktree_and_index_to_tree>>=
let set_worktree_and_index_to_tree r tree =
  (* todo: need lock on index? on worktree? *)
  let hcurrent = 
    r.index |> List.map (fun e -> e.Index.name, false) |> Hashtbl_.of_list in
  let new_index = ref [] in
  (* less: honor file mode from config file? *)
  tree |> Tree.walk_tree (read_tree r) "" (fun relpath entry ->
    let perm = entry.Tree.perm in
    match perm with
    | Tree.Dir -> 
      (* bugfix: need also here to mkdir; doing it below is not enough
       * when a dir has no file but only subdirs
       *)
      let fullpath = r.worktree / relpath in
      if not (Sys.file_exists fullpath)
      then Unix.mkdir fullpath dirperm;
    | Tree.Normal | Tree.Exec | Tree.Link ->
      (* less: validate_path? *)
      let fullpath = r.worktree / relpath in
      if not (Sys.file_exists (Filename.dirname fullpath))
      then Unix.mkdir (Filename.dirname fullpath) dirperm;
      let sha = entry.Tree.id in
      let blob = read_blob r sha in
      let stat = build_file_from_blob fullpath blob perm in
      Hashtbl.replace hcurrent relpath true;
      Common.push (Index.mk_entry relpath sha stat) new_index;
    <<[[Repository.set_worktree_and_index_to_tree()]] walk tree cases>>
  );
  let index = List.rev !new_index in
  r.index <- index;
  write_index r;
  hcurrent |> Hashtbl.iter (fun file used ->
    if not used
    then 
      (* todo: should check if modified? otherwise lose modif! *)
      let fullpath = r.worktree / file in
      Unix.unlink fullpath
  )
  (* less: delete if a dir became empty, just walk_dir? *)
@

\t should also delete file not present in old version but were in
\t  current version

<<signature Tree.walk_tree>>=
val walk_tree: 
  (hash -> t) -> Common.filename (* dir *) -> 
  (Common.filename -> entry -> unit) -> t -> unit
@
<<function Tree.walk_tree>>=
(* we must visit in sorted order, so the caller of walk_tree can rely on 'f'
 * being called in order (so it can easily create for example sorted 
 * index entries while visiting a tree)
 *)
let rec walk_tree read_tree dirpath f xs =
  xs |> List.iter (fun entry ->
    let relpath = Filename.concat dirpath entry.name in
    f relpath entry;
    match entry.perm with
    | Dir ->
      walk_tree read_tree relpath f (read_tree entry.id)
    | Normal | Exec | Link -> ()
    <<[[Tree.walk_tree()]] match perm cases>>
  )
@
% there is also walk_trees, later.


\subsection{Creating a file from a blob}

<<function Repository.build_file_from_blob>>=
let build_file_from_blob fullpath blob perm =
  let oldstat =
    try 
      Some (Unix.lstat fullpath)
    with Unix.Unix_error _ -> None
  in
  (match perm with 
  | Tree.Link -> 
    if oldstat <> None
    then Unix.unlink fullpath;
    Unix.symlink blob fullpath;
  | Tree.Normal | Tree.Exec ->
    (match oldstat with
    (* opti: if same content, no need to write anything *)
    | Some { Unix.st_size = x } when x = Bytes.length blob && 
      (fullpath |> Common.with_file_in (fun ch -> 
        (ch |> IO.input_channel |> IO.read_all ) = blob
       )) ->
      ()
    | _ ->
      fullpath |> Common.with_file_out (fun ch ->
        output_bytes ch blob
      );
      (* less: honor filemode? *)
      Unix.chmod fullpath 
        (match perm with 
        | Tree.Normal -> 0o644
        | Tree.Exec -> 0o755
        | _ -> raise (Impossible "matched before")
        )
    )
  | Tree.Dir -> raise (Impossible "dirs filtered in walk_tree iteration")
  <<[[Repository.build_file_from_blob()]] match perm cases>>
  );
  Unix.lstat fullpath
@


\subsection{Checking out an old version}

<<[[Cmd_checkout.checkout()]] cases>>=
| _ when Hexsha.is_hexsha str ->
  let commitid = Hexsha.to_sha str in
  let commit = Repository.read_commit r commitid in
  let treeid = commit.Commit.tree in
  let tree = Repository.read_tree r treeid in
  (* todo: order of operation? set ref before index? reverse? *)
  Repository.write_ref r (Refs.Head) (Refs.Hash commitid);
  Repository.set_worktree_and_index_to_tree r tree;
  pr (spf "Note: checking out '%s'." str);
  pr ("You are in 'detached HEAD' state");
@

% convenient to go back! but then can not modify that! 

%gitless: shows that as a misfit, detached.
% but can create branch from that point at least

%\subsection{[[validate_path()]]}


\section{Resetting a branch: [[git reset]]}

<<constant Cmd_reset.cmd>>=
let cmd = { Cmd.
  name = "reset";
  help = " [options] ";
(* less: or: git reset <paths>... *)
  options = [
    "--hard", Arg.Set hard, " reset HEAD, index and working tree";
    "--soft", Arg.Set soft, " reset only HEAD";
    "--mixed", Arg.Set mixed, " reset HEAD and index";
    (* less: --patch, --quiet, --merge *)
  ];
  f = (fun args ->
    let r, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> 
      if !soft || !mixed || not !hard
      then begin
        pr2 "only --hard supported";
        raise Cmd.ShowUsage
      end;
      reset_hard r
    | _ -> raise Cmd.ShowUsage
  );
}
@

<<constant Cmd_reset.hard>>=
let hard = ref false
@
<<constant Cmd_reset.soft>>=
let soft = ref false
@
<<constant Cmd_reset.mixed>>=
let mixed = ref false
@


<<function Cmd_reset.reset_hard>>=
let reset_hard r =
  let commitid = Repository.follow_ref_some r (Refs.Head) in
  let commit = Repository.read_commit r commitid in
  let treeid = commit.Commit.tree in
  let tree = Repository.read_tree r treeid in
  Repository.set_worktree_and_index_to_tree r tree;
  pr (spf "HEAD is now at %s %s" 
        (String.sub (Hexsha.of_sha commitid) 0 6)
        (String.sub commit.Commit.message 0 40))
@

\chapter{Merging}
% "Integrating changes" in misfit paper

%trans: after branch, of course dual is merge

% for // devel but also concurrent devel. everyone is a branch.

% ??? no code in dulwich for merge? or just do_commit with multiple
% parents? the <<< >>> conflict is not part of git but can be third-party?

% MERGE_HEADS?

% saw merge_tag before in commit, and merge_heads in do_commit.

%On need for clever merge:
%https://wincent.com/blog/a-look-back-bram-cohen-vs-linus-torvalds:

%"There is no need for fancy metadata, rename tracking and so forth. The
%only thing you need to store is the state of the tree before and after
%each change. What files were renamed? Which ones were copied? Which
%ones were deleted? What lines were added? Which ones were removed?
%Which lines had changes made inside them? Which slabs of text were
%copied from one file to another? You shouldn't have to care about any
%of these questions and you certainly shouldn't have to keep special
%tracking data in order to help you answer them: all the changes to the
%tree (additions, deletes, renames, edits etc) are implicitly encoded
%in the delta between the two states of the tree; you just track what
%is the content.
%
%Git is already very smart, and it can (and will) get smarter about
%figuring out what happened, and where a given line in a given revision
%came from, and it will do so without ever having to embed additional
%meta data in its repositories. Absolutely everything can (and should)
%be inferred.
%
%Git breaks the mould because it thinks about content, not files. It
%doesn't track renames, it tracks content. And it does so at a
%whole-tree level. This is a radical departure from most version
%control systems. It doesn't bother trying to store per-file histories;
%it instead stores the history at the tree level. When you perform a
%diff you are comparing two trees, not two files.
%
%As a result of this fundamental design decision, the structure of a
%Git repository is stunningly simple. It's so simple in fact, that
%you'll be surprised at the sophistication of the things you can do
%with it. But that's the way the best code will always be: simple,
%solid premises out of which complex applications arise.
%
%The other fundamentally smart design decision is how Git does merges.
%The merging algorithms are smart but they don't try to be too smart.
%Unambiguous decisions are made automatically, but when there's doubt
%it's up to the user to decide. This is the way it should be. You don't
%want a machine making those decisions for you. You never will want it.
%That's the fundamental insight in the Git approach to merging: while
%every other version control system is trying to get smarter, Git is
%happily self-described as the "stupid content manager", and it's
%better for it."


% 3-way merge algorithm? diff3?

\section{merge: [[git merge]]}

% Pb of history-sensitive merging? If share some patches? Arch better?
% Or just completely forget the pb and do a general 3-way merge from
% base and just care about final state of both branches?

\section{Rebase: [[git rebase]]}

\section{Cherry-pick: [[git cherry-pick]]}





\chapter{Inspecting}

\section{Showing the content of an object: [[git show]]}
% can be useful to understand formats

<<constant Cmd_show.cmd>>=
let cmd = { Cmd.
  name = "show";
  help = " <objectish>";
  (* less: --oneline *)
  options = [];
  f = (fun args ->
    let r, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> show r (Repository.ObjByRef (Refs.Head))
    | xs ->
      xs |> List.iter (fun str ->
        show r (Repository.ObjByHex (str))
      )
  );
}
@
\l could have shorthex here, or branchname

<<function Cmd_show.show>>=
let show r objectish =
  let obj = Repository.read_objectish r objectish in
  match obj with
  <<[[Cmd_show.show()]] match obj cases>>
@

\subsection{Showing a blob}

<<[[Cmd_show.show()]] match obj cases>>=
| Objects.Blob x -> 
  Blob.show x
@

<<signature Blob.show>>=
val show: t -> unit
@
<<function Blob.show>>=
let show x =
  pr x
@


\subsection{Showing a tree}

<<[[Cmd_show.show()]] match obj cases>>=
| Objects.Tree x ->
  (* =~ git ls-tree --names-only *)
  pr "tree\n"; (* less: put sha of tree *)
  Tree.show x
@

<<signature Tree.show>>=
val show: t -> unit
@
<<function Tree.show>>=
let show xs =
  xs |> List.iter (fun entry ->
    pr (spf "%s%s" entry.name
          (match entry.perm with
          | Dir -> "/"
          | _ -> ""
          ))
  )
@
% git adds a '/' suffix when it's a dir

\subsection{Showing a commit}

% So can be used after git log to show the diff!


<<[[Cmd_show.show()]] match obj cases>>=
| Objects.Commit x -> 
  pr "commit"; (* less: put sha of commit *)
  Commit.show x;
  let tree2 = Repository.read_tree r x.Commit.tree in
  let parent1 = Repository.read_commit r (List.hd x.Commit.parents) in
  let tree1 = Repository.read_tree r parent1.Commit.tree in
  let changes = 
    Changes.changes_tree_vs_tree 
      (Repository.read_tree r) 
      (Repository.read_blob r)
      tree1 tree2 
  in
  changes |> List.iter Diff_unified.show_change
@


<<signature Commit.show>>=
val show: t -> unit
@
<<function Commit.show>>=
let show x =
  pr (spf "Author: %s <%s>" x.author.User.name x.author.User.email);
  (* less: date of author or committer? *)
  let date = x.author.User.date in
  pr (spf "Date:   %s" (User.string_of_date date));
  pr "";
  pr ("    " ^ x.message)
  (* showing diff done in caller in Cmd_show.show *)        
@

% print_commit() before
% write_tree_diff in caller.

<<signature User.string_of_date>>=
(* for show *)
val string_of_date: (int64 * tz_offset) -> string
@

<<function User.string_of_date>>=
let string_of_date (date, tz) =
  let f = Int64.to_float date in
  let tm = Unix.localtime f in

  spf "%s %s %d %02d:%02d:%02d %d %c%02d%02d"
    (Date.string_of_day tm.Unix.tm_wday) (Date.string_of_month tm.Unix.tm_mon) 
    tm.Unix.tm_mday 
    tm.Unix.tm_hour tm.Unix.tm_min tm.Unix.tm_sec (tm.Unix.tm_year + 1900)
    (char_of_sign tz.sign) tz.hours tz.min
@

<<function User.char_of_sign>>=
let char_of_sign = function
  | Plus -> '+'
  | Minus -> '-'
@

\subsection{Showing an old version of a file}

% git show /path/:@?? ^ ? or different command?

% Just get commit, tree and follow path until blob.

\section{Changes}

%trans:
% We will see a few commands showing changes (git diff, git status),
% so first introduce changes types.

\subsection{Tree changes}

<<type Change.t>>=
(* entry below refers only to files (not dirs), and their name
 * are adjusted to show a relative path from the root of the
 * project.
 *)
type t = 
  | Add of entry
  | Del of entry
  | Modify of entry * entry (* before / after *)
  (* less: Rename, Copy *)
  (*| Identical of Tree.entry *)
@

<<type Change.entry>>=
type entry = {
  (* relative path *)
  path: Common.filename;
  mode: Index.mode;
  content: content Lazy.t;
}
@
% lazy, subtle, for performance, otherwise operation like git XXX are too
% slow.

<<type Change.content>>=
type content = bytes
@

% Note that changes used only for inspecting. Not part of core DS.
% Git store content, not diff (well except in Pack, see later).

%\subsection{Worktree versus index}
%\subsection{Index versus tree}
%\subsection{Tree versus tree}

\subsection{File changes}

<<type Diff.diff>>=
type diff = diff_elem list
@

<<type Diff.diff_elem>>=
(* similar to change.ml, but for content of the file *)
type diff_elem = 
  | Added of item
  | Deleted of item
  | Equal of item
@

<<type Diff.item>>=
type item = string
@

% Again diff not part of core DS. Used for inspecting.

\section{Showing file differences: [[git diff]]}

<<constant Cmd_diff.cmd>>=
let cmd = { Cmd.
  name = "diff";
  help = " ";
  options = [];
  f = (fun args ->
    let r, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> diff_worktree_vs_index r
    | xs -> raise Cmd.ShowUsage
  );
}
@

<<function Cmd_diff.diff_worktree_vs_index>>=
let diff_worktree_vs_index r =
  let changes = 
    Changes.changes_worktree_vs_index 
      (Repository.read_blob r)
      r.Repository.worktree 
      r.Repository.index 
  in
  changes |> List.iter Diff_unified.show_change
@

\subsection{Computing tree changes}

% naive version. Want heuristics for rename detection!

<<signature Changes.changes_worktree_vs_index>>=
(* for git diff and git status *)
val changes_worktree_vs_index:
  (Blob.hash -> Change.content) ->
  Common.filename -> Index.t -> Change.t list
@
<<function Changes.changes_worktree_vs_index>>=
(* less: could factorize with Diff_tree.changes_tree_vs_tree? would need
 * to generate flat list of files (but then less opti opportunity
 * in changes_tree_vs_tree when hash for a whole subtree is the same)
 * and then just do set differences to compute new, deleted, and
 * for changes just look intersection and check if same content.
 *)
let changes_worktree_vs_index read_blob worktree index =
  index |> List.map (fun entry ->
    let old_stat = entry.Index.stats in
    let path = Filename.concat worktree entry.Index.name in
    let new_stat_opt = 
      try Some (Unix.lstat path |> Index.stat_info_of_lstats)
      with Unix.Unix_error _ -> None
    in
    match new_stat_opt with
    | None -> 
      [Change.Del { Change.path = entry.Index.name;
                    mode = old_stat.Index.mode;
                    content = lazy (read_blob entry.Index.id);
                  }]
    | Some new_stat ->
      (match () with
      (* useful opti? *)
      | _ when new_stat.Index.mtime = old_stat.Index.mtime -> []
      (* a change of mode is converted in a del/add *)
      | _ when new_stat.Index.mode <> old_stat.Index.mode ->
        [Change.Del { Change.path = entry.Index.name;
                      mode = old_stat.Index.mode;
                      content = lazy (read_blob entry.Index.id)};
         Change.Add { Change.path = entry.Index.name;
                      mode = new_stat.Index.mode;
                      content = lazy 
                        (content_from_path_and_stat_index path new_stat)}
          ]
      | _ -> 
        [Change.Modify (
          { Change.path = entry.Index.name;
            mode = old_stat.Index.mode;
            content = lazy (read_blob entry.Index.id) },
          { Change.path = entry.Index.name;
            mode = new_stat.Index.mode;
            content = lazy 
              (content_from_path_and_stat_index path new_stat) }
        )]
      )
  ) |> List.flatten
@

<<function Changes.content_from_path_and_stat_index>>=
(* similar to Repository.content_from_path_and_unix_stat *)
let content_from_path_and_stat_index path stat_info =
  match stat_info.Index.mode with
  | Index.Link ->
    Unix.readlink path
  | Index.Normal | Index.Exec ->
      path |> Common.with_file_in (fun ch ->
        ch |> IO.input_channel |> IO.read_all
      )
  <<[[Changes.content_from_path_and_stat_index()]] match mode cases>>
@

\subsection{Computing file changes}

% naive version. Want heuristics for block-move detection!

% string below is Change.content
<<signature Diff.diff>>=
val diff: string -> string -> diff
@
% see appendix
<<function Diff.diff>>=
(* seems correct *)
let diff str1 str2 =
  let xs = split_lines str1 in
  let ys = split_lines str2 in
  let res = StringDiff.diff (Array.of_list xs) (Array.of_list ys) in
  res |> List.rev |> List.map (function
    | `Common (_, _, s) -> Equal s
    | `Removed (_, s) -> Deleted s
    | `Added (_, s) -> Added s
  )
@

<<function Diff.split_lines>>=
let split_lines str =
  (* alt: let xs = Str.full_split (Str.regexp "\n") str in *)
  let rec aux start = 
    try
      let idx = String.index_from str start '\n' in
      let line = String.sub str start (idx - start + 1) in
      line::aux (idx + 1)
    with Not_found ->
      if start = String.length str
      then []
      else [String.sub str start (String.length str - start)]
  in
  aux 0
@


<<module Diff.StringDiff>>=
module StringDiff = Diff_myers.Make(struct
  type t = string array
  type elem = string
  let get t i = Array.get t i
  let length t = Array.length t
end)
@

\subsection{Showing changes}

<<signature Diff_unified.show_change>>=
val show_change: Change.t -> unit
@
<<function Diff_unified.show_change>>=
let show_change change =
  (* less: if mode is gitlink? *)
  let (old_path, old_content), (new_path, new_content) = 
    match change with
    | Change.Add entry ->
      ("dev/null", lazy ""), 
      ("b/" ^ entry.Change.path, entry.Change.content)
    | Change.Del entry ->
      ("a/" ^ entry.Change.path, entry.Change.content), 
      ("dev/null", lazy "")
    | Change.Modify (entry1, entry2) ->
      ("a/" ^ entry1.Change.path, entry1.Change.content), 
      ("b/" ^ entry2.Change.path, entry2.Change.content)
  in
  let diffs = Diff.diff (Lazy.force old_content) (Lazy.force new_content) in
  if not (diffs |> List.for_all (function Diff.Equal _ -> true | _ -> false))
  then begin
    pr (spf "diff --git %s %s" old_path new_path);
    (* less: display change of modes *)
    show_unified_diff diffs
  end
@


<<function Diff_unified.show_unified_diff>>=
let show_unified_diff diffs =
  (* naive: no contextual:  diffs |> List.iter print *)
  let rec aux context_lines nctx_before nctx_after nold nnew diffs =
    match diffs with
    (* todo: say if 'No newline at end of file' *)
    | [] -> ()
    | x::xs ->
      (match x with
      | Diff.Equal s ->
        (match () with
        | _ when nctx_after > 0 ->
          print x;
          aux [] 0 (nctx_after - 1) (nold + 1) (nnew + 1) xs
        | _ when nctx_before < nContext ->
          aux (x::context_lines) (nctx_before + 1) 0 (nold + 1) (nnew + 1) xs
        | _ when nctx_before = nContext ->
          let new_context_lines = List_.take nContext (x::context_lines) in
          aux new_context_lines nContext 0 (nold + 1) (nnew + 1) xs
        | _ -> raise (Impossible "")
        )
      | Diff.Deleted s  ->
        let prevs = List_.take nctx_before context_lines |> List.rev in
        if prevs <> [] then print_header nctx_before nold nnew;
        prevs |> List.iter print;
        print x;
        aux [] 0 nContext (nold + 1) (nnew) xs
      | Diff.Added s ->
        let prevs = List_.take nctx_before context_lines |> List.rev in
        if prevs <> [] then print_header nctx_before nold nnew;
        prevs |> List.iter print;
        print x;
        aux [] 0 nContext (nold) (nnew+1) xs
      )
  in
  aux [] 0 0 1 1 diffs
@

<<constant Diff_unified.nContext>>=
let nContext = 3
@

<<function Diff_unified.print>>=
let print = function
  | Diff.Equal s -> 
    print_string (" " ^ s)
  | Diff.Deleted s -> 
    print_string ("-" ^ s)
  | Diff.Added s -> 
    print_string ("+" ^ s)
@

<<function Diff_unified.print_header>>=
let print_header nctx_before nold nnew =
  (* todo: should print size of hunk also here, but then
   * need to wait we finished processing this hunk
   *)
  print_string (spf "@@ -%d, +%d, @@\n"
                  (nold - nctx_before) (nnew - nctx_before))
@


\section{Commit history walker}
\l make it a chapter? Walking a Repository?
\t rename History walker? or commit history walker? so less confusing
\t  with object store walker?

% actually a DAG of commits, not a graph of commits.

\t used outside git log? so just put inside git log?

\subsection{Basic walker}

<<signature Commit.walk_history>>=
val walk_history:  
  (hash -> t) -> (hash -> t -> unit) -> hash ->
  unit
@
<<function Commit.walk_history>>=
(* less: sort by time? so have a sorted queue of commits *)
let walk_history read_commit f sha =
  (* we are walking a DAG, so we need to remember already processed nodes *)
  let hdone = Hashtbl.create 101 in
  let rec aux sha =
    if Hashtbl.mem hdone sha
    then ()
    else begin
      Hashtbl.add hdone sha true;
      let commit = read_commit sha in
      (* todo: path matching *)
      f sha commit;
      commit.parents |> List.iter aux
    end
  in
  aux sha
(* 
let walk_graph r f =
  let heads = 
    Repository.all_refs r |> Common.map_filter (fun aref ->
      if aref =~ "refs/heads/"
      then Some (Repository.follow_ref_some r (Refs.Ref aref))
      else None
    )
  in
  ...
  heads |> List.iter aux
*)
@

\subsection{Extra features}
\l mv in advanced topics?

\subsubsection{max entries}
% git log -1, -10, useful.

\subsubsection{Reverse walking}
% requires O(n). will call iterator and store result a list.

\subsubsection{Exclude set}

\subsubsection{Time range}

\subsubsection{Path restrictions}

\subsubsection{Topological order}


\section{Showing the commit history: [[git log]]}

<<constant Cmd_log.cmd>>=
let cmd = { Cmd.
  name = "log";
  help = " [options]";
  options = [
    "--name-status", Arg.Set name_status, 
    " print name/status for each changed file";
    (* todo: -1, -10 *)
    (* less: --reverse *)
  ];
  f = (fun args ->
    let r, relpaths = Repository.find_root_open_and_adjust_paths args in
    match relpaths with
    | [] -> log r
    (* todo: git log path *)
    (* less: revision range *)
    | xs -> raise Cmd.ShowUsage
  );
}
@

<<function Cmd_log.log>>=
(* todo: track only selected paths 
 * (and then rename detection to track correctly)
 *)
let log r =
  let start = Repository.follow_ref_some r (Refs.Head) in
  start |> Commit.walk_history (Repository.read_commit r) (fun sha commit ->
    print_commit sha commit;
    if !name_status
    then begin
      let tree1 = Repository.read_tree r commit.Commit.tree in
      let tree2 =
        match commit.Commit.parents with
        | [] -> []
        | [sha] -> 
          let commit2 = Repository.read_commit r sha in
          Repository.read_tree r commit2.Commit.tree
        | x::y::xs ->
          failwith "TODO: log: handle merge"
      in
      let changes = Changes.changes_tree_vs_tree
        (Repository.read_tree r)
        (Repository.read_blob r)
        tree2
        tree1
      in
      changes |> List.iter print_change;
      pr "";
    end
  )
@

<<constant Cmd_log.name_status>>=
let name_status = ref false
@



\subsection{Comparing trees}


<<signature Changes.changes_tree_vs_tree>>=
(* for git show commit *)
val changes_tree_vs_tree: 
  (Tree.hash -> Tree.t) ->
  (Blob.hash -> Change.content) ->
  Tree.t -> Tree.t -> Change.t list
@
<<function Changes.changes_tree_vs_tree>>=
(* see also Cmd_diff.changes_index_vs_worktree
 *     and  Cmd_status.changes_index_vs_HEAD
 *)
let changes_tree_vs_tree read_tree read_blob tree1 tree2 =
  let changes = ref [] in
  let add x = Common.push x changes in
  Tree.walk_trees read_tree "" (fun dirpath entry1_opt entry2_opt ->
    (* if entries are directories, then we would be called again
     * with their individual files, so safe to skip the dir entries.
     *)
    let entry1_opt = skip_tree_and_adjust_path read_blob dirpath entry1_opt in
    let entry2_opt = skip_tree_and_adjust_path read_blob dirpath entry2_opt in
    
    match entry1_opt, entry2_opt with
    | None, None -> ()
    | Some (a, asha), Some (b, bsha) ->
      (match () with
      (* file type changed reported as delete/add (meh) *)
      | _ when a.Change.mode <> b.Change.mode ->
        add (Change.Del a);
        add (Change.Add b);
      | _ when asha <> bsha ->
        add (Change.Modify (a, b))
      | _ -> ()
      )
    | Some (a,_), None -> add (Change.Del a)
    | None, Some (b,_) -> add (Change.Add b)
  ) tree1 tree2 ;
  List.rev !changes
@

<<signature Tree.walk_trees>>=
val walk_trees:
  (hash -> t) -> Common.filename (* dir *) ->
  (Common.filename -> entry option -> entry option -> unit) -> t -> t -> unit
@
<<function Tree.walk_trees>>=
let rec walk_trees read_tree dirpath f xs ys =
  let g dirpath entry1_opt entry2_opt =
    f dirpath entry1_opt entry2_opt;
    (match entry1_opt, entry2_opt with
    | Some { perm = Dir; name = str; id = sha }, None ->
      walk_trees read_tree (Filename.concat dirpath str) f
        (read_tree sha) []
    | None, Some { perm = Dir; name = str; id = sha } ->
      walk_trees read_tree (Filename.concat dirpath str) f
        [] (read_tree sha)
    | Some { perm = Dir; name = str1; id = sha1 },
      Some { perm = Dir; name = str2; id = sha2 } ->
      assert (str1 = str2);
        (* todo: could skip if sha1 = sha2 here, useful opti *)
        walk_trees read_tree (Filename.concat dirpath str1) f
          (read_tree sha1) (read_tree sha2)
    | None, None -> raise (Impossible "two None in walk_trees.g")
    (* no directories, no need to recurse *)
    | Some _, None
    | None, Some _
    | Some _, Some _
      -> ()
    )
  in
  match xs, ys with
  | [], [] -> ()
  | x::xs, [] ->
    g dirpath (Some x) None;
    walk_trees read_tree dirpath f xs ys
  | [], y::ys ->
    g dirpath None (Some y);
    walk_trees read_tree dirpath f xs ys
  | x::xs, y::ys ->
    (match x.name <=> y.name with
    | Equal -> 
      g dirpath (Some x) (Some y);
      walk_trees read_tree dirpath f xs ys
    | Inf -> 
      g dirpath (Some x) None;
      walk_trees read_tree dirpath f xs (y::ys)
    | Sup ->
      g dirpath None (Some y);
      walk_trees read_tree dirpath f (x::xs) ys
    )
@



<<function Changes.skip_tree_and_adjust_path>>=
let skip_tree_and_adjust_path read_blob dirpath entry_opt =
  match entry_opt with
  | Some { Tree.perm = Tree.Dir } -> None
  | Some { Tree.perm = Tree.Commit } -> failwith "submodule not supported"
  | Some x -> Some ({ Change.
    path = Filename.concat dirpath x.Tree.name;
    mode = Index.mode_of_perm x.Tree.perm;
    
    (* todo: do that later? once know we will return a change with this entry?
     * make it lazy?
     *)
    content = lazy (read_blob x.Tree.id);
  }, x.Tree.id)
  | None -> None
@

<<signature Index.mode_of_perm>>=
val mode_of_perm: Tree.perm -> mode
@
<<function Index.mode_of_perm>>=
let mode_of_perm perm = 
  match perm with
  | Tree.Normal -> Normal
  | Tree.Exec -> Exec
  | Tree.Link -> Link
  <<[[Index.mode_of_perm()]] match perm cases>>
  | Tree.Dir -> failwith "index entry does not support Tree.dir perm"
@


\subsection{Printing a commit}

<<function Cmd_log.print_commit>>=
let print_commit sha commit =
  pr (spf "commit: %s" (Hexsha.of_sha sha));
  (match commit.Commit.parents with
  | [] | [_] -> ()
  | x::xs ->
    pr (spf "merge: %s" 
          (xs |> List.map Hexsha.of_sha |> String.concat "..."));
  );
  let author = commit.Commit.author in
  pr (spf "Author: %s <%s>" author.User.name author.User.email);
  let committer = commit.Commit.committer in
  if author <> committer
  then 
    pr (spf "Committer: %s <%s>" committer.User.name committer.User.email);
  pr (spf "Date:   %s" (User.string_of_date author.User.date));
  pr "";
  pr ("    " ^ commit.Commit.message);
  ()
@

\subsection{Diff summary: [[git log --name-status]]}

<<function Cmd_log.print_change>>=
let print_change change =
  match change with
  | Change.Add entry ->
    pr (spf "A       %s" entry.Change.path)
  | Change.Del entry ->
    pr (spf "D       %s" entry.Change.path)
  | Change.Modify (entry1, entry2) ->
    pr (spf "M       %s" entry1.Change.path)
@

\subsection{Showing differences between past versions}
% git show sha1?

\subsection{Showing the history of a file or directory, [[git log <path>]]}

% Format of git does not make this fast, as opposed to CVS.
% More reliable when rename?

\section{Showing file status: [[git status]]}

<<constant Cmd_status.cmd>>=
let cmd = { Cmd.
  name = "status";
  help = " [options]"; (* less: <pathspec> *)
  options = [
    "--short", Arg.Set short_format, " show status concisely";
    "--long", Arg.Clear short_format, " show status in long format (default)";
    (* less: --branch, --ignored *)
  ];
  f = (fun args ->
    let r, relpaths = Repository.find_root_open_and_adjust_paths args in
    match relpaths with
    | [] -> status r
    | xs -> raise Cmd.ShowUsage
  );
}
@

<<function Cmd_status.status>>=
let status r =
  let st = status_of_repository r in
  if !short_format
  then print_status_short st
  else print_status_long st
@

<<constant Cmd_status.short_format>>=
let short_format = ref false
@

<<function Cmd_status.print_status_short>>=
let print_status_short st =
  raise Todo
@


<<function Cmd_status.print_status_long>>=
let print_status_long st =
  if st.staged <> []
  then begin
    pr "Changes to be committed:";
(*  (use "git reset HEAD <file>..." to unstage) *)
    pr "";
    st.staged |> List.iter print_change_long;
    pr "";
  end;
  if st.unstaged <> []
  then begin
    pr "Changes not staged for commit:";
    pr "";
(*
  (use "git add/rm <file>..." to update what will be committed)
  (use "git checkout -- <file>..." to discard changes in working directory)
*)

    st.unstaged |> List.iter print_change_long;
    pr "";
  end;
  if st.untracked <> []
  then begin
    pr "Untracked files:";
(*  (use "git add <file>..." to include in what will be committed) *)
    pr "";
    st.untracked |> List.iter (fun file ->
      pr (spf "	%s" file)
    );
    pr "";
  end
@

<<type Cmd_status.status>>=
type status = {
  (* diff index vs HEAD *)
  staged: Change.t list;
  (* diff worktree vs index *)
  unstaged: Change.t list;
  (* other *)
  untracked: Common.filename list;
}
@


<<function Cmd_status.print_change_long>>=
(* very similar to Cmd_log.print_change, but with more indentation *)
let print_change_long change =
  match change with
  | Change.Add entry ->
    pr (spf "	new file:	%s" entry.Change.path)
  | Change.Del entry ->
    pr (spf "	deleted:	%s" entry.Change.path)
  | Change.Modify (entry1, entry2) ->
    pr (spf "	modified:	%s" entry1.Change.path)
@


<<function Cmd_status.status_of_repository>>=
let status_of_repository r =
  { staged = changes_index_vs_HEAD r;
    unstaged = 
      Changes.changes_worktree_vs_index 
        (Repository.read_blob r)
        r.Repository.worktree 
        r.Repository.index;
    untracked = untracked r;
  }
@


\subsection{Staged modifications}
%Comparing the index to the [[HEAD]] (

<<function Cmd_status.changes_index_vs_HEAD>>=
let changes_index_vs_HEAD r =
  let commitid = Repository.follow_ref_some r (Refs.Head) in
  let commit = Repository.read_commit r commitid in
  let treeid = commit.Commit.tree in
  Changes.changes_index_vs_tree (Repository.read_tree r) 
    r.Repository.index
    treeid
@

<<signature Changes.changes_index_vs_tree>>=
(* for git status (to compare index vs HEAD) *)
val changes_index_vs_tree:
  (Tree.hash -> Tree.t) ->
  Index.t -> Tree.hash -> Change.t list
@
<<function Changes.changes_index_vs_tree>>=
(* some commonalities with Repository.set_worktree_and_index_to_tree *)
let changes_index_vs_tree read_tree index treeid =
  let tree = read_tree treeid in

  let h_in_index_and_head = Hashtbl.create 101 in
  let hindex = 
    index 
    |> List.map (fun entry -> entry.Index.name, entry)
    |> Hashtbl_.of_list
  in
  let changes = ref [] in

  tree |> Tree.walk_tree read_tree "" (fun relpath entry_head ->
    let perm = entry_head.Tree.perm in
    match perm with
    | Tree.Dir -> ()
    | Tree.Commit -> failwith "submodule not yet supported"
    | Tree.Normal | Tree.Exec | Tree.Link ->
      try
        let entry_index = Hashtbl.find hindex relpath in
        Hashtbl.add h_in_index_and_head relpath true;
        (* less: if change mode, then report as del/add *)
        if entry_head.Tree.id <> entry_index.Index.id
        then changes |> Common.push (Change.Modify (
          { Change.path = relpath; 
            mode = Index.mode_of_perm perm; 
            content = lazy (raise (Impossible "not called")); },
          { Change.path = relpath; 
            mode = entry_index.Index.stats.Index.mode;
            content = lazy (raise (Impossible "not called")); }
        ))
      with Not_found ->
        changes |> Common.push (Change.Del { Change.
             path = relpath;
             mode = Index.mode_of_perm perm;
             content = lazy (raise (Impossible "not called"));
                                           });
  );
  index |> List.iter (fun entry ->
    if not (Hashtbl.mem h_in_index_and_head entry.Index.name)
    then changes |> Common.push (Change.Add { Change.
             path = entry.Index.name;
             mode = entry.Index.stats.Index.mode;                                            content = lazy (raise (Impossible "not called")); }
    )
  );
  (* less: sort by path *)
  List.rev !changes
@


\subsection{Unstaged modifications}
%Comparing the worktree to the index (

\l should also put delete (D) or modified (M) information here


\subsection{Untracked files}
% Finding files in worktree and not in the index ()

<<function Cmd_status.untracked>>=
(* todo: need parse .gitignore *)
let untracked r =
  let h = r.Repository.index 
      |> List.map (fun entry -> entry.Index.name, true) 
      |> Hashtbl_.of_list 
  in
  let res = ref [] in
  r.Repository.worktree |> Repository.walk_dir (fun dir dirs files ->
    files |> List.iter (fun file ->
      let path = Filename.concat dir file in
      let path = 
        if path =~ "^\\./\\(.*\\)"
        then Regexp_.matched1 path
        else path
      in
      if not (Hashtbl.mem h path)
      then Common.push path res
    );
  );
  List.rev !res
@

% what about .ignore?


\chapter{Exchanging}
% Collaborating?

% In centralized, when you commit it also "publish" to central repo
% for other to see. In distributed, commit and publish are decoupled.
% You commit and then you push somewhere.


% Pulling requires merging. When you diverge on master from the remote,
% then pulling is similar to merging where master and origin/master
% are 2 different branches.
% See my little experiment:
% master/home/pad/tmp/t2 $ git log --graph --oneline --decorate --all
% *   4960dcf (HEAD, master) Merge branch 'master' of /home/pad/tmp/t1
% |\  
% | * 1d0c911 (origin/master, origin/HEAD) log3
% * |   764e0b2 merge
% |\ \  
% | |/  
% | * 1d6cb05 log2
% * | 54b0dbb t2log1
% |/  
% * 60b5161 log1

%master/home/pad/tmp/t1 $ git log --graph --oneline --decorate --all
%*   4960dcf (HEAD, master) Merge branch 'master' of /home/pad/tmp/t1
%|\  
%| * 1d0c911 log3
%* |   764e0b2 merge
%|\ \  
%| |/  
%| * 1d6cb05 log2
%* | 54b0dbb t2log1
%|/  
%* 60b5161 log1

% Note that usually pull from a repo that has more stuff than you,
% but it's not always the case, so the code below must handle both cases
% (e.g., compute top_commons)

% Note that sha1 allow global namespace! can safely pull commits
% from someone else, can know if same because sha1!!

\section{Pulling updates from another repository: [[git pull]]}

% saw get_transport_and_path before in core DS and its default
% implem to LocalGitClient

% why return path and client, could embed path information
% in client already.

% determine_wants is about which refs to fetch. Get all remote_refs
% as arguments and returned the sha of the one to fetch (usually
% the one for HEAD)

\t this assumes no merge needed?

% Flow is to set the starting refs you want to fetch from,
% then compute common commits and missing commits by walking graph
% of commits on target repo and comparing to commits from source repo.
% find all missing objects needed by those commits.


<<constant Cmd_pull.cmd>>=
let cmd = { Cmd.
  name = "pull";
  help = " [options] [<url repository>]";
  options = [
  ];
  f = (fun args ->
    let dst, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> 
      failwith "TODO: use remote information in config file"
    | [url] -> 
      pull dst url
    | _ -> raise Cmd.ShowUsage
  );
}
@

<<function Cmd_pull.pull>>=
(* =~ git fetch + git merge *)
let pull dst url =
  (* todo: detect if clean repo? status is empty? *)
  let client = Clients.client_of_url url in

  (* less: allow to grab from multiple heads, not just HEAD *)
  let remote_HEAD_sha = client.Client.fetch dst in
  
  (* detect if need merge, if current HEAD not parent of new HEAD *)
  let current_HEAD_sha = Repository.follow_ref_some dst (Refs.Head) in
  let ancestors_remote_HEAD = 
    Commit.collect_ancestors (Repository.read_commit dst) [remote_HEAD_sha]
      (Hashtbl.create 101)
  in
  (match () with
  | _ when remote_HEAD_sha = current_HEAD_sha -> ()
  | _ when Hashtbl.mem ancestors_remote_HEAD current_HEAD_sha ->
    (* easy case *)
    pr (spf "fast forward to %s" (Hexsha.of_sha remote_HEAD_sha));
    Repository.set_ref dst (Refs.Head) remote_HEAD_sha;
    let commit = Repository.read_commit dst remote_HEAD_sha in
    let tree = Repository.read_tree dst (commit.Commit.tree) in
    Repository.set_worktree_and_index_to_tree dst tree
  | _ -> failwith "TODO: git pull need merge"
  )
@

<<signature Repository.set_ref>>=
(* better than write_ref, will follow symbolic ref *)
val set_ref: t -> Refs.t -> Commit.hash -> unit
@
<<function Repository.set_ref>>=
let set_ref r aref newh =
  let (refs, _) = follow_ref r aref in
  let lastref = List.hd (List.rev refs) in
  let file = ref_to_filename r lastref in
  file |> with_file_out_with_lock (fun ch ->
    ch |> IO.output_channel |> IO_.with_close_out 
        (Refs.write (Refs.Hash newh))
  )
@

<<signature Client_local.mk_client>>=
val mk_client: Common.filename -> Client.t
@
<<function Client_local.mk_client>>=
let mk_client path =
  { Client.
    url = path;
    fetch = (fun dst ->
      let src = Repository.open_ path in
      fetch_objects src dst;
      (* less: all_refs *)
      Repository.follow_ref_some src Refs.Head
   );
  }
@


\subsection{Fetching objects (locally)}

% will see fetching remote later in Networking chapter.

%python: fetch will return an iterator over objects?
% so no huge memory consumption? Hmm but in PackObjectStore.add_objects
% it calls len() on it so this should trigger the computation of the
% whole list.
%ocaml: again, no need this to be in BaseRepo, can be in localGitClient

% Note that graph walker is for the target! pass so dource can know
% which one the target needs. So it's also a kind of determine_wants
% but for objects this time.

%python: iterate so add_objects can add one by one the elt, no need
% to store huge list of objects in memory.

% [[haves]] are just the top commits starting from heads in dst repo
% that the src repo has (should really be called top_commons_commits).
% Because of ack(), the graph walker does not go through the whole
% history.
% If src repo has strictly more stuff than dst, then
% [[haves]] will be the dst heads, the "frontline".


<<function Client_local.fetch_objects>>=
let fetch_objects src dst =
  (* less: determine_wants from pull command *)
  let top_wanted_commits = [Repository.follow_ref_some src Refs.Head] in
  (* less: shallows? unshallows? *)
  let top_common_commits = find_top_common_commits src dst in
  iter_missing_objects top_common_commits top_wanted_commits src 
    (fun sha1 obj_opt ->
    (* less: opti: copy raw files directly without unmarshalling/marshalling *)
    let obj = 
      match obj_opt with
      | None -> Repository.read_obj src sha1
      | Some obj -> obj
    in
    (* todo: count objects progress *)
    (* pr2 (spf "adding %s" (Hexsha.of_sha sha1)); *)
    let sha2 = Repository.add_obj dst obj in
    assert (sha1 = sha2)
  )
@



\subsubsection{Find top common commits}


% ack() will tell graph walker that there is no need to explore
% the parents of sha. So this will not iterate over the whole graph,
% just enough to find the commot frontline.

<<function Client_local.find_top_common_commits>>=
(* find the common frontline *)
let find_top_common_commits src dst =
  let top_commons = Hashtbl.create 101 in
  let walker = mk_graph_walker dst in

  let rec loop_while_sha commit_sha_opt =
    commit_sha_opt |> Common.if_some (fun commit_sha ->
      if Repository.has_obj src commit_sha
      then begin
        Hashtbl.add top_commons commit_sha true;
        walker.ack commit_sha;
      end;
      loop_while_sha (walker.next ())
    )
  in
  loop_while_sha (walker.next ());
  top_commons |> Hashtbl_.to_list |> List.map fst
@

<<signature Repository.has_obj>>=
val has_obj: t -> Sha1.t -> bool
@
<<function Repository.has_obj>>=
let has_obj r h =
  let path = h |> Hexsha.of_sha |> hexsha_to_filename r in
  Sys.file_exists path
@



% see graphwalker in next section

%\subsubsection{Determine the references wanted}
% will see some refinements later where can ask only HEAD.


\subsubsection{Find missing objects}

% haves below are set of top commits.
% wants are also set of (starting) commits (comes from refs)


\t why need ancestors of haves? they are already set of commits
% in common and so they must have all the parents too.
\l not slow to each time you fetch read and compute all
\l  the shas of all the past commits?

% put objects_to_send in triple. First is sha, second is useless?
% and third is whether this is a leaf. This is important to avoid
% reading blob objects.

<<function Client_local.iter_missing_objects>>=
let iter_missing_objects top_common_commits top_wanted_commits src f =
  (* less: split_commits_and_tags? *)
  let all_common_commits = 
    Commit.collect_ancestors (Repository.read_commit src) top_common_commits 
      (Hashtbl.create 101) in
  (* bugfix: do not forget Hashtbl.copy because collect_ancestors modify 
   * the second parameter by side effect
   *)
  let missing_commits = 
    Commit.collect_ancestors (Repository.read_commit src) top_wanted_commits 
      (Hashtbl.copy all_common_commits)
  in

  (* let's iterate over all common commits *)
  
  let dst_have_sha = Hashtbl.create 101 in
  (* less: start from second returned result from collect_ancestors?
   * common_commits different from all_ancestors in VCS.nw? 
   *)
  (* expensive loop below? so use parallel threads? *)
  all_common_commits |> Hashtbl.iter (fun commit_sha _true ->
    Hashtbl.add dst_have_sha commit_sha true;
    let commit = Repository.read_commit src commit_sha in
    collect_filetree (Repository.read_tree src) commit.Commit.tree dst_have_sha
  );

  (* and now let's iterate over all missing commits *)

  (* less: tags handling *)
  let rec missing sha is_blob = 
    if Hashtbl.mem dst_have_sha sha
    then ()
    else begin
      Hashtbl.add dst_have_sha sha true;
      (if is_blob
       then f sha None
       else begin
        let obj = Repository.read_obj src sha in
        f sha (Some obj);
        (match obj with
        | Objects.Commit commit ->
          missing commit.Commit.tree false
        | Objects.Tree tree ->
          tree |> List.iter (fun entry ->
            if entry.Tree.perm = Tree.Commit
            then failwith "submodule not supported";
            (* bugfix: it's <>, not = *)
            missing entry.Tree.id (entry.Tree.perm <> Tree.Dir)
          )
        | Objects.Blob _ ->
          raise (Impossible "is_blob guard")
        )
       end
      );
    end
  in
  missing_commits |> Hashtbl.iter (fun commit_sha _true ->
    missing commit_sha false
  )
@
\t LP split

<<function Client_local.collect_filetree>>=
let rec collect_filetree read_tree treeid have_sha =
  let tree = read_tree treeid in
  tree |> List.iter (fun entry ->
    let sha = entry.Tree.id in
    if not (Hashtbl.mem have_sha sha) then begin
      Hashtbl.add have_sha sha true;
      match entry.Tree.perm with
      | Tree.Normal | Tree.Exec | Tree.Link -> ()
      | Tree.Dir ->  collect_filetree read_tree sha have_sha
      | Tree.Commit -> failwith "submodule not supported yet"
    end
  )
@


<<signature Commit.collect_ancestors>>=
val collect_ancestors: 
  (hash -> t) ->  hash list -> (hash, bool) Hashtbl.t -> 
  (hash, bool) Hashtbl.t
@
<<function Commit.collect_ancestors>>=
(* similar to walk_history but with exposed hdone hash *)
let collect_ancestors read_commit top_commits hdone =
  let hcommits = Hashtbl.create 101 in
  let rec aux sha =
    if Hashtbl.mem hdone sha
    then ()
    else begin
      Hashtbl.add hdone sha true;
      Hashtbl.add hcommits sha true;
      let commit = read_commit sha in
      commit.parents |> List.iter aux
    end
  in
  top_commits |> List.iter aux;
  hcommits
@

\subsubsection{Iterating over objects}


\subsubsection{Adding Objects}

%\subsubsection{Shallow requests}
% advanced topic? related to graft? related to git clone --depth?


\subsection{Fetching references}

\subsubsection{Refspecs}

%https://git-scm.com/book/en/v2/Git-Internals-The-Refspec

\subsubsection{Selecting the refs}

\subsubsection{Parsing ref tuples}

\subsection{Fetching objects in a pack}

%\subsection{Diff statistics}
% nice that git pull after updating also display diffstat for each 
% updated file and the create/delete.

\section{Object store walker}

% used to explore target graph, not source graph.
% To know which (top) commits have in common with source.

\t Diff with graph walker? history walker vs object walker!

<<type Client_local.graph_walker>>=
(* will start from the heads and iterate over the ancestry of heads
 * until the caller ack that some top commits are already known and
 * do not need to be iterated furthermore.
 *)
type graph_walker = {
  next: unit -> Commit.hash option;
  ack: Commit.hash -> unit;
}
@

<<function Client_local.ml_graph_walker>>=
let (mk_graph_walker: Repository.t -> graph_walker) = fun r ->
  (* less: start just from HEAD? *)
  let heads = 
    Repository.all_refs r |> Common.map_filter (fun aref ->
      if aref =~ "refs/heads/"
      then Some (Repository.follow_ref_some r (Refs.Ref aref))
      else None
    )
  in
  let todos = ref heads in
  let todos_next_round = ref [] in
  let last_round = ref None in
  let hdone = Hashtbl.create 101 in

  { next = (fun () ->
    todos := !todos_next_round @ !todos;
    todos_next_round := [];
    match !todos with
    | [] -> None
    | x::xs ->
      todos := xs;
      Hashtbl.add hdone x true;
      last_round := Some x;
      let commit = Repository.read_commit r x in
      let parents = commit.Commit.parents in
      parents |> List.iter (fun parent ->
        if Hashtbl.mem hdone parent
        then ()
        else todos_next_round := parent::!todos_next_round;
      );
      Some x
    );

    ack = (fun commit_sha ->
      (* less: do weird loop where recurse also over parents as in dulwich? *)
      match !last_round with
      | None -> raise (Impossible "ack always after at least one next");
      | Some x ->
        if x <> commit_sha
        then raise (Impossible "'ack(x)' should follow 'x = next()'");
        (* skip those one then because parent already in common *)
        todos_next_round := []
    );
  }
@


% subtle. Will iterate over the graph from the heads,
% which can be long, but while doing so, it can be instructed to 
% skip some ancestors because the src repo already has them (via ack()),
% which is then faster.


% Why record also parents of commit? because if later ack this
% commit, then we need to filter its parents from the todos.


\section{Pushing changes to another repository: [[git push]]}

% Not really needed. The other guy can just pull from yours.
% In fact restrictions about pushing where can only push
% to a bare repository (unless --force?)

<<constant Cmd_push.cmd>>=
let cmd = { Cmd.
  name = "push";
  help = " [options] [<url repository>]";
  options = [
    (* less: --all, --force, --progress *)
  ];
  f = (fun args ->
    let src, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> 
      failwith "TODO: use remote information in config file"
    | [url] -> 
      push src url
    | _ -> raise Cmd.ShowUsage
  );
}
@

<<function Cmd_push.push>>=
(* =~ git fetch + git merge but inverting dst and src  *)
let push src_repo url_dst =
  let url = src_repo.Repository.worktree in
  let dst = Repository.open_ url_dst in
  (* todo: detect if clean repo? status is empty? *)
  let client = Clients.client_of_url url in


  (* less: allow to grab from multiple heads, not just HEAD *)
  let remote_HEAD_sha = client.Client.fetch dst in
  
  (* detect if need merge, if current HEAD not parent of new HEAD *)
  let current_HEAD_sha = Repository.follow_ref_some dst (Refs.Head) in
  let ancestors_remote_HEAD = 
    Commit.collect_ancestors (Repository.read_commit dst) [remote_HEAD_sha]
      (Hashtbl.create 101)
  in
  (match () with
  | _ when current_HEAD_sha = remote_HEAD_sha -> ()
  | _ when Hashtbl.mem ancestors_remote_HEAD current_HEAD_sha ->
    (* easy case *)
    pr (spf "fast forward to %s" (Hexsha.of_sha remote_HEAD_sha));
    Repository.set_ref dst (Refs.Head) remote_HEAD_sha;
    let commit = Repository.read_commit dst remote_HEAD_sha in
    let tree = Repository.read_tree dst (commit.Commit.tree) in
    Repository.set_worktree_and_index_to_tree dst tree
  | _ -> failwith "TODO: git pull need merge"
  )
@

\subsection{Sending objects (locally)}
% dummy protocol?

\subsection{Sending objects in a pack}



\section{Cloning a repository: [[git clone]]}

% In the end, quite similar to git pull; we just pull everything.

<<constant Cmd_clone.cmd>>=
let cmd = { Cmd.
  name = "clone";
  help = " [options] <repo> [<dir>]";
  options = [
    (* less: --bare, --progress, --depth *)
  ];
  f = (fun args ->
    match args with
    | [url]     -> clone url "."
    | [url;dst] -> clone url dst
    | _ -> raise Cmd.ShowUsage
  );
}
@

<<function Cmd_clone.clone>>=
(* =~ git pull from scratch (itself =~ git fetch + git merge) *)
let clone url path_dst =
  let client = Clients.client_of_url url in
  
  Repository.init path_dst;
  let dst = Repository.open_ path_dst in

  (* less: allow to grab from different head? *)
  let remote_HEAD_sha = client.Client.fetch dst in
  Repository.set_ref dst (Refs.Head) remote_HEAD_sha;

  (* =~ reset index *)
  let commit = Repository.read_commit dst remote_HEAD_sha in
  let tree = Repository.read_tree dst (commit.Commit.tree) in
  Repository.set_worktree_and_index_to_tree dst tree
@


\subsection{Fetching objects}

% determine_wants is about the refs, not the objects.

\subsection{Importing references}

\t clone should import refs, not just HEAD



\chapter{Networking}

% We should not need that code below. Should mount fs with NFS or sshfs
% or a plan9 fileserver or whatever and then simply use LocalGitClient!

% Distributed VCS! 
% for pull and push you can pass a URL!


% ssh and http in adv topics.
% in this chapter we will focus on git://


<<[[Clients.client_of_url()]] match url cases>>=
(* less: should use URL parsing library *)
| s when s =~ "^git://" -> 
  Client_git.mk_client url
@

\section{[[git://]] protocol}

% smart vs dumb protocol.

%https://github.com/blog/809-git-dumb-http-transport-to-be-turned-off-in-90-days


% pkt line. Show example of session


\subsection{Reading}


\subsection{Writing}

\section{Capabilities}
\l adv topics? or hard to avoid because first _connect return
\l  refs and capabilities

% see Adv topics.


\section{[[git://]] client}

%\subsection{Local client}
% seen before, can be used for NFS too!

%\subsection{[[git://]]}

<<signature Client_git.mk_client>>=
val mk_client: Common.filename -> Client.t
@
<<function Client_git.mk_client>>=
let mk_client url =
  raise Todo
@


\subsection{Fetching remote objects}

% so pass the target graph walker and way to write on target to
% client fetch_pack

\subsection{Fetching pack files}


% pack_data is target add_pack f.write()

%flow:
%  get remote refs, determine wants, tell wants, get objects and pack_data


% ask git-upload-pack service!

\subsubsection{[[read_pkt_refs()]]}

\subsubsection{[[_handle_upload_pack_head()]]}


\subsubsection{[[_handle_upload_pack_tail()]]}


\subsection{Sending pack files}


\section{[[git://]] server}


%\subsection{[[TCPGitServer]]}

%\subsection{[[FileSystemBackend]]}

%\subsection{[[Handler]]}

\subsection{[[git-upload-pack]]}
% when pull


\subsection{[[git-receive-pack]]}
% when push


\chapter{Debugging Support}

%trans:
% not only manage changes, go to past versions.
% Can also help debug issues.

\section{Identifying the version of a buggy program}

% Useful to get version from binary version!
% RCS had this with $Id$ and ident program.

% Git does not support $Id: as in CVS.
% Alternative?? 
% No $Log:, but anyway can use git log.
% other useful keywords?

\section{Finding the buggy diff: [[git bisect]]}
% great tool, I should use it more, but requires discipline
% and good commits with good hooks

% How goes when multiple paths between 2 versions (diamond)?

\section{Blaming the buggy code: [[git blame]]}
% aka annotate

% great tool again. See who, why, and also see related changes!
% Can infer what to do by looking at past commit
% (see my facebook experience!)

% related: git log <path>

%\chapter{Development Support}
% Tags
% Hooks
 

\chapter{Advanced Topics}

\section{Bytes versus ASCII versus UTF-8}
% Encoding.

% Git doc says git is agnostic to encoding. Just treat filenames
% and file content as bytes. But for commit messages, assume utf8,
% if not then have to specify an encoding commit tag?

% Why need speak about encoding early?
% Can not just use bytes everywhere? filenames mentionned in
% tree objects are utf8? the content of blob might be utf8 but we do not care.


\section{Reliability and signals}

% First, immutable object store and order of operation (a la ext2fs?)
% leaves state of repo in consistent state always!
% Only tricky part is update references! and done via lock to be atomic.

% What if C-c in middle of operations?
% Handled by atomic ref update?

\section{Advanced features}

\subsection{Tags}

% Why need tags? Why not simply refs?
% Because refs just point to something but can not have meta-data.
% If you dont want to give any comment about a version and that
% its name is enough, then you just need a ref. Otherwise
% you need a ref to an object (container) containing itself
% ref to a version and metadata: The tag.

% As opposed to a ref (or branch), it always refer to the same commit!
% Just a name to a commit. Also can have a description text.

% Can do tags by abusing refs/tags/xxx. In fact in pfff seems like
% github did that to create tags ...

\subsubsection{[[Tag.t]]}

<<[[Objects.t]] cases>>=
(*  | Tag of Tag.t *)
@

<<[[Repository.objectish]] cases>>=
(* ObjByTag *)
@

\subsubsection{IO}

<<[[Objects.read()]] match str cases>>=
(* "tag" -> Tag (Tag.read raw) *)
@

<<[[Objects.write()]] match obj cases>>=
@
<<[[Objects.write()]] return header, match obj cases>>=
@

<<[[Cmd_show.show()]] match obj cases>>=
@

\subsubsection{[[git tag]]}

% to create, list, delete

\subsubsection{[[git clone]] and tags}
% should import tags

\subsubsection{[[git pull]] and tags}
% should split_commit_and_tags (see dulwich)

\subsection{Reflog}

% quite simple, just an history of the content of a ref.
% So very meta, refs allow to access the history of files,
% and the refs themselves have an history.
% so .git/logs/HEAD will contain the different values of HEAD
% so when you switch branch, when you commit, etc., all of that
% will generate different entries there.

% but code of dulwich does not maintain reflog. When you
% update a ref, it should update the reflog of this ref!


\subsection{Stash}
% again, just a ref?

\subsubsection{[[git stash]]}
% pretty useful in the end

\subsection{Grafts}

% I used this feature to represent the full history of Linux from 0.01 to 2.6!

\subsubsection{Reading a graft file}

\subsubsection{Writing a graft file}

\subsubsection{Using a graft file}


\subsection{Submodules}

%S_IFGITLINK = 0o160000
% hack to encode submodule?

<<[[Tree.perm]] cases>>=
| Commit (* ?? submodule? *)
@

<<[[Tree.perm_of_string()]] match str cases>>=
| "160000" -> Commit
@
<<[[Tree.string_of_perm()]] match perm cases>>=
| Commit -> "160000"
@


<<[[Repository.set_worktree_and_index_to_tree()]] walk tree cases>>=
| Tree.Commit -> failwith "submodule not yet supported"
@

<<[[Tree.walk_tree()]] match perm cases>>=
| Commit ->
  failwith "submodule not supported yet"
@

<<[[Repository.build_file_from_blob()]] match perm cases>>=
| Tree.Commit -> failwith "submodule not yet supported"
@


<<[[Index.mode]] cases>>=
| Gitlink (*?? submodule? *)
@

<<[[Index.read_mode()]] match [[n lsr 12]] cases>>=
| 0b1110 -> Gitlink
@
<<[[Index.write_mode()]] match mode cases>>=
| Gitlink -> 0b1110__000__000_000_000 
@

<<[[Changes.content_from_path_and_stat_index()]] match mode cases>>=
| Index.Gitlink -> failwith "submodule not supported"
@


<<[[Index.perm_of_mode()]] match mode cases>>=
| Gitlink -> Tree.Commit (* sure? *)
@
% when compute tree_of_index

<<[[Index.mode_of_perm()]] match perm cases>>=
| Tree.Commit -> Gitlink
@



\subsection{hooks: [[.git/hooks/]]}

%self.hooks['pre-commit'] = PreCommitShellHook(self.controldir())
%self.hooks['commit-msg'] = CommitMsgShellHook(self.controldir())
%self.hooks['post-commit'] = PostCommitShellHook(self.controldir())


\subsection{Configuration file: [[.git/config]]}

% ex of use:
%config = self.get_config()
%honor_filemode = config.get_boolean(
%    'core', 'filemode', os.name != "nt")

\subsubsection{Initialization}

\subsubsection{[[Config.t]]}

\subsubsection{Reading}

\subsubsection{Writing}

\subsubsection{Stacked config, [[~/.gitconfig]] and [[.git/config]]}

\subsection{Ignore file: [[.gitignore]]}

%For details for the matching rules, see https://git-scm.com/docs/gitignore

% Seems unused though ... many os.walk do not filter files based
% on information in .ignore I think.


%\section{Advanced diff capabilities}
\subsection{Rename detection}

% useful to have git log tracking a file through rename

%\subsection{Refactorings}
% Nice feature of darcs is token rename patch! So do CEs
% when merge another branch!


\section{Optimizations}

%\subsection{LRU cache}
% Needs that for?

\section{Pack files}

% kinda an optimization.
% Complex code.

%https://git-scm.com/book/en/v2/Git-Internals-Packfiles

\subsection{[[Pack.t]]}

% data and idx.

\subsection{Reading}

\subsection{Writing}

\subsection{Modifications}

\subsubsection{Object Store}

% pack dir

% loose vs pack objects

\subsubsection{Refs}

% packed refs
% peeled refs??

\subsection{Delta}

\subsection{Pack data}

%\subsection{Unpacked Object}

\subsection{Pack index}

% Diff discussed in OASA vol II section 6.7 

\subsubsection{Index pack v1}


\subsubsection{Index pack v2}

\subsection{Pack commands}

\subsubsection{[[git pack-objects]]}


\subsubsection{[[git repack]]}

\subsubsection{[[git fetch-pack]]}

% similar to git pull, but will not update the references.
\t but then lost? graph walker will not find them back?


\subsubsection{[[git receive-pack]]}

\section{Fast import and export}
% another opti? why need that?

% another way to clone a repo?
%$ git fast-export --all | (cd /empty/repository && git fast-import)

\section{Alternates}

\t ??? related to pack files?

%\section{Peeled}
% seems related to tags, so move with Tags?
%https://stackoverflow.com/questions/26492303/what-does-peel-mean-in-git

\section{Other clients}

\subsection{[[ssh://]]}

<<[[Clients.client_of_url()]] match url cases>>=
| s when s =~ "^ssh://" -> 
  failwith "ssh not supported"
@

\subsection{[[http://]]}

<<[[Clients.client_of_url()]] match url cases>>=
| s when s =~ "^http://" -> 
  failwith "http not supported"
@


\section{Other servers}

%\subsection{[[git daemon]]}

%\subsection{[[git web-daemon]]}

\subsection{[[http://]]}
% git smart http protocol

% also cgit? nice web interface to explore repo?

\section{Advanced client/server capabilities}

\subsection{Report status}
% mv in Debugging appendix?

\subsection{Quiet}

\subsection{Thin pack}

\subsection{Side band 64k}

\section{Other repository format}

\subsection{Bare repository}

% convenient when want to have a centralized repo and
% people push to it. If non-bare repo then git refuses to push
% because the index and worktree would be inconsistent.

% when git init --bare

% when objects/ directly at root, not under hidden_path (controldir).

\subsection{[[.git]] file}
% linked working tree? see docstring of commondir()


\section{Other commands}

%\subsection{[[git blame]]}
% Debugging support section

\subsection{[[git revert]]}

\subsection{[[git archive]]}
% create tarball from git repo

\subsection{[[git grep]]}
% pretty useful


\section{Plumbing commands}
% original git is plumbing vs porcelain

\subsection{[[git fetch]]}

\subsection{[[git symbolic-ref]]}

\subsection{[[git rev-list]]}
% 'git log' used to be a shell script calling git rev-list

\subsection{[[git diff-tree]]}

\subsection{[[git commit-tree]]}
%? to commit without author and commiter??

\subsection{[[git ls-tree]]}
% pretty simple.

\subsection{[[git remote add]]}

\subsection{[[git ls-remote]]}

\section{Security}

% Ownership?
% Less an issue with git because distribute VCS, so anybody
% can have own copy of entire repo (not just of work tree).
% So no need special admin of RCS/foo.c,v 

%rcs: rely on unix permission (give foo.c,v to a group) and
% can have additional access (restriction list)

% How protect who can modify a repo?
%sccs: could even limit to certain dirs or files what someone could modify

\chapter{Conclusion}






\appendix

\chapter{Debugging}

<<constant Cmds.extra_commands>>=
let extra_commands = [
  Cmd_test.cmd;
  Cmd_dump.cmd;
]
@

\section{[[ocamlgit dump]]}
% ocamlgit specific, so I specify ocamlgit
% but there is a git dump-index though.

<<constant Cmd_dump.cmd>>=
let cmd = { Cmd.
  name = "dump";
  help = " <file>";
  options = [
    "-raw", Arg.Set raw, " do not pretty print";
    "-index", Arg.Set index, " pretty print index content";
  ];
  f = (fun args ->
    match args with
    | [file] -> dump file
    | _ -> failwith (spf "dump command [%s] not supported"
                       (String.concat ";" args))
  );
}
@
\l git dump pack

<<constant Cmd_dump.raw>>=
let raw = ref false
@

<<constant Cmd_dump.index>>=
let index = ref false
@


<<function Cmd_dump.dump>>=
let dump file =
  if !index
  then dump_index file
  else dump_object file
@

<<function Cmd_dump.dump_index>>=
(* =~ dulwich dump-index, =~ git ls-files --stage *)
let dump_index file =
  let chan = open_in file in
  let input = IO.input_channel chan in
  let index = Index.read input in
  let v = Dump.vof_index index in
  pr (Ocaml.string_of_v v)
@

<<signature Dump.vof_index>>=
val vof_index: Index.t -> Ocaml.v
@
<<constant Dump.vof_index>>=
let vof_index = Index.vof_t
@



<<function Cmd_dump.dump_object>>=
(* =~ git cat-file -p *)
let dump_object file =
  let chan = open_in file in
  let input = IO.input_channel chan in
  let unzipped = Unzip.inflate input in
  
  try
    if !raw
    then 
      let str = IO.read_all unzipped in 
      pr2 str
    else begin
      let obj = Objects.read unzipped in
      let v = Dump.vof_obj obj in
      pr (Ocaml.string_of_v v)
    end
  with Unzip.Error _err ->
    failwith "unzip error"
@



<<signature Dump.vof_obj>>=
val vof_obj: Objects.t -> Ocaml.v
@
<<constant Dump.vof_obj>>=
let vof_obj = Objects.vof_t
@


\section{[[ocamlgit test]]}

<<constant Cmd_test.cmd>>=
let cmd = { Cmd.
  name = "test";
  help = " ";
  options = [];
  f = (fun args ->
    match args with
    | ["sha1"] -> test_sha1 ()
    | _ -> failwith (spf "test command [%s] not supported"
                       (String.concat ";" args))
  );
}
@

<<function Cmd_test.test_sha1>>=
(* see https://git-scm.com/book/en/v2/Git-Internals-Git-Objects *)
let test_sha1 () =
  let content = "what is up, doc?"
    (*"test content\n"  *)
  in
  let header = "blob 16\000" in
  let store = header ^ content in

  let sha = Sha1.sha1 store in
  pr (spf "len = %d, raw = %s" (String.length sha) sha);
  let hexsha = Hexsha.of_sha sha in
  pr (spf "len = %d, str = %s" (String.length hexsha) hexsha);
  ()
@


\chapter{Profiling}

\chapter{Error Management}
% centralize all errors? have a error.ml?

\chapter{Utilities}

% Common.with_file_in, IO.input_channel (channel vs IO)

\section{Binary IO}

% Not lex/yacc here for git but low-level bytes reading.

% IO.ml and a few addons in IO_.ml

<<signature IO_.with_close_out>>=
val with_close_out: ('a IO.output -> unit) -> 'a IO.output -> 'a
@
<<function IO_.with_close_out>>=
let with_close_out f ch =
  f ch;
  let res = IO.close_out ch in
  res
@

<<signature IO_.read_string_and_stop_char>>=
val read_string_and_stop_char: 
  IO.input -> char -> string
@
<<function IO_.read_string_and_stop_char>>=
let read_string_and_stop_char ch stop_char =
  let b = Buffer.create 8 in
  let rec loop() =
    let c = IO.read ch in
    if c <> stop_char then begin
      Buffer.add_char b c;
      loop();
    end;
  in
  loop();
  Buffer.contents b
@

<<signature IO_.read_int_and_nullbyte>>=
val read_int_and_nullbyte: 
  IO.input -> int
@
<<function IO_.read_int_and_nullbyte>>=
let read_int_and_nullbyte ch =
  let str = IO.read_c_string ch in
  int_of_string str
@

<<signature IO_.read_key_space_value_newline>>=
val read_key_space_value_newline: 
  IO.input -> string (* key *) -> (IO.input -> 'a) -> 'a
@
<<function IO_.read_key_space_value_newline>>=
let read_key_space_value_newline ch k f =
  let str = read_string_and_stop_char ch ' ' in
  if str <> k
  then failwith (spf 
    "read_key_space_value_newline: wrong key got %s (expecting %s)"
    str k);
  let v = f ch in
  let c = IO.read ch in
  if c <> '\n'
  then failwith "read_key_space_value_newline: wrong format, no newline";
  v
@


\chapter{Algorithms}

\section{SHA1}

<<function Sha1.sha1>>=
(* sha-1 digest. Based on pseudo-code of RFC 3174.
   Slow and ugly but does the job. *)
let sha1 s =
  let sha_1_pad s =
    let len = String.length s in
    let blen = 8 * len in
    let rem = len mod 64 in
    let mlen = if rem > 55 then len + 128 - rem else len + 64 - rem in
    let m = Bytes.create mlen in
    Bytes.blit_string s 0 m 0 len;
    Bytes.fill m len (mlen - len) '\x00';
    Bytes.set m len '\x80';
    if Sys.word_size > 32 then begin
      Bytes.set m (mlen - 8) (Char.unsafe_chr (blen lsr 56 land 0xFF));
      Bytes.set m (mlen - 7) (Char.unsafe_chr (blen lsr 48 land 0xFF));
      Bytes.set m (mlen - 6) (Char.unsafe_chr (blen lsr 40 land 0xFF));
      Bytes.set m (mlen - 5) (Char.unsafe_chr (blen lsr 32 land 0xFF));
    end;
    Bytes.set m (mlen - 4) (Char.unsafe_chr (blen lsr 24 land 0xFF));
    Bytes.set m (mlen - 3) (Char.unsafe_chr (blen lsr 16 land 0xFF));
    Bytes.set m (mlen - 2) (Char.unsafe_chr (blen lsr 8 land 0xFF));
    Bytes.set m (mlen - 1) (Char.unsafe_chr (blen land 0xFF));
    m
  in
  (* Operations on int32 *)
  let ( &&& ) = ( land ) in
  let ( lor ) = Int32.logor in
  let ( lxor ) = Int32.logxor in
  let ( land ) = Int32.logand in
  let ( ++ ) = Int32.add in
  let lnot = Int32.lognot in
  let sr = Int32.shift_right in
  let sl = Int32.shift_left in
  let cls n x = (sl x n) lor (Int32.shift_right_logical x (32 - n)) in
  (* Start *)
  let m = sha_1_pad s in
  let w = Array.make 16 0l in
  let h0 = ref 0x67452301l in
  let h1 = ref 0xEFCDAB89l in
  let h2 = ref 0x98BADCFEl in
  let h3 = ref 0x10325476l in
  let h4 = ref 0xC3D2E1F0l in
  let a = ref 0l in
  let b = ref 0l in
  let c = ref 0l in
  let d = ref 0l in
  let e = ref 0l in
  for i = 0 to ((Bytes.length m) / 64) - 1 do              (* For each block *)
    (* Fill w *)
    let base = i * 64 in
    for j = 0 to 15 do
      let k = base + (j * 4) in
      w.(j) <- sl (Int32.of_int (Char.code @@ Bytes.get m k)) 24 lor
               sl (Int32.of_int (Char.code @@ Bytes.get m (k + 1))) 16 lor
               sl (Int32.of_int (Char.code @@ Bytes.get m (k + 2))) 8 lor
               (Int32.of_int (Char.code @@ Bytes.get m (k + 3)))
    done;
    (* Loop *)
    a := !h0; b := !h1; c := !h2; d := !h3; e := !h4;
    for t = 0 to 79 do
      let f, k =
        if t <= 19 then (!b land !c) lor ((lnot !b) land !d), 0x5A827999l else
        if t <= 39 then !b lxor !c lxor !d, 0x6ED9EBA1l else
        if t <= 59 then
          (!b land !c) lor (!b land !d) lor (!c land !d), 0x8F1BBCDCl
        else
        !b lxor !c lxor !d, 0xCA62C1D6l
      in
      let s = t &&& 0xF in
      if (t >= 16) then begin
        w.(s) <- cls 1 begin
            w.((s + 13) &&& 0xF) lxor
            w.((s + 8) &&& 0xF) lxor
            w.((s + 2) &&& 0xF) lxor
            w.(s)
          end
      end;
      let temp = (cls 5 !a) ++ f ++ !e ++ w.(s) ++ k in
      e := !d;
      d := !c;
      c := cls 30 !b;
      b := !a;
      a := temp;
    done;
    (* Update *)
    h0 := !h0 ++ !a;
    h1 := !h1 ++ !b;
    h2 := !h2 ++ !c;
    h3 := !h3 ++ !d;
    h4 := !h4 ++ !e
  done;
  let h = Bytes.create 20 in
  let i2s h k i =
    Bytes.set h k (Char.unsafe_chr ((Int32.to_int (sr i 24)) &&& 0xFF));
    Bytes.set h (k + 1) (Char.unsafe_chr ((Int32.to_int (sr i 16)) &&& 0xFF));
    Bytes.set h (k + 2) (Char.unsafe_chr ((Int32.to_int (sr i 8)) &&& 0xFF));
    Bytes.set h (k + 3) (Char.unsafe_chr ((Int32.to_int i) &&& 0xFF));
  in
  i2s h 0 !h0;
  i2s h 4 !h1;
  i2s h 8 !h2;
  i2s h 12 !h3;
  i2s h 16 !h4;
  Bytes.unsafe_to_string h
@

\section{Unzip}

% entry point:
<<signature Unzip.inflate>>=
val inflate : ?header:bool -> IO.input -> IO.input
(** wrap an input using "inflate" decompression algorithm. raises [Error] if
  an error occurs (this can only be caused by malformed input data). *)
@



<<type Unzip.huffman>>=
type huffman =
  | Found of int
  | NeedBit of huffman * huffman
  | NeedBits of int * huffman array
@

<<type Unzip.adler32>>=
type adler32 = {
  mutable a1 : int;
  mutable a2 : int;
}
@

<<type Unzip.window>>=
type window = {
  mutable wbuffer : bytes;
  mutable wpos : int;
  wcrc : adler32;
}
@

<<type Unzip.state>>=
type state =
  | Head
  | Block
  | CData
  | Flat
  | Crc
  | Dist
  | DistOne
  | Done
@

<<type Unzip.t>>=
type t = {
  mutable znbits : int;
  mutable zbits : int;
  mutable zstate : state;
  mutable zfinal : bool;
  mutable zhuffman : huffman;
  mutable zhuffdist : huffman option;
  mutable zlen : int;
  mutable zdist : int;
  mutable zneeded : int;
  mutable zoutput : bytes;
  mutable zoutpos : int;
  zinput : IO.input;
  zlengths : int array;
  zwindow : window;
}
@

<<type Unzip.error_msg>>=
type error_msg =
  | Invalid_huffman
  | Invalid_data
  | Invalid_crc
  | Truncated_data
  | Unsupported_dictionary
@

<<exception Unzip.Error>>=
exception Error of error_msg
@

<<function Unzip.error>>=
let error msg = raise (Error msg)
@

<<function Unzip.tree_depth>>=
let rec tree_depth = function
  | Found _ -> 0
  | NeedBits _ -> assert false
  | NeedBit (a,b) ->
    1 + min (tree_depth a) (tree_depth b)
@

<<function Unzip.tree_compress>>=
let rec tree_compress t =
  match tree_depth t with
  | 0 -> t
  | 1 ->
    (match t with
    | NeedBit (a,b) -> NeedBit (tree_compress a,tree_compress b)
    | _ -> assert false)
  | d ->
    let size = 1 lsl d in
    let tbl = Array.make size (Found (-1)) in
    tree_walk tbl 0 0 d t;
    NeedBits (d,tbl)

and tree_walk tbl p cd d = function
  | NeedBit (a,b) when d > 0 ->
    tree_walk tbl p (cd + 1) (d-1) a;
    tree_walk tbl (p lor (1 lsl cd)) (cd + 1) (d-1) b;
  | t ->
    Array.set tbl p (tree_compress t)
@

<<function Unzip.make_huffman>>=
let make_huffman lengths pos nlengths maxbits =
  let counts = Array.make maxbits 0 in
  for i = 0 to nlengths - 1 do
    let p = Array.unsafe_get lengths (i + pos) in
    if p >= maxbits then error Invalid_huffman;
    Array.unsafe_set counts p (Array.unsafe_get counts p + 1);
  done;
  let code = ref 0 in
  let tmp = Array.make maxbits 0 in
  for i = 1 to maxbits - 2 do
    code := (!code + Array.unsafe_get counts i) lsl 1;
    Array.unsafe_set tmp i !code;
  done;
  let bits = Hashtbl.create 0 in
  for i = 0 to nlengths - 1 do
    let l = Array.unsafe_get lengths (i + pos) in
    if l <> 0 then begin
      let n = Array.unsafe_get tmp (l - 1) in
      Array.unsafe_set tmp (l - 1) (n + 1);
      Hashtbl.add bits (n,l) i;
    end;
  done;
  let rec tree_make v l =
    if l > maxbits then error Invalid_huffman;
    try
      Found (Hashtbl.find bits (v,l))
    with
      Not_found ->
        NeedBit (tree_make (v lsl 1) (l + 1) , tree_make (v lsl 1 lor 1) (l + 1))
  in
  tree_compress (NeedBit (tree_make 0 1 , tree_make 1 1))
@

<<function Unzip.adler32_create>>=
let adler32_create() = {
  a1 = 1;
  a2 = 0;
}
@

<<function Unzip.adler32_update>>=
let adler32_update a s p l =
  let p = ref p in
  for i = 0 to l - 1 do
    let c = int_of_char (Bytes.unsafe_get s !p) in
    a.a1 <- (a.a1 + c) mod 65521;
    a.a2 <- (a.a2 + a.a1) mod 65521;
    incr p;
  done
@

<<function Unzip.adler32_read>>=
let adler32_read ch =
  let a2a = IO.read_byte ch in
  let a2b = IO.read_byte ch in
  let a1a = IO.read_byte ch in
  let a1b = IO.read_byte ch in
  {
    a1 = (a1a lsl 8) lor a1b;
    a2 = (a2a lsl 8) lor a2b;
  }
@

<<constant Unzip.window_size>>=
let window_size = 1 lsl 15
@

<<constant Unzip.buffer_size>>=
let buffer_size = 1 lsl 16
@

<<function Unzip.window_create>>=
let window_create size = {
    wbuffer = Bytes.create buffer_size;
    wpos = 0;
    wcrc = adler32_create()
  }
@

<<function Unzip.window_slide>>=
let window_slide w = 
  adler32_update w.wcrc w.wbuffer 0 window_size;
  let b = Bytes.create buffer_size in
  w.wpos <- w.wpos - window_size;
  Bytes.unsafe_blit w.wbuffer window_size b 0 w.wpos;
  w.wbuffer <- b
@

<<function Unzip.window_add_bytes>>=
let window_add_bytes w s p len =
  if w.wpos + len > buffer_size then window_slide w;
  Bytes.unsafe_blit s p w.wbuffer w.wpos len;
  w.wpos <- w.wpos + len
@

<<function Unzip.window_add_char>>=
let window_add_char w c =
  if w.wpos = buffer_size then window_slide w;
  Bytes.unsafe_set w.wbuffer w.wpos c;
  w.wpos <- w.wpos + 1
@

<<function Unzip.window_get_last_char>>=
let window_get_last_char w =
  Bytes.unsafe_get w.wbuffer (w.wpos - 1)
@

<<function Unzip.window_available>>=
let window_available w =
  w.wpos
@

<<function Unzip.window_checksum>>=
let window_checksum w =
  adler32_update w.wcrc w.wbuffer 0 w.wpos;
  w.wcrc
@

<<constant Unzip.len_extra_bits_tbl>>=
let len_extra_bits_tbl = [|0;0;0;0;0;0;0;0;1;1;1;1;2;2;2;2;3;3;3;3;4;4;4;4;5;5;5;5;0;-1;-1|]
@

<<constant Unzip.len_base_val_tbl>>=
let len_base_val_tbl = [|3;4;5;6;7;8;9;10;11;13;15;17;19;23;27;31;35;43;51;59;67;83;99;115;131;163;195;227;258|]
@

<<constant Unzip.dist_extra_bits_tbl>>=
let dist_extra_bits_tbl = [|0;0;0;0;1;1;2;2;3;3;4;4;5;5;6;6;7;7;8;8;9;9;10;10;11;11;12;12;13;13;-1;-1|]
@

<<constant Unzip.dist_base_val_tbl>>=
let dist_base_val_tbl = [|1;2;3;4;5;7;9;13;17;25;33;49;65;97;129;193;257;385;513;769;1025;1537;2049;3073;4097;6145;8193;12289;16385;24577|]
@

<<constant Unzip.code_lengths_pos>>=
let code_lengths_pos = [|16;17;18;0;8;7;9;6;10;5;11;4;12;3;13;2;14;1;15|]
@

<<constant Unzip.fixed_huffman>>=
let fixed_huffman = make_huffman (Array.init 288 (fun n ->
                  if n <= 143 then 8
                  else if n <= 255 then 9
                  else if n <= 279 then 7
                  else 8
                )) 0 288 10
@

<<function Unzip.get_bits>>=
let get_bits z n =
  while z.znbits < n do
    z.zbits <- z.zbits lor ((IO.read_byte z.zinput) lsl z.znbits);
    z.znbits <- z.znbits + 8;
  done;
  let b = z.zbits land (1 lsl n - 1) in
  z.znbits <- z.znbits - n;
  z.zbits <- z.zbits lsr n;
  b
@

<<function Unzip.get_bit>>=
let get_bit z =
  if z.znbits = 0 then begin
    z.znbits <- 8;
    z.zbits <- IO.read_byte z.zinput;
  end;
  let b = z.zbits land 1 = 1 in
  z.znbits <- z.znbits - 1;
  z.zbits <- z.zbits lsr 1;
  b
@

<<function Unzip.get_rev_bits>>=
let rec get_rev_bits z n =
  if n = 0 then
    0
  else if get_bit z then
    (1 lsl (n - 1)) lor (get_rev_bits z (n-1))
  else
    get_rev_bits z (n-1)
@

<<function Unzip.reset_bits>>=
let reset_bits z =
  z.zbits <- 0;
  z.znbits <- 0
@

<<function Unzip.add_bytes>>=
let add_bytes z s p l =
  window_add_bytes z.zwindow s p l;
  Bytes.unsafe_blit s p z.zoutput z.zoutpos l;
  z.zneeded <- z.zneeded - l;
  z.zoutpos <- z.zoutpos + l
@

<<function Unzip.add_char>>=
let add_char z c =
  window_add_char z.zwindow c;
  Bytes.unsafe_set z.zoutput z.zoutpos c;
  z.zneeded <- z.zneeded - 1;
  z.zoutpos <- z.zoutpos + 1
@

<<function Unzip.add_dist_one>>=
let add_dist_one z n =
  let c = window_get_last_char z.zwindow in
  let s = Bytes.make n c in
  add_bytes z s 0 n
@

<<function Unzip.add_dist>>=
let add_dist z d l =
  add_bytes z z.zwindow.wbuffer (z.zwindow.wpos - d) l
@

<<function Unzip.apply_huffman>>=
let rec apply_huffman z = function
  | Found n -> n
  | NeedBit (a,b) -> apply_huffman z (if get_bit z then b else a)
  | NeedBits (n,t) -> apply_huffman z (Array.unsafe_get t (get_bits z n))
@

<<function Unzip.inflate_lengths>>=
let inflate_lengths z a max =
  let i = ref 0 in
  let prev = ref 0 in
  while !i < max do
    match apply_huffman z z.zhuffman with
    | n when n <= 15 ->
      prev := n;
      Array.unsafe_set a !i n;
      incr i
    | 16 ->
      let n = 3 + get_bits z 2 in
      if !i + n > max then error Invalid_data;
      for k = 0 to n - 1 do
        Array.unsafe_set a !i !prev;
        incr i;
      done;
    | 17 ->
      let n = 3 + get_bits z 3 in
      i := !i + n;
      if !i > max then error Invalid_data;
    | 18 ->
      let n = 11 + get_bits z 7 in
      i := !i + n;
      if !i > max then error Invalid_data;
    | _ ->
      error Invalid_data
  done
@

<<function Unzip.inflate_loop>>=
let rec inflate_loop z =
  match z.zstate with
  | Head ->
    let cmf = IO.read_byte z.zinput in
    let cm = cmf land 15 in
    let cinfo = cmf lsr 4 in
    if cm <> 8 || cinfo <> 7 then error Invalid_data;
    let flg = IO.read_byte z.zinput in
    (*let fcheck = flg land 31 in*)
    let fdict = flg land 32 <> 0 in
    (*let flevel = flg lsr 6 in*)
    if (cmf lsl 8 + flg) mod 31 <> 0 then error Invalid_data;
    if fdict then error Unsupported_dictionary;
    z.zstate <- Block;
    inflate_loop z
  | Crc ->
    let calc = window_checksum z.zwindow in
    let crc = adler32_read z.zinput in
    if calc <> crc then error Invalid_crc;
    z.zstate <- Done;
    inflate_loop z
  | Done ->
    ()
  | Block ->
    z.zfinal <- get_bit z;
    let btype = get_bits z 2 in
    (match btype with
    | 0 -> (* no compression *)
      z.zlen <- IO.LittleEndian.read_ui16 z.zinput;
      let nlen = IO.LittleEndian.read_ui16 z.zinput in
      if nlen <> 0xffff - z.zlen then error Invalid_data;
      z.zstate <- Flat;
      inflate_loop z;
      reset_bits z
    | 1 -> (* fixed Huffman *)
      z.zhuffman <- fixed_huffman;
      z.zhuffdist <- None;
      z.zstate <- CData;
      inflate_loop z
    | 2 -> (* dynamic Huffman *)
      let hlit = get_bits z 5 + 257 in
      let hdist = get_bits z 5 + 1 in
      let hclen = get_bits z 4 + 4 in
      for i = 0 to hclen - 1 do
        Array.unsafe_set z.zlengths (Array.unsafe_get code_lengths_pos i) (get_bits z 3);
      done;
      for i = hclen to 18 do
        Array.unsafe_set z.zlengths (Array.unsafe_get code_lengths_pos i) 0;
      done;
      z.zhuffman <- make_huffman z.zlengths 0 19 8;
      let lengths = Array.make (hlit + hdist) 0 in
      inflate_lengths z lengths (hlit + hdist);
      z.zhuffdist <- Some (make_huffman lengths hlit hdist 16);
      z.zhuffman <- make_huffman lengths 0 hlit 16;      
      z.zstate <- CData;
      inflate_loop z
    | _ ->
      error Invalid_data)
  | Flat ->
    let rlen = min z.zlen z.zneeded in
    let str = IO.nread z.zinput rlen in
    let len = Bytes.length str in
    z.zlen <- z.zlen - len;
    add_bytes z str 0 len;
    if z.zlen = 0 then z.zstate <- (if z.zfinal then Crc else Block);
    if z.zneeded > 0 then inflate_loop z
  | DistOne ->
    let len = min z.zlen z.zneeded in
    add_dist_one z len;
    z.zlen <- z.zlen - len;
    if z.zlen = 0 then z.zstate <- CData;
    if z.zneeded > 0 then inflate_loop z
  | Dist ->
    while z.zlen > 0 && z.zneeded > 0 do
      let len = min z.zneeded (min z.zlen z.zdist) in
      add_dist z z.zdist len;
      z.zlen <- z.zlen - len;
    done;
    if z.zlen = 0 then z.zstate <- CData;
    if z.zneeded > 0 then inflate_loop z
  | CData ->
    match apply_huffman z z.zhuffman with
    | n when n < 256 ->
      add_char z (Char.unsafe_chr n);
      if z.zneeded > 0 then inflate_loop z
    | 256 ->
      z.zstate <- if z.zfinal then Crc else Block;
      inflate_loop z
    | n ->
      let n = n - 257 in
      let extra_bits = Array.unsafe_get len_extra_bits_tbl n in
      if extra_bits = -1 then error Invalid_data;
      z.zlen <- (Array.unsafe_get len_base_val_tbl n) + (get_bits z extra_bits);
      let dist_code = (match z.zhuffdist with None -> get_rev_bits z 5 | Some h -> apply_huffman z h) in
      let extra_bits = Array.unsafe_get dist_extra_bits_tbl dist_code in
      if extra_bits = -1 then error Invalid_data;
      z.zdist <- (Array.unsafe_get dist_base_val_tbl dist_code) + (get_bits z extra_bits);
      if z.zdist > window_available z.zwindow then error Invalid_data;
      z.zstate <- (if z.zdist = 1 then DistOne else Dist);
      inflate_loop z
@

<<signature Unzip.inflate_data>>=
val inflate_data : t -> bytes -> int -> int -> int
@
<<function Unzip.inflate_data>>=
let inflate_data z s pos len =
  if pos < 0 || len < 0 || pos + len > Bytes.length s then invalid_arg "inflate_data";
  z.zneeded <- len;
  z.zoutpos <- pos;
  z.zoutput <- s;
  try
    if len > 0 then inflate_loop z;
    len - z.zneeded
  with
    IO.No_more_input -> error Truncated_data
@

<<signature Unzip.inflate_init>>=
val inflate_init : ?header:bool -> IO.input -> t
@
<<function Unzip.inflate_init>>=
let inflate_init ?(header=true) ch = 
  {
    zfinal = false;
    zhuffman = fixed_huffman;
    zhuffdist = None;
    zlen = 0;
    zdist = 0;
    zstate = (if header then Head else Block);
    zinput = ch;
    zbits = 0;
    znbits = 0;
    zneeded = 0;
    zoutput = Bytes.empty;
    zoutpos = 0;
    zlengths = Array.make 19 (-1);
    zwindow = window_create (1 lsl 15)
  }
@

<<function Unzip.inflate>>=
let inflate ?(header=true) ch =
  let z = inflate_init ~header ch in
  let s = Bytes.create 1 in
  IO.create_in
    ~read:(fun() ->
      let l = inflate_data z s 0 1 in
      if l = 1 then Bytes.unsafe_get s 0 else raise IO.No_more_input
    )
    ~input:(fun s p l ->
      let n = inflate_data z s p l in
      if n = 0 then raise IO.No_more_input;
      n
    )
    ~close:(fun () ->
      IO.close_in ch
    )
@


\section{Zip}

% entry point:
<<signature Zlib.compress>>=
val compress:
  ?level: int -> ?header: bool -> 
  (bytes -> int) -> (bytes -> int -> unit) -> unit
@

<<function Zlib.compress>>=
let compress ?(level = 6) ?(header = true) refill flush =
  let inbuf = Bytes.create buffer_size
  and outbuf = Bytes.create buffer_size in
  let zs = deflate_init level header in
  let rec compr inpos inavail =
    if inavail = 0 then begin
      let incount = refill inbuf in
      if incount = 0 then compr_finish() else compr 0 incount
    end else begin
      let (_, used_in, used_out) =
        deflate zs inbuf inpos inavail outbuf 0 buffer_size Z_NO_FLUSH in
      flush outbuf used_out;
      compr (inpos + used_in) (inavail - used_in)
    end
  and compr_finish () =
    let (finished, _, used_out) =
       deflate zs inbuf 0 0 outbuf 0 buffer_size Z_FINISH in
    flush outbuf used_out;
    if not finished then compr_finish()
  in
    compr 0 0;
    deflate_end zs
@


<<exception Zlib.Error>>=
exception Error of string * string
@

<<toplevel Zlib._1>>=
let _ =
  Callback.register_exception "Zlib.Error" (Error("",""))
@

<<type Zlib.flush_command>>=
type flush_command =
    Z_NO_FLUSH
  | Z_SYNC_FLUSH
  | Z_FULL_FLUSH
  | Z_FINISH
@

<<constant Zlib.buffer_size>>=
let buffer_size = 1024
@




<<signature Zlib.compress_direct>>=
val compress_direct:
  ?level: int -> ?header: bool -> (bytes -> int -> unit) ->
  (bytes -> int -> int -> unit) * (unit -> unit)
@
<<function Zlib.compress_direct>>=
let compress_direct  ?(level = 6) ?(header = true) flush =
  let outbuf = Bytes.create buffer_size in
  let zs = deflate_init level header in
  let rec compr inbuf inpos inavail =
    if inavail = 0 then ()
    else begin
      let (_, used_in, used_out) =
        deflate zs inbuf inpos inavail outbuf 0 buffer_size Z_NO_FLUSH in
      flush outbuf used_out;
      compr inbuf (inpos + used_in) (inavail - used_in)
    end
  and compr_finish () =
    let (finished, _, used_out) =
      deflate zs (Bytes.unsafe_of_string "") 0 0
                 outbuf 0 buffer_size Z_FINISH in
    flush outbuf used_out;
    if not finished then compr_finish()
  in
  compr, compr_finish
@



<<signature Zlib.uncompress>>=
val uncompress:
  ?header: bool -> (bytes -> int) -> (bytes -> int -> unit) -> unit
@

<<function Zlib.uncompress>>=
let uncompress ?(header = true) refill flush =
  let inbuf = Bytes.create buffer_size
  and outbuf = Bytes.create buffer_size in
  let zs = inflate_init header in
  let rec uncompr inpos inavail =
    if inavail = 0 then begin
      let incount = refill inbuf in
      if incount = 0 then uncompr_finish true else uncompr 0 incount
    end else begin
      let (finished, used_in, used_out) =
        inflate zs inbuf inpos inavail outbuf 0 buffer_size Z_SYNC_FLUSH in
      flush outbuf used_out;
      if not finished then uncompr (inpos + used_in) (inavail - used_in)
    end
  and uncompr_finish first_finish =
    (* Gotcha: if there is no header, inflate requires an extra "dummy" byte
       after the compressed stream in order to complete decompression
       and return finished = true. *)
    let dummy_byte = if first_finish && not header then 1 else 0 in
    let (finished, _, used_out) =
       inflate zs inbuf 0 dummy_byte outbuf 0 buffer_size Z_SYNC_FLUSH in
    flush outbuf used_out;
    if not finished then uncompr_finish false
  in
    uncompr 0 0;
    inflate_end zs
@

\section{Diff}

% \cite{James and McIlroy - 1976}
% \cite{Myers - 19??}

%https://blog.jcoglan.com/2017/02/12/the-myers-diff-algorithm-part-1/
\t use regular types

<<type Diff_myers.common>>=
(** an element of lcs of seq1 and seq2 *)
type 'a common =
  [ `Common of int * int * 'a ]
@

<<type Diff_myers.edit>>=
(** an element of diff of seq1 and seq2. *)
type 'a edit =
  [ `Added of int * 'a
  | `Removed of int * 'a
  | 'a common
  ]
@

<<signature Diff_myers.SeqType>>=
module type SeqType = sig
  type t
  (** The type of the sequence. *)

  type elem
  (** The type of the elements of the sequence. *)

  val get : t -> int -> elem
  (** [get t n] returns [n]-th element of the sequence [t]. *)

  val length : t -> int
  (** [length t] returns the length of the sequence [t]. *)
end
(** Input signature of {!Diff.Make}. *)
@

<<signature Diff_myers.S>>=
module type S = sig
  type t
  (** The type of input sequence. *)

  type elem
  (** The type of the elemenents of result / input sequence. *)

  val lcs :
      ?equal:(elem -> elem -> bool) ->
      t -> t -> elem common list
  (**
     [lcs ~equal seq1 seq2] computes the LCS (longest common sequence) of
     [seq1] and [seq2].
     Elements of [seq1] and [seq2] are compared with [equal].
     [equal] defaults to [Pervasives.(=)].

     Elements of lcs are [`Common (pos1, pos2, e)]
     where [e] is an element, [pos1] is a position in [seq1],
     and [pos2] is a position in [seq2].
   *)

  val diff :
      ?equal:(elem -> elem -> bool) ->
      t -> t -> elem edit list
  (**
     [diff ~equal seq1 seq2] computes the diff of [seq1] and [seq2].
     Elements of [seq1] and [seq2] are compared with [equal].

     Elements only in [seq1] are represented as [`Removed (pos, e)]
     where [e] is an element, and [pos] is a position in [seq1];
     those only in [seq2] are represented as [`Added (pos, e)]
     where [e] is an element, and [pos] is a position in [seq2];
     those common in [seq1] and [seq2] are represented as
     [`Common (pos1, pos2, e)]
     where [e] is an element, [pos1] is a position in [seq1],
     and [pos2] is a position in [seq2].
   *)

  val fold_left :
      ?equal:(elem -> elem -> bool) ->
      f:('a -> elem edit -> 'a) ->
      init:'a ->
      t -> t -> 'a
  (**
     [fold_left ~equal ~f ~init seq1 seq2] is same as
     [diff ~equal seq1 seq2 |> ListLabels.fold_left ~f ~init],
     but does not create an intermediate list.
   *)

  val iter :
      ?equal:(elem -> elem -> bool) ->
      f:(elem edit -> unit) ->
      t -> t -> unit
  (**
     [iter ~equal ~f seq1 seq2] is same as
     [diff ~equal seq1 seq2 |> ListLabels.iter ~f],
     but does not create an intermediate list.
   *)
end
(** Output signature of {!Diff.Make}. *)
@

<<signature Diff_myers.Make>>=
module Make :
  functor (M : SeqType) -> (S with type t = M.t and type elem = M.elem)
(** Functor building an implementation of the diff structure
    given a sequence type.  *)
@

<<module Diff_myers.Make>>=
module Make(M : SeqType) : (S with type t = M.t and type elem = M.elem) = struct
  type t = M.t
  type elem = M.elem

  let lcs ?(equal = (=)) a b =
    let n = M.length a in
    let m = M.length b in
    let mn = m + n in
    let sz = 2 * mn + 1 in
    let vd = Array.make sz 0 in
    let vl = Array.make sz 0 in
    let vr = Array.make sz [] in
    let get v i = Array.get v (i + mn) in
    let set v i x = Array.set v (i + mn) x in
    let finish () =
      let rec loop i maxl r =
        if i > mn then
          List.rev r
        else if get vl i > maxl then
          loop (i + 1) (get vl i) (get vr i)
        else
          loop (i + 1) maxl r
      in loop (- mn) 0 []
    in
    if mn = 0 then
      []
    else
      (* For d <- 0 to mn Do *)
      let rec dloop d =
        assert (d <= mn);
        (* For k <- -d to d in steps of 2 Do *)
        let rec kloop k =
          if k > d then
            dloop @@ d + 1
          else
            let x, l, r =
              if k = -d || (k <> d && get vd (k - 1) < get vd (k + 1)) then
                get vd (k + 1), get vl (k + 1), get vr (k + 1)
              else
                get vd (k - 1) + 1, get vl (k - 1), get vr (k - 1)
            in
            let x, y, l, r =
              let rec xyloop x y l r =
                if x < n && y < m && equal (M.get a x) (M.get b y) then
                  xyloop (x + 1) (y + 1) (l + 1) (`Common(x, y, M.get a x) :: r)
                else
                  x, y, l, r
              in xyloop x (x - k) l r
            in
            set vd k x;
            set vl k l;
            set vr k r;
            if x >= n && y >= m then
              (* Stop *)
              finish ()
            else
              kloop @@ k + 2
        in kloop @@ -d
      in dloop 0

  let fold_left ?(equal = (=)) ~f ~init a b =
    let ff x y = f y x in
    let fold_map f g x from to_ init =
      let rec loop i init =
        if i >= to_ then
          init
        else
          loop (i + 1) (f (g i @@ M.get x i) init)
      in loop from init
    in
    let added i x = `Added (i, x) in
    let removed i x = `Removed (i, x) in
    let rec loop cs apos bpos init =
      match cs with
      | [] ->
          init
          |> fold_map ff removed a apos (M.length a)
          |> fold_map ff added b bpos (M.length b)
      | `Common (aoff, boff, _) as e :: rest ->
          init
          |> fold_map ff removed a apos aoff
          |> fold_map ff added b bpos boff
          |> ff e
          |> loop rest (aoff + 1) (boff + 1)
    in loop (lcs ~equal a b) 0 0 init

  let diff ?(equal = (=)) a b =
    fold_left ~equal ~f:(fun xs x -> x::xs) ~init:[] a b

  let iter ?(equal = (=)) ~f a b =
    fold_left a b
      ~equal
      ~f:(fun () x -> f x)
      ~init:()
end
@


\section{Diff3}
% aka merge

\chapter{Extra Code}

\ifallcode
#include "VCS_extra.nw"
\fi

%\chapter{Changelog}
%\label{sec:changelog}

% code via mk loc = 6157 LOC (but miss advanced features of dulwich/git)
% orig VCS.nw = 6318, just lpized and few comments, 75 pages pdf
% now: =~ XX LOC so added XX LOE (Lines of explanations)
% dulwich: =~ 16 000 LOC 

\chapter{Glossary}
\label{sec:glossary}

\begin{verbatim}
VCS = Version Control System
SHA1 = Secure Hash Algorithm 1
\end{verbatim}

\chapter*{Indexes}
\addcontentsline{toc}{section}{Index}

%\chapter{References} 
\addcontentsline{toc}{section}{References}

\bibliography{../docs/latex/Principia}
\bibliographystyle{alpha}

%******************************************************************************
% Postlude
%******************************************************************************

\end{document}
