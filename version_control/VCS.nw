\documentclass[twocolumn, landscape]{report}

%******************************************************************************
% Prelude
%******************************************************************************
\newif\iffinal
\newif\ifverbose
\finaltrue\verbosefalse % see also other newif in Macros.tex

%------------------------------------------------------------------------------
%history: 
%------------------------------------------------------------------------------

%thx to LP, I changed for the better a few things:
% - have a small set of cmd_xxx.ml files 
%   (dulwich has big porcelain.py and dulwich.py files, 
%    ocaml-git has just ogit.ml,
%    git has many git-xxx.c but too many; porcelain vs plumb is useless)

%thx to this manual, I better understand VCSs (and git):
% - intuition of Torvalds for a stupid content tracker with very
%   different strategies
% - merge and MERGE_HEADS state?
% - beauty of design using SHA1 used for so many things (Graydon Hoare?)

%history LP-ization:
% * wanted to LPize camp (simplified clone of darcs, also in Haskell)
% * LPized finally dulwich (clone of git in Python)
% - skeleton, mostly copy paste of Template.nw skeleton
% - put all content of files in the Extra section, via 'pfff -lpize'
%   which also now split in chunks!
%    * function, global, struct, enum, constant, macro(actually function)
%    * [[xxx]] other fields, [[xxx]] extra fields
% - read Extra section, identify concepts, first TOC
% - distribute parts of the Extra section in the main file
% - understand main(), LP split main, improve TOC
% - understand main functions, LP split, cluster, improve TOC
% - LP split the structures, use datalog for flow to field info
% - nullify, boolify, errorify, enumify,  typeify,    scheckify, plan9ify
% - aspecify advanced features! remove useless features
% * port dulwich to OCaml thx to lpized version of dulwich
% * LPized my ocaml port of dulwich
% - TODO add figures
% - TODO add explanations

%------------------------------------------------------------------------------
% Packages
%------------------------------------------------------------------------------

\usepackage{../docs/latex/noweb}
 \noweboptions{footnotesizecode,nomargintag}
 %note: allow chunk on different pages, less white space at bottom of pages
 \def\nwendcode{\endtrivlist \endgroup}
 \let\nwdocspar=\par
\usepackage{xspace}
\usepackage{verbatim}
%note: required by noweblatexpad for the \t \l \n in this file
\usepackage{fancyvrb}
\usepackage{url}
\usepackage{hyperref}
 \hypersetup{colorlinks=true}
\usepackage[pageref]{backref}
 \def\backref{{\footnotesize cited page(s)}~}
\usepackage{booktabs} 
 \newcommand{\otoprule}{\midrule[\heavyrulewidth]}
\usepackage{graphicx}

%------------------------------------------------------------------------------
% Macros
%------------------------------------------------------------------------------
\input{../docs/latex/Macros}

%------------------------------------------------------------------------------
% Config
%------------------------------------------------------------------------------
\allcodefalse
% ifallcode is used for:
% - extra copyright 
% - file skeleton, extra signatures (stuff in Extra.nw)

\addtolength{\topmargin}{-.850in}
\addtolength{\textheight}{1.70in}

\begin{document}
%******************************************************************************
% Title
%******************************************************************************
\title{
{\Huge 
Principia Softwarica: The Version Control System ([[ocaml]])[[git]]
}\\
{version 0.1}
}

\author{
Yoann Padioleau\\
\texttt{yoann.padioleau@gmail.com}\\
\\
with code from\\
Yoann Padioleau
}
\maketitle 
\l Jelmer Vernooij, Thomas Gazagnaire

\onecolumn
\hrule
\input{../docs/latex/Copyright}
%nope: \input{../docs/latex/CopyrightPlan9}
\begin{quote}
The source code is Copyright \copyright{} 2017 Yoann Padioleau.\\
Permission is granted to copy, distribute, and/or modify the source code
under the terms of the GNU Lesser General Public License version 2.1.
\end{quote}
\hrule
\twocolumn

\begingroup
\hypersetup{linkcolor=blue}
% need to s/onecolumn/twocolumn in report.cls :) for \tableofcontents
\tableofcontents
\endgroup

%******************************************************************************
% Body
%******************************************************************************

\chapter{Introduction}

The goal of this book is to explain with full details the source code of
a {version control system}.

\section{Motivations}

Why a version control system (VCS)?
Because I think you are a better programmer if
you fully understand how things work under the hood, and
%dup: Make.nw
a VCS is one of the tools a programmer uses the most.
\n def, cos maybe not super well known term and can be confused with SCM
Indeed, VCSs manage {efficiently} changes to a file or set of files, and
programmers use them to manage the vital product of their labour: source code.

%src: SCCS paper
VCSs allow to {store} and {retrieve} past versions of a file, and to {record}
{who} made each change, {when}, {where}, and {why}.
\l Important cos program changes all the time! bugs/features/maintenance/opti
\l need 'system' to help 'control versions' otherwise chaos.
\l introduce checkin/checkout, delta so can talk about it in next section?
\l store/retrieve/track and coordinate work of multiple people.
%
VCSs are mostly used by programmers but
you can use a VCS to manage any text-based document
(e.g., the source of this book), configuration files, and even binaries.
\n e.g., images, but not good IMHO to store binaries.
\l Word/Excel/Google-Docs/Wikipedia have their own VCS.

For projects with a single developer, a VCS is useful
to keep track of changes: it allows the programmer to easily go back to
past versions if he messed things up.
\l also git grep, git bisect, git revert, git blame, ... (said later?)
%
For projects with multiple developers, a VCS is almost mandatory:
it allows programmers to collaborate with each other and 
even to work on and modify the same files concurrently.
\l also git merge, git blame, ... (said later?)


%dup: Make.nw
\l not as interesting as kernel/compiler, but necessary!
\n bootstrapping issues (said later)
\l many nice algos. interesting study.

Here are a few questions I hope this book will answer:
\begin{itemize}

%dup: Make.nw
\item What are the fundamental concepts of a VCS? 
\n repo (file db), commit (changeset), branches, version DAG
What are the core algorithms behind a VCS?
\n delta? (diff?), diff3 (merge), zip/unzip, sha1 (at least consistency check)

\item How does a VCS store efficiently multiple versions of a file?
\l store efficiently past versions of set of files
\n delta (diff), reversed-delta
%git: sha1 deduplicating (but not delta/diff really), compression,
% dedup of blob but also of (sub)trees, pack delta and compression

\item How does a VCS represent changes to a file, or changes 
to set of files? 
\n changeset tree, other?
%git: does not record change but state!
How does a VCS represent the addition, deletion, or renaming of a file?
\n CVS Attic is a mess, git simple model for rename (del/add)

\item How does a VCS allow multiple users to work on and 
modify the same files at the same time?
\l pseudo-simultaneously (CVS uses this term)
How can a VCS help coordinate the actions of multiple users?
\l concurrent development
\n locks, merge

\item How does a VCS support parallel developments in a project?
How can
some developers work on the main release, 
some developers on experimental features, and 
others on fixing bugs on previously shipped releases 
all at the same time?
What is a branch?
How does a VCS reconcile multiple branches?
%What are the differences between concurrent and parallel development?
%src: 7 concurrency book:
% - concurrent program has multiple logical threads of control. These threads
%   may or may not run in parallel (can interleave)
% - parallel program runs more quickly than a sequential program by
%   executing different parts of the computation simultaneously (in //).
%   It may or may not have more than one logical thread of control.

\item What is a merge algorithm? When is a merge safe? 
What is a merge conflict? How does a VCS resolve conflicts?
\n it does not resolve conflicts! it lets user, too complicated, ok to delegate

\end{itemize}

\t put in conclusion non-trivial adv algo and data structures seen? see comment
%data-structures (beyond list/hashtbl): (use lists, hashtbl)
% - crypto SHA1 DAG (authentificated from the root!) of commit
% - Merkel Trees (related to version DAG)
% - Huffman?
% - graph (DAG)

%algorithms (beyond search/sort): (appendix)
% - sha1
% - unzip (with huffman inside, adler32, lzh)
% - zip
% - diff
% - diff3 (aka merge)

%tags used in this file for different recurring themes::
 %git: git specific stuff in early sections
 %rcs: %cvs: %sccs: good to see alternate design decisions
 %facebook: my facebook experience using a VCS (mostly SVN -> git -> hg)
 %ocaml: ocaml-specific trick or annoyance
 %
 %toc: %trans: %dup: %example: %chunks:

\section{The version control system Git (and [[ocamlgit]])}
\label{sec:vcs-git-ocamlgit}

I will explain in this book the code of the VCS 
[[ocamlgit]]\furl{https://github.com/aryx/plan9-ocaml/tree/master/version_control}, which contains about 6200 lines of code (LOC).
\n [[gut]] shortand? meh, confusing. ocamlgit and git should have same UI.
%
As its name suggests, [[ocamlgit]] is written in OCaml and is a clone
of the popular VCS
Git\furl{https://git-scm.com/}, which is written in C.

As opposed to most books in \principia, I could not choose a \plan
program for this book because there are no \plan VCSs.
\l (they rely on fs?) /n/sources/? (said later?)
%
There are many open source \unix VCSs with different user interfaces, storage
strategies, concurrency models, or features. I will present
a few of those VCSs in Section~\ref{sec:other-vcs}.
%
For this book, I decided to base the presentation on Git because
Git is one of the most popular VCSs in the open source community.
Moreover, when coupled with the hosting website 
GitHub\furl{https://github.com}, 
Git makes it really easy for people to collaborate with each other.
\n mercurial/bitbucket, CVS/sourceforge/savannah but GitHub better interface

However, Git is a rather large project with more
than 200 000 LOC. It is impossible to present all this code
in a book of a reasonable size.
%
There are a few clones of Git written in higher-level languages than C,
for example, Dulwich\furl{https://www.dulwich.io/} written
in Python with only 16 000 LOC.
%
I could have based this book on Dulwich, but this would introduce
another language in the \principia book series in addition
to C (used in most of the books) 
and OCaml (used in the editor, web browser, and code generators books).
%
This would also in turn require to present the code of the Python interpreter,
which contains more than 170 000 lines of C code.
\n and far more of Python code (not counting test and third-party C libs)
%
Instead, I decided to port the Python code of Dulwich to OCaml, resulting
in [[ocamlgit]], and to present the code of [[ocamlgit]].
\n other ocaml clones ocaml-git (said later)
\l not as efficient as git, not as famous as Torvalds for coding style,
\l  but not too bad (bench?) and easier entry point to then look code of git.

% related book:
% - https://building-git.launchrock.com/ 


\section{Other version control systems}
\label{sec:other-vcs}
%me: manual backups -> RCS -> CVS -> PRCS -> git -> darcs -> SVN -> git -> hg

Here are a few VCSs that I considered for this book, but
which I ultimately discarded:
\begin{itemize}

\item The Revision Control System
(RCS)~\cite{rcs}\furl{https://www.gnu.org/software/rcs/}
was the first open source VCS.
\n https://en.wikipedia.org/wiki/List_of_version_control_software
%
Like its predecessor, the Source Code Control System
(SCCS)~\cite{sccs}\furl{http://sccs.sourceforge.net/},
\n RCS closed in 1982, free in 1990? (SCCS closed in 1976, free in 2006)
\n CSSC alternative OSS version of SCCS
RCS uses {\em deltas} to store efficiently the past versions of a file. 
However, RCS improves over SCCS by using {\em reverse-deltas} to 
enable the user to also retrieve quickly the last version of a file
(a recurring operation).
\l but blaming is faster with SCCS

RCS is still a reasonable choice to manage a small project
with a single developer or a small set of developers who can 
share access to a common directory 
(for example, by using NFS and symbolic links).
%
However, the use of {\em locks} in RCS to forbid multiple developers
to modify the same file and its focus on individual files make
% Mostly single file. treat files separately. Each has different version. 
%  can be used for multiple files, but abuse shell (wildcard on ,v)
%  but not really good for projects with subdirs.
RCS inadequate for large projects with many independent developers.
%
Moreover, even if RCS is very limited compared to modern VCSs like Git,
RCS still contains more than 17 500 LOC.
\n (not including testsuite, but small anyway)
\l Why? too subtle diff representation?
\n has kinda branch, and rcsmerge, and tags, but hacks
\l SRC wrapper from ESR? 


\item The Concurrent Versions System
CVS~\cite{cvs}\furl{http://www.nongnu.org/cvs/}
was the most popular VCS for over a decade
before distributed VCS (e.g., Git) took over.
%
CVS introduced a few important innovations.
\n STUG award 2003
First, CVS was designed to operate on a set of files 
at once\footnote{RCS can operate on multiple files by using shell 
wildcards, but it was not designed for it.}, 
with files possibly organized in a tree.
\n RCS cannot do that.
With CVS, you can group together related changes to a set of files 
and you can easily retrieve past versions of a whole project.
\l not atomic commit though, SVN fixed that (said later?)
\n can with RCS, with tags, or date, but again not really designed for
%
Secondly, CVS allows multiple users to work on and modify the same
files concurrently. 
CVS relies on a {\em merge} program instead of locks.
\l who commit first always succeeds and snd needs update and merge (said later)
%
Finally, CVS introduced a {\em client/server} architecture 
where a {\em repository} could be stored on a remote machine.
\n TCP/IP really made took off, but was done later, not in 1986.
When coupled with the free hosting site
Sourceforge\furl{https://sourceforge.net}, 
CVS allowed developers to easily start and collaborate on new projects.
\l but branch and parallel development is really tedious (said later?)

CVS started as a few shell scripts using RCS as a backend.
\n so did not need free version of RCS?
\n rewritten in C in 1990
However, today CVS is a very large C program with more than
80 000 LOC.
\n not third-party libs (diff/zlib/lib/os2/NT/vms) and sanity.sh
The backend file [[src/rcs.s]] contains already 9000 LOC.
\l reputed difficult to understand, hence SVN

\n I presented a bit git before so needs less intro
\item Git~\cite{git-book}\furl{https://git-scm.com} was originally created
by Linus Torvalds in 2005 to manage the source code of the Linux kernel.
It followed a series of
{\em distributed VCSs} (e.g., Arch, Monotone, Bazaar, BitKeeper) 
designed to overcome the main limitations of CVS (a {centralized VCS}).
%
Because a distributed VCS (DVCS) does not require access to a
central repository, it allows developers to work independently offline.
%
A DVCS makes it also easy and cheap to create {\em branches}
representing parallel developments, and to reconcile later those branches.
\l has to, because everybody is a branch (said later?)
\l also atomic, consistency checks! fast! done the right way!
\l peer-to-peer (said later?)

As explained in Section~\ref{sec:vcs-git-ocamlgit}, Git
is a large program with more than 200~000 LOC spread over more than 400 files
(not including the tests, GUIs, and extra contributions).
%
The first version of Git was small and contained only 1000 LOC\footnote{
\url{https://github.com/git/git/commit/e83c5163316f89bfbde7d9ab23ca2e25604af290}}.
However, it contained only a few low-level commands that were not easy to use.
This forced programmers to develop and use the extra program 
[[cogito]]\furl{http://git.or.cz/cogito/}, which
provided an extra layer of higher-level commands (called {\em porcelain}).
\l also libgit2, LOC? share code with git?

\item Mercurial~\cite{hgbook}\furl{https://www.mercurial-scm.org/}
is another popular DVCS started by another Linux kernel programmer
(Matt Mackal) in 2005.
\l after BitKeeper fiasco
It is mostly written in Python and relies only on a few C files for critical
operations. Its code is arguably easier to understand than Git
but it still contains more than 100~000 LOC spread over more than 170 files
(not including the tests, extensions, and extra contributions).
\l core of 1.0 is? maybe not that bad
\l bitbucket equivalent of github

\end{itemize}

[[ocamlgit]] is not as efficient and complete as Git or Mercurial, 
but it provides almost all of the essential features of those programs
%dup: intro/ocamlgit
for more than an order of magnitude less code (6500 LOC).
\l could bench ocamlgit vs git? also percentage commands covered in Cheat sheet?

% In the end I picked a mix between git and mercurial: git, but
% implemented in the language used for mercurial (Python)
% by the guy who apparently has been involved in bazaar :)

%industry:
% - Perforce
% - Microsoft Visual Sourcesafe
% - Rational Clearcase
% - Sun TeamWare (distributed VCS on top of SCCS), atomic updates
% - BitKeeper (main inspiration for git), followed TeamWare
%history:
% - SCCS http://sccs.sourceforge.net
%   and modern version CSSC https://www.gnu.org/software/cssc/
%other:
% - Subversion (630 000 LOC, hmm)
% - PRCS http://prcs.sourceforge.net/ P for project, better than RCS and
%   CVS for grouping. Kinda snapshot based
%other DVCSs:
% - Darcs 80 000 LOC (using literate haskell), maybe good candidate, simpler
%   model, arguably simpler than git (rebase for free?), some patch theory.
%   But code looks actually awful. Lots of boilerplate. Huge types.
% - GNU Arch (aka tla 273 000 LOC) described as very complicated by many
%   but seems like one of the first DVCS
% - Bazaar (477 000 LOC) and bazaar-NG
%   https://www.jelmer.uk/pages/bzr-a-retrospective.html
% - Monotone (99 000 LOC for 1.1), apparently good source of inspiration
%   for Git because introduced the DAG of SHA1; focused a lot on security
% - Codeville, by Bram Cohen of Bittorrent fame
% - Pijul, initially in OCaml (3000 LOC), then in Rust, but seems to have 
%   a slow development
% - Fossil??
%git alternate porcelain:
% - Gitless, a better design for git, great paper:
%   http://people.csail.mit.edu/sperezde/pre-print-oopsla16.pdf
%   (can implement this design with dulwich?)
%mini:
% - Camp is a simplified version at 6300 LOC
%   a mini Darcs. Simple? Elegant? Arguably more powerful. < 10 000 LOC.
%   Can be good opportunity also to read some haskell code. Maybe can then
%   port the code to OCaml.
% - http://benhoyt.com/writings/pygit/ 500 LOC to push to github,
%   with init/add/commit/push/status/diff/, very nice, but simplified
%   so only support toplevel files, no subdirs (so no subtree).
% - http://gitlet.maryrosecook.com/ mini git in Javascript, heavily
%   commented (but LP would be better)
% - gg 7000 LOC, but no locking, no push, and requires external diff.
%   http://www-cs-students.stanford.edu/~blynn/gg/
%   this guy also wrote a book on Git "Git Magic"
% - SRC, by raymond, wrapper around RCS
%   http://www.catb.org/esr/src/
%clones in other languages (all clones of git actually):
% - dulwich: git written in python (15000 LOC (without tests))
%   which includes some porcelain now (there is also another project
%   called gittle which is porcelain for dulwich).
%   Used by Google for some projects to provide bridge between
%   mercurial and git.
%   Originally created to offer bridge between bazaar and git by one
%   of bazaar maintainer. Based on python-git hack by James Westby.
% - git-go: git written in Go (but seems limited to archeology command)
% - JGit: git in Java
% - Git in Javascript
%    https://github.com/creationix/js-git
% - libgit(2): git in C, but reuse git code or new implem?
% - gat: git clone in haskell http://evan-tech.livejournal.com/254793.html
%   another one:
%   http://stefan.saasen.me/articles/git-clone-in-haskell-from-the-bottom-up/
%   pretty complete, nice figures, quite long
% - ocaml-git: 15 000 LOC, but  heavily functorized (to support unix 
%   but also mirage), many dependencies (mstructs, cstruct, topkg, logs)
%   and seems to be only an API to access data. No support
%   for diffs; no merge; limited porcelain.
% - Git in Ruby?
%   https://www.thestrangeloop.com/2017/re-writing-history.html

%https://en.wikipedia.org/wiki/List_of_revision_control_software
%http://www.catb.org/esr/writings/version-control/version-control.html
%http://better-scm.shlomifish.org/comparison/comparison.html

%future:
% - my semantic-vcs proposal!
%   related: https://www.semanticmerge.com/
% - gitless design  http://people.csail.mit.edu/sperezde/pre-print-oopsla16.pdf
%   that uses pygit2 (a binding to libgit2)
% - CRDTs? inspired by merge in VCS?
% - use git model for more things, like in mirage and irmin?



\section{Getting started}
\label{sec:getting-started}

To play with [[ocamlgit]], you will first need to install it
by following the instructions at~\urlinstallbis\footnote{
%bootstrap: 
As you follow the document in the Wiki, you will see that
you will need a VCS program ([[git]]) to get the source of another 
VCS program ([[ocamlgit]]).
This is similar to bootstrapping issues in compilers.
However, it is easy to avoid those issues by providing
instead an archive file of [[ocamlgit]] (e.g., [[ocamlgit-0.1.tar.gz]]).
\n and extra patches 
\l but then need wget or browser and network stack 
}.
Once installed, you can test [[ocamlgit]] under \plan or \unix with
the following commands:

\begin{verbatim}
1 $ cd /tests/
2 $ mkdir hello
3 $ cd hello/
4 $ ocamlgit init
Initialized empty Git repository in /tests/hello/.git/
5 $ echo "Hello Git" > hello.txt
6 $ ocamlgit add hello.txt
7 $ ocamlgit commit -m "first commit" 
...
\end{verbatim}
\l implicit pad author when use commit. and date?

The command in Line~4 {initializes} a new {\em repository} by
creating the appropriate {metadata} in the [[/tests/hello/.git/]]
subdirectory.
%
Line~6 then {adds} the new file [[hello.txt]] to the {\em staging area} of Git
(I will explain later in Section~\ref{sec:staging-area} what is this area).
\l same than index? no index is internal DS for managing stage area
Finally, Line~7 {\em commits} what was staged to the repository and {records}
this commit with the {message} ``first commit''.
\l and author and date?

\label{sec:git-abbrev}
In the rest of this document, I will often abbreviate 
the command [['ocamlgit']] by using instead the command [['git']].
You can even define [['git']] as an alias for [['ocamlgit']] in your shell.
Indeed, [[ocamlgit]] uses the same command-line interface
than the program [[git]]. 
Almost all [[ocamlgit]] commands are valid [[git]] commands\footnote{
The reverse is not true. [[ocamlgit]] implements only a subset of the
commands supported by [[git]].}.
When the interfaces differ, I will explicitely use [['ocamlgit']].



\section{Requirements}

Because most of this book is made of OCaml source code, 
you will need to know the 
OCaml programming language~\cite{ocaml-ref-manual} to understand it.
%
The code of [[ocamlgit]] uses only the core language of OCaml, and none
of its advanced features 
(e.g., functors, objects, labels, polymorphic variants, GADTs),
thus a knowledge of 
Caml~\cite{caml-leroy}, 
Standard ML~\cite{ml-working-programmer}, or 
any of the dialect of ML (e.g., F\#, Elm) 
should be enough to understand this book.

You do not need to know Git, or more generally any VCSs,
to understand this book.
%
However, if while reading this book you have specific questions
on the interface of Git, I suggest you to consult the man
pages of Git\furl{https://git-scm.com/docs}, 
or any of the books on Git (e.g., \cite{git-book}).


\section{About this document}
#include "../docs/latex/About.nw"

\section{Copyright}

I wrote most of the code in this document. 

<<copyright ocamlgit>>=
(* Copyright 2017 Yoann Padioleau, see copyright.txt *)
@

The code is licensed under the 
GNU Lesser General Public License version 2.1
as published by the Free Software Foundation.

%dup: intro/ocamlgit
As I said in Section~\ref{sec:vcs-git-ocamlgit},
most of the code of [[ocamlgit]] is a port in OCaml of Python code from
Dulwich\furl{https://www.dulwich.io/}, which is governed by the following
copyright:

<<dulwich license>>=
# Dulwich is dual-licensed under the Apache License, Version 2.0 and the GNU
# General Public License as public by the Free Software Foundation; version 2.0
# or (at your option) any later version. You can redistribute it and/or
# modify it under the terms of either of these two licenses.
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# You should have received a copy of the licenses; if not, see
# <http://www.gnu.org/licenses/> for a copy of the GNU General Public License
# and <http://www.apache.org/licenses/LICENSE-2.0> for a copy of the Apache
# License, Version 2.0.
@

I also sometimes took inspiration from code written by Thomas Gazagnaire 
for [[ocaml-git]]\furl{https://github.com/mirage/ocaml-git}
(another clone of Git in OCaml but intented to be used
as a library in the MirageOS ecosystem\furl{https://mirage.io/}).
\l explain more later?

<<copyright ocaml-git>>=
(*
 * Copyright (c) 2013-2017 Thomas Gazagnaire <thomas@gazagnaire.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 *)
@

\ifallcode
% Also use code from a few OCaml libraries.

<<copyright ocaml-diff-myers>>=
(*
 * Copyright (C) 2016 OOHASHI Daichi
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 * THE SOFTWARE.
 *)
@

<<copyright ocaml-hex>>=
(*
 * Copyright (c) 2015 Trevor Summers Smith <trevorsummerssmith@gmail.com>
 * Copyright (c) 2014 Thomas Gazagnaire <thomas@gazagnaire.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 *)
@

<<copyright uuidm>>=
(*
Copyright (c) 2008 Daniel C. Bünzli

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
*)
@

<<copyright ocaml-unzip>>=
(*
 * Unzip - inflate format decompression algorithm
 * Copyright (C) 2004 Nicolas Cannasse
 * Compliant with RFC 1950 and 1951
 *
 * This library is free software; you can redistribute it and/or
 * modify it under the terms of the GNU Lesser General Public
 * License as published by the Free Software Foundation; either
 * version 2.1 of the License, or (at your option) any later version,
 * with the special exception on linking described in file LICENSE.
 *
 * This library is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public
 * License along with this library; if not, write to the Free Software
 * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
 *)
@

<<copyright camlzip>>=
(***********************************************************************)
(*                                                                     *)
(*                         The CamlZip library                         *)
(*                                                                     *)
(*            Xavier Leroy, projet Cristal, INRIA Rocquencourt         *)
(*                                                                     *)
(*  Copyright 2001 Institut National de Recherche en Informatique et   *)
(*  en Automatique.  All rights reserved.  This file is distributed    *)
(*  under the terms of the GNU Lesser General Public License, with     *)
(*  the special exception on linking described in file LICENSE.        *)
(*                                                                     *)
(***********************************************************************)
@
\fi

The prose and figures are mine and are licensed under the \license.

\section{Acknowledgments}

I would like to acknowledge first the author of Dulwich,
Jelmer Vernooij, who wrote in some sense most of this book.
%dup: intro/ocamlgit intro/copyright
Indeed, I used mainly the code of Dulwich to write the code of [[ocamlgit]]. 
Dulwich provided an easier path towards understanding
the concepts and implementation of Git.
\l Also Thomas gazanaire.
%
I would like also to thank Linus Torvalds, the original author of Git,
for designing this simple but powerful VCS.
%
Many of his design decisions seem obvious
in retrospect but they are not: most VCSs chose different designs
(for the storage, 
file permissions, 
renames,
etc.)
\l snapshot-based > changeset?, SHA1 DAG (but Monotone), GMT time, etc.
which in the end are more complicated
and usually less efficient than in Git.
\l ocamlgit only 6400 LOC (C bigger but original C 1000 LOC), far more powerful 
\l than RCS 30 000, in big part due to simple but clever design of Git





\chapter{Overview}

%trans: %dup: Assembler.nw
Before showing the source code of [[ocamlgit]] in the following chapters, 
%toc: %dup: Assembler.nw
I first give an overview in this chapter of the general principles of a VCS.
I also quickly describe the command-line interface of [[ocamlgit]],
\l (and so of [[git]] too),
the format of a Git repository, and show a simple terminal session using
[[ocamlgit]] to illustrate its major features.
%dup: Assembler.nw
Finally, I define terms, explain how the code is organized, 
and more generally give the background necessary
to understand the code I will show later.

\section{Version control system principles}

% nice docs:
% - ten innovations in the history of vcs:
%    http://www.flourish.org/2011/12/astonishments-ten-in-the-history-of-version-control/
% - https://betterexplained.com/articles/a-visual-guide-to-version-control/
% - Misfits paper, great summary of essential purposes.
% - git from the bottom up intro with nice glossary
% - Mercurial chapter in AOSA book (ok)
% - Git chapter in AOSA book (meh)
% - dulwich/docs/ (very limited)

%without:
One way to understand the core principles and features of a VCS
is to see how people are struggling when they are managing
documents that evolves (e.g., source code, LaTeX files, notes) without
a VCS.

%manual backups, tarballs, email back and forth patches?
% (\footnote{how Linux done for a long time}, human VCS) :) )
% no git blame. discipline.
%src: SCCS paper
% Code changes all the time. Bugs, experimentatl features, optims.
%  not just current version but last year's (still supported) and next year!
%  maintenance old code. Chaos if no tool, if no discipline.

\l VCS vs SCM?

%toc:
% store and retrieve past versions
% track changes
% help multiple developers to collaborate

% try be general and add %git: for git instantiation of general principles
\subsection{Storing past versions}

%trans:
% first purpose of VCS is store (and also retrieve) past versions.

% Some fs can do that. in fact plan9 used that! \cite? VMS had versioned FS?
% But dedicated FS. VCS is regular tool, no need special kernel.

% Time filesystem could do that, e.g. cd /2016/01/01/project/.
% Can even be encoded efficiently (deltas backup system, deduplication).
% But need special fs. And VCS provides additional nice services
% like commit message, and git blame!! who, when, why, where!
% (but could have a history.txt file in the project,
% and also symlinks to tag version at specific time).

\subsubsection{The repository}
%\subsubsection{Metadata}

% No fs, no hidden meta-data, 
% so need use filesystem as a db.

% file version database
% metadata (RCS/,v, .git/objects/, CVS/CVSRoot and other dir or server, etc.)
% metadata and data in fact. past versions are really data.

% First, store past versions. Can go back in time if made a mistake.
% Could get that with copy, but need discipline, filename encoding
%  better organized, and storing deltas has efficiency implications. 
%update: actually git does not really use delta. really more a content tracker.
%update: actually can use delta, but for packfile.

% Different storage strategy.
% Some use per-file history [[,v]], flat dirs (.git/objects/), 
% Berkely DB (SVN), Sqlite (monotone), changesets (?)

\subsubsection{Working copy}
% working tree

% checkout, checkin

% So can use any editor to edit!
% (departure from Word/Excel where versions and editing are using same tool)

%rcs: checkout


\subsection{Tracking changes}

%trans: %dup: intro/motivations
% second is track changes. when, where, who, why each change.

% fs could do. But which granularity? let user records
% relevant change points!

\subsubsection{The commit}

%dup: intro/motivations
% who, when, what/where, and why.

% attach note to changeset.
% incredibly useful for git blame! can help find bugs, see related
% code because related changes!

% record who made change, what change, and even why! great resource.
% git blame!

%rcs: checkin

% then commit information.
%git: again use object for that. then easy to reference
% a tree version by referencing a commit id.
% Also then can have references, symbolic references.
% Also have parents! so full history on how you got there.


\subsubsection{Version identifier}

% version, revision.

% need have different versions, different version id.
%git: use simple scheme: not v1, v2, ... but sha1 of content!
% then get for free consistency checking

% release.level
% so one way to organize set of files and have changeset by having
% all developers increment release (but then need modify every file? RCS
% does not accept empty updates)

%sccs: introduced extra lettre for different customer, so 1.2.p

% 1.1, 1.2,
%git:
%  or sha1! identified by its content! file content! but can
%  also scale to set of files! or tree! or commit!
%  has some advantages.
%Also in distributed settings, how can have global identifier?
% each user need tags its version number with its name?
% another thing where sha1 is good, they are stable across machines,
% they are global!

\subsubsection{Change granularity}

% set of logical changes as an individual group (atomic).

%cvs: not atomic?

% then need to have not just version of one file (RCS) but version
% of a tree.
%git: have tree structure which references other blob id and other trees.
% if a full subtree does not change, then share reference.

% single-file history, or whole-tree history.

% - release/level discipline, so update release for all files at certain
%   point
% - use date
% - use tag

% or simply use commit id in modern VCSs :)


\subsubsection{[[diff]]}

% cite paper

% Source code is text!

% sometimes people use commit and diff and patch interchangebly.

% diff can be used especially internally in VCS to efficiently store deltas.
%git: used in pack only
% It got used after as a way to display changes? (and later for coccinelle!)

% Also by having delta
% and message associated with it help explore history. Git log, git
% blame are fantastic tool, even in single-user mode. To know
% code related to a line, the message of this patch, etc.
% Also in multi-user mode good to know the author, test plan, test
% files, coupled code, etc.
% I used it a lot to understand code at Facebook.

% Usually diff at granularity line-level. So add/delete a line are 
% the primitives
% (since SCCS). Fine granularity for source code.
% Could use char, but too big then.


\subsubsection{[[patch]]}

% diff -u, unified format.

%dual of diff. One create diff on his machine, other can apply patch on his.
% (also some fuzzy apply algorithm).

% first years of Linux was managed just with patches.
% tarballs and patches. linux-mm still use patches (quilt).

% In fact git has some commands to deal with paches contained in email
% or to generate such patches.

\subsection{Concurrent development}

%trans:
% Other role of VCS is help coordinate work of multiple developers.

% When multiple developers, may modify same file, dont want one
% to overwrite change of other. Need control access to shared
% resource, the source file.
% How?

% Then when work in groups, useful to have way to work concurrently,
% to not pass his copy and wait for the "token". Concurrent
% techniques are lock, or better optimistic and later merge.

%\subsubsection{Shared space}
%if collaborate, need shared space (hmm with DVCS no, except central repo
% sometimes)

\subsubsection{Locks}

% Simple.

% NFS symlinks

% but easy to forget to unlock, and really annoying for other.
% RCS.

% Locks make sense only with centralized model.

\subsubsection{Merging}
% optimistic merging?

% surprisingly, it works!
% CVS.
% Pseudo-simultaneously

% 3 way merge.
% cite paper?

% but need update first. 
%facebook: What if time update and time commit long
% so always another guy in the middle.

\subsubsection{Merge conflicts}

% show conflict with <<<< === >>>>

\subsection{Parallel development}

%trans:
% Finally, can help organize development.

% like concurrent, but longer time-scale. Does not expect to merge
% immediately.

\subsubsection{Branch}

% Branches are also very useful. Work on different tasks, different
% branches. Can juggle between those.

% - temp fixes (never merged)
% - parallel devel for experimental feature (may be merged)
% - real fork (may be merged)

% RCS had branches, but per-file! tedious.
% CVS got it, but complicated, because was relying on RCS.
% git far easier! because every different repo/user is a branch! because
%  distributed, so had to get merge right and fast!

% so line, then tree, then DAG.

% Saw merge before, but merge really make sense with branching.
% Useful to branch and merge. 
% Also useful for branch and merge on a peer-to-peer basis
% (networking)

\subsubsection{Merging}

% Same, but usually bigger, and can get complicated?

% Real VCS needs cheap branches and good (heuristics) merging.

%\subsection{Revision graph}
% RCS was a tree, but then when introduce real branches get merges and a DAG!
% head, tip, branch, fork, merge, root, trunk, ... lots of graph words.
%\subsubsection{A mainline} 
%\subsubsection{A tree of branches} 
%\subsubsection{A direct-acyclic graph of merges} 
\subsubsection{A direct acyclic graph of versions}
%Again, ... as in Make.nw.


% really important. linear versions, then tree, then DAG!
% Lots of terminology about graph (HEAD, tip, ...)

% Previous VCS did not record relation between changeset (which
% requires identify changeset), and so merge could also not work good?




%\subsection{Variants}
\subsection{Centralized versus distributed}
% pulling and pushing

% but in both cases pull and push.

% github kinda centralize, but still independent repo! can work offline

% decentralized so no need access permission! Can fork, work,
% commit locally, and then ask for master to merge you.

% What brings distributed then? More convenient than centralized.
% Less imposing. Nice to have everything locally. Just more general.
% Can do centralized with distributed (e.g. "main" repo on github
% is the main thing to pull from).

% When distributed, not centralized, so no need path to shared repo
% or CVSROOT and so no need concepts such as module as in CVS.
% (actually there is concept of submodule and gitlink)
% Have different projects? Use different repo! Simple.

%\subsection{Snapshot versus changeset}
% on changesets vs snapshot-based VCS
%https://web.archive.org/web/20100327150715/sourcefrog.net/weblog/software/vc/derivatives.html
% snapshot fast to go back to previous version. No delta application.
% Just copy blob!
% But blame slower with snapshot. Need explore all history.

%\subsection{Hosting}
%\subsection{Github}
% sourceforge before.
% Finally github is fantastic. Easy to setup and start sharing work.

% Before pain create repo to collaborate. Need server, start and config
% CVS server there, password, etc. Now just create on github and clone!

%\subsection{Git}
% many more concepts: index/HEAD/master/remote/sha1 but git specific



\section{[[git]] command-line interface}

%trans: %dup: Windows.nw
I just described the general principles of a VCS, 
and illustrated some of those principles with examples from RCS, CVS, or Git.
I will now focus exclusively on Git and give more details about
the interface of its command-line program: [[git]].
%dup: intro/getting-started
As I mentioned in Section~\ref{sec:git-abbrev}, the
command-line interface of [[ocamlgit]] is almost identical
to the one of the program [[git]]. This is why I will often use
[[git]] as an alias for [[ocamlgit]] in the rest of this document.

The command-line interface of [[git]] is pretty simple:
%dup: (but use git not ocamlgit this time) intro/getting-started
\begin{verbatim}
$ git
usage: git <init|add|rm|commit|branch|checkout|reset|...> [options]
% git init
Initialized empty Git repository in /tests/hello/.git/
$ git add hello.txt
$ git commit -m "first commit"
\end{verbatim}
% git <cmd> [-options] <extra arguments>
\l implicit pad author for commit? and date?

[[git]] takes first a {\em command} as its first argument and then
options and extra arguments specific to this command.
\l git uses also some common options for all its commands (but not ocamlgit)
%
For example the command 
[[init]] does not need any extra arguments, but
[[add]] requires at least the name of a file or directory, and 
[[commit]] usually requires command-line flags.
%chunks:
I will gradually describe the [[git]] commands, their
options, and implementations in the following chapters.
%alt:
\l vcs <cmd> simpler than having 10 command-line /bin programs (started by CVS?)

\section{[[hello/.git/]]}

%trans: ?
%toc:
In this section, I will give a short tutorial on Git. 
I will explain the main commands of [[git]] by using a terminal session
starting from an empty [[hello/]] directory.
%trans:
I will continue the series of commands I introduced 
in Section~\ref{sec:getting-started}.
%
I will also describe the semantics of those commands by showing
their effects on the Git metadata stored under the [[hello/.git/]] subdirectory.
%
This will hopefully help you to understand the code of
those commands I will present later.
%trans: %toc:
However, before showing this terminal session, I need to present the main
concepts behind Git, some Git-specific terminology, and
the format of the [[.git/]] repository.

\subsection{Git concepts}

%git docs:
% - https://www.kernel.org/pub/software/scm/git/docs/user-manual.html#birdview-on-the-source-code
% - https://git-scm.com/book/en/v2/Git-Internals-Plumbing-and-Porcelain
% - git v0:
%   https://github.com/git/git/commit/e83c5163316f89bfbde7d9ab23ca2e25604af290
% - git from the bottom up (great, I read it while at FB)
% - https://building-git.launchrock.com/ 
%   learn git by building your own, an expansion of a blog on git
% - https://codewords.recurse.com/issues/two/git-from-the-inside-out
% - http://eagain.net/articles/git-for-computer-scientists/
% - https://stevebennett.me/2012/02/24/10-things-i-hate-about-git/
% - Bram cohen vs torvalds on deep algo in git:
%   http://www.wincent.com/a/about/wincent/weblog/archives/2007/07/a_look_back_bra.php

%trans:
To understand how Git is implemented, and 
to some degree to learn how to use Git effectively,
you need to know the few concepts underlying Git.
%toc:
Those concepts are 
%toc:
the {object store}, 
\l (SHA1 (double DAG) Merkel Tree?)
the {reference}, and 
the {staging area}.
%
They correspond also to the main data structures
of [[ocamlgit]], which I will describe fully in Chapter~\ref{chap:core-ds}.
%toc:
The following sections will give an overview of those data structures. 

\subsubsection{Object store}

%torvalds:
To really understand Git, you need to realize that at its core,
Git is a simple {\em content-addressable storage system}.
\l stupid content tracker, as said by torvalds in his first commit
%
Given the {\em hash} of a content (Git uses SHA1 hashes, as explained below), 
Git can retrieve back quickly the full corresponding content.
%
Git internally is simply a {\em persistent hash table}, also known
as a {\em key/value store}.

\n the value
In this store, Git manipulates mainly three kinds of values, known
as {\em objects} in Git terminology (hence the term {\em object store}):
\begin{itemize}
\item A {\em blob}: to represent the content of a file

\item A {\em tree}: to assign names to blobs or other subtrees

\item A {\em commit}: to associate to a specific toplevel tree
a message, an author, a date, and zero or more {\em parent} commits

\end{itemize}

You will see another kind of objects in Section~\ref{sec:tags} with the tag.
%
In addition to those objects, Git maintains also {references}
to specific commits and an index of specific blobs as explained 
in the next sections.

%\subsubsection{SHA1 objects DAG}

\n the key
Regarding the keys of the store, Git uses the 
SHA1 algorithm~\cite{sha1,rfc3174}
to compute the hash of an object.
This algorithm associates an almost unique number of 160 bits
(which amounts to 20 bytes, or 40 digits in hexadecimal format) to 
any content of arbitrary length.
\l message digest (MD as in MD5), actually message must be < 2^64
Appendix~\ref{sec:sha1-algo} presents the code of this algorithm
and gives more information on SHA1.
%
For example, given the content [[Hello Git\n]], SHA1 will return
the number [[9f4d96d5b00d98959ea9960f069585ce42b1349a]]
in hexadecimal format.
%
Here the hashing is not very interesting because the hash is bigger
than the original content, but in practice most files under a VCS
are far bigger than 20 bytes.



SHA1 is a complex {cryptographic hash function}. It is outside
the scope of this book to explain how it works, but
what is important is that SHA1 is an almost perfect hash function:
\l gperf?
given two different content, there is an almost zero probability
that SHA1 will return the same hash number. 
Such an event is called a {\em collision}, and in practice it
should never happen.
%
Thanks to this almost perfect hash function, Git can {identify}
any content of any length with just a 20 bytes number.
%
In Git, the SHA1 of a file is similar to the {\em inode} of
a file in a filesystem (see the \book{Kernel} for more information
on filesystems and inodes)\footnote{
%torvalds:
The author of Git, Linus Torvalds, is also the author of Linux,
which explains why he chose a design inspired by filesystems.
}.
%
In the tree object, which associates names to blobs, Git
uses the SHA1 of a blob to identify this blob. In the same way,
in the commit object, Git uses the SHA1 of a tree to identify
the toplevel tree a commit refers to.
%
Figure~\ref{fig:objects-sha1-dag} presents the content of the Git objects
and their relationships after the addition of another
commit after the last command in Section~\ref{sec:getting-started}.
%
I will describe soon in Section~\ref{sec:repository-format} 
how those objects are stored on the disk

\begin{figure}[!]\centering
\begin{verbatim}
commit 19d977...-----+
|tree:               |   tree 2f092e...-------+      blob 9f4d96...+
| 2f092e... ---------+-->| hello.txt 9f4d96.--+----->| Hello Git   |
|parents:            |   +--------------------+      |             |
| None               |                            +->|             |
|Author: pad         |                            |  +-------------+
| <todo@todo>        |                            |
|Date: Fri Sep 29    |                            |
| 14:04:46 2017 -0700|                            |
|Message:            |                            |
| first commit       |                            |
+--------------------+                            |
                   ^                              |  blob 452a53...+
                   |                              |  |baaaaaaaaaa  |
commit 5d9dfe...---+---+   tree 0c4b27...-------+ |+>|aaaaaaaaaaa  |
|tree:             |   | +-+ dir1 7e8bb2...     | || |aaaaaaaaaar  |
| 0c4b27...--------+---+-+>| hello.txt 9f4d96.--+-+| +-------------+
|parents:          |   | | +--------------------+  |
| 19d977-----------+   | |                         |
|Author: pad           | |   tree 7e8bb2...-----+  |
| <todo@todo>          | +-->| bar.txt 452a53.--+--+ blob 96ea4a...+
|Date: Fri Sep 29      |     | foo.txt 96ea4a.--+--->| fooooooooo  |
| 14:26:23 2017 -0700  |     +------------------+    | oooooooooo  |
|Message:              |                             | oooooooooo  |
| second commit, subdir|                             +-------------+
+----------------------+
\end{verbatim}
\caption{Git objects relationships.}\label{fig:objects-sha1-dag}
\end{figure}
\t comment figure


\l so back to content-addressable storage, given hash xxx
\l  Git can retrieve quickly blob content.

\l similar to FS. Tree, files. But differences.
\l First DAG! blob can have multiple parents
\l  (also when add in index, some blob get multiple parents)
\l tree can refer same blob, same subtree. DAG.
\l   Like versioned FS.

\l SHA1 used for many things for Git (said later?)
\l SHA1 dedup (said later)
%torvalds:
\l SHA1 checking .not just for identify, also for checking. signature
\l   Make sure what get back what was put. Essential for VCS for torvalds
\l SHA1 to index key/value

\l git does not track changes, it track states! so very different approach
% which in the end I think simplify many things.
% snapshot-based (so fast, at potentially cost of disk space, always
% tradeoff). No delta app.

\l Stored as diffs? apparently not. Just compressed and indexed by sha.
% If same content, then same id.
% No delta (well more on this later with packing).


\subsubsection{References}
\l and the commit graph

%\subsubsection{SHA1 Commit DAG}

Commit objects are linked together, 
as shown in Figure~\ref{fig:objects-sha1-dag}
with the second commit linked to the first commit
through the [[parents]] field of the object.
%
Those links represent the history of the repository, also known
as its {\em log}.
%
Because a commit can have multiple parents 
(in the case of a {\em merge}, as explained below),
the log forms a {\em graph}, or more specifically 
a {\em direct acyclic graph} (DAG).


Figure~\ref{fig:commit-dag} shows such a graph for a series of
commits following the first two commits of Figure~\ref{fig:objects-sha1-dag}.
%
In this example, a developer {\em forked} first 
an experimental branch called [[branch1]] 
(I will explain briefly how to create a branch in
Section~\ref{sec:create-branch-tutorial}
and fully in Section~\ref{sec:create-branch})
following the second commit of Figure~\ref{fig:objects-sha1-dag}. 
%
At the same time, development on the main branch, called the 
{\em master branch} in Git terminology, continued and saw two commits:
[[commit4]] and [[commit6]].
%
The experimental branch got {\em merged} later at [[commit7]]
(I will explain in Section~\ref{sec:git-merge} how to merge branches).
This is why this commit has two parents.
%
Later on, a developer created another branch called [[experiment]] that
remained {active} and did not get merged yet; 
it follows in parallel the development of the {master branch}.

\begin{figure}[!]\centering
\begin{verbatim}
       master
+-------------------+
|commit1 (19d977...)|
+--------+----------+
         |
+--------v----------+    Fork (branch)
|commit2 (5d9dfe...)|----------+
+--------+----------+          |
         |             branch1 |
         |            +--------v-------+
 +-------v--------+   |    commit3     |
 |    commit4     |   +--------+-------+
 +-------+--------+            |
         |            +--------v-------+
 +-------v--------+   |    commit5     |
 |    commit6     |   +-------+--------+
 +-------+--------+           |
         |                    |
 +-------v--------+           |
 |commit7 (merge) |<----------+
 +-------+--------+          Merge
         |
 +-------v--------+     Fork (branch)            -
 |    commit8     |---------------+
 +-------+--------+<------refs/remotes/origin/master
         |                        |
 +-------v--------+               |
 |    commit10    |     experiment|
 +----------------+         +-----+->-------+
         ^                  |    commit9    |
         |                  +---------------+
         |                          ^
         |                          |
 refs/heads/master          refs/heads/experiment
          ^
           \------\
                   \
                   HEAD
\end{verbatim}
\caption{Commit graph and references.}\label{fig:commit-dag}
\end{figure}

% branches, fork, and then merge!
\l second DAG. commit can have multiple parents

%trans: %dup: overview/hello.git/concepts/content-addressable
As I mentionned briefly in the previous section, 
Git maintains, in addition to the object store, {\em references} to
specific commit objects. 
%
Those references have a {\em name} and a {\em content}.
%
For example, in Figure~\ref{fig:commit-dag}, the reference named
[[refs/heads/experiment]]
points to the last commit of the [[experiment]] branch, and so
its content is the SHA1 of the [[commit9]] object.
%
I will explain in Section~\ref{sec:repository-format} how
Git stores those references on the disk.

Git maintains also a {special reference} called the {\em HEAD}
which points to the last commit of the {\em current branch}.
Its content is usually not a SHA1 but the name of another reference.
%
By default, [[HEAD]] points to the master branch, as shown at the bottom of
Figure~\ref{fig:commit-dag}, and so its content is
the string [[ref: refs/heads/master]]
(and [[refs/heads/master]] contains the SHA1 of the last 
commit of the master branch).
%
When you switch branch
(I will explain how to switch branch briefly in 
Section~\ref{sec:switch-branch-tutorial:} and fully in 
Section~\ref{sec:switch-branch}),
the content of the [[HEAD]] will change.


All the references that are pointing to the last commit of a branch
are called {\em heads} in Git terminology and starts with [[refs/heads/]].
In Figure~\ref{fig:commit-dag}, those heads are [[refs/heads/experiment]]
and [[refs/heads/master]].

Git maintains a final set of special references called
the {\em remotes}, for example [[refs/remotes/origin/master]]
pointing to [[commit8]]
in Figure~\ref{fig:commit-dag}. Those references are used 
when people are collaborating with each other and will be fully explained
in Chapter~\ref{chap:exchanging}.
\l commit at last synchro and so local commits diverging from remote

% really object store and then .git/refs/ and using sha1 can encode
% many idioms (branches, origin for push/pull, tags, stash)

\subsubsection{Staging area}
\label{sec:staging-area}

%trans:
The last important concept of Git is the {\em staging area}.
\l which is a concept specfic to Git.
%
Git operates mainly on three different areas, as shown at
the top of Figure~\ref{fig:git-areas}:
\begin{enumerate}
\item The {\em working copy} contains the current state of the files

\item The {\em repository} contains all past versions of all the files 
including the state of the files at the last commit

\item The {\em staging area} contains what will be the next commit
\end{enumerate}

\begin{figure}[!]\centering
\begin{verbatim}

Repository          Staging               working
  (HEAD)              area                  copy
             |                     |
 foo.txt     |                     |     foo.txt
             |                     |     (unmodified)
             |                     |
 bar.txt     |                     |     bar.txt
             |                     |     (modified)
             |                 git add
 foobar.txt  | foobar.txt   <------+---  foobar.txt
             | (staged)            |     (modified)
             |                 git rm    (misc.txt)
 misc.txt    | misc.txt       <----+---- (deleted)
             | (marked for delete) |
             |                     |
             |                     |    untracked.txt
         git commit                |
       <-----+------               |
\end{verbatim}
\caption{Git areas.}\label{fig:git-areas}
\end{figure}
\l put remote1 and remote2 too?

After you {modified} a set of files in your working copy,
for example, [[bar.txt]], [[foobar.txt]], and [[misc.txt]]
at the right of Figure~\ref{fig:git-areas}, you need to
indicate which of those files and modifications should be part
of the next commit.
%
To do so, you need to mark those files by using the command
[[git add]] (or [[git rm]] if you want to mark for deletion a file).
%
Note that you must use [[git add]] when you want to add a new file 
to the repository.
In that case the file is said to be {\em tracked} in Git terminology.
%
You must also use [[git add]] when you modified a tracked file
to mark it for the next commit.


Once you marked all the relevant files, you can use the command [[git commit]]
to commit the modifications to the repository.
\l also git add --patch for interactively adding hunks (used by magit?)
For example, in Figure~\ref{fig:git-areas} only the modifications
to [[foobar.txt]] and the deletion of [[misc.txt]] will be part
of the next commit, and not the modifications to [[bar.txt]].

You can sometimes avoid manipulating explicitely the staging area 
by using instead the command [[git commit -a]] to automatically commit all
the modifications to the tracked files.
However, the staging area and [[git add]] give more flexibility
to the user by allowing to split a set of modifications in multiple
commits. For example in Figure~\ref{fig:git-areas} the modification
to [[bar.txt]] can be put in another commit.
%gitless: useless area

% git status, modified, staged, or untracked.

Internally, Git uses a data structure called the {\em index}
(also known as {\em directory cache})
to manage the staging area.
%
I will explain later in Section~\ref{sec:index} why
this data structure is called an index.



\subsection{Repository format: [[.git/]]}
\label{sec:repository-format}

%trans: 
Now that you know the main concepts and data structures underlying Git, 
it will be easy to understand the format of the [[.git/]] directory.
%
Here is the sligtly edited output of the \unix command 
[[tree]]\footnote{See \url{http://mama.indstate.edu/users/ice/tree/}
for more information about the [[tree]] program. The [[-F]] option
used in the terminal session above is to add the special mark [['/']]
at the end of directory names.
}
applied on the [[.git/]] directory after the last command in 
Section~\ref{sec:getting-started}:

\begin{verbatim}
8 $ tree -F .git/
.git/
|-- HEAD
...
|-- index
|-- objects/
|   |-- 2f/
|   |   `-- 092e9cadfc1eb4a6d2febfddb941f4c1fe6fd6
|   |-- 19/
|   |   `-- d977a48d1d7b7ae8d520dd66190702dd4fb5bc
|   |-- 9f/
|   |   `-- 4d96d5b00d98959ea9960f069585ce42b1349a
......
`-- refs/
    |-- heads/
    |   `-- master
.....
\end{verbatim}
\n more elided to simplify
%|-- COMMIT_EDITMSG
%|-- branches/
%|-- config
%|-- description
%|-- hooks/
%...
%|-- info/
%|   `-- exclude
%|-- logs/
%|   |-- HEAD
%|   `-- refs/
%|       `-- heads/
%|           `-- master
%`-- refs/
%    `-- tags/

\l encoding UTF8 for filenames.
% https://github.com/git/git/blob/master/Documentation/i18n.txt

The objects of the key/value store are simply stored in separate
files under [[.git/objects/]]. The hexadecimal digits of the
SHA1 of the object is split in two parts: the first two digits are used
for the directory name containing the object and the remaining
digits for the filename of the object. For example, the file
[[.git/objects/9f/4d96d5b00d98959ea9960f069585ce42b1349a]] contains
the blob of [[Hello Git\n]] (see Figure~\ref{fig:objects-sha1-dag}).

Git uses the first two digits of the SHA1 to classify objects
in separate folders to avoid having too many files in the same
directory. Indeed, this would slow down filesystem operations
such as opening a file referenced by a specific SHA1 key
(see the \book{Kernel} for more information on the performance
of filesystem operations), a recurring operation under Git.

The references are also stored simply in separate files.
Git uses the name of the reference as the path to a file
under [[.git/refs/]] (e.g., [[.git/refs/heads/master]] in the
example above).

Finally, the index and the HEAD are stored directly under [[.git/]].

\subsection{A terminal session using [[git]]}

%trans:
I can finally present the tutorial on how to use a few of the main commands
of Git. I can now also describe the precise semantics of those commands.
%
I will start from the same commands than in Section~\ref{sec:getting-started},
but I will also explain this time how those commands modify
files under [[.git/]] (by using mainly the output of the [[tree]] command,
as in the previous section).
%inspiration:
% - http://eagain.net/articles/git-for-computer-scientists/
% - git from the bottom up (great, I read it while at FB)

\l Here just quick session, quick tutorial.See book to learn how to use git
%dup: use git below, but really ocamlgit, try compatible UI.

\subsubsection{Creating a repository}

Here are commands to create a fresh new repository:

%dup: (but uses git not ocamlgit and add tree command) intro/getting-started
\begin{verbatim}
1 $ cd /tests/
2 $ mkdir hello
3 $ cd hello/
4 $ git init
Initialized empty Git repository in /tests/hello/.git/
5 $ tree -F .git/
.git/
|-- HEAD
...
|-- objects/
`-- refs/
    |-- heads/
6 $ cat .git/HEAD
ref: refs/heads/master
\end{verbatim}
%|-- branches/
%|-- config
%|-- description
%|-- hooks/
% ...
%|-- info/
%|   `-- exclude
%...
%|   |-- info/
%|   `-- pack/
%...
%    `-- tags/

The [[init]] command creates just the directory structure
under [[.git/]], without any objects or references in it.
%
There is also not yet an index file.
%
There is a [[HEAD]] file, but its contents ([[ref: refs/heads/master]])
references an head that does not exist yet under [[.git/refs/heads/]].

\subsubsection{Staging a diff}

Here is the command to add a new file to the repository:

\begin{verbatim}
1 $ echo "Hello Git" > hello.txt
2 $ git add hello.txt
3 $ tree -F .git/
.git/
|-- HEAD
...
|-- index
...
|-- objects/
|   |-- 9f/
|   |   `-- 4d96d5b00d98959ea9960f069585ce42b1349a
...
`-- refs/
    |-- heads/
4 $ cat .git/objects/9f/4d96d5b00d98959ea9960f069585ce42b1349a 
x^K\312\311OR04`\360H\315\311\311Wp\317,\341^B^@4\201^Ec
\end{verbatim}
\l git rm


Adding the first file in a repository has two effects:

\begin{enumerate}
\item The creation of a new {blob object} 
(here in [[.git/objects/9f/4d96...]])
containing essentially the compressed form of the content of the added file.
I will fully explain in Chapter~\ref{chap:reading} the format
of a blob on the disk.
\n can now understand compression/decompression in code orga tabular
\l dedup discuss here? and git does not track changes but state?

\item The creation of the index file. Again, I will describe
precisely the format of the index file in Chapter~\ref{chap:reading},
but the index essentially associates to every tracked filenames
the SHA1 of the blob corresponding to the filename. 
In the example above, the index will associate to the filename [[hello.txt]]
the SHA1 [[9f4d96...]].

\end{enumerate}


Note that you use the command [[add]] to add a new file
to the repository, when the file was not yet {tracked} by
the repository. However, you must also use the command [[add]]
to stage the modifications on a tracked file as in 
Figure~\ref{fig:git-areas}.
%
In that case, the [[add]] command also creates a new blob with the
current content of the file. It also updates the index so the filename
of the added file now points to the SHA1 of the new blob.
%
Note that using [[git add]] on an unmodified file will have no effect. Indeed,
Git will compute the SHA1 of the current content, which will be
identical to the SHA1 of an existing blob. Updating the index will have also
no effect because the filename will reference the same SHA1.
\l or look at date to optimize? 
\l immutable object store beauty (said later?)

\subsubsection{Committing a diff}

Here is the command to commit to the repository what was previously
staged:

\begin{verbatim}
1 $ git commit -m "first commit"
2 $ tree -F .git/
.git/
|-- HEAD
|-- index
|-- objects/
|   |-- 2f/
|   |   `-- 092e9cadfc1eb4a6d2febfddb941f4c1fe6fd6
|   |-- 19/
|   |   `-- d977a48d1d7b7ae8d520dd66190702dd4fb5bc
|   |-- 9f/
|   |   `-- 4d96d5b00d98959ea9960f069585ce42b1349a
`-- refs/
    |-- heads/
    |   `-- master
3 $ cat .git/refs/heads/master
19d977a48d1d7b7ae8d520dd66190702dd4fb5bc
\end{verbatim}
\t normally gives more output when commit something [master (root-commit)...]
%|-- COMMIT_EDITMSG
%|-- branches/
%|-- config
%|-- description
%|-- hooks/
%|-- info/
%|   `-- exclude
%|-- logs/
%|   |-- HEAD
%|   `-- refs/
%|       `-- heads/
%|           `-- master
%...
%|   |-- info/
%|   `-- pack/
%...
%    `-- tags/

The [[commit]] command has three effects:

\begin{enumerate}
\item The creation of a new {tree object}, in the example above
[[.git/objects/2f/092e...]]
(see Figure~\ref{fig:objects-sha1-dag} for the content of this tree).
The content of this tree object derives from the content of the index.

\item The creation of a new {commit object}, here
[[.git/objects/19/d977...]],
referencing the newly created tree object
(again, see Figure~\ref{fig:objects-sha1-dag} for the content of this commit).

\item The update of the content of the head of the current branch
([[refs/heads/master]] according to the content of [[.git/HEAD]])
to contain the SHA1 of the newly created commit object
(here [[19d977...]]).
\l note that first commit, so create first time refs/heads/master file
\end{enumerate}


\subsubsection{Managing branches}
\label{sec:create-branch-tutorial}

%trans:
% covered all commands in Section X.
%Together, the [[init]], [[add]], and [[commit]] commands can cover
%most of the use case of a developer using Git by himself.
%Now powerful command for parallel development.
%As explained in Section X, To experiment with new features, 
% as in Figure~\ref{fig:commit-dag}.

Here is the command to create a new branch:

\begin{verbatim}
1 $ git branch experiment
2 $ tree -F .git/
.git/
HEAD
...
`-- refs/
    |-- heads/
    |   |-- experiment
    |   `-- master
...
3 $ cat .git/HEAD 
ref: refs/heads/master
4 $ cat .git/refs/heads/master
19d977a48d1d7b7ae8d520dd66190702dd4fb5bc
5 $ cat .git/refs/heads/experiment
19d977a48d1d7b7ae8d520dd66190702dd4fb5bc
\end{verbatim}

Creating a new branch is an extremely cheap operation under Git. 
%
It consists just in adding a file under [[.git/refs/heads/]]
with the name of the new branch (here [[.git/refs/heads/experiment]]),
and the SHA1 commit of the current branch
(here [[19d977...]]) for its content.
%
Creating a branch does not switch to this branch though.

\label{sec:switch-branch-tutorial}
Here is the command to switch to the new branch:

\begin{verbatim}
1 $ git checkout experiment
Switched to branch 'experiment'
2 $ cat .git/HEAD
ref: refs/heads/experiment
\end{verbatim}

Switching to a branch is usually a more costly operation.
%
It modifies [[HEAD]], which is fast, 
but it also recomputes the index from the tree
object referenced from the commit of the head of the new branch
as well as from all its substrees
(see Section~\ref{sec:index-from-tree} for the full description 
of this operation).
%
It also updates all the files so that they contain the content of
the blob referenced in the index.

\subsubsection{Inspecting objects}
\label{sec:git-show-examples}

Git provides a few commands to query the repository.
%
The first one, [[show]], shows the content of a Git object.
It takes the SHA1 of an object as a parameter (in the hexadecimal format)
\l or objectish ref?
and pretty print its content.
%
Here are a few examples of this command:

\begin{verbatim}
1 $ tree -F .git/
...
|-- objects/
|   |-- 2f/
|   |   `-- 092e9cadfc1eb4a6d2febfddb941f4c1fe6fd6
|   |-- 19/
|   |   `-- d977a48d1d7b7ae8d520dd66190702dd4fb5bc
|   |-- 9f/
|   |   `-- 4d96d5b00d98959ea9960f069585ce42b1349a
...
2 $ git show 9f4d96d5b00d98959ea9960f069585ce42b1349a
Hello Git
3 $ git show 2f092e9cadfc1eb4a6d2febfddb941f4c1fe6fd6
tree 2f092e9cadfc1eb4a6d2febfddb941f4c1fe6fd6

hello.txt
4 $ git show 19d977a48d1d7b7ae8d520dd66190702dd4fb5bc
commit 19d977a48d1d7b7ae8d520dd66190702dd4fb5bc
Author: pad  <todo@todo>
Date:   Fri Sep 29 14:04:46 2017 -0700

    first commit

diff --git a/hello.txt b/hello.txt
new file mode 100644
index 0000000..9f4d96d
--- /dev/null
+++ b/hello.txt
@@ -0,0 +1 @@
+Hello Git
\end{verbatim}
\t need fix ocamlgit to output that diff format
\l would be nice to have tree SHA1 reference from commit and also
\l SHA1 reference of blobs in the tree.

The command [[show]] mainly opens the appropriate file under [[.git/objects/]],
decompresses the file, and finally displays its content.

Another important query command is [[log]] to see the full history
of the repository. Here is the output of this command on the
repository we used this far:

\begin{verbatim}
1 $ git log
commit 19d977a48d1d7b7ae8d520dd66190702dd4fb5bc
Author: pad  <todo@todo>
Date:   Fri Sep 29 14:04:46 2017 -0700

    first commit
\end{verbatim}


\subsubsection{Other commands}

%trans:
%Together, the [[init]], [[add]], [[commit]], [[branch]], [[checkout]]
% commands can cover
%most of the use case of a developer using Git by himself.

%chunks:
There are a few other important commands: 
[[merge]], 
[[status]], 
[[diff]],
[[clone]], 
[[pull]], or 
[[push]], 
but I will introduce them gradually later in this document.


\section{Code organization}

%dup: (and heavily adapted) from Assembler.nw
Table~\ref{tab:code-orga} presents short descriptions
of the source files used by [[ocamlgit]]
%together with the main entities (e.g., types, functions) the file defines,
and the corresponding chapters in this document in which the code
contained in the file is primarily discussed.
\n sorted by chapters, make more sense than sorted by dir

\begin{table*}[tbh!]
\begin{center}
\begin{tabular}{lcllr}
\toprule
{\bf Function}  & {\bf Chapter} & {\bf Files} & {\bf LOC} \\
\otoprule
SHA1 binary and hexadecimal hashes & \ref{chap:core-ds}              & [[sha1.ml]] [[hexsha.ml]] &    \\
repository type and main API       & \ref{chap:core-ds}              & [[repository.ml]] &    \\ % lots of func actually introduced later
objects                            & \ref{chap:core-ds}              & [[objects.ml]] [[blob.ml]] [[tree.ml]] [[commit.ml]] [[user.ml]] &    \\
references                         & \ref{chap:core-ds}              & [[refs.ml]] &    \\
staging area                       & \ref{chap:core-ds}              & [[index.ml]] &    \\
client/server architecture         & \ref{chap:core-ds}              & [[client.ml]] &    \\ % server.ml

\midrule

list of commands                   & \ref{chap:main}              & [[cmd.ml]] [[cmds.ml]] &    \\
entry point and command dispatcher & \ref{chap:main}              & [[main.ml]] &    \\
getting help                       & \ref{chap:main}              & [[cmd_help.ml]] &    \\

\midrule

creating a repository     & \ref{chap:creating}              & [[cmd_init.ml]] &    \\
%\midrule
reading from a repository & \ref{chap:reading}              & [[decompression.ml]] &    \\
%\midrule compressed data
writing to a repository   & \ref{chap:writing}              & [[compression.ml]] &    \\
%\midrule and compressing data
staging a diff            & \ref{chap:staging}              & [[cmd_add.ml]] [[cmd_rm.ml]]  &    \\ % [[cmd_mv.ml]]
%\midrule
committing a diff         & \ref{chap:committing}              & [[cmd_commit.ml]]           &    \\
%\midrule
manipulating branches     & \ref{chap:branching}              & [[cmd_branch.ml]] [[cmd_checkout.ml]] [[cmd_reset.ml]] &    \\
%\midrule
merging multiple branches & \ref{chap:merging}              & [[cmd_merge.ml]] &    \\ %cmd_merge.ml cmd_cherrypick.ml 
\midrule

inspecting objects    & \ref{chap:inspecting}              & [[cmd_show.ml]] &    \\
tree and file changes & \ref{chap:inspecting}              & [[change.ml]] [[diff.ml]] &    \\
showing differences   & \ref{chap:inspecting}             &  [[cmd_diff.ml]] [[changes.ml]] [[diff_unified.ml]]  &    \\
commit history        & \ref{chap:inspecting}              & [[cmd_log.ml]]  &    \\
file status           & \ref{chap:inspecting}              & [[cmd_status.ml]]  &    \\
\midrule
packing objects and delta compression   & \ref{chap:packing}              & [[pack.ml]] &    \\

exchanging commits    & \ref{chap:exchanging}              & [[cmd_pull.ml]] [[cmd_push.ml]]  &    \\
local exchange        & \ref{chap:exchanging}              & [[client_local.ml]]  &    \\
cloning a repository  & \ref{chap:exchanging}              & [[cmd_clone.ml]]  &    \\
\midrule
networking clients    & \ref{chap:networking}              & [[clients.ml]]  &    \\ % protocol.ml
[[git://]] protocol   & \ref{chap:networking}              & [[client_git.ml]]  &    \\
\midrule
% bisect, blame
%\midrule

advanced features                & \ref{chap:advanced-features}              & [[tag.ml]]  &    \\ %reflog.ml stash.ml graft.ml submodule.ml hook.ml
% config.ml ignore.ml rename.ml
advanced commands                & \ref{chap:advanced-commands}              &   &    \\ %cmd_bisect.ml cmd_revert.ml cmd_blame.ml cmd_grep.ml cmd_archive.ml
% cmd_plumb_fetch.ml
advanced networking & \ref{chap:advanced-networking} & & \\ % client_ssh.ml, ...

\midrule

dumpers and debugging support    & \ref{chap:debugging-ocamlgit}              & [[cmd_dump.ml]] [[dump.ml]] [[cmd_test.ml]]  &    \\
binary IO utilities       & \ref{chap:utilities}              & [[IO_.ml]]  &    \\
core algorithms           & \ref{chap:algorithms}             & [[zip.ml]] [[unzip.ml]] [[diff_myers.ml]]  &    \\ %diff3.ml (sha1.ml before)

\otoprule
Total           &               &            &                & 6196  \\
\bottomrule
\end{tabular}
\end{center}
\caption{Chapters and source files of [[ocamlgit]].}
\label{tab:code-orga}
\end{table*}
\n see SRC_VIEWS in the mkfile, and mk loc
\l shorten diff and repo?

% requires also:
% - zlib (but hope I can port decompress code so no need libc)

% style: Xxx.t, match () with _ when ... ->, Common.

The most important files are [[repository.ml]], which contains
the main API to manipulate a repository, and the [[cmd_xxx.ml]]
files implementing each a Git command
(e.g., [[cmd_init.ml]] for [[git init]]).

\section{Software architecture}
\label{sec:archi}

Figure~\ref{fig:controlflow} describes the main {modules}
of [[ocamlgit]] and their main dependencies.
\n hidden client/pull/push stuff and reduced deps 
Those dependencies correspond rougly also to the main control 
flow of [[ocamlgit]].
%
This flow starts at the top with the execution of [[Main.main()]]
when the program [[ocamlgit]] starts. 
%
This function looks if the first argument of [[ocamlgit]] is one
of the command listed in the global [[Cmds.main_commands]].
%
If it is, then [[Main.main()]] dispatches the appropriate
command, for example, [[Cmd_add.cmd]] if the first argument
to [[ocamlgit]] was [[add]].
%
Each command usually processes the remaining command-line arguments
to [[ocamlgit]] and uses functions from the API provided by
the [[Repository]] module. This API contains functions to
open a repository ([[open_()]]),
read an object ([[read_obj()]]),
add an object ([[add_obj()]]),
modify a reference ([[set_ref()]]),
modify the index ([[add_in_index()]]),
etc.
%
Internally, the [[Repository]] module relies on the
[[Objects]], [[Refs]], and [[Index]] modules to read and write
files under the [[.git/]] directory 
(e.g., [[Index.read()]] and [[Index.write()]]).
\l explain Blob/Tree/Commit ?
%
Those modules in turn rely on algorithms 
to compute SHA1 hashes ([[Sha1.sha1()]]),
to list the differences between two files ([[Diff.diff()]]),
or to compress ([[Zip.deflate()]]) 
and decompress ([[Unzip.inflate()]]) data.
\l explain pull/push and clients? not enough space? too complicated for now?

\begin{figure}[!]\centering
\begin{verbatim}
                  +-------+
                  | Main  |
                  +---+---+
                      |
                  +---v---+
                  | Cmds  |
                  +-------+
                      |
      +-------------+-+-----------+
 +----v---+   +-----v--+       +--v------+
 |Cmd_init|   |Cmd_add |  ...  |Cmd_pull |
 +------+-+   +------+-+       +--+------+
        |            |            |
        +----------+ | +----------+
                +--v-v-v---+
                |Repository|
                +-+--+--+--+
         +--------+  |  +------------+
   +-----v----+  +---v------+  +-----v----+
   | Objects  |  |   Refs   |  |  Index   |
   +---+-+--+-+  +----------+  +--+-------+
       | |  +----+------+ +-------+
       | +----+  |      | |
  +----v-+ +--v--v+ +---v-v+
  | Tree | |Commit| | Blob |
  +------+ +------+ +------+


+------+ +------+ +----------+ +------+
| Sha1 | |Hexsha| |Zip/Unzip | |Diff  |
+------+ +------+ +----------+ +------+
\end{verbatim}
\caption{Main module dependencies of [[ocamlgit]].}\label{fig:controlflow}
\end{figure}
\n see archi.pdf generated by ocamldot -dot, but too big and better hand-made

\n no really data flow. I could put DS relationships though, but
\l  explained before?


\l plumbing vs porcelain in original git version,
% because Linus started with very low-level commands for
% essentially a content addressable storage engine but not important here. 

%\section{Bootstrapping}
%bootstrap:
% just a tar.gz, simple, as mentioned before.

\section{Book structure}

%trans: %dup: (and adapted) from Assembler.nw
You now have enough background to understand the source code of [[ocamlgit]].
%toc: 
The rest of the book is organized as follows.
%dup: (repeat a bit) intro/code-orga
I will start by describing the core data structures of [[ocamlgit]]
in Chapter~\ref{chap:core-ds}.
%
Then, I will switch to a top-down approach, starting with 
Chapter~\ref{chap:main} with the description of [[Main.main()]] 
and the dispatch of the Git commands.
%
In Chapter~\ref{chap:creating} I will describe the [[init]] command
to create the [[.git/]] repository and in Chapter~\ref{chap:reading}
and Chapter~\ref{chap:writing} the code to respectively read
and write files under [[.git/]].
%
The following chapters will describe the commands of [[ocamlgit]]
%dup:? ?
that cover most of the use-cases for a single developer:
%which rely on the code of the previous chapters to manipulate the files
%under [[.git/]]:
Chapter~\ref{chap:staging} will present the code to add files in
the staging area,
Chapter~\ref{chap:committing} the code to commit what was staged, 
Chapter~\ref{chap:branching} the code to manipulate branches,
Chapter~\ref{chap:merging} the code to merge branches, and finally
Chapter~\ref{chap:inspecting} the code to inspect Git objects.
%
Chapter~\ref{chap:packing} presents the code to pack and compress objects,
which is an important optimization.
Then I will present the commands for collaborating with other developers:
Chapter~\ref{chap:exchanging} presents the code to exchange commits between
repositories, and
Chapter~\ref{chap:networking} the code to exchange those commits through
the network.
%
Then, I will present advanced functionalities of Git 
that I did not present before to simplify the explanations:
Chapter~\ref{chap:advanced-features} presents advanced features,
for instance, {Tags},
Chapter~\ref{chap:advanced-commands} presents advanced commands,
for example commands that are useful for developers to develop 
and debug programs when the  source code of those programs is managed by Git
such as [[git bisect]], 
% to help develop! not just store/retrieve
and Chapter~\ref{chap:advanced-networking} presents advanced networking options,
for instance, a Git client and server using the [[http://]] protocol.
%
Finally, Chapter~\ref{chap:conclusion} concludes
and gives pointers to other books in the \principia series.
\l really what the conclusion does? no much pointers I think

Some appendices present the code of non-functional properties:
code to help debug [[ocamlgit]] itself 
in Appendix~\ref{chap:debugging-ocamlgit}.
%Chapter~\ref{chap:profiling-ocamlgit}
%Chapter~\ref{chap:error}
%
Appendix~\ref{chap:utilities} contains the code of generic utility
functions used by [[ocamlgit]] but which are not specific to [[ocamlgit]].
%
Finally, Appendix~\ref{chap:algorithms} presents the code of the
core algorithms used by [[ocamlgit]] (e.g., 
the algorithm to compute the SHA1 of any string,
the algorithm to compute the differences between two files).

%##############################################################################

\chapter{Core Data Structures}
\label{chap:core-ds}

\begin{verse}
\begin{flushright}
  {\it Show me your code and conceal your data structures, and I shall
    continue to be mystified. Show me your data structures, and I
    won't usually need your code; it'll be obvious.\\
    ~\\
    Fred Brooks}
\end{flushright}
\end{verse}

%toc:

\section{Secure Hash Algorithm (SHA1) hashes}
\n Secure, not Simple.

% used for 
%  - identifying (and versioning), 
%  - consistency checking, 
%  - indexing (and also for folders), 
%  - deduplicating (good for rename detection too)
% SHA1 underlies lots of things in git.

%sccs: used checksum (as opposed to RCS) to detect corrupted history files

\subsection{Binary hashes}

% sha1 is large number of 20 bytes.

<<type Sha1.t>>=
(* a 20 bytes number (really a string of length 20) *)
type t = bytes
@

% Given arbitrary long sequence of bytes, return 20 bytes hash.

<<signature Sha1.sha1>>=
(* computes SHA1 of a series of bytes *) 
val sha1: bytes -> t
@
\n bytes to bytes in the end

% See appendix for code for sha1().
% outside scope of this book. Complex cryptography.
%for more information on SHA1:
% http://www-cs-students.stanford.edu/~blynn/gitmagic/ch08.html

% Defensive programming:

<<signature Sha1.is_sha>>=
val is_sha: t -> bool
@
<<function Sha1.is_sha>>=
let is_sha x =
  Bytes.length x = 20
@
\n extra checks? forbidden bytes? I dont think so.


\subsection{Hexadecimal hashes}

% SHA1 used in git to identify things version ID (e.g., commit).
% But some commands expect version id. 
%rcs:
% With RCS easy to say retrive version 1.1, but wuth git
% Not easy enter binary data. 
% Enter Hexsha, ASCII Hexadecimal,  can be input

% Given that 1 byte can be encoded by 2 hex (e.g. 255 = 0xFF),
% then you need 40 hex number to represent a sha1.
% hexsha type! 40 bytes number as number in hexa.
% (each byte is actually encoding only 16 values, an hexadecimal number)

<<type Hexsha.t>>=
(* a 40 characters string, e.g. "d670460b4b4aece5915caf5c68d12f560a9fe3e4" *)
type t = string
@

%dup:
% As I said, easier format for user to enter or read sha in terminal.

<<signature Hexsha.is_hexsha>>=
val is_hexsha: t -> bool
@
<<function Hexsha.is_hexsha>>=
let is_hexsha x =
 String.length x = 40 && x =~ "^[0-9a-fA-F]+$"
@
%$

% git use mostly internally binsha, so need convert user
% Hexsha to bin sha1
% (actually commit file format contains hexsha).

<<signature Hexsha.to_sha>>=
val to_sha: t -> Sha1.t
@
<<function Hexsha.to_sha>>=
let to_sha x =
  assert (is_hexsha x);
  to_string x
@

<<function Hexsha.to_string>>=
let to_string ((*`Hex*) s) =
  if s = "" 
  then ""
  else
    let n = String.length s in
    let buf = Bytes.create (n/2) in
    let rec aux i j =
      if i >= n 
      then ()
      else if j >= n 
           then raise (Invalid_argument "hex conversion: invalid hex string")
      else (
        Bytes.set buf (i/2) (to_char s.[i] s.[j]);
        aux (j+1) (j+2)
      )
    in
    aux 0 1;
    buf
@
%old:
%<<function Hexsha.to_string>>=
%let to_string hex =
%  to_helper ~empty_return:"" ~create:Bytes.create ~set:Bytes.set hex
%@

<<function Hexsha.to_char>>=
let to_char x y =
  let code c = 
    match c with
    | '0'..'9' -> Char.code c - 48 (* Char.code '0' *)
    | 'A'..'F' -> Char.code c - 55 (* Char.code 'A' + 10 *)
    | 'a'..'f' -> Char.code c - 87 (* Char.code 'a' + 10 *)
    | _ -> 
      raise (Invalid_argument 
              (spf "Hex.to_char: %d is an invalid char" (Char.code c)))
  in
  Char.chr (code x lsl 4 + code y)
@
%old:
% <<function Hexsha.invalid_arg>>=
% let invalid_arg fmt =
%   Printf.ksprintf (fun str -> raise (Invalid_argument str)) fmt
% @


% When communicate with user, 
% or when access loose object,
% need opposite conversion:


<<signature Hexsha.of_sha>>=
val of_sha: Sha1.t -> t
@
<<function Hexsha.of_sha>>=
let of_sha x =
  assert (Sha1.is_sha x);
  of_string_fast x
@

<<function Hexsha.of_string_fast>>=
let of_string_fast s =
  let len = String.length s in
  let buf = Bytes.create (len * 2) in
  for i = 0 to len - 1 do
    Bytes.unsafe_set buf (i * 2)
      (String.unsafe_get hexa1 (Char.code (String.unsafe_get s i)));
    Bytes.unsafe_set buf (succ (i * 2))
      (String.unsafe_get hexa2 (Char.code (String.unsafe_get s i)));
  done;
  (*pad:`Hex*) buf
@
\l unsafe_get opti useful?




\section{[[Repository.t]]}

% Repository type is main type. Main API functions take
% repo as first parameter.

% Store path worktree, path metadata (dotgit),
% and also index. 3 main areas.

<<type Repository.t>>=
type t = {
  (* less: on bare repo, this could be None *)
  worktree: Common.filename;
  (* less: on bare repo this could be the toplevel dir *)
  dotgit: Common.filename;

  <<[[Repository.t]] index field>>
  (* less: compression level config field? *)
}
@
\n dotgit could be called commondir or controldir when have bare repo.
\l Hooks later.
\l info?? useful for grafts and?

% will see open_() later.

% a repo is really a set of commits,
% and also set of names of commits (branches, tags, HEAD).
% But represented in subtle way in git.
% set of objects, and then refs of this object, where some objects can
% be commit.


%trans:
% dotgit contains objects and refs (see next 2 sections).
%python: [] accessors for repo.object_store and repo.refs
% (and even [] for repo itself for objectish)

% Present main API too? as I said in code orga tabular.

\section{[[Objects.t]]}

%dup:
% As I said in Section~\ref{X}, Git uses mainly three kinds of objects
%https://git-scm.com/book/en/v2/Git-Internals-Git-Objects

<<type Objects.t>>=
type t = 
  | Blob   of Blob.t
  | Commit of Commit.t
  | Tree   of Tree.t
  <<[[Objects.t]] cases>>
@

\subsection{Object store}

% git really is a content addressable storage engine,
% objects are stored in object store.
% To retrive object given its hash, just need path

% internal functions not exposed in repository.mli
<<function Repository.hexsha_to_filename>>=
(* for loose objects *)
let hexsha_to_filename r hexsha =
  let dir = String.sub hexsha 0 2 in
  let file = String.sub hexsha 2 (String.length hexsha - 2) in
  r.dotgit / "objects" / dir / file
@
%python: nice syntax for string access like hex[:2] and hex[2:]

<<function Repository.hexsha_to_dirname>>=
let hexsha_to_dirname r hexsha =
  let dir = String.sub hexsha 0 2 in
  r.dotgit / "objects" / dir
@

% Regular files!

% talk about the encoding stuff? should aspectize? confusing?

%python: nice overloading of [] (but bad to abuse it) to access object
% store.

\subsection{[[Blob.t]]}
% =~ file content (but no name, name is in tree)

<<type Blob.t>>=
type t = bytes
@

<<type Blob.hash>>=
type hash = Sha1.t
@
% Later will want to specify that sha1 corresponds to a blob, so
% use type alias for readability (but not really typechecked)


% But no interleave deltas (SCCS), reverse deltas (RCS).
% Each modif generates new blob! disk is cheap now!
% But dedup!
% deduplicating! empty file! copy of file.
% And will see soon compressed on disk!
% And will see later more optim with pack files and deltas.

\subsection{[[Tree.t]]}
% =~ directories =~ project content.

%"It doesn't bother trying to store per-file histories;
%it instead stores the history at the tree level. When you perform a
%diff you are comparing two trees, not two files."

<<type Tree.t>>=
(* todo: entries must be sorted! and each name must be unique *)
type t = entry list
@

<<type Tree.hash>>=
type hash = Sha1.t
@

<<type Tree.entry>>=
type entry = {
  (* relative to tree, so does not contain any '/', or '.' or '..' *)
  name: string;
  (* Blob.hash or Tree.hash *)
  id: Sha1.t;
  perm: perm;
}
@
%old: use id instead of node, so more consistent with Index.entry.id

% recursive here! with entry.id referencing another tree!

% Name can contain space, utf8, whatever! 
% (seemed to be a pb in many other SCMs)

<<type Tree.perm>>=
(* very similar to Index.mode, but with also a 'Dir' *)
type perm = 
  | Normal
  | Exec
  | Link
  | Dir
  <<[[Tree.perm]] cases>>
@
% Nice simplification :) just needs that!
% Dont care about permission, time, inode-id, etc. 

% deduplicating! share subdir if no change.

%alt: flat list of revision number for each file? how retrive file?
% if renamed? if removed?

% Merkel trees?
% Can reference entire tree with just hash of root tree! because
% This tree itself is hashed by its content.

\subsection{[[Commit.t]]}

%trans:
% finally last object, commit.

% =~ history
% each commit has a tree and a parent, so can trace history of full project.

<<type Commit.t>>=
type t = {
  tree     : Tree.hash;
  (* first commit has no parent, and merge commits have 2 parents *)
  parents  : hash list;
  (* note that User.t contains a time *)
  author   : User.t;
  committer: User.t;

  message  : string;

  (* less: encoding, gpgsig, mergetag, extra *)
}
@

<<type Commit.hash>>=
and hash = Sha1.t
@


<<type User.t>>=
type t = {
  name : string;
  email: string;
  date : int64 * tz_offset(*option*);
}
@

%rcs: %sccs: had 2 digits for the year for a long time and was
% using local time

<<type User.tz_offset>>=
type tz_offset = {
  sign: sign;
  hours: int;
  min: int;
}
@

<<type User.sign>>=
type sign = Plus | Minus
@


% Fast checkout. Give me commit and I can grab
% all files from object store (looking first tree and then
% going recursively grabbing blobs on the way).
%rcs: innovated over slow sccs by storing diffs in reverse! fast checkout.

% DAG of version on top of tree of files. Subtle.
% Also merkle tree.

\section{References}

%dup:
% Object store and reference store.

% kinda correspond to branch name.
% .git/refs/heads/xxx are branches.
% .git/HEAD is current branch (usually point to .git/refs/heads/master
%  but 'master' is really just a convention could be 'trunk' or whatever)
% then this simple model allow to encode many idioms:
% - remote push/pull .git/refs/remote/origin/master
% - tags (refs/tags/xxx)
% - stash
% - ?

%torvalds:
% And that's it! with objects and (atomic) refs, you can do everything!
% far more complicated to achieve the same in other VCSs.

\l when stuff under refs/... contain indirect ref? HEAD is indirect
\l ref, but when need indirect ref under refs/?

% then can even save history of those refs (the reflog).

%https://git-scm.com/book/en/v2/Git-Internals-Git-References
%references vs symbolic references.

\subsection{Reference names}

% Valid branch name:

<<type Refs.refname>>=
(* should always start with "refs/", see is_valid_refname() later *)
type refname = string (* e.g. "refs/heads/master" *)
@

<<signature Refs.is_valid_refname>>=
val is_valid_refname: refname -> bool
@
<<function Refs.is_valid_refname>>=
let is_valid_refname str =
  str =~ "^refs/"
  (* todo: git-check-ref-format *)
@

\subsection{[[HEAD]]}

<<type Refs.t>>=
type t =
  | Head
  | Ref of refname
@

% used for? dumper?
<<signature Refs.string_of_ref>>=
val string_of_ref: t -> string
@
<<function Refs.string_of_ref>>=
let string_of_ref = function
  | Head -> "HEAD"
  | Ref x -> x
@

\subsection{Reference content}

<<type Refs.ref_content>>=
type ref_content =
  (* the final value when follow all the pointers *)
  | Hash of Commit.hash
  (* pointer (may contain sha1 or another pointer again) *)
  | OtherRef of refname
@

<<signature Refs.default_head_content>>=
val default_head_content: ref_content
@
<<constant Refs.default_head_content>>=
let default_head_content = 
  OtherRef "refs/heads/master"
@

% follow() later.

\subsection{Reference store}
%similar to Object store, indeed .git/ is mostly objects and refs (and index)

% disk!
<<function Repository.ref_to_filename>>=
let ref_to_filename r aref =
  match aref with
  | Refs.Head -> r.dotgit / "HEAD"
  (* less: win32: should actually replace '/' in name *)
  | Refs.Ref name -> r.dotgit / name
@


\subsection{Objectish references}

<<type Repository.objectish>>=
(* todo: handle ^ like HEAD^, so need more complex objectish parser *)
type objectish =
  | ObjByRef of Refs.t
  | ObjByHex of Hexsha.t
  <<[[Repository.objectish]] cases>>
@

<<[[Repository.objectish]] cases>>=
(* todo:
 *  ObjByBranch
 *  ObjByShortHex
 *)
@
%branch is shorter name than Refs.


\section{[[Index.t]]}
\label{sec:index}
% Staging area, Initially called DIRC, directory cache?

%trans:
% Seen in Section X staging area. Marks. But in practice
% not set of files with marks. Instead full set of files
% and current blob SHA1.

% To know diff between working tree and HEAD.
%gitless: misfit paper says that you do not need staging area and that in fact
%  it causes misfits

<<[[Repository.t]] index field>>=
mutable index: Index.t;
@

<<function Repository.index_to_filename>>=
let index_to_filename r =
  r.dotgit / "index"
@


<<type Index.t>>=
(* the entries are sorted (see compare_entries below) *)
type t = entry list
@

% flat list

<<type Index.entry>>=
(** The type for a Git index entry. *)
type entry = {
  (* relative path *)
  name  : Common.filename;
  id    : Blob.hash;
  stats : stat_info;
}
@
%old: stage : int; (*?? *)


% Here id can refer only to a Blob. No subtree like for Tree.
% An index is a flat list of files (sorted).

% Index.stats vs Tree.perm.

<<type Index.stat_info>>=
(** The type for file-system stat information. *)
type stat_info = {
  mode : mode;

  ctime: time;
  mtime: time;

  dev  : Int32.t;
  inode: Int32.t;

  uid  : Int32.t;
  gid  : Int32.t;

  size : Int32.t;
}
@
% all those info disappear once in Tree.entry.

<<type Index.mode>>=
and mode =
  (* no directory here *)
  | Normal
  | Exec
  | Link
  <<[[Index.mode]] cases>>
@

<<type Index.time>>=
(** The type for a time represented by its [lsb32] and [nsec] parts. *)
and time = {
  lsb32: Int32.t;
  nsec : Int32.t;
}
@


<<signature Index.empty>>=
val empty: t
@
<<constant Index.empty>>=
let empty = []
@

<<signature Index.mk_entry>>=
val mk_entry: Common.filename -> Sha1.t -> Unix.stats -> entry
@
<<function Index.mk_entry>>=
let mk_entry relpath sha stats =
  { name = relpath;
    id = sha;
    stats = stat_info_of_lstats stats;
  }
@
%old:    stage = 0; (* ?? *)


<<signature Index.stat_info_of_lstats>>=
val stat_info_of_lstats: Unix.stats -> stat_info
@
<<function Index.stat_info_of_lstats>>=
let stat_info_of_lstats stats = 
    { ctime = { lsb32 = Int32.of_float stats.Unix.st_ctime; nsec = 0l };
      mtime = { lsb32 = Int32.of_float stats.Unix.st_mtime; nsec = 0l };
      dev = Int32.of_int stats.Unix.st_dev;
      inode = Int32.of_int stats.Unix.st_ino;
      mode = 
        (match stats.Unix.st_kind, stats.Unix.st_perm with
        | Unix.S_REG, p -> 
          if p land 0o100 = 0o100 
          then Exec 
          else Normal
        | Unix.S_LNK, _ -> Link
        | _ -> failwith ("unsupported file type")
        );
      uid = Int32.of_int stats.Unix.st_uid;
      gid = Int32.of_int stats.Unix.st_gid;
      size = Int32.of_int stats.Unix.st_size;
    }
@


\section{Pack files}

% pack objects, pack refs, pack-idx.
% Compression, delta.
% Adv topics, but referenced many times (especially in Networking chapter).

\section{Networking}

% for git://, ssh://, but also for local.
% Abstracted behind Client interface.
% Will not see commands before chapter X.

\subsection{[[Client.t]]}

<<type Client.t>>=
type t = {
  (* path to remote (e.g., /path/other/repo, or git://github.com/foo/bar) *)
  url: string;
  (* less: more parameters:
   *  - determine_refs_wanted. for now grabs everything from remote HEAD 
   *  - return set of remote refs, not just the one for HEAD
   * Note that fetch will modify the target repository by side effect.
   *)
  fetch: Repository.t -> Commit.hash;
  (* less: progress *)
}
@
\t will get send method too?

% Repo param of fetch is dst repo, not remote repo.

<<signature Clients.client_of_url>>=
val client_of_url: string -> Client.t
@
<<function Clients.client_of_url>>=
(* old: was called get_transport_and_path (and xxx_from_url) in dulwich *)
let client_of_url url =
  match url with
  <<[[Clients.client_of_url()]] match url cases>>
  | s -> 
    if Sys.file_exists s
    then Client_local.mk_client url
    else failwith (spf "remote repository URL not supported: %s" url)
@

% Will see Client_local.mk_client later and match url cases later too.

\subsection{[[Server.t]]}






\chapter{Main Functions}
\label{chap:main}

% Entry point Main.main().

%toc: before main(), important type.
% git works with commands, git cmd args
% where each command have own options and actions.

\section{Main commands}

\subsection{[[Cmd.t]]}

<<type Cmd.t>>=
type t = {
  name: string;
  help: string;
  options: (Arg.key * Arg.spec * Arg.doc) list;

  (* the command! *)
  f: string list -> unit;
  (* less: man: when do git -help get short help, and with --help man page *)
}
@
%alt: use of 'Term.()' and '$' to not require globals for flags (src: ocaml-git)
% but not worth it. With split cmd_xxx.ml can have different globals in
% those different files.

%cvs: the one who introduced cvs xxx style instead of many programs? 
% (ci/co/...)

\subsection{[[Cmds.main_commands]]}

<<constant Cmds.main_commands>>=
let main_commands = [
  (* creating *)
  Cmd_init.cmd;
  Cmd_add.cmd;
  Cmd_rm.cmd;
  Cmd_commit.cmd;

  (* branching *)
  Cmd_branch.cmd;
  Cmd_checkout.cmd;
  Cmd_reset.cmd;
  
  (* inspecting *)
  Cmd_show.cmd;
  Cmd_diff.cmd;
  Cmd_log.cmd;
  Cmd_status.cmd;

  (* networking *)
  Cmd_pull.cmd;
  Cmd_push.cmd;
  Cmd_clone.cmd;
]
@
%todo: no merge 
%less: rebase

%chunks:
% will see in next chapters code for each of those commands.

% There is also extra_commands (for debugging) and Cmd_help.cmd (for help).

\section{[[Main.main()]]}

<<toplevel Main._1>>=
let _ =
  main ()
@


<<function Main.main>>=
let main () =
  Gc.set {(Gc.get ()) with Gc.stack_limit = 1000 * 1024 * 1024};
  <<[[Main.main()]] sanity check arguments>>
  else begin
    let cmd = 
      try 
        Hashtbl.find hcommands Sys.argv.(1) 
      with Not_found ->
        <<[[Main.main()]] print usage and exit>>
    in
    <<[[Main.main()]] execute [[cmd]]>>
  end
@


<<constant Main.hcommands>>=
let hcommands = 
  commands |> List.map (fun cmd -> cmd.Cmd.name, cmd) |> Hashtbl_.of_list
@

<<constant Main.commands>>=
let commands = List.flatten [
  Cmds.main_commands;
  Cmds.extra_commands;
  [Cmd_help.cmd];
]
@
%ocaml:
% Cmd_help reference itself main_commands, and ocaml forbids
% mutually recursive dependencies, so here it is.
% Extra is for git help vs git help --all?

%dup: Make.nw?
% Sanity check. obvious but necessary. will not comment

<<[[Main.main()]] sanity check arguments>>=
if Array.length Sys.argv < 2
then begin
  <<[[Main.main()]] print usage and exit>>
end
@
% git cmd xxx so at least 2.

<<[[Main.main()]] print usage and exit>>=
pr2 (usage ());
exit 1
@

<<function Main.usage>>=
let usage () =
  spf "usage: ocamlgit <%s> [options]"
    (String.concat "|" (commands |> List.map (fun cmd -> cmd.Cmd.name)))
@
% See Section~{sec:git-command-line}


% compute arguments and dispatch command callback.

<<[[Main.main()]] execute [[cmd]]>>=
let argv = Array.sub Sys.argv 1 (Array.length Sys.argv -1) in
let usage_msg_cmd = spf "usage: %s %s%s"
  (Filename.basename Sys.argv.(0))
  cmd.Cmd.name
  cmd.Cmd.help
in
let remaining_args = ref [] in
<<[[Main.main()]] parse [[argv]] for [[cmd]] options and remaining args>>
(* finally! *)
try 
  cmd.Cmd.f (List.rev !remaining_args)
with 
  | Cmd.ShowUsage ->
    Arg.usage (Arg.align cmd.Cmd.options) usage_msg_cmd;
    exit 1
@

<<exception Cmd.ShowUsage>>=
(* f can raise ShowUsage which will be catched by caller in main.ml *)
exception ShowUsage
@


<<[[Main.main()]] parse [[argv]] for [[cmd]] options and remaining args>>=
(try 
 (* todo: look if --help and factorize treatment of usage for subcmds *)
   Arg.parse_argv argv (Arg.align cmd.Cmd.options) 
     (fun arg -> Common.push arg remaining_args) usage_msg_cmd;
 with Arg.Bad str | Arg.Help str->  
   prerr_string str;
   exit 1
);
@




\section{Getting help: [[git help]]}

% First command example, simple:

<<constant Cmd_help.list_extra>>=
let list_extra = ref false
@

<<constant Cmd_help.cmd>>=
let rec cmd = { Cmd.
  name = "help";
  help = "";
  options = ["-a", Arg.Set list_extra, " see all commands"];
  f = (fun args ->
    let xs = 
      if !list_extra
      then Cmds.main_commands @ Cmds.extra_commands @ [cmd]
      else Cmds.main_commands
    in
    pr ("Available commands: ");
    xs |> List.iter (fun cmd ->
      pr (spf "  %s" cmd.Cmd.name);
    );
  );
}
@
%ocaml:
% let rec, subtle! not a function but still!


% will have also 'git cmd --help' later.


\chapter{Creating a Repository}
\label{chap:creating}
\n Initializing? reserved for 'creating empty', so would match only git init

% Different ways to create a repo. 
% Most common is create fresh repo, other is clone.

\section{Initializing a new repository: [[git init]]}
% Creating a fresh repository

<<constant Cmd_init.cmd>>=
let cmd = { Cmd.
  name = "init";
  help = " [directory]";
  options = [
   (* less: -bare, --quiet *)
  ];
  f = (fun args ->
    match args with
    | []    -> Repository.init "."
    | [dir] -> Repository.init dir
    | _ -> raise Cmd.ShowUsage
  );
}
@

<<signature Repository.init>>=
val init: Common.filename -> unit
@
<<function Repository.init>>=
let init root =
  if not (Sys.file_exists root)
  then Unix.mkdir root dirperm;

  (* less: bare argument? so no .git/ prefix? *)
  let dirs = [
    ".git";
    ".git/objects";
    ".git/refs";
    ".git/refs/heads";
    ".git/refs/tags";
    ".git/refs/remote";
    ".git/refs/remote/origin";
    ".git/hooks";
    ".git/info";
  ] in
  dirs |> List.iter (fun dir ->
    (* less: exn if already there? *)
    Unix.mkdir (root / dir) dirperm;
  );
  let r = {
    worktree = root;
    dotgit = root / ".git";
    index = Index.empty;
  } in
  add_ref_if_new r Refs.Head Refs.default_head_content |> ignore;

  (* less: config file, description, hooks, etc *)
  Sys.chdir root;
  let absolute = Sys.getcwd () in
  pr (spf "Initialized empty Git repository in %s" (absolute / ".git/"))
@

% will see add_ref_if_new later.

<<constant Repository.TODOOPERATOR>>=
let (/) = Filename.concat
@

<<constant Repository.dirperm>>=
(* rwxr-x--- *)
let dirperm = 0o750
@


%\subsection{Common directory}
% To abstract diff between bare and normal repository

%\subsection{Named files}

\section{Copying an existing repository: [[cp -r]]}

% well, can just do cp :) simple! DVCS power!

% Can also use branch, see later.
% actually at FB some people (Ola?) were prefering copy to
% branch cos git was not scaling enough when lots of files
% so switching branch was too slow (but doing cd /other/repo was fast)

% will see clone later, but useful more in networking context
% (and even there cp would be better thx to NFS)

% clone creates a connexion to original repo. cp does not.
% no remote and push/pull.


\section{Cloning an existing repository: [[git clone]]}

% Other common way to initialize a repo is clone! Copy from
% network location (or local too, but less useful).

% Will see clone code later.

% Diff with cp? take URL! (could NFS), and
% then connect local to remote for futur pull/push.

%\section{Checking out a repository: [[git checkout]]}
% if cp -a just .git, then can checkout by doing git checkout.

%\section{Fast Import/Export}
%adv topics


\section{Opening a repository}
% will see later most op need a Repository.t structure representing
% an existing repo.

<<signature Repository.open_>>=
val open_: Common.filename -> t
@
% not open cos conflict with ocaml keyword
<<function Repository.open_>>=
let open_ root = 
  let path = root / ".git" in
  if Sys.file_exists path &&
     (Unix.stat path).Unix.st_kind = Unix.S_DIR
  then 
    { worktree = root;
      dotgit = path;
      (* less: grafts, hooks *)
      index = 
        if Sys.file_exists (path / "index")
        then 
          (path / "index") |> Common.with_file_in (fun ch ->
            ch |> IO.input_channel |> Index.read)
        else Index.empty
    }
  else failwith (spf "Not a git repository at %s" root)
@
%todo: bar repo, 
\l cant used index_to_filename cos no repo yet, sad.

% See appendix for IO.xxx, Common.with_file_in
% Will see Index.read later.

% Most git commands can operate from the top dir of a object
% or any subdirectory. Convenient, git add foo.txt from
% any dir, no need go back to top.
% But internally simple have canonical representation of
% path and always use relative path to top dir.
% Enter find_root_... helper function used first in many commands.

<<signature Repository.find_dotgit_root_and_open>>=
val find_root_open_and_adjust_paths: 
 Common.filename list -> t * Common.filename list
@
<<function Repository.find_dotgit_root_and_open>>=
let find_root_open_and_adjust_paths paths = 
  (* todo: allow git from different location *)
  let r = open_ "." in
  (* todo: support also absolute paths and transform in relpaths *)
  let relpaths = paths |> List.map (fun path ->
    if Filename.is_relative path
    then 
      (* todo: may have to adjust if root was not pwd *)
      path
    else failwith (spf "TODO: Not a relative path: %s" path)
    )
  in
  r, relpaths
@




\chapter{Reading from a Repository}
\label{chap:reading}
\t should enforce that read every bytes

%trans:
% Saw init, does not create objects, just create dirs.
% Create also index. Will see later commands adding
% objects and commands reading those objects. 
% This chapter focus on all reading API.

\section{Objects}

% repo * sha -> path -> (channel -> IO.input) -> decompress -> deserialize

<<signature Repository.read_obj>>=
val read_obj: t -> Sha1.t -> Objects.t
@
<<function Repository.read_obj>>=
let read_obj r h =
  (* todo: look for packed obj *)
  let path = h |> Hexsha.of_sha |> hexsha_to_filename r in
  path |> Common.with_file_in (fun ch ->
    (* less: check read everything from channel? *)
    (* todo: check if sha consistent? *)
    ch |> IO.input_channel |> Compression.decompress |> Objects.read
  )
@
\l loose vs pack objects

% when reading no need lock, so simply with_file_in.


<<signature Objects.read>>=
(* assumes input is in decompressed form *)
val read: IO.input -> t
@
<<function Objects.read>>=
let read ch =
  let str = IO_.read_string_and_stop_char ch ' ' in
  let n = IO_.read_int_and_nullbyte ch in
  let raw = IO.really_nread ch n in
  (* less: assert finished ch? use IO.pos_in? *)
  let ch2 = IO.input_bytes raw in
  (* less: just reuse ch so avoid use of intermediate strings? *)
  match str with
  <<[[Objects.read()]] match str cases>>
  (* less: assert finished ch2? *)
  | str -> failwith (spf "Objects.read: invalid header: %s" str)
@

\subsection{Decompression}

<<signature Compression.decompress>>=
val decompress: 
  IO.input -> IO.input
@
<<function Compression.decompress>>=
let decompress ch = 
  Unzip.inflate ch
@
% See appendix for Unzip.inflate().



\subsection{Reading a blob}


<<[[Objects.read()]] match str cases>>=
| "blob"   -> Blob   (Blob.read ch2)
@
<<signature Blob.read>>=
(* assumes have already read the 'blob <size>\000' header from unzipped input *)
val read: IO.input -> t
@
<<function Blob.read>>=
let read ch =
  IO.read_all ch
@


<<signature Repository.read_blob>>=
val read_blob: t -> Sha1.t -> Blob.t
@
<<function Repository.read_blob>>=
let read_blob r h =
  match read_obj r h with
  | Objects.Blob x -> x
  | _ -> failwith "read_commit: was expecting a blob"
@

\subsection{Reading a tree}

<<[[Objects.read()]] match str cases>>=
| "tree"   -> Tree   (Tree.read ch2)
@

<<signature Tree.read>>=
(* assumes have already read the 'tree <size>\000' header from unzipped input *)
val read: IO.input -> t
@

<<function Tree.read>>=
let read ch =
  let rec aux acc =
    try 
      (* todo: how diffentiate no more input from wrong input ?
       * pass size ch and use IO.pos_in ?
       *)
      let e = read_entry ch in
      aux (e::acc)
    with IO.No_more_input ->
      List.rev acc
  in
  aux []
@

<<function Tree.read_entry>>=
(* todo: should transform some No_more_input exn in something bad,
 * on first one it's ok, but after it means incomplete entry.
 *)
let read_entry ch =
  let perm = IO_.read_string_and_stop_char ch ' ' in
  (* todo: handle escape char in filenames? encode/decode *)
  let name = IO_.read_string_and_stop_char ch '\000' in
  let hash = Sha1.read ch in
  { perm = perm_of_string perm; name = name; id = hash }
@

<<signature Sha1.read>>=
val read: IO.input -> t
@
<<function Sha1.read>>=
let read ch =
  let s = IO.really_nread ch 20 in
  assert (is_sha s);
  s
@

<<function Tree.perm_of_string>>=
let perm_of_string = function
  | "44"
  | "100644" -> Normal
  | "100755" -> Exec
  | "120000" -> Link
  | "40000"  -> Dir
  <<[[Tree.perm_of_string()]] match str cases>>
  | x        -> failwith (spf "Tree.perm_of_string: %s is not a valid perm." x)
@


<<signature Repository.read_tree>>=
val read_tree: t -> Sha1.t -> Tree.t
@
<<function Repository.read_tree>>=
let read_tree r h =
  match read_obj r h with
  | Objects.Tree x -> x
  | _ -> failwith "read_commit: was expecting a tree"
@

\subsection{Reading a commit}

<<[[Objects.read()]] match str cases>>=
| "commit" -> Commit (Commit.read ch2)
@

<<signature Commit.read>>=
(* assumes have already read the 'commit <size>\000' hdr from unzipped input *)
val read: IO.input -> t
@

<<function Commit.read>>=
let read ch =
  let tree = 
    IO_.read_key_space_value_newline ch "tree" Hexsha.read in
  (* todo: read "parent" or "author", because first commit has no parent *)
  let parents, author = 
    let rec loop parents =
      let str = IO_.read_string_and_stop_char ch ' ' in
      match str with
      | "parent" -> 
        let v = Hexsha.read ch in
        let c = IO.read ch in
        if c <> '\n'
        then failwith "Commit.read: missing newline after parent";
        loop (v::parents)
      | "author" ->
        let v = User.read ch in
        let c = IO.read ch in
        if c <> '\n'
        then failwith "Commit.read: missing newline after author";
        List.rev parents, v
      | _ -> failwith (spf "Commit.read: was expecting parent or author not %s"
                         str)
    in
    loop []
  in
  let committer = 
    IO_.read_key_space_value_newline ch "committer" User.read in
  let c = IO.read ch in
  if c <> '\n'
  then failwith "Commit.read: missing newline before message";
  let msg = IO.read_all ch in
  { tree = Hexsha.to_sha tree; 
    parents = parents |> List.map Hexsha.to_sha; 
    author = author; committer = committer;
    message = msg;
  }
@

% As opposed to Tree, the Commit contains sha in Hexsha form
<<signature Hexsha.read>>=
val read: IO.input -> t
@
<<function Hexsha.read>>=
let read ch =
  let s = IO.really_nread ch 40 in
  assert (is_hexsha s);
  s
@



<<signature User.read>>=
val read: IO.input -> t
@

<<function User.read>>=
let read ch =
  let name = IO_.read_string_and_stop_char ch '<' in
  let email = IO_.read_string_and_stop_char ch '>' in
  let c = IO.read ch in
  if c <> ' ' then failwith "User.read: wrong format, missing space";

  let seconds = IO_.read_string_and_stop_char ch ' ' in
  let sign = IO.read ch in
  let hours = IO.nread_string ch 2 in
  let mins = IO.nread_string ch 2 in
  { name = String.sub name 0 (String.length name - 1);
    email = email;
    date = (Int64.of_string seconds,
            {
              sign = sign_of_char sign;
              hours = int_of_string hours;
              min = int_of_string mins;
            });
  }
@

<<function User.sign_of_char>>=
let sign_of_char = function
  | '+' -> Plus
  | '-' -> Minus
  | c -> failwith (spf "User.sign_of_string: not a sign, got %c" c)
@

<<signature Repository.read_commit>>=
val read_commit: t -> Sha1.t -> Commit.t
@
<<function Repository.read_commit>>=
let read_commit r h =
  match read_obj r h with
  | Objects.Commit x -> x
  | _ -> failwith "read_commit: was expecting a commit"
@

%\section{[[git show]]}
%here?


\section{References}

<<signature Repository.read_ref>>=
val read_ref: t -> Refs.t -> Refs.ref_content
@
<<function Repository.read_ref>>=
let read_ref r aref =
  (* less: packed refs *)
  let file = ref_to_filename r aref in
  file |> Common.with_file_in (fun ch ->
    ch |> IO.input_channel |> Refs.read
  )
@
\l loose vs pack refs

<<signature Refs.read>>=
val read: IO.input -> ref_content
@
<<function Refs.read>>=
let read ch =
  let str = IO.read_all ch in
  (* less: check finish by newline? *)
  match str with
  | _ when str =~ "^ref: \\(.*\\)$" -> OtherRef (Regexp_.matched1 str)
  | _ -> Hash (str |> IO.input_string |> Hexsha.read |> Hexsha.to_sha)
@
%$



% useful function, used at many places (not just read_objectish)
<<signature Repository.follow_ref>>=
val follow_ref: t -> Refs.t -> Refs.t list * Commit.hash option
@
<<function Repository.follow_ref>>=
let rec follow_ref r aref =
  (* less: check if depth > 5? *)
  try (
  let content = read_ref r aref in
  match content with
  | Refs.Hash sha -> [aref], Some sha
  | Refs.OtherRef refname ->
    let (xs, shaopt) = follow_ref r (Refs.Ref refname) in
    aref::xs, shaopt
  ) 
  (* inexistent ref file, can happen at the beginning when have .git/HEAD
   * pointing to an inexistent .git/refs/heads/master
   *)
  with Sys_error _ (* no such file or directory *) -> [aref], None
@

% In some code we assume there is one, otherwise would be internal error
\l but should still be fault tolerant and have nice error msg?
<<signature Repository.follow_ref_some>>=
val follow_ref_some: t -> Refs.t -> Commit.hash
@
<<function Repository.follow_ref_some>>=
let follow_ref_some r aref =
  match follow_ref r aref |> snd with
  | Some sha -> sha
  | None -> failwith (spf "could not follow %s" (Refs.string_of_ref aref))
@



%\section{Objectish}

<<signature Repository.read_objectish>>=
val read_objectish: t -> objectish -> Sha1.t * Objects.t
@
<<function Repository.read_objectish>>=
let read_objectish r objectish =
  match objectish with
  | ObjByRef aref -> 
    (match follow_ref r aref |> snd with
    | None -> failwith (spf "could not resolve %s" (Refs.string_of_ref aref))
    | Some sha -> 
      sha, read_obj r sha
    )
  | ObjByHex hexsha ->
    let sha = Hexsha.to_sha hexsha in
    sha, read_obj r sha
@



\section{Index}

<<signature Repository.read_index>>=
val read_index: t -> Index.t
@
<<function Repository.read_index>>=
let read_index r =
  r.index
@
% initialized when open_ a repo (possibly to Index.empty if no index file)

<<signature Index.read>>=
val read: IO.input -> t
@
<<function Index.read>>=
let read ch =
  let header = IO.really_nread_string ch 4 in
  if header <> "DIRC"
  then failwith "Index.read: expecting DIRC header";
  let version = IO.BigEndian.read_i32 ch in
  if version <> 2
  then failwith "Index.read: expecting version 2";
  let entries = read_entries ch in
  (* todo: read_extensions but need know when reach last 20 bytes *)
  (* todo: check hash correctly stored in last 20 bytes *)
  entries
@

<<function Index.read_entries>>=
let read_entries ch =
  let n = IO.BigEndian.read_i32 ch in
  let rec loop acc n =
    if n = 0 
    then List.rev acc
    else
      let entry = read_entry ch in
      loop (entry :: acc) (n - 1) in
  loop [] n
@

<<function Index.read_entry>>=
let read_entry ch =
  let stats = read_stat_info ch in
  let id = Sha1.read ch in
  let stage, len =
    let i = IO.BigEndian.read_ui16 ch in
    (i land 0x3000) lsr 12,
    (i land 0x0FFF)
  in
  if (stage <> 0)
  then failwith (spf "stage is not 0: %d" stage);
  let name = IO.really_nread_string ch len in
  let c = IO.read ch in
  if c <> '\000'
  then failwith "Index.read_entry: expecting null char after name";
  let len = 63 + String.length name in
  let pad = 
    match len mod 8 with
    | 0 -> 0
    | n -> 8-n 
  in
  let _zeros = IO.really_nread ch pad in
  (* less: assert zeros *)
  { stats; id; name }
@
%old: was using stage

<<function Index.read_stat_info>>=
let read_stat_info ch =
  let ctime = read_time ch in
  let mtime = read_time ch in
  (* less: unsigned again *)
  let dev = IO.BigEndian.read_real_i32 ch in
  let inode = IO.BigEndian.read_real_i32 ch in
  let mode = read_mode ch in
  let uid = IO.BigEndian.read_real_i32 ch in
  let gid = IO.BigEndian.read_real_i32 ch in
  let size = IO.BigEndian.read_real_i32 ch in
  { mtime; ctime; dev; inode; mode; uid; gid; size }
@


<<function Index.read_time>>=
let read_time ch =
  (* less: unsigned actually *)
  let lsb32 = IO.BigEndian.read_real_i32 ch in
  let nsec = IO.BigEndian.read_real_i32 ch in
  { lsb32; nsec }
@

<<function Index.read_mode>>=
let read_mode ch =
  let _zero = IO.BigEndian.read_ui16 ch in
  let n = IO.BigEndian.read_ui16 ch in
  match n lsr 12 with
  | 0b1010 -> Link
  <<[[Index.read_mode()]] match [[n lsr 12]] cases>>
  | 0b1000 ->
    (match n land 0x1FF with
    | 0o755 -> Exec
    | 0o644 -> Normal
    | d     -> failwith (spf "Index.mode: invalid permission (%d)" d)
    )
  | m -> failwith (spf "Index.mode: invalid (%d)" m)
@


\chapter{Writing to a Repository}
\label{chap:writing}

% dual.

\section{Objects}

<<signature Repository.add_obj>>=
val add_obj: t -> Objects.t -> Sha1.t
@
<<function Repository.add_obj>>=
let add_obj r obj =
  let bytes = 
    IO.output_bytes () |> IO_.with_close_out (Objects.write obj) in
  let sha = Sha1.sha1 bytes in
  let hexsha = Hexsha.of_sha sha in
  let dir = hexsha_to_dirname r hexsha in
  if not (Sys.file_exists dir)
  then Unix.mkdir dir dirperm;
  let file = hexsha_to_filename r hexsha in
  if (Sys.file_exists file)
  then sha (* deduplication! nothing to write, can share objects *)
  else begin
    file |> with_file_out_with_lock (fun ch ->
      let ic = IO.input_bytes bytes in
      let oc = IO.output_channel ch in
      Compression.compress ic oc;
      IO.close_out oc;
    );
    sha
  end
@

% should warn if add obj already there?
% No! deduplication! if you add a file that hash to content of already
% existing file, then great


<<signature Objects.write>>=
(* will not compress, will return unserialized content for sha1 computation *)
val write: t -> bytes IO.output -> unit
@
<<function Objects.write>>=
let write obj ch =
  let body = 
    IO.output_bytes () |> IO_.with_close_out (fun ch ->
      match obj with
      | Blob x   -> Blob.write x ch
      | Commit x -> Commit.write x ch
      | Tree x   -> Tree.write x ch
      <<[[Objects.write()]] match obj cases>>
    )
  in
  let header = 
    spf "%s %d\000"
      (match obj with
      | Blob _   -> "blob"
      | Commit _ -> "commit"
      | Tree  _  ->  "tree"
      <<[[Objects.write()]] return header, match obj cases>>
      ) 
      (Bytes.length body)
  in
  IO.nwrite ch header;
  IO.nwrite ch body
@



% because when write object, write its size.


\subsection{Compression}

<<signature Compression.compress>>=
val compress: 
  IO.input -> 'a IO.output -> unit
@
<<function Compression.compress>>=
let compress ic oc =
  Zlib.compress 
    (fun buf -> 
      try IO.input ic buf 0 (Bytes.length buf)
      with IO.No_more_input -> 0
    )
    (fun buf len -> 
      IO.output oc buf 0 len |> ignore)
@
% See appendix for Zlib.compress

% So bench? what overhead over working copy uses git to
% store all past versions?

\subsection{Locking}

% Locking here is different from lock on files.
% Concurrent updates to same .git file are not permitted
% (anyway less a pb with git because objects are immutable,
% but still need to modify reference files! especially HEAD)

<<function Repository.with_file_out_with_lock>>=
(* todo: see code of _Gitfile.__init__ O_EXCL ... *)
let with_file_out_with_lock f file =
  (* todo: create .lock file and then rename *)
  Common.with_file_out f file
@
% but really need that for objects?


\subsection{Writing a blob}

<<signature Blob.write>>=
(* does not write the header, does not compress *)
val write: t -> bytes IO.output -> unit
@
<<function Blob.write>>=
let write blob ch =
  IO.nwrite ch blob
@


\subsection{Writing a tree}

<<signature Tree.write>>=
(* does not write the header, does not compress *)
val write: t -> bytes IO.output -> unit
@
<<function Tree.write>>=
let write t ch =
  t |> List.iter (write_entry ch)
@

<<function Tree.write_entry>>=
let write_entry ch e =
  IO.nwrite ch (string_of_perm e.perm);
  IO.write ch ' ';
  (* todo: handle escape char in filenames? encode/decode *)
  IO.nwrite ch e.name;
  IO.write ch '\000';
  Sha1.write ch e.id
@

<<signature Sha1.write>>=
val write: 'a IO.output -> t -> unit
@
<<function Sha1.write>>=
let write ch x =
  IO.nwrite ch x
@

<<function Tree.string_of_perm>>=
let string_of_perm = function
  | Normal -> "100644"
  | Exec   -> "100755"
  | Link   -> "120000"
  | Dir    -> "40000"
  <<[[Tree.string_of_perm()]] match perm cases>>
@


\subsection{Writing a commit}

<<signature Commit.write>>=
(* does not write the header, does not compress *)
val write: t -> 'a IO.output -> unit
@
<<function Commit.write>>=
let write commit ch =
  IO.nwrite ch "tree ";
  Hexsha.write ch (Hexsha.of_sha commit.tree);
  IO.write ch '\n';
  commit.parents |> List.iter (fun parent ->
    IO.nwrite ch "parent ";
    Hexsha.write ch (Hexsha.of_sha parent);
    IO.write ch '\n';
  );
  IO.nwrite ch "author ";
  User.write ch commit.author;
  IO.write ch '\n';
  IO.nwrite ch "committer ";
  User.write ch commit.committer;
  IO.write ch '\n';

  IO.write ch '\n';
  IO.nwrite ch commit.message
@


<<signature Hexsha.write>>=
val write: 'a IO.output -> t -> unit
@
<<function Hexsha.write>>=
let write ch x =
  IO.nwrite ch x
@

<<signature User.write>>=
val write: 'a IO.output -> t -> unit
@
<<function User.write>>=
let write ch user =
  IO.nwrite ch (spf "%s <%s> " user.name user.email);
  write_date ch user.date
@

<<function User.write_date>>=
let write_date ch (date, tz) =
  IO.nwrite ch (Int64.to_string date);
  IO.write ch ' ';
  let sign = match tz.sign with Plus -> "+" | Minus -> "-" in
  IO.nwrite ch (spf "%s%02d%02d" sign tz.hours tz.min)
@

\section{References}

<<signature Repository.write_ref>>=
val write_ref: t -> Refs.t -> Refs.ref_content -> unit
@
<<function Repository.write_ref>>=
(* low-level *)
let write_ref r aref content =
  let file = ref_to_filename r aref in
  file |> with_file_out_with_lock (fun ch ->
    ch |> IO.output_channel |> IO_.with_close_out (Refs.write content))
@
\l check_refname? git-check-ref-format
%    [1] http://www.kernel.org/pub/software/scm/git/docs/git-check-ref-format.html

<<signature Refs.write>>=
val write: ref_content -> unit IO.output -> unit
@
<<function Refs.write>>=
let write content ch =
  match content with
  | Hash h -> 
    IO.nwrite_string ch (Hexsha.of_sha h ^ "\n")
  | OtherRef name ->
    IO.nwrite_string ch ("ref: " ^ name ^ "\n")
@



\section{Index}

% used in init, with empty index.

<<signature Repository.write_index>>=
val write_index: t -> unit
@
<<function Repository.write_index>>=
let write_index r =
  let path = index_to_filename r in
  path |> with_file_out_with_lock (fun ch ->
    ch |> IO.output_channel |> IO_.with_close_out (Index.write r.index)
  )
@


<<signature Index.write>>=
(* will write the header, and sha checksum at the end *)
val write: t -> unit IO.output -> unit
@
<<function Index.write>>=
let write idx ch =
  let n = List.length idx in
  let body =
    IO.output_bytes () |> IO_.with_close_out (fun ch ->
      IO.nwrite ch "DIRC";
      IO.BigEndian.write_i32 ch 2;
      IO.BigEndian.write_i32 ch n;
      idx |> List.iter (write_entry ch)
    )
  in
  let sha = Sha1.sha1 body in
  IO.nwrite ch body;
  Sha1.write ch sha
@

<<function Index.write_entry>>=
let write_entry ch e =
  write_stat_info ch e.stats;
  Sha1.write ch e.id;
  let flags = (0 lsl 12 + String.length e.name) land 0x3FFF in
  IO.BigEndian.write_ui16 ch flags;
  IO.nwrite ch e.name;
  let len = 63 + String.length e.name in
  let pad = 
    match len mod 8 with
    | 0 -> 0
    | n -> 8-n 
  in
  IO.nwrite ch (Bytes.make pad '\000');
  IO.write ch '\000'
@
%old: was using e.stage

<<function Index.write_stat_info>>=
let write_stat_info ch stats =
  write_time ch stats.ctime;
  write_time ch stats.mtime;
  IO.BigEndian.write_real_i32 ch stats.dev;
  IO.BigEndian.write_real_i32 ch stats.inode;
  write_mode ch stats.mode;
  IO.BigEndian.write_real_i32 ch stats.uid;
  IO.BigEndian.write_real_i32 ch stats.gid;
  IO.BigEndian.write_real_i32 ch stats.size;
  ()
@


<<function Index.write_mode>>=
let write_mode ch mode =
  IO.BigEndian.write_ui16 ch 0;
  let n = 
    match mode with
    | Exec    -> 0b1000__000__111_101_101
    | Normal  -> 0b1000__000__110_100_100
    | Link    -> 0b1010__000__000_000_000
    <<[[Index.write_mode()]] match mode cases>>
  in
  IO.BigEndian.write_ui16 ch n
@


<<function Index.write_time>>=
let write_time ch time =
  IO.BigEndian.write_real_i32 ch time.lsb32;
  IO.BigEndian.write_real_i32 ch time.nsec
@



%\chapter{Walking a Repository}

\chapter{Staging a Diff}
\label{chap:staging}

%trans:
% Ok enough introduction. Now ready for real commands again!

%gitless: staging is not necessary.
% But if modified a b c and want different commits, then can!
% (can even use magit-status and pick each changes!)

\section{Adding files: [[git add]]}
% Adding and modifying

<<constant Cmd_add.cmd>>=
let cmd = { Cmd.
  name = "add";
  help = " <file>..."; (* less: pathspec? *)
  options = [
    (* todo: --interactive, --patch for picking, --force (if ignored) 
     * --all, 
     * --recursive
     *)
  ];
  f = (fun args ->
    match args with
    | [] -> pr2 "Nothing specified, nothing added."
    | xs ->
      let r, relpaths = Repository.find_root_open_and_adjust_paths xs in
      (* less: support directories *)
      add r relpaths
  );
}
@

<<function Cmd_add.add>>=
let add r relpaths = 
  (* this will also add some blobs to the object store *)
  Repository.add_in_index r relpaths
@

% build a series of tree objects if different from last one?
% No, commit does that. Here we just add blobs.

% Note that git add is to add new file to repo but also
% to add existing modified file to the commit!

% if git add foo.txt, then modif, then git add other one
% then 2 objects (and one "stale", git gc can clean it)

\section{Creating a blob from a file}

<<signature Repository.add_in_index>>=
val add_in_index: t -> Common.filename list -> unit
@

% create blob and add object! so 'git add' add object to repo.
% if git add again same file then old object is useless (git gc).

<<function Repository.add_in_index>>=
(* old: was called stage() in dulwich *)
let add_in_index r relpaths =
  assert (relpaths |> List.for_all Filename.is_relative);
  relpaths |> List.iter (fun relpath ->
    let full_path = r.worktree / relpath in
    let stat = 
      try Unix.lstat full_path 
      with Unix.Unix_error _ ->
        failwith (spf "Repository.add_in_index: %s does not exist anymore"
                    relpath)
    in
    let blob = Objects.Blob (content_from_path_and_unix_stat full_path stat) in
    let sha = add_obj r blob in
    let entry = Index.mk_entry relpath sha stat in
    r.index <- Index.add_entry r.index entry;
  );
  write_index r
@
\l sanitize fs_path (win32)

<<signature Index.add_entry>>=
val add_entry: t -> entry -> t
@
<<function Index.add_entry>>=
let rec add_entry idx entry =
  match idx with
  | [] -> [entry]
  | x::xs ->
    (match entry.name <=> x.name with
    | Sup -> x::(add_entry xs entry)
    (* replacing old entry is ok *)
    | Equal -> entry::xs
    (* the entries are sorted *)
    | Inf -> entry::x::xs
    )
@

<<function Repository.content_from_path_and_unix_stat>>=
let content_from_path_and_unix_stat full_path stat =
  match stat.Unix.st_kind with
  | Unix.S_LNK ->
    Unix.readlink full_path
  | Unix.S_REG -> 
    full_path |> Common.with_file_in (fun ch ->
      ch |> IO.input_channel |> IO.read_all
    )
  | _ -> failwith (spf "Repository.add_in_index: %s kind not handled" 
                     full_path)
@

% blob can be a symlink! git allows to store symlinks.

% Order of operation is important. Always in a consistent state.
% Will add index entry only if blob has been added! if failure after
% blob created, no pb!

\section{Removing files: [[git rm]]}

<<constant Cmd_rm.cmd>>=
let cmd = { Cmd.
  name = "rm";
  help = " [options] <file>...";
  options = [
  (* less: -f force, -r recursive, --quiet *)
  ];
  f = (fun args ->
    match args with
    | [] -> raise Cmd.ShowUsage
    | xs ->
      let r, relpaths = Repository.find_root_open_and_adjust_paths xs in
      rm r relpaths
  );
}
@

<<function Cmd_rm.rm>>=
let rm r relpaths =
  (* removing is simpler than adding; no need to add blobs in
   * the object store, so can just use functions from Index
   *)
  (* less: not super efficient, could use hashes to speedup things *)
  r.Repository.index <-
    relpaths |> List.fold_left (fun idx relpath ->
          (* todo: -f? remove also file *)
      Index.remove_entry idx relpath
    ) r.Repository.index;
  Repository.write_index r
@


<<signature Index.remove_entry>>=
val remove_entry: t -> Common.filename -> t
@
<<function Index.remove_entry>>=
let rec remove_entry idx name =
  match idx with
  | [] -> failwith (spf "The file %s is not in the index" name)
  | x::xs ->
    (match name <=> x.name with
    | Sup -> x::(remove_entry xs name)
    | Equal -> xs
    (* the entries are sorted *)
    | Inf -> failwith (spf "The file %s is not in the index" name)
    )
@

% when rm, we just want to build from index a tree without
% this entry. Simple.

% Does not remove from working tree. Or need rm -f.
% (Otherwise will be listed as untracked, see Section~\ref{x}).

\section{Renaming files: [[git mv]]}

% huge debate. How to track rename of files and dirs.
%cvs: was terrible at renaming

%git: Just add and rm.
% Note that same sha1 when rename, because same content, so no space lost.

% See later how git handle remames in git log foo.txt, to try to
% infer renames.
% Sha1 can be used to quickly detect renames when explore history.
% See Section~{X}.

\chapter{Committing a Diff}
\label{chap:committing}

\section{Committing the index: [[git commit]]}
%snapshotting the index?

<<constant Cmd_commit.cmd>>=
let cmd = { Cmd.
  name = "commit";
  help = " [options]"; (* less: <pathspec>... *)
  options = [
    "-m",        Arg.Set_string message, " commit message";
    "--message", Arg.Set_string message, " commit message";
    "--author", Arg.Set_string author, " <author> override author";
    "--committer", Arg.Set_string author, " ";
    (* less: commit mesg option: --file, --date, --signoff *)
    (* less: commit content options: -a, --interactive, --patch *)
    (* todo: --amend *)
  ];
  f = (fun args ->
    match args with
    | [] -> 
      let r, _ = Repository.find_root_open_and_adjust_paths [] in
      <<[[Cmd_commit.cmd]] compute [[today]]>>
      <<[[Cmd_commit.cmd]] compute [[author]]>>
      <<[[Cmd_commit.cmd]] compute [[comitter]]>>
      commit r author committer !message

    | xs -> raise Cmd.ShowUsage
  );
}
@

<<constant Cmd_commit.message>>=
let message = ref ""
@

<<function Cmd_commit.commit>>=
let commit r author committer message =
  (* todo: imitate git output
   *   [master 0b50159] xxx
   *   1 file changed, 0 insertions(+), 0 deletions(-)
   *   create mode 100644 foobar.txt
   *)
  (* todo: nothing to commit, working directory clean *)
  Repository.commit_index r author committer message
@


<<signature Repository.commit_index>>=
val commit_index: 
  t -> User.t (* author *) -> User.t (* committer *) -> string (* msg *) -> unit
@
<<function Repository.commit_index>>=
let commit_index r author committer message =
  let aref = Refs.Head in
  let tree = Index.tree_of_index r.index 
    (fun t -> add_obj r (Objects.Tree t)) 
  in
  (* todo: execute pre-commit hook *)

  (* less: Try to read commit message from .git/MERGE_MSG *)
  let message = message in
  (* todo: execute commit-msg hook *)

  let commit = { Commit. parents = []; tree; author; committer; message } in

  let ok =
    match follow_ref r aref |> snd with
    | Some old_head ->
      (* less: merge_heads from .git/MERGE_HEADS *)
      let merge_heads = [] in
      let commit = { commit with Commit.parents = old_head :: merge_heads } in
      let sha = add_obj r (Objects.Commit commit) in
      set_ref_if_same_old r aref old_head sha
    | None ->
      (* maybe first commit so refs/heads/master may not even exist yet *)
      let commit = { commit with Commit.parents = [] } in
      let sha = add_obj r (Objects.Commit commit) in
      add_ref_if_new r aref (Refs.Hash sha)
  in
  if not ok
  then failwith (spf "%s changed during commit" (Refs.string_of_ref aref));
  (* todo: execute post-commit hook *)
  ()
@



\section{Computing the tree from an index}

% FIGURE, flat index to tree.

<<type Index.dirs>>=
type dirs = (string (* full relpath of dir *), dir) Hashtbl.t
@

<<type Index.dir>>=
type dir = dir_entry list ref
@
<<type Index.dir_entry>>=
  and dir_entry =
    | Subdir of string (* basename *)
    | File of string (* basename *) * entry
@



<<signature Index.tree_of_index>>=
val tree_of_index: t -> (* add_obj *)(Tree.t -> Tree.hash) -> Tree.hash
@
<<function Index.tree_of_index>>=
let tree_of_index idx add_tree_obj =
  let (dirs: dirs) = Hashtbl.create 11 in
  Hashtbl.add dirs "." (ref []);
  (* populate dirs *)
  idx |> List.iter (fun entry ->
    let relpath = entry.name in
    let (dir, base) = Filename.dirname relpath, Filename.basename relpath in
    let dir = add_dir dirs dir in
    dir := (File (base, entry))::!dir
  );
  (* build trees *)
  build_trees dirs "." add_tree_obj
@

<<function Index.add_dir>>=
let rec add_dir dirs dirpath =
  try 
    Hashtbl.find dirs dirpath
  with Not_found ->
    let newdir = ref [] in
    Hashtbl.add dirs dirpath newdir;
    let (parent, base) = 
      Filename.dirname dirpath, Filename.basename dirpath in
    (* !recursive call! should stop at some point because "." is in dirs *)
    let dir = add_dir dirs parent in
    dir := Subdir (base)::!dir;
    newdir
@


% FIGURE for trees.
% It maps relative path of dir to dir content



<<function Index.build_trees>>=
let rec build_trees dirs dirpath add_tree_obj =
  let dir = Hashtbl.find dirs dirpath in
  (* entries of a Tree.t must be sorted, but entries of an index too,
   * so we can assume add_dir was called in sorted order
   *)
  let xs = List.rev !dir in
  let tree = 
    xs |> List.map (function
      | File (base, entry) ->
        {Tree.
         name = base; 
         id = entry.id; 
         perm = perm_of_mode entry.stats.mode;
        }
      | Subdir base ->
        let sha = 
          build_trees dirs (Filename.concat dirpath base) add_tree_obj in
        {Tree. perm = Tree.Dir; name = base; id = sha }
    )
  in
  add_tree_obj tree
@

<<signature Index.perm_of_mode>>=
val perm_of_mode: mode -> Tree.perm
@
<<function Index.perm_of_mode>>=
let perm_of_mode mode = 
  match mode with
  | Normal -> Tree.Normal
  | Exec -> Tree.Exec
  | Link -> Tree.Link
  <<[[Index.perm_of_mode()]] match mode cases>>
@


\section{Storing the author and committer}

<<[[Cmd_commit.cmd]] compute [[today]]>>=
let today = 
  (Int64.of_float (Unix.time ()),
   { User.
 (* todo: use localtime vs gmtime? *)
     sign = User.Minus;
     hours = 7; (* SF *)
     min = 0;
   })
in
@


<<constant Cmd_commit.author>>=
let author = ref ""
@
<<constant Cmd_commit.committer>>=
let committer = ref ""
@

<<[[Cmd_commit.cmd]] compute [[author]]>>=
(* todo: read from .git/config or ~/.gitconfig *)
let author = 
  if !author = ""
  then { User.
         name = Unix.getlogin ();
         email = "todo@todo";
         date = today;
       }
  else raise Todo (* need parse author string *)
in
@
<<[[Cmd_commit.cmd]] compute [[comitter]]>>=
let committer =
  if !committer = ""
  then author
  else raise Todo
in
@



% Use config for default, see adv topics.

\section{Recording the message}


\section{Updating [[HEAD]]}

% HEAD by default

%concurrency:
% need atomic operations for updating the refs, because
% push/pull will modify other repos that may be concurrently
% accessed by another user at the same time.

% why important atomic? because when push, you will write to another
% repo, and you will modify refs possibly? so need atomic?

%cvs: CVS was first to consider a set of files, but it was not atomic!

%torvalds: simple, just need update the ref! no need lock
% on set of files (immutable hashed objects), just lock
% one ref, refs/heads/master (or other branch name)

% Can have pb, in which case just stale objects? (git gc)

\subsection{Updating an existing reference}


<<signature Repository.set_ref_if_same_old>>=
val set_ref_if_same_old: t -> Refs.t -> Sha1.t -> Sha1.t -> bool
@
<<function Repository.set_ref_if_same_old>>=
let set_ref_if_same_old r aref oldh newh =
  let (refs, _) = follow_ref r aref in
  let lastref = List.hd (List.rev refs) in
  let file = ref_to_filename r lastref in
  try 
    file |> with_file_out_with_lock (fun ch ->
      (* TODO generate some IO.No_more_input 
      let prev = read_ref r lastref in
      if prev <> (Refs.Hash oldh)
      then raise Not_found
      else 
      *)
        ch |> IO.output_channel |> IO_.with_close_out 
            (Refs.write (Refs.Hash newh))
    );
    true
  with Not_found -> false
@

\subsection{Creating a new reference (first commit)}

<<signature Repository.add_ref_if_new>>=
val add_ref_if_new: t -> Refs.t -> Refs.ref_content -> bool
@
<<function Repository.add_ref_if_new>>=
let add_ref_if_new r aref refval =
  let (refs, shaopt) = follow_ref r aref in
  if shaopt <> None
  then false
  else begin
    let lastref = List.hd (List.rev refs) in
    let file = ref_to_filename r lastref in
    (* todo: ensure dirname exists *)
    file |> with_file_out_with_lock (fun ch ->
      (* todo: check file does not exist aleady *)
      ch |> IO.output_channel |> IO_.with_close_out (Refs.write refval)
    );
    true
  end
@


\chapter{Branching}
\label{chap:branching}

% branching, aka fork.

%dup: (but expanded?) intro/motivations
% purpose: parallel development (!= concurrent development)
% 

%gitless: records working version of files, so can easily switch branch!
% no problem if got uncommitted stuff in current dir or untracked file
% that conflicts with tracked file in another branch, it will be saved!
% in gitless, it really is like you had 2 separate dirs with 2
%  separate working versions!

% Again can simply use cp and create another repo :)

% Branch operations are very simple. Just list/create/delete
% entries under refs/.
% cheap
%cvs: was terrible at managing branch. Relied on RCS branch mechanism,
% which was per file with complex encoding 1.1.1.1 and file format
% (forward-deltas on top of reverse-deltas).

% Important in DVCS to have cheap and simple branching (and merging), because
% everybody is a branch! everybody maintains its own fork!

<<constant Cmd_branch.cmd>>=
let cmd = { Cmd.
  name = "branch";
  help = " [options]
   or: ocamlgit branch [options] <branchname>
   or: ocamlgit branch [options] (-d | -D) <branchname>
";
  options = [
    "-d",       Arg.Set del_flag, " delete fully merged branch";
    "--delete", Arg.Set del_flag, " delete fully merged branch";
    "-D",       Arg.Set del_force, " delete branch (even if not merged)";
    (* less: --merged, --no-merged, --all for listing 
     *  --move to rename branch
     *  --force (force creation, deletion, rename)
    *)
  ];
  f = (fun args ->
    let r, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> list_branches r
    | [name] ->
      (match () with
      | _ when !del_flag  -> delete_branch r name false
      | _ when !del_force -> delete_branch r name true
      | _ -> create_branch r name
      )
    | [name;objectish] ->
      raise Todo
    | _ -> raise Cmd.ShowUsage
  );
}
@
%pijul: use 'fork' and 'delete-branch' as commands instead of 
% abusing branch for everything

<<constant Cmd_branch.del_flag>>=
let del_flag = ref false
@
<<constant Cmd_branch.del_force>>=
let del_force = ref false
@


\section{Listing branches: [[git branch]]}

<<function Cmd_branch.list_branches>>=
(* less: remote_flag set with --all to also list remote refs *)
let list_branches r =
  let head_branch = Repository.read_ref r (Refs.Head) in
  let all_refs = Repository.all_refs r in
  all_refs |> List.iter (fun refname ->
    if refname =~ "^refs/heads/\\(.*\\)"
    then 
      let short = Regexp_.matched1 refname in
      let prefix = 
        if (Refs.OtherRef refname = head_branch)
        then " * "
        else "   "
      in
      pr (spf "%s%s" prefix short)
  )
@

<<signature Repository.all_refs>>=
val all_refs: t -> Refs.refname list
@
<<function Repository.all_refs>>=
let all_refs r =
  let root = r.dotgit ^ "/" in
  let rootlen = String.length root in
  let res = ref [] in
  (root / "refs") |> walk_dir (fun path dirs files ->
    files |> List.iter (fun file ->
      (* less: replace os.path.sep *)
      let dir = String.sub path rootlen (String.length path - rootlen) in
      let refname = dir / file in
      Common.push refname res
    );
   );
  List.rev !res
@

% all_refs | ?? -> <>
<<signature Repository.walk_dir>>=
val walk_dir: 
  (Common.filename -> Common.filename list -> Common.filename list -> unit) ->
  Common.filename ->
  unit
@
<<function Repository.walk_dir>>=
(* inspired from os.path.walk in Python *)
let rec walk_dir f dir =
  dir |> with_opendir (fun handle ->
    let dirs = ref [] in
    let files = ref [] in
    try 
      while true do
        let s = Unix.readdir handle in
        (* git specific here *)
        if s <> "." && s <> ".." && s <> ".git" then begin
          let path = Filename.concat dir s in
          let st = Unix.lstat path in
          (match st.Unix.st_kind with
          | Unix.S_DIR -> Common.push s dirs
          | _ -> Common.push s files
          )
        end
      done
    with End_of_file ->
      let dirs = List.rev !dirs in
      let files = List.rev !files in
      f dir dirs files;
      dirs |> List.iter (fun s ->
        walk_dir f (Filename.concat dir s)
      )
  )
@

<<function Repository.with_opendir>>=
(* less: use finalize *)
let with_opendir f dir =
  let handle = Unix.opendir dir in
  let res = f handle in
  Unix.closedir handle;
  res
@

\section{Creating a branch: [[git branch <name>]]}
\label{sec:create-branch}

<<function Cmd_branch.create_branch>>=
let create_branch r name (* sha *) =
  let all_refs = Repository.all_refs r in
  let refname = "refs/heads/" ^ name in
  <<[[Cmd_branch.create_branch()]] sanity check refname>>
  let sha = Repository.follow_ref_some r (Refs.Head) in
  let ok = Repository.add_ref_if_new r (Refs.Ref refname) (Refs.Hash sha) in
  if not ok
  then failwith (spf "could not create branch '%s'" name)
@

% cheap! (ok checkout takes time)
% and then usually checkout!

<<[[Cmd_branch.create_branch()]] sanity check refname>>=
if List.mem refname all_refs
(* less: unless -force *)
then failwith (spf "A branch named '%s' already exists." name);
@

\section{Deleting a branch: [[git branch -d <name>]]}

<<function Cmd_branch.delete_branch>>=
let delete_branch r name force =
  let refname = "refs/heads/" ^ name in
  let aref = Refs.Ref refname in
  let sha = Repository.follow_ref_some r aref in
  if not force
  (* todo: detect if fully merged branch! *)    
  then ();
  Repository.del_ref r aref;
  pr (spf "Deleted branch %s (was %s)" name (Hexsha.of_sha sha))
@

<<signature Repository.del_ref>>=
val del_ref: t -> Refs.t -> unit
@
<<function Repository.del_ref>>=
let del_ref r aref =
  let file = ref_to_filename r aref in
  Unix.unlink file
@

% git gc

\section{Checking out a branch: [[git checkout]]}
\label{sec:switch-branch}
\l switching branch


<<constant Cmd_checkout.cmd>>=
let cmd = { Cmd.
  name = "checkout";
  help = " [options] <branch>
   or: ocamlgit checkout [options] <commitid>
   or: ocamlgit checkout [options]
";
  options = [
    (* less: --detach, --patch?
     * -b create and checkout a branch
     *)
  ];
  f = (fun args ->
    let r, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> update r
    | [str] -> checkout r str
    | _ -> raise Cmd.ShowUsage
  );
}
@

<<function Cmd_checkout.checkout>>=
let checkout r str =
  let all_refs = Repository.all_refs r in
  let refname = "refs/heads/" ^ str in

  match () with
  | _ when List.mem refname all_refs ->
    let commitid = Repository.follow_ref_some r (Refs.Ref refname) in
    let commit = Repository.read_commit r commitid in
    let treeid = commit.Commit.tree in
    let tree = Repository.read_tree r treeid in
    (* todo: order of operation? set ref before index? reverse? *)
    Repository.write_ref r (Refs.Head) (Refs.OtherRef refname);
    Repository.set_worktree_and_index_to_tree r tree;
    pr (spf "Switched to branch '%s'" str);
    (* less: if master, then check if up-to-date with origin/master *)
  <<[[Cmd_checkout.checkout()]] cases>>
  | _ -> raise Cmd.ShowUsage
@


% reset_index use for checkout!

% build_index and also set worktree from tree.



<<function Cmd_checkout.update>>=
(* Your branch is up-to-date with 'origin/master'. *)
let update r =
  raise Todo
@

\subsection{Computing the index (and worktree) from a tree}
\label{sec:index-from-tree}
% opposite of what we saw before for git commit.

<<signature Repository.set_worktree_and_index_to_tree>>=
val set_worktree_and_index_to_tree:
  t -> Tree.t -> unit
@
<<function Repository.set_worktree_and_index_to_tree>>=
let set_worktree_and_index_to_tree r tree =
  (* todo: need lock on index? on worktree? *)
  let hcurrent = 
    r.index |> List.map (fun e -> e.Index.name, false) |> Hashtbl_.of_list in
  let new_index = ref [] in
  (* less: honor file mode from config file? *)
  tree |> Tree.walk_tree (read_tree r) "" (fun relpath entry ->
    let perm = entry.Tree.perm in
    match perm with
    | Tree.Dir -> 
      (* bugfix: need also here to mkdir; doing it below is not enough
       * when a dir has no file but only subdirs
       *)
      let fullpath = r.worktree / relpath in
      if not (Sys.file_exists fullpath)
      then Unix.mkdir fullpath dirperm;
    | Tree.Normal | Tree.Exec | Tree.Link ->
      (* less: validate_path? *)
      let fullpath = r.worktree / relpath in
      if not (Sys.file_exists (Filename.dirname fullpath))
      then Unix.mkdir (Filename.dirname fullpath) dirperm;
      let sha = entry.Tree.id in
      let blob = read_blob r sha in
      let stat = build_file_from_blob fullpath blob perm in
      Hashtbl.replace hcurrent relpath true;
      Common.push (Index.mk_entry relpath sha stat) new_index;
    <<[[Repository.set_worktree_and_index_to_tree()]] walk tree cases>>
  );
  let index = List.rev !new_index in
  r.index <- index;
  write_index r;
  hcurrent |> Hashtbl.iter (fun file used ->
    if not used
    then 
      (* todo: should check if modified? otherwise lose modif! *)
      let fullpath = r.worktree / file in
      Unix.unlink fullpath
  )
  (* less: delete if a dir became empty, just walk_dir? *)
@

\t should also delete file not present in old version but were in
\t  current version

<<signature Tree.walk_tree>>=
val walk_tree: 
  (hash -> t) -> Common.filename (* dir *) -> 
  (Common.filename -> entry -> unit) -> t -> unit
@
<<function Tree.walk_tree>>=
(* we must visit in sorted order, so the caller of walk_tree can rely on 'f'
 * being called in order (so it can easily create for example sorted 
 * index entries while visiting a tree)
 *)
let rec walk_tree read_tree dirpath f xs =
  xs |> List.iter (fun entry ->
    let relpath = Filename.concat dirpath entry.name in
    f relpath entry;
    match entry.perm with
    | Dir ->
      walk_tree read_tree relpath f (read_tree entry.id)
    | Normal | Exec | Link -> ()
    <<[[Tree.walk_tree()]] match perm cases>>
  )
@
% there is also walk_trees, later.


\subsection{Creating a file from a blob}

<<function Repository.build_file_from_blob>>=
let build_file_from_blob fullpath blob perm =
  let oldstat =
    try 
      Some (Unix.lstat fullpath)
    with Unix.Unix_error _ -> None
  in
  (match perm with 
  | Tree.Link -> 
    if oldstat <> None
    then Unix.unlink fullpath;
    Unix.symlink blob fullpath;
  | Tree.Normal | Tree.Exec ->
    (match oldstat with
    (* opti: if same content, no need to write anything *)
    | Some { Unix.st_size = x } when x = Bytes.length blob && 
      (fullpath |> Common.with_file_in (fun ch -> 
        (ch |> IO.input_channel |> IO.read_all ) = blob
       )) ->
      ()
    | _ ->
      fullpath |> Common.with_file_out (fun ch ->
        output_bytes ch blob
      );
      (* less: honor filemode? *)
      Unix.chmod fullpath 
        (match perm with 
        | Tree.Normal -> 0o644
        | Tree.Exec -> 0o755
        | _ -> raise (Impossible "matched before")
        )
    )
  | Tree.Dir -> raise (Impossible "dirs filtered in walk_tree iteration")
  <<[[Repository.build_file_from_blob()]] match perm cases>>
  );
  Unix.lstat fullpath
@


%\subsection{[[validate_path()]]}


\section{Resetting a branch: [[git reset]]}

<<constant Cmd_reset.cmd>>=
let cmd = { Cmd.
  name = "reset";
  help = " [options] ";
(* less: or: git reset <paths>... *)
  options = [
    "--hard", Arg.Set hard, " reset HEAD, index and working tree";
    "--soft", Arg.Set soft, " reset only HEAD";
    "--mixed", Arg.Set mixed, " reset HEAD and index";
    (* less: --patch, --quiet, --merge *)
  ];
  f = (fun args ->
    let r, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> 
      if !soft || !mixed || not !hard
      then begin
        pr2 "only --hard supported";
        raise Cmd.ShowUsage
      end;
      reset_hard r
    | _ -> raise Cmd.ShowUsage
  );
}
@

<<constant Cmd_reset.hard>>=
let hard = ref false
@
<<constant Cmd_reset.soft>>=
let soft = ref false
@
<<constant Cmd_reset.mixed>>=
let mixed = ref false
@


<<function Cmd_reset.reset_hard>>=
let reset_hard r =
  let commitid = Repository.follow_ref_some r (Refs.Head) in
  let commit = Repository.read_commit r commitid in
  let treeid = commit.Commit.tree in
  let tree = Repository.read_tree r treeid in
  Repository.set_worktree_and_index_to_tree r tree;
  pr (spf "HEAD is now at %s %s" 
        (String.sub (Hexsha.of_sha commitid) 0 6)
        (String.sub commit.Commit.message 0 40))
@

\t should also reset selectively files or dirs

\chapter{Merging}
\label{chap:merging}
% "Integrating changes" in misfit paper

%trans: after fork, of course dual is merge

% for // devel but also concurrent devel. everyone is a branch.

% ??? no code in dulwich for merge? or just do_commit with multiple
% parents? the <<< >>> conflict is not part of git but can be third-party?

% MERGE_HEADS?

% saw merge_tag before in commit, and merge_heads in do_commit.

%torvalds:
% On need for clever merge:
% https://wincent.com/blog/a-look-back-bram-cohen-vs-linus-torvalds:

%"There is no need for fancy metadata, rename tracking and so forth. The
%only thing you need to store is the state of the tree before and after
%each change. What files were renamed? Which ones were copied? Which
%ones were deleted? What lines were added? Which ones were removed?
%Which lines had changes made inside them? Which slabs of text were
%copied from one file to another? You shouldn't have to care about any
%of these questions and you certainly shouldn't have to keep special
%tracking data in order to help you answer them: all the changes to the
%tree (additions, deletes, renames, edits etc) are implicitly encoded
%in the delta between the two states of the tree; you just track what
%is the content.
%
%Git is already very smart, and it can (and will) get smarter about
%figuring out what happened, and where a given line in a given revision
%came from, and it will do so without ever having to embed additional
%meta data in its repositories. Absolutely everything can (and should)
%be inferred.
%
%Git breaks the mould because it thinks about content, not files. It
%doesn't track renames, it tracks content. And it does so at a
%whole-tree level. This is a radical departure from most version
%control systems. It doesn't bother trying to store per-file histories;
%it instead stores the history at the tree level. When you perform a
%diff you are comparing two trees, not two files.
%
%As a result of this fundamental design decision, the structure of a
%Git repository is stunningly simple. It's so simple in fact, that
%you'll be surprised at the sophistication of the things you can do
%with it. But that's the way the best code will always be: simple,
%solid premises out of which complex applications arise.
%
%The other fundamentally smart design decision is how Git does merges.
%The merging algorithms are smart but they don't try to be too smart.
%Unambiguous decisions are made automatically, but when there's doubt
%it's up to the user to decide. This is the way it should be. You don't
%want a machine making those decisions for you. You never will want it.
%That's the fundamental insight in the Git approach to merging: while
%every other version control system is trying to get smarter, Git is
%happily self-described as the "stupid content manager", and it's
%better for it."


%related? history sensitive merging?
%https://tahoe-lafs.org/~zooko/badmerge/simple.html

\section{merge: [[git merge]]}
\label{sec:git-merge}

% Pb of history-sensitive merging? If share some patches? Arch better?
% Or just completely forget the pb and do a general 3-way merge from
% base and just care about final state of both branches?

% 3-way merge algorithm? diff3?

\section{Rebase: [[git rebase]]}

% Cite GitFlow blob controversy?

\section{Cherry-pick: [[git cherry-pick]]}

%:darcs: %pijul: better for that
% src: https://pijul.org/manual/why_pijul.html
% when cherry picking git changes the commit. 
% It does not have the same parent and so not
% same commit id, and so later this can cause pb because git
% has no way to know when merging that this patch is common.


\chapter{Inspecting}
\label{chap:inspecting}

%trans: %toc: log, diff, status. keep track on what's going on.
% but before show, less useful, but simpler, and can be used
% to further inspect output from other commands (e.g. git show after git log
% (or use git log -P to see patch)

\section{Showing the content of an object: [[git show]]}
% can be useful to understand formats

<<constant Cmd_show.cmd>>=
let cmd = { Cmd.
  name = "show";
  help = " <objectish>";
  (* less: --oneline *)
  options = [];
  f = (fun args ->
    let r, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> show r (Repository.ObjByRef (Refs.Head))
    | xs ->
      xs |> List.iter (fun str ->
        show r (Repository.ObjByHex (str))
      )
  );
}
@
\l could have shorthex here, or branchname

<<function Cmd_show.show>>=
let show r objectish =
  let sha, obj = Repository.read_objectish r objectish in
  match obj with
  <<[[Cmd_show.show()]] match obj cases>>
@

\subsection{Showing a blob}

<<[[Cmd_show.show()]] match obj cases>>=
| Objects.Blob x -> 
  Blob.show x
@

<<signature Blob.show>>=
val show: t -> unit
@
<<function Blob.show>>=
let show x =
  print_string x
@


\subsection{Showing a tree}

<<[[Cmd_show.show()]] match obj cases>>=
| Objects.Tree x ->
  (* =~ git ls-tree --names-only *)
  pr (spf "tree %s\n" (Hexsha.of_sha sha));
  Tree.show x
@

<<signature Tree.show>>=
val show: t -> unit
@
<<function Tree.show>>=
let show xs =
  xs |> List.iter (fun entry ->
    pr (spf "%s%s" entry.name
          (match entry.perm with
          | Dir -> "/"
          | _ -> ""
          ))
  )
@
% git adds a '/' suffix when it's a dir

\subsection{Showing a commit}

% So can be used after git log to show the diff!


<<[[Cmd_show.show()]] match obj cases>>=
| Objects.Commit x -> 
  pr (spf "commit %s" (Hexsha.of_sha sha));
  Commit.show x;
  let tree2 = Repository.read_tree r x.Commit.tree in
  let tree1 = 
    try 
      let parent1 = Repository.read_commit r (List.hd x.Commit.parents) in
      Repository.read_tree r parent1.Commit.tree 
    with Failure _ ->
    (* no parent *)
      []
  in
  let changes = 
    Changes.changes_tree_vs_tree 
      (Repository.read_tree r) 
      (Repository.read_blob r)
      tree1 tree2 
  in
  changes |> List.iter Diff_unified.show_change
@


<<signature Commit.show>>=
val show: t -> unit
@
<<function Commit.show>>=
let show x =
  pr (spf "Author: %s <%s>" x.author.User.name x.author.User.email);
  (* less: date of author or committer? *)
  let date = x.author.User.date in
  pr (spf "Date:   %s" (User.string_of_date date));
  pr "";
  pr ("    " ^ x.message)
  (* showing diff done in caller in Cmd_show.show *)        
@

% print_commit() before
% write_tree_diff in caller.

<<signature User.string_of_date>>=
(* for show *)
val string_of_date: (int64 * tz_offset) -> string
@

<<function User.string_of_date>>=
let string_of_date (date, tz) =
  let f = Int64.to_float date in
  let tm = Unix.localtime f in

  spf "%s %s %d %02d:%02d:%02d %d %c%02d%02d"
    (Date.string_of_day tm.Unix.tm_wday) (Date.string_of_month tm.Unix.tm_mon) 
    tm.Unix.tm_mday 
    tm.Unix.tm_hour tm.Unix.tm_min tm.Unix.tm_sec (tm.Unix.tm_year + 1900)
    (char_of_sign tz.sign) tz.hours tz.min
@

<<function User.char_of_sign>>=
let char_of_sign = function
  | Plus -> '+'
  | Minus -> '-'
@

\section{Representing changes}

%trans:
% We will see a few commands showing changes (git diff, git status),
% so first introduce changes types.

\subsection{Tree changes}

<<type Change.t>>=
(* entry below refers only to files (not dirs), and their name
 * are adjusted to show a relative path from the root of the
 * project.
 *)
type t = 
  | Add of entry
  | Del of entry
  | Modify of entry * entry (* before / after *)
  (* less: Rename, Copy *)
  (*| Identical of Tree.entry *)
@

<<type Change.entry>>=
type entry = {
  (* relative path *)
  path: Common.filename;
  mode: Index.mode;
  content: content Lazy.t;
}
@
% lazy, subtle, for performance, otherwise operation like git XXX are too
% slow.

<<type Change.content>>=
type content = bytes
@

% Note that changes used only for inspecting. Not part of core DS.
% Git store content, not diff (well except in Pack, see later).

%\subsection{Worktree versus index}
%\subsection{Index versus tree}
%\subsection{Tree versus tree}

\subsection{File changes}

<<type Diff.diff>>=
type diff = (item diff_elem) list
@

<<type Diff.diff_elem>>=
(* similar to change.ml, but for content of the file *)
type 'item diff_elem = 
  | Added   of 'item
  | Deleted of 'item
  | Equal   of 'item
@

<<type Diff.item>>=
type item = string
@

% Again diff not part of core DS. Used for inspecting.

\section{Showing file differences: [[git diff]]}

<<constant Cmd_diff.cmd>>=
let cmd = { Cmd.
  name = "diff";
  help = " ";
  options = [];
  f = (fun args ->
    let r, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> diff_worktree_vs_index r
    | xs -> raise Cmd.ShowUsage
  );
}
@

<<function Cmd_diff.diff_worktree_vs_index>>=
let diff_worktree_vs_index r =
  let changes = 
    Changes.changes_worktree_vs_index 
      (Repository.read_blob r)
      r.Repository.worktree 
      r.Repository.index 
  in
  changes |> List.iter Diff_unified.show_change
@

\subsection{Computing tree changes}

% naive version. Want heuristics for rename detection!

<<signature Changes.changes_worktree_vs_index>>=
(* for git diff and git status *)
val changes_worktree_vs_index:
  (Blob.hash -> Change.content) ->
  Common.filename -> Index.t -> Change.t list
@
<<function Changes.changes_worktree_vs_index>>=
(* less: could factorize with Diff_tree.changes_tree_vs_tree? would need
 * to generate flat list of files (but then less opti opportunity
 * in changes_tree_vs_tree when hash for a whole subtree is the same)
 * and then just do set differences to compute new, deleted, and
 * for changes just look intersection and check if same content.
 *)
let changes_worktree_vs_index read_blob worktree index =
  index |> List.map (fun entry ->
    let old_stat = entry.Index.stats in
    let path = Filename.concat worktree entry.Index.name in
    let new_stat_opt = 
      try Some (Unix.lstat path |> Index.stat_info_of_lstats)
      with Unix.Unix_error _ -> None
    in
    match new_stat_opt with
    | None -> 
      [Change.Del { Change.path = entry.Index.name;
                    mode = old_stat.Index.mode;
                    content = lazy (read_blob entry.Index.id);
                  }]
    | Some new_stat ->
      (match () with
      (* useful opti? *)
      | _ when new_stat.Index.mtime = old_stat.Index.mtime -> []
      (* a change of mode is converted in a del/add *)
      | _ when new_stat.Index.mode <> old_stat.Index.mode ->
        [Change.Del { Change.path = entry.Index.name;
                      mode = old_stat.Index.mode;
                      content = lazy (read_blob entry.Index.id)};
         Change.Add { Change.path = entry.Index.name;
                      mode = new_stat.Index.mode;
                      content = lazy 
                        (content_from_path_and_stat_index path new_stat)}
          ]
      | _ -> 
        [Change.Modify (
          { Change.path = entry.Index.name;
            mode = old_stat.Index.mode;
            content = lazy (read_blob entry.Index.id) },
          { Change.path = entry.Index.name;
            mode = new_stat.Index.mode;
            content = lazy 
              (content_from_path_and_stat_index path new_stat) }
        )]
      )
  ) |> List.flatten
@

<<function Changes.content_from_path_and_stat_index>>=
(* similar to Repository.content_from_path_and_unix_stat *)
let content_from_path_and_stat_index path stat_info =
  match stat_info.Index.mode with
  | Index.Link ->
    Unix.readlink path
  | Index.Normal | Index.Exec ->
      path |> Common.with_file_in (fun ch ->
        ch |> IO.input_channel |> IO.read_all
      )
  <<[[Changes.content_from_path_and_stat_index()]] match mode cases>>
@

\subsection{Computing file changes}

% naive version. Want heuristics for block-move detection!

% string below is Change.content
<<signature Diffs.diff>>=
val diff: string -> string -> Diff.diff
@
% see appendix
<<function Diffs.diff>>=
let diff str1 str2 =
  let xs = split_lines str1 in
  let ys = split_lines str2 in
  Diff_myers.diff (Array.of_list xs) (Array.of_list ys)
@

<<function Diffs.split_lines>>=
let split_lines str =
  (* alt: let xs = Str.full_split (Str.regexp "\n") str in *)
  let rec aux start = 
    try
      let idx = String.index_from str start '\n' in
      let line = String.sub str start (idx - start + 1) in
      line::aux (idx + 1)
    with Not_found ->
      if start = String.length str
      then []
      else [String.sub str start (String.length str - start)]
  in
  aux 0
@



\subsection{Showing changes}

<<signature Diff_unified.show_change>>=
val show_change: Change.t -> unit
@
<<function Diff_unified.show_change>>=
let show_change change =
  (* less: if mode is gitlink? *)
  let (old_path, old_content), (new_path, new_content) = 
    match change with
    | Change.Add entry ->
      ("dev/null", lazy ""), 
      ("b/" ^ entry.Change.path, entry.Change.content)
    | Change.Del entry ->
      ("a/" ^ entry.Change.path, entry.Change.content), 
      ("dev/null", lazy "")
    | Change.Modify (entry1, entry2) ->
      ("a/" ^ entry1.Change.path, entry1.Change.content), 
      ("b/" ^ entry2.Change.path, entry2.Change.content)
  in
  let diffs = Diffs.diff (Lazy.force old_content) (Lazy.force new_content) in
  if not (diffs |> List.for_all (function Diff.Equal _ -> true | _ -> false))
  then begin
    pr (spf "diff --git %s %s" old_path new_path);
    (* less: display change of modes *)
    show_unified_diff diffs
  end
@


<<function Diff_unified.show_unified_diff>>=
let show_unified_diff diffs =
  (* naive: no contextual:  diffs |> List.iter print *)
  let rec aux context_lines nctx_before nctx_after nold nnew diffs =
    match diffs with
    (* todo: say if 'No newline at end of file' *)
    | [] -> ()
    | x::xs ->
      (match x with
      | Diff.Equal s ->
        (match () with
        | _ when nctx_after > 0 ->
          print x;
          aux [] 0 (nctx_after - 1) (nold + 1) (nnew + 1) xs
        | _ when nctx_before < nContext ->
          aux (x::context_lines) (nctx_before + 1) 0 (nold + 1) (nnew + 1) xs
        | _ when nctx_before = nContext ->
          let new_context_lines = List_.take nContext (x::context_lines) in
          aux new_context_lines nContext 0 (nold + 1) (nnew + 1) xs
        | _ -> raise (Impossible "")
        )
      | Diff.Deleted s  ->
        let prevs = List_.take nctx_before context_lines |> List.rev in
        if prevs <> [] then print_header nctx_before nold nnew;
        prevs |> List.iter print;
        print x;
        aux [] 0 nContext (nold + 1) (nnew) xs
      | Diff.Added s ->
        let prevs = List_.take nctx_before context_lines |> List.rev in
        if prevs <> [] then print_header nctx_before nold nnew;
        prevs |> List.iter print;
        print x;
        aux [] 0 nContext (nold) (nnew+1) xs
      )
  in
  aux [] 0 0 1 1 diffs
@

<<constant Diff_unified.nContext>>=
let nContext = 3
@

<<function Diff_unified.print>>=
let print = function
  | Diff.Equal s -> 
    print_string (" " ^ s)
  | Diff.Deleted s -> 
    print_string ("-" ^ s)
  | Diff.Added s -> 
    print_string ("+" ^ s)
@

<<function Diff_unified.print_header>>=
let print_header nctx_before nold nnew =
  (* todo: should print size of hunk also here, but then
   * need to wait we finished processing this hunk
   *)
  print_string (spf "@@ -%d, +%d, @@\n"
                  (nold - nctx_before) (nnew - nctx_before))
@


\section{Commit history walker}
\l make it a chapter? Walking a Repository?
\n renamed commit history walker so less confusing with object store walker?

% actually a DAG of commits, not a graph of commits.

\t used outside git log? so just put inside git log?

\subsection{Basic walker}

<<signature Commit.walk_history>>=
val walk_history:  
  (hash -> t) -> (hash -> t -> unit) -> hash ->
  unit
@
<<function Commit.walk_history>>=
(* less: sort by time? so have a sorted queue of commits *)
let walk_history read_commit f sha =
  (* we are walking a DAG, so we need to remember already processed nodes *)
  let hdone = Hashtbl.create 101 in
  let rec aux sha =
    if Hashtbl.mem hdone sha
    then ()
    else begin
      Hashtbl.add hdone sha true;
      let commit = read_commit sha in
      (* todo: path matching *)
      f sha commit;
      commit.parents |> List.iter aux
    end
  in
  aux sha
(* 
let walk_graph r f =
  let heads = 
    Repository.all_refs r |> Common.map_filter (fun aref ->
      if aref =~ "refs/heads/"
      then Some (Repository.follow_ref_some r (Refs.Ref aref))
      else None
    )
  in
  ...
  heads |> List.iter aux
*)
@

\subsection{Extra features}
\l mv in advanced topics?

\subsubsection{max entries}
% git log -1, -10, useful.

\subsubsection{Reverse walking}
% requires O(n). will call iterator and store result a list.

\subsubsection{Exclude set}

\subsubsection{Time range}

\subsubsection{Path restrictions}

\subsubsection{Topological order}


\section{Showing the commit history: [[git log]]}

<<constant Cmd_log.cmd>>=
let cmd = { Cmd.
  name = "log";
  help = " [options]";
  options = [
    "--name-status", Arg.Set name_status, 
    " print name/status for each changed file";
    (* todo: -1, -10 *)
    (* less: --reverse *)
  ];
  f = (fun args ->
    let r, relpaths = Repository.find_root_open_and_adjust_paths args in
    match relpaths with
    | [] -> log r
    (* todo: git log path *)
    (* less: revision range *)
    | xs -> raise Cmd.ShowUsage
  );
}
@

<<function Cmd_log.log>>=
(* todo: track only selected paths 
 * (and then rename detection to track correctly)
 *)
let log r =
  let start = Repository.follow_ref_some r (Refs.Head) in
  start |> Commit.walk_history (Repository.read_commit r) (fun sha commit ->
    print_commit sha commit;
    <<[[Cmd_log.log()]] if [[--name-status]] flag>>
    end
  )
@


\subsection{Printing a commit}

<<function Cmd_log.print_commit>>=
let print_commit sha commit =
  pr (spf "commit: %s" (Hexsha.of_sha sha));
  (match commit.Commit.parents with
  | [] | [_] -> ()
  | x::xs ->
    pr (spf "merge: %s" 
          (xs |> List.map Hexsha.of_sha |> String.concat "..."));
  );
  let author = commit.Commit.author in
  pr (spf "Author: %s <%s>" author.User.name author.User.email);
  let committer = commit.Commit.committer in
  if author <> committer
  then 
    pr (spf "Committer: %s <%s>" committer.User.name committer.User.email);
  pr (spf "Date:   %s" (User.string_of_date author.User.date));
  pr "";
  pr ("    " ^ commit.Commit.message);
  ()
@

\subsection{Diff summary: [[git log --name-status]]}

<<constant Cmd_log.name_status>>=
let name_status = ref false
@
<<[[Cmd_log.log()]] if [[--name-status]] flag>>=
if !name_status
then begin
  let tree1 = Repository.read_tree r commit.Commit.tree in
  let tree2 =
    match commit.Commit.parents with
    | [] -> []
    | [sha] -> 
      let commit2 = Repository.read_commit r sha in
      Repository.read_tree r commit2.Commit.tree
    | x::y::xs ->
      failwith "TODO: log: handle merge"
  in
  let changes = Changes.changes_tree_vs_tree
    (Repository.read_tree r)
    (Repository.read_blob r)
    tree2
    tree1
  in
  changes |> List.iter print_change;
  pr "";
@


<<function Cmd_log.print_change>>=
let print_change change =
  match change with
  | Change.Add entry ->
    pr (spf "A       %s" entry.Change.path)
  | Change.Del entry ->
    pr (spf "D       %s" entry.Change.path)
  | Change.Modify (entry1, entry2) ->
    pr (spf "M       %s" entry1.Change.path)
@

\subsection{Comparing trees}


<<signature Changes.changes_tree_vs_tree>>=
(* for git show commit *)
val changes_tree_vs_tree: 
  (Tree.hash -> Tree.t) ->
  (Blob.hash -> Change.content) ->
  Tree.t -> Tree.t -> Change.t list
@
<<function Changes.changes_tree_vs_tree>>=
(* see also Cmd_diff.changes_index_vs_worktree
 *     and  Cmd_status.changes_index_vs_HEAD
 *)
let changes_tree_vs_tree read_tree read_blob tree1 tree2 =
  let changes = ref [] in
  let add x = Common.push x changes in
  Tree.walk_trees read_tree "" (fun dirpath entry1_opt entry2_opt ->
    (* if entries are directories, then we would be called again
     * with their individual files, so safe to skip the dir entries.
     *)
    let entry1_opt = skip_tree_and_adjust_path read_blob dirpath entry1_opt in
    let entry2_opt = skip_tree_and_adjust_path read_blob dirpath entry2_opt in
    
    match entry1_opt, entry2_opt with
    | None, None -> ()
    | Some (a, asha), Some (b, bsha) ->
      (match () with
      (* file type changed reported as delete/add (meh) *)
      | _ when a.Change.mode <> b.Change.mode ->
        add (Change.Del a);
        add (Change.Add b);
      | _ when asha <> bsha ->
        add (Change.Modify (a, b))
      | _ -> ()
      )
    | Some (a,_), None -> add (Change.Del a)
    | None, Some (b,_) -> add (Change.Add b)
  ) tree1 tree2 ;
  List.rev !changes
@

<<signature Tree.walk_trees>>=
val walk_trees:
  (hash -> t) -> Common.filename (* dir *) ->
  (Common.filename -> entry option -> entry option -> unit) -> t -> t -> unit
@
<<function Tree.walk_trees>>=
let rec walk_trees read_tree dirpath f xs ys =
  let g dirpath entry1_opt entry2_opt =
    f dirpath entry1_opt entry2_opt;
    (match entry1_opt, entry2_opt with
    | Some { perm = Dir; name = str; id = sha }, None ->
      walk_trees read_tree (Filename.concat dirpath str) f
        (read_tree sha) []
    | None, Some { perm = Dir; name = str; id = sha } ->
      walk_trees read_tree (Filename.concat dirpath str) f
        [] (read_tree sha)
    | Some { perm = Dir; name = str1; id = sha1 },
      Some { perm = Dir; name = str2; id = sha2 } ->
      assert (str1 = str2);
        (* todo: could skip if sha1 = sha2 here, useful opti *)
        walk_trees read_tree (Filename.concat dirpath str1) f
          (read_tree sha1) (read_tree sha2)
    | None, None -> raise (Impossible "two None in walk_trees.g")
    (* no directories, no need to recurse *)
    | Some _, None
    | None, Some _
    | Some _, Some _
      -> ()
    )
  in
  match xs, ys with
  | [], [] -> ()
  | x::xs, [] ->
    g dirpath (Some x) None;
    walk_trees read_tree dirpath f xs ys
  | [], y::ys ->
    g dirpath None (Some y);
    walk_trees read_tree dirpath f xs ys
  | x::xs, y::ys ->
    (match x.name <=> y.name with
    | Equal -> 
      g dirpath (Some x) (Some y);
      walk_trees read_tree dirpath f xs ys
    | Inf -> 
      g dirpath (Some x) None;
      walk_trees read_tree dirpath f xs (y::ys)
    | Sup ->
      g dirpath None (Some y);
      walk_trees read_tree dirpath f (x::xs) ys
    )
@



<<function Changes.skip_tree_and_adjust_path>>=
let skip_tree_and_adjust_path read_blob dirpath entry_opt =
  match entry_opt with
  | Some { Tree.perm = Tree.Dir } -> None
  | Some { Tree.perm = Tree.Commit } -> failwith "submodule not supported"
  | Some x -> Some ({ Change.
    path = Filename.concat dirpath x.Tree.name;
    mode = Index.mode_of_perm x.Tree.perm;
    
    (* todo: do that later? once know we will return a change with this entry?
     * make it lazy?
     *)
    content = lazy (read_blob x.Tree.id);
  }, x.Tree.id)
  | None -> None
@

<<signature Index.mode_of_perm>>=
val mode_of_perm: Tree.perm -> mode
@
<<function Index.mode_of_perm>>=
let mode_of_perm perm = 
  match perm with
  | Tree.Normal -> Normal
  | Tree.Exec -> Exec
  | Tree.Link -> Link
  <<[[Index.mode_of_perm()]] match perm cases>>
  | Tree.Dir -> failwith "index entry does not support Tree.dir perm"
@


\section{Showing file status: [[git status]]}

<<constant Cmd_status.cmd>>=
let cmd = { Cmd.
  name = "status";
  help = " [options]"; (* less: <pathspec> *)
  options = [
    "--short", Arg.Set short_format, " show status concisely";
    "--long", Arg.Clear short_format, " show status in long format (default)";
    (* less: --branch, --ignored *)
  ];
  f = (fun args ->
    let r, relpaths = Repository.find_root_open_and_adjust_paths args in
    match relpaths with
    | [] -> status r
    | xs -> raise Cmd.ShowUsage
  );
}
@

<<function Cmd_status.status>>=
let status r =
  let st = status_of_repository r in
  if !short_format
  then print_status_short st
  else print_status_long st
@

<<constant Cmd_status.short_format>>=
let short_format = ref false
@

<<function Cmd_status.print_status_short>>=
let print_status_short st =
  raise Todo
@


<<function Cmd_status.print_status_long>>=
let print_status_long st =
  if st.staged <> []
  then begin
    pr "Changes to be committed:";
(*  (use "git reset HEAD <file>..." to unstage) *)
    pr "";
    st.staged |> List.iter print_change_long;
    pr "";
  end;
  if st.unstaged <> []
  then begin
    pr "Changes not staged for commit:";
    pr "";
(*
  (use "git add/rm <file>..." to update what will be committed)
  (use "git checkout -- <file>..." to discard changes in working directory)
*)

    st.unstaged |> List.iter print_change_long;
    pr "";
  end;
  if st.untracked <> []
  then begin
    pr "Untracked files:";
(*  (use "git add <file>..." to include in what will be committed) *)
    pr "";
    st.untracked |> List.iter (fun file ->
      pr (spf "	%s" file)
    );
    pr "";
  end
@

<<type Cmd_status.status>>=
type status = {
  (* diff index vs HEAD *)
  staged: Change.t list;
  (* diff worktree vs index *)
  unstaged: Change.t list;
  (* other *)
  untracked: Common.filename list;
}
@


<<function Cmd_status.print_change_long>>=
(* very similar to Cmd_log.print_change, but with more indentation *)
let print_change_long change =
  match change with
  | Change.Add entry ->
    pr (spf "	new file:	%s" entry.Change.path)
  | Change.Del entry ->
    pr (spf "	deleted:	%s" entry.Change.path)
  | Change.Modify (entry1, entry2) ->
    pr (spf "	modified:	%s" entry1.Change.path)
@


<<function Cmd_status.status_of_repository>>=
let status_of_repository r =
  { staged = changes_index_vs_HEAD r;
    unstaged = 
      Changes.changes_worktree_vs_index 
        (Repository.read_blob r)
        r.Repository.worktree 
        r.Repository.index;
    untracked = untracked r;
  }
@

%pijul: also show current branch name, current conflicts!

\subsection{Listing staged modifications}
%Comparing the index to the [[HEAD]] (

<<function Cmd_status.changes_index_vs_HEAD>>=
let changes_index_vs_HEAD r =
  let commitid = Repository.follow_ref_some r (Refs.Head) in
  let commit = Repository.read_commit r commitid in
  let treeid = commit.Commit.tree in
  Changes.changes_index_vs_tree (Repository.read_tree r) 
    r.Repository.index
    treeid
@

<<signature Changes.changes_index_vs_tree>>=
(* for git status (to compare index vs HEAD) *)
val changes_index_vs_tree:
  (Tree.hash -> Tree.t) ->
  Index.t -> Tree.hash -> Change.t list
@
<<function Changes.changes_index_vs_tree>>=
(* some commonalities with Repository.set_worktree_and_index_to_tree *)
let changes_index_vs_tree read_tree index treeid =
  let tree = read_tree treeid in

  let h_in_index_and_head = Hashtbl.create 101 in
  let hindex = 
    index 
    |> List.map (fun entry -> entry.Index.name, entry)
    |> Hashtbl_.of_list
  in
  let changes = ref [] in

  tree |> Tree.walk_tree read_tree "" (fun relpath entry_head ->
    let perm = entry_head.Tree.perm in
    match perm with
    | Tree.Dir -> ()
    | Tree.Commit -> failwith "submodule not yet supported"
    | Tree.Normal | Tree.Exec | Tree.Link ->
      try
        let entry_index = Hashtbl.find hindex relpath in
        Hashtbl.add h_in_index_and_head relpath true;
        (* less: if change mode, then report as del/add *)
        if entry_head.Tree.id <> entry_index.Index.id
        then changes |> Common.push (Change.Modify (
          { Change.path = relpath; 
            mode = Index.mode_of_perm perm; 
            content = lazy (raise (Impossible "not called")); },
          { Change.path = relpath; 
            mode = entry_index.Index.stats.Index.mode;
            content = lazy (raise (Impossible "not called")); }
        ))
      with Not_found ->
        changes |> Common.push (Change.Del { Change.
             path = relpath;
             mode = Index.mode_of_perm perm;
             content = lazy (raise (Impossible "not called"));
                                           });
  );
  index |> List.iter (fun entry ->
    if not (Hashtbl.mem h_in_index_and_head entry.Index.name)
    then changes |> Common.push (Change.Add { Change.
             path = entry.Index.name;
             mode = entry.Index.stats.Index.mode;                                            content = lazy (raise (Impossible "not called")); }
    )
  );
  (* less: sort by path *)
  List.rev !changes
@


\subsection{Listing unstaged modifications}
%Comparing the worktree to the index (

\l should also put delete (D) or modified (M) information here


\subsection{Listing untracked files}
% Finding files in worktree and not in the index ()

<<function Cmd_status.untracked>>=
(* todo: need parse .gitignore *)
let untracked r =
  let h = r.Repository.index 
      |> List.map (fun entry -> entry.Index.name, true) 
      |> Hashtbl_.of_list 
  in
  let res = ref [] in
  r.Repository.worktree |> Repository.walk_dir (fun dir dirs files ->
    files |> List.iter (fun file ->
      let path = Filename.concat dir file in
      let path = 
        if path =~ "^\\./\\(.*\\)"
        then Regexp_.matched1 path
        else path
      in
      if not (Hashtbl.mem h path)
      then Common.push path res
    );
  );
  List.rev !res
@

% what about .ignore?


\section{Archeology}

\subsection{Checking out an old version}

<<[[Cmd_checkout.checkout()]] cases>>=
| _ when Hexsha.is_hexsha str ->
  let commitid = Hexsha.to_sha str in
  let commit = Repository.read_commit r commitid in
  let treeid = commit.Commit.tree in
  let tree = Repository.read_tree r treeid in
  (* todo: order of operation? set ref before index? reverse? *)
  Repository.write_ref r (Refs.Head) (Refs.Hash commitid);
  Repository.set_worktree_and_index_to_tree r tree;
  pr (spf "Note: checking out '%s'." str);
  pr ("You are in 'detached HEAD' state");
@

% convenient to go back! but then can not modify that! 

%gitless: shows that as a misfit, detached.
% but can create branch from that point at least

\subsection{Showing an old version of a file}

% git show /path/:@?? ^ ? or different command?

% Just get commit, tree and follow path until blob.


\subsection{Showing differences between past versions}
% git show sha1?

%cvs: not easy in CVS to "display all changes made by a user in his last
% commit (src: prcs paper). Because internally CVS still uses RCS and
% so a commit is a group of single-file RCS operations.

\subsection{Showing the history of a file or directory: [[git log <path>]]}

% Format of git does not make this fast, as opposed to CVS.
% More reliable when rename?


\chapter{Packing}
\label{chap:packing}
\n kinda an opti (was in adv topics), but referenced too much in Exchanging

% Complex code.

%https://git-scm.com/book/en/v2/Git-Internals-Packfiles

\section{[[Pack.t]]}

\subsection{Pack data}

\subsection{Pack Index}

\subsubsection{Index pack v1}


\subsubsection{Index pack v2}

\section{IO}

\subsection{Reading a pack}

\subsection{Writing a pack}

\section{Modifications}

\subsection{Object Store}

% pack dir

% loose vs pack objects

\subsection{Refs}

% packed refs
% peeled refs??

\section{Delta}

%\subsection{Unpacked Object}

% Diff discussed in OASA vol II section 6.7 


\section{Pack commands}

\subsection{[[git pack-objects]]}


\subsection{[[git repack]]}

\subsection{[[git fetch-pack]]}

% similar to git pull, but will not update the references.
\t but then lost? graph walker will not find them back?


\subsection{[[git receive-pack]]}


\chapter{Exchanging}
\label{chap:exchanging}
% Collaborating?
% Sharing and updating

%trans: most commands useful for single developer.
% but VCS really shine when multiple developers, to help
% collaborate. Saw merge that alleviate need for locks
% and enable multiple people to work on same files and reconcile their work.

% In centralized, when you commit it also "publish" to central repo
% for other to see. In distributed, commit and publish are decoupled.
% You commit and then you push somewhere.


% Pulling requires merging. When you diverge on master from the remote,
% then pulling is similar to merging where master and origin/master
% are 2 different branches.
% See my little experiment:
% master/home/pad/tmp/t2 $ git log --graph --oneline --decorate --all
% *   4960dcf (HEAD, master) Merge branch 'master' of /home/pad/tmp/t1
% |\  
% | * 1d0c911 (origin/master, origin/HEAD) log3
% * |   764e0b2 merge
% |\ \  
% | |/  
% | * 1d6cb05 log2
% * | 54b0dbb t2log1
% |/  
% * 60b5161 log1

%master/home/pad/tmp/t1 $ git log --graph --oneline --decorate --all
%*   4960dcf (HEAD, master) Merge branch 'master' of /home/pad/tmp/t1
%|\  
%| * 1d0c911 log3
%* |   764e0b2 merge
%|\ \  
%| |/  
%| * 1d6cb05 log2
%* | 54b0dbb t2log1
%|/  
%* 60b5161 log1

% Note that usually pull from a repo that has more stuff than you,
% but it's not always the case, so the code below must handle both cases
% (e.g., compute top_commons)

% Note that sha1 allow global namespace! can safely pull commits
% from someone else, can know if same because sha1!!

\section{Pulling updates from another repository: [[git pull]]}

% saw get_transport_and_path before in core DS and its default
% implem to LocalGitClient

% why return path and client, could embed path information
% in client already.

% determine_wants is about which refs to fetch. Get all remote_refs
% as arguments and returned the sha of the one to fetch (usually
% the one for HEAD)

\t this assumes no merge needed?

% Flow is to set the starting refs you want to fetch from,
% then compute common commits and missing commits by walking graph
% of commits on target repo and comparing to commits from source repo.
% find all missing objects needed by those commits.


<<constant Cmd_pull.cmd>>=
let cmd = { Cmd.
  name = "pull";
  help = " [options] [<url repository>]";
  options = [
  ];
  f = (fun args ->
    let dst, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> 
      failwith "TODO: use remote information in config file"
    | [url] -> 
      pull dst url
    | _ -> raise Cmd.ShowUsage
  );
}
@

<<function Cmd_pull.pull>>=
(* =~ git fetch + git merge *)
let pull dst url =
  (* todo: detect if clean repo? status is empty? *)
  let client = Clients.client_of_url url in

  (* less: allow to grab from multiple heads, not just HEAD *)
  let remote_HEAD_sha = client.Client.fetch dst in
  
  (* detect if need merge, if current HEAD not parent of new HEAD *)
  let current_HEAD_sha = Repository.follow_ref_some dst (Refs.Head) in
  let ancestors_remote_HEAD = 
    Commit.collect_ancestors (Repository.read_commit dst) [remote_HEAD_sha]
      (Hashtbl.create 101)
  in
  (match () with
  | _ when remote_HEAD_sha = current_HEAD_sha -> ()
  | _ when Hashtbl.mem ancestors_remote_HEAD current_HEAD_sha ->
    (* easy case *)
    pr (spf "fast forward to %s" (Hexsha.of_sha remote_HEAD_sha));
    Repository.set_ref dst (Refs.Head) remote_HEAD_sha;
    let commit = Repository.read_commit dst remote_HEAD_sha in
    let tree = Repository.read_tree dst (commit.Commit.tree) in
    Repository.set_worktree_and_index_to_tree dst tree
  | _ -> failwith "TODO: git pull need merge"
  )
@

<<signature Repository.set_ref>>=
(* better than write_ref, will follow symbolic ref *)
val set_ref: t -> Refs.t -> Commit.hash -> unit
@
<<function Repository.set_ref>>=
let set_ref r aref newh =
  let (refs, _) = follow_ref r aref in
  let lastref = List.hd (List.rev refs) in
  let file = ref_to_filename r lastref in
  file |> with_file_out_with_lock (fun ch ->
    ch |> IO.output_channel |> IO_.with_close_out 
        (Refs.write (Refs.Hash newh))
  )
@

<<signature Client_local.mk_client>>=
val mk_client: Common.filename -> Client.t
@
<<function Client_local.mk_client>>=
let mk_client path =
  { Client.
    url = path;
    fetch = (fun dst ->
      let src = Repository.open_ path in
      fetch_objects src dst;
      (* less: all_refs *)
      Repository.follow_ref_some src Refs.Head
   );
  }
@


\subsection{Fetching objects (locally)}

% will see fetching remote later in Networking chapter.

%python: fetch will return an iterator over objects?
% so no huge memory consumption? Hmm but in PackObjectStore.add_objects
% it calls len() on it so this should trigger the computation of the
% whole list.
%ocaml: again, no need this to be in BaseRepo, can be in localGitClient

% Note that graph walker is for the target! pass so dource can know
% which one the target needs. So it's also a kind of determine_wants
% but for objects this time.

%python: iterate so add_objects can add one by one the elt, no need
% to store huge list of objects in memory.

% [[haves]] are just the top commits starting from heads in dst repo
% that the src repo has (should really be called top_commons_commits).
% Because of ack(), the graph walker does not go through the whole
% history.
% If src repo has strictly more stuff than dst, then
% [[haves]] will be the dst heads, the "frontline".


<<function Client_local.fetch_objects>>=
let fetch_objects src dst =
  (* less: determine_wants from pull command *)
  let top_wanted_commits = [Repository.follow_ref_some src Refs.Head] in
  (* less: shallows? unshallows? *)
  let top_common_commits = find_top_common_commits src dst in
  iter_missing_objects top_common_commits top_wanted_commits src 
    (fun sha1 obj_opt ->
    (* less: opti: copy raw files directly without unmarshalling/marshalling *)
    let obj = 
      match obj_opt with
      | None -> Repository.read_obj src sha1
      | Some obj -> obj
    in
    (* todo: count objects progress *)
    (* pr2 (spf "adding %s" (Hexsha.of_sha sha1)); *)
    let sha2 = Repository.add_obj dst obj in
    assert (sha1 = sha2)
  )
@



\subsubsection{Find top common commits}


% ack() will tell graph walker that there is no need to explore
% the parents of sha. So this will not iterate over the whole graph,
% just enough to find the commot frontline.

<<function Client_local.find_top_common_commits>>=
(* find the common frontline *)
let find_top_common_commits src dst =
  let top_commons = Hashtbl.create 101 in
  let walker = mk_graph_walker dst in

  let rec loop_while_sha commit_sha_opt =
    commit_sha_opt |> Common.if_some (fun commit_sha ->
      if Repository.has_obj src commit_sha
      then begin
        Hashtbl.add top_commons commit_sha true;
        walker.ack commit_sha;
      end;
      loop_while_sha (walker.next ())
    )
  in
  loop_while_sha (walker.next ());
  top_commons |> Hashtbl_.to_list |> List.map fst
@

<<signature Repository.has_obj>>=
val has_obj: t -> Sha1.t -> bool
@
<<function Repository.has_obj>>=
let has_obj r h =
  let path = h |> Hexsha.of_sha |> hexsha_to_filename r in
  Sys.file_exists path
@



% see graphwalker in next section

%\subsubsection{Determine the references wanted}
% will see some refinements later where can ask only HEAD.


\subsubsection{Find missing objects}

% haves below are set of top commits.
% wants are also set of (starting) commits (comes from refs)


\t why need ancestors of haves? they are already set of commits
% in common and so they must have all the parents too.
\l not slow to each time you fetch read and compute all
\l  the shas of all the past commits?

% put objects_to_send in triple. First is sha, second is useless?
% and third is whether this is a leaf. This is important to avoid
% reading blob objects.

<<function Client_local.iter_missing_objects>>=
let iter_missing_objects top_common_commits top_wanted_commits src f =
  (* less: split_commits_and_tags? *)
  let all_common_commits = 
    Commit.collect_ancestors (Repository.read_commit src) top_common_commits 
      (Hashtbl.create 101) in
  (* bugfix: do not forget Hashtbl.copy because collect_ancestors modify 
   * the second parameter by side effect
   *)
  let missing_commits = 
    Commit.collect_ancestors (Repository.read_commit src) top_wanted_commits 
      (Hashtbl.copy all_common_commits)
  in

  (* let's iterate over all common commits *)
  
  let dst_have_sha = Hashtbl.create 101 in
  (* less: start from second returned result from collect_ancestors?
   * common_commits different from all_ancestors in VCS.nw? 
   *)
  (* expensive loop below? so use parallel threads? *)
  all_common_commits |> Hashtbl.iter (fun commit_sha _true ->
    Hashtbl.add dst_have_sha commit_sha true;
    let commit = Repository.read_commit src commit_sha in
    collect_filetree (Repository.read_tree src) commit.Commit.tree dst_have_sha
  );

  (* and now let's iterate over all missing commits *)

  (* less: tags handling *)
  let rec missing sha is_blob = 
    if Hashtbl.mem dst_have_sha sha
    then ()
    else begin
      Hashtbl.add dst_have_sha sha true;
      (if is_blob
       then f sha None
       else begin
        let obj = Repository.read_obj src sha in
        f sha (Some obj);
        (match obj with
        | Objects.Commit commit ->
          missing commit.Commit.tree false
        | Objects.Tree tree ->
          tree |> List.iter (fun entry ->
            if entry.Tree.perm = Tree.Commit
            then failwith "submodule not supported";
            (* bugfix: it's <>, not = *)
            missing entry.Tree.id (entry.Tree.perm <> Tree.Dir)
          )
        | Objects.Blob _ ->
          raise (Impossible "is_blob guard")
        )
       end
      );
    end
  in
  missing_commits |> Hashtbl.iter (fun commit_sha _true ->
    missing commit_sha false
  )
@
\t LP split

<<function Client_local.collect_filetree>>=
let rec collect_filetree read_tree treeid have_sha =
  let tree = read_tree treeid in
  tree |> List.iter (fun entry ->
    let sha = entry.Tree.id in
    if not (Hashtbl.mem have_sha sha) then begin
      Hashtbl.add have_sha sha true;
      match entry.Tree.perm with
      | Tree.Normal | Tree.Exec | Tree.Link -> ()
      | Tree.Dir ->  collect_filetree read_tree sha have_sha
      | Tree.Commit -> failwith "submodule not supported yet"
    end
  )
@


<<signature Commit.collect_ancestors>>=
val collect_ancestors: 
  (hash -> t) ->  hash list -> (hash, bool) Hashtbl.t -> 
  (hash, bool) Hashtbl.t
@
<<function Commit.collect_ancestors>>=
(* similar to walk_history but with exposed hdone hash *)
let collect_ancestors read_commit top_commits hdone =
  let hcommits = Hashtbl.create 101 in
  let rec aux sha =
    if Hashtbl.mem hdone sha
    then ()
    else begin
      Hashtbl.add hdone sha true;
      Hashtbl.add hcommits sha true;
      let commit = read_commit sha in
      commit.parents |> List.iter aux
    end
  in
  top_commits |> List.iter aux;
  hcommits
@

\subsubsection{Iterating over objects}


\subsubsection{Adding Objects}

%\subsubsection{Shallow requests}
% advanced topic? related to graft? related to git clone --depth?


\subsection{Fetching references}

\subsubsection{Refspecs}

%https://git-scm.com/book/en/v2/Git-Internals-The-Refspec

\subsubsection{Selecting the refs}

\subsubsection{Parsing ref tuples}

\subsection{Fetching objects in a pack}
\n now that Packing chapter is before exchanging, easier to talk about pack here

%\subsection{Diff statistics}
% nice that git pull after updating also display diffstat for each 
% updated file and the create/delete.

\section{Object store walker}

% used to explore target graph, not source graph.
% To know which (top) commits have in common with source.

\t diff with graph walker? history walker vs object walker!

<<type Client_local.graph_walker>>=
(* will start from the heads and iterate over the ancestry of heads
 * until the caller ack that some top commits are already known and
 * do not need to be iterated furthermore.
 *)
type graph_walker = {
  next: unit -> Commit.hash option;
  ack: Commit.hash -> unit;
}
@

<<function Client_local.ml_graph_walker>>=
let (mk_graph_walker: Repository.t -> graph_walker) = fun r ->
  (* less: start just from HEAD? *)
  let heads = 
    Repository.all_refs r |> Common.map_filter (fun aref ->
      if aref =~ "refs/heads/"
      then Some (Repository.follow_ref_some r (Refs.Ref aref))
      else None
    )
  in
  let todos = ref heads in
  let todos_next_round = ref [] in
  let last_round = ref None in
  let hdone = Hashtbl.create 101 in

  { next = (fun () ->
    todos := !todos_next_round @ !todos;
    todos_next_round := [];
    match !todos with
    | [] -> None
    | x::xs ->
      todos := xs;
      Hashtbl.add hdone x true;
      last_round := Some x;
      let commit = Repository.read_commit r x in
      let parents = commit.Commit.parents in
      parents |> List.iter (fun parent ->
        if Hashtbl.mem hdone parent
        then ()
        else todos_next_round := parent::!todos_next_round;
      );
      Some x
    );

    ack = (fun commit_sha ->
      (* less: do weird loop where recurse also over parents as in dulwich? *)
      match !last_round with
      | None -> raise (Impossible "ack always after at least one next");
      | Some x ->
        if x <> commit_sha
        then raise (Impossible "'ack(x)' should follow 'x = next()'");
        (* skip those one then because parent already in common *)
        todos_next_round := []
    );
  }
@


% subtle. Will iterate over the graph from the heads,
% which can be long, but while doing so, it can be instructed to 
% skip some ancestors because the src repo already has them (via ack()),
% which is then faster.


% Why record also parents of commit? because if later ack this
% commit, then we need to filter its parents from the todos.


\section{Pushing changes to another repository: [[git push]]}

% Not really needed. The other guy can just pull from yours.
% In fact restrictions about pushing where can only push
% to a bare repository (unless --force?)

<<constant Cmd_push.cmd>>=
let cmd = { Cmd.
  name = "push";
  help = " [options] [<url repository>]";
  options = [
    (* less: --all, --force, --progress *)
  ];
  f = (fun args ->
    let src, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> 
      failwith "TODO: use remote information in config file"
    | [url] -> 
      push src url
    | _ -> raise Cmd.ShowUsage
  );
}
@

<<function Cmd_push.push>>=
(* =~ git fetch + git merge but inverting dst and src  *)
let push src_repo url_dst =
  let url = src_repo.Repository.worktree in
  let dst = Repository.open_ url_dst in
  (* todo: detect if clean repo? status is empty? *)
  let client = Clients.client_of_url url in


  (* less: allow to grab from multiple heads, not just HEAD *)
  let remote_HEAD_sha = client.Client.fetch dst in
  
  (* detect if need merge, if current HEAD not parent of new HEAD *)
  let current_HEAD_sha = Repository.follow_ref_some dst (Refs.Head) in
  let ancestors_remote_HEAD = 
    Commit.collect_ancestors (Repository.read_commit dst) [remote_HEAD_sha]
      (Hashtbl.create 101)
  in
  (match () with
  | _ when current_HEAD_sha = remote_HEAD_sha -> ()
  | _ when Hashtbl.mem ancestors_remote_HEAD current_HEAD_sha ->
    (* easy case *)
    pr (spf "fast forward to %s" (Hexsha.of_sha remote_HEAD_sha));
    Repository.set_ref dst (Refs.Head) remote_HEAD_sha;
    let commit = Repository.read_commit dst remote_HEAD_sha in
    let tree = Repository.read_tree dst (commit.Commit.tree) in
    Repository.set_worktree_and_index_to_tree dst tree
  | _ -> failwith "TODO: git pull need merge"
  )
@

\subsection{Sending objects (locally)}
% dummy protocol?

\subsection{Sending objects in a pack}



\section{Cloning a repository: [[git clone]]}

% In the end, quite similar to git pull; we just pull everything.

<<constant Cmd_clone.cmd>>=
let cmd = { Cmd.
  name = "clone";
  help = " [options] <repo> [<dir>]";
  options = [
    (* less: --bare, --progress, --depth *)
  ];
  f = (fun args ->
    match args with
    | [url]     -> clone url "."
    | [url;dst] -> clone url dst
    | _ -> raise Cmd.ShowUsage
  );
}
@

<<function Cmd_clone.clone>>=
(* =~ git pull from scratch (itself =~ git fetch + git merge) *)
let clone url path_dst =
  let client = Clients.client_of_url url in
  
  Repository.init path_dst;
  let dst = Repository.open_ path_dst in

  (* less: allow to grab from different head? *)
  let remote_HEAD_sha = client.Client.fetch dst in
  Repository.set_ref dst (Refs.Head) remote_HEAD_sha;

  (* =~ reset index *)
  let commit = Repository.read_commit dst remote_HEAD_sha in
  let tree = Repository.read_tree dst (commit.Commit.tree) in
  Repository.set_worktree_and_index_to_tree dst tree
@


\subsection{Fetching objects}

% determine_wants is about the refs, not the objects.

\subsection{Importing references}

\t clone should import refs, not just HEAD



\chapter{Networking}
\label{chap:networking}

% We should not need that code below. Should mount fs with NFS or sshfs
% or a plan9 fileserver or whatever and then simply use LocalGitClient!

% Distributed VCS! 
% for pull and push you can pass a URL!


% ssh and http in adv topics.
% in this chapter we will focus on git://


<<[[Clients.client_of_url()]] match url cases>>=
(* less: should use URL parsing library *)
| s when s =~ "^git://" -> 
  Client_git.mk_client url
@

\section{[[git://]] protocol}

% smart vs dumb protocol.

%https://github.com/blog/809-git-dumb-http-transport-to-be-turned-off-in-90-days


% pkt line. Show example of session


\subsection{Reading}


\subsection{Writing}

\section{Capabilities}
\l adv topics? or hard to avoid because first _connect return
\l  refs and capabilities

% see Adv topics.


\section{[[git://]] client}

%\subsection{Local client}
% seen before, can be used for NFS too!

%\subsection{[[git://]]}

<<signature Client_git.mk_client>>=
val mk_client: Common.filename -> Client.t
@
<<function Client_git.mk_client>>=
let mk_client url =
  raise Todo
@


\subsection{Fetching remote objects}

% so pass the target graph walker and way to write on target to
% client fetch_pack

\subsection{Fetching pack files}


% pack_data is target add_pack f.write()

%flow:
%  get remote refs, determine wants, tell wants, get objects and pack_data


% ask git-upload-pack service!

\subsubsection{[[read_pkt_refs()]]}

\subsubsection{[[_handle_upload_pack_head()]]}


\subsubsection{[[_handle_upload_pack_tail()]]}


\subsection{Sending pack files}


\section{[[git://]] server}


%\subsection{[[TCPGitServer]]}

%\subsection{[[FileSystemBackend]]}

%\subsection{[[Handler]]}

\subsection{[[git-upload-pack]]}
% when pull


\subsection{[[git-receive-pack]]}
% when push

\chapter{Advanced Features}
\label{chap:advanced-features}

\section{Tags}
\label{sec:tags}

% Why need tags? Why not simply refs?
% Because refs just point to something but can not have meta-data.
% If you dont want to give any comment about a version and that
% its name is enough, then you just need a ref. Otherwise
% you need a ref to an object (container) containing itself
% ref to a version and metadata: The tag.

% As opposed to a ref (or branch), it always refer to the same commit!
% Just a name to a commit. Also can have a description text.

% Can do tags by abusing refs/tags/xxx. In fact in pfff seems like
% github did that to create tags ...

\subsection{[[Tag.t]]}

<<[[Objects.t]] cases>>=
(*  | Tag of Tag.t *)
@

<<[[Repository.objectish]] cases>>=
(* ObjByTag *)
@

\subsection{Reading a tag}

<<[[Objects.read()]] match str cases>>=
(* "tag" -> Tag (Tag.read raw) *)
@

\subsection{Writing a tag}

<<[[Objects.write()]] match obj cases>>=
@
<<[[Objects.write()]] return header, match obj cases>>=
@

<<[[Cmd_show.show()]] match obj cases>>=
@

\subsection{[[git tag]]}

% to create, list, delete

\subsection{[[git clone]] and tags}
% should import tags

\subsection{[[git pull]] and tags}
% should split_commit_and_tags (see dulwich)

\section{Reflog}

% quite simple, just an history of the content of a ref.
% So very meta, refs allow to access the history of files,
% and the refs themselves have an history.
% so .git/logs/HEAD will contain the different values of HEAD
% so when you switch branch, when you commit, etc., all of that
% will generate different entries there.

% but code of dulwich does not maintain reflog. When you
% update a ref, it should update the reflog of this ref!


\section{Stash}
% again, just a ref?

\subsection{[[git stash]]}
% pretty useful in the end

\section{Grafts}

% I used this feature to represent the full history of Linux from 0.01 to 2.6!

\subsection{Reading a graft file}

\subsection{Writing a graft file}

\subsection{Using a graft file}


\section{Submodules}

%S_IFGITLINK = 0o160000
% hack to encode submodule?

<<[[Tree.perm]] cases>>=
| Commit (* ?? submodule? *)
@

<<[[Tree.perm_of_string()]] match str cases>>=
| "160000" -> Commit
@
<<[[Tree.string_of_perm()]] match perm cases>>=
| Commit -> "160000"
@


<<[[Repository.set_worktree_and_index_to_tree()]] walk tree cases>>=
| Tree.Commit -> failwith "submodule not yet supported"
@

<<[[Tree.walk_tree()]] match perm cases>>=
| Commit ->
  failwith "submodule not supported yet"
@

<<[[Repository.build_file_from_blob()]] match perm cases>>=
| Tree.Commit -> failwith "submodule not yet supported"
@


<<[[Index.mode]] cases>>=
| Gitlink (*?? submodule? *)
@

<<[[Index.read_mode()]] match [[n lsr 12]] cases>>=
| 0b1110 -> Gitlink
@
<<[[Index.write_mode()]] match mode cases>>=
| Gitlink -> 0b1110__000__000_000_000 
@

<<[[Changes.content_from_path_and_stat_index()]] match mode cases>>=
| Index.Gitlink -> failwith "submodule not supported"
@


<<[[Index.perm_of_mode()]] match mode cases>>=
| Gitlink -> Tree.Commit (* sure? *)
@
% when compute tree_of_index

<<[[Index.mode_of_perm()]] match perm cases>>=
| Tree.Commit -> Gitlink
@



\section{hooks: [[.git/hooks/]]}

%self.hooks['pre-commit'] = PreCommitShellHook(self.controldir())
%self.hooks['commit-msg'] = CommitMsgShellHook(self.controldir())
%self.hooks['post-commit'] = PostCommitShellHook(self.controldir())


\section{Configuration file: [[.git/config]]}

% ex of use:
%config = self.get_config()
%honor_filemode = config.get_boolean(
%    'core', 'filemode', os.name != "nt")

\subsection{Initialization}

\subsection{[[Config.t]]}

\subsection{Reading a configuration file}

\subsection{Writing a configuration file}

\subsection{Stacked configurations: [[~/.gitconfig]] and [[.git/config]]}

\section{Ignore file: [[.gitignore]]}

%For details for the matching rules, see https://git-scm.com/docs/gitignore

% Seems unused though ... many os.walk do not filter files based
% on information in .ignore I think.


%\section{Advanced diff capabilities}
\section{Rename detection}

% useful to have git log tracking a file through rename

%\subsection{Refactorings}
% Nice feature of darcs is token rename patch! So do CEs
% when merge another branch!



\chapter{Advanced Commands}
\label{chap:advanced-commands}

\section{Developer commands}
% To help develop, to help debug

%trans:
% not only manage changes, go to past versions.
% Can also help debug issues. Can help developer develop!

%\subsection{Identifying the version of a buggy program}
% Useful to get version from binary version!
% RCS had this with $Id$ and ident program.
% Git does not support $Id: as in CVS.
% Alternative?? 
% No $Log:, but anyway can use git log.
% other useful keywords?

\subsection{Finding the buggy diff: [[git bisect]]}
% great tool, I should use it more, but requires discipline
% and good commits with good hooks

% How goes when multiple paths between 2 versions (diamond)?

\subsection{Reverting a change: [[git revert]]}
% 

\subsection{Blaming the buggy code: [[git blame]]}
% aka annotate

% great tool again. See who, why, and also see related changes!
% Can infer what to do by looking at past commit
% (see my facebook experience!)

% related: git log <path>

%\chapter{Development Support}
% Tags
% Hooks
 
\subsection{Finding code: [[git grep]]}
% pretty useful

\subsection{Creating archive: [[git archive]]}
% create tarball from git repo
%bootstrap:
% can greate ocamlgit-0.1.tgz so no need git to get ocamlgit

\section{Plumbing commands}
% original git is plumbing vs porcelain

\subsection{[[git fetch]]}

\subsection{[[git symbolic-ref]]}

\subsection{[[git rev-list]]}
% 'git log' used to be a shell script calling git rev-list

\subsection{[[git diff-tree]]}

\subsection{[[git commit-tree]]}
%? to commit without author and commiter??

\subsection{[[git ls-tree]]}
% pretty simple.

\subsection{[[git remote add]]}

\subsection{[[git ls-remote]]}

\section{Misc commands}


\subsection{[[git filter-branch]]}
% useful?

% http://manishearth.github.io/blog/2017/03/05/understanding-git-filter-branch


\chapter{Advanced Networking}
\label{chap:advanced-networking}

\section{Other clients}

\subsection{[[ssh://]]}

<<[[Clients.client_of_url()]] match url cases>>=
| s when s =~ "^ssh://" -> 
  failwith "ssh not supported"
@

\subsection{[[http://]]}

<<[[Clients.client_of_url()]] match url cases>>=
| s when s =~ "^http://" -> 
  failwith "http not supported"
@


\section{Other servers}

%\subsection{[[git daemon]]}

%\subsection{[[git web-daemon]]}

\subsection{[[http://]]}
% git smart http protocol

% also cgit? nice web interface to explore repo?

\section{Other client/server capabilities}

\subsection{Report status}
% mv in Debugging appendix?

\subsection{Quiet}

\subsection{Thin pack}

\subsection{Side band 64k}



\chapter{Advanced Topics}
\label{chap:advanced-topics}

\section{Bytes versus ASCII versus UTF-8}
% Encoding.

% Git doc says git is agnostic to encoding. Just treat filenames
% and file content as bytes. But for commit messages, assume utf8,
% if not then have to specify an encoding commit tag?

% Why need speak about encoding early?
% Can not just use bytes everywhere? filenames mentionned in
% tree objects are utf8? the content of blob might be utf8 but we do not care.


\section{Reliability and signals}

% First, immutable object store and order of operation (a la ext2fs?)
% leaves state of repo in consistent state always!
% Only tricky part is update references! and done via lock to be atomic.

% What if C-c in middle of operations?
% Handled by atomic ref update?

%\section{Advanced features}
% now in separate chapter

\section{Optimizations}

%\subsection{LRU cache}
% Needs that for?

\section{Fast import and export}
% another opti? why need that?
% to collaborate with other VCS? like import SVN in git?

% another way to clone a repo?
%$ git fast-export --all | (cd /empty/repository && git fast-import)

\section{Alternates}

\t ??? related to pack files?

%\section{Peeled}
% seems related to tags, so move with Tags?
%https://stackoverflow.com/questions/26492303/what-does-peel-mean-in-git

\section{Other repository format}

\subsection{Bare repository}

% convenient when want to have a centralized repo and
% people push to it. If non-bare repo then git refuses to push
% because the index and worktree would be inconsistent.

% when git init --bare

% when objects/ directly at root, not under hidden_path (controldir).

\subsection{[[.git]] file}
% linked working tree? see docstring of commondir()


\section{Security}

% Ownership?
% Less an issue with git because distribute VCS, so anybody
% can have own copy of entire repo (not just of work tree).
% So no need special admin of RCS/foo.c,v 

%rcs: rely on unix permission (give foo.c,v to a group) and
% can have additional access (restriction list)

% How protect who can modify a repo?
%sccs: could even limit to certain dirs or files what someone could modify

\chapter{Conclusion}
\label{chap:conclusion}






\appendix

\chapter{Debugging}
\label{chap:debugging-ocamlgit}

<<constant Cmds.extra_commands>>=
let extra_commands = [
  Cmd_test.cmd;
  Cmd_dump.cmd;
]
@

\section{[[ocamlgit dump]]}
% ocamlgit specific, so I specify ocamlgit
% but there is a git dump-index though.

<<constant Cmd_dump.cmd>>=
let cmd = { Cmd.
  name = "dump";
  help = " <file>";
  options = [
    "-raw", Arg.Set raw, " do not pretty print";
    "-index", Arg.Set index, " pretty print index content";
  ];
  f = (fun args ->
    match args with
    | [file] -> dump file
    | _ -> failwith (spf "dump command [%s] not supported"
                       (String.concat ";" args))
  );
}
@
\l git dump pack

<<constant Cmd_dump.raw>>=
let raw = ref false
@

<<constant Cmd_dump.index>>=
let index = ref false
@


<<function Cmd_dump.dump>>=
let dump file =
  if !index
  then dump_index file
  else dump_object file
@

<<function Cmd_dump.dump_index>>=
(* =~ dulwich dump-index, =~ git ls-files --stage *)
let dump_index file =
  let chan = open_in file in
  let input = IO.input_channel chan in
  let index = Index.read input in
  let v = Dump.vof_index index in
  pr (Ocaml.string_of_v v)
@

<<signature Dump.vof_index>>=
val vof_index: Index.t -> Ocaml.v
@
<<constant Dump.vof_index>>=
let vof_index = Index.vof_t
@



<<function Cmd_dump.dump_object>>=
(* =~ git cat-file -p *)
let dump_object file =
  let chan = open_in file in
  let input = IO.input_channel chan in
  let unzipped = Unzip.inflate input in
  
  try
    if !raw
    then 
      let str = IO.read_all unzipped in 
      pr2 str
    else begin
      let obj = Objects.read unzipped in
      let v = Dump.vof_obj obj in
      pr (Ocaml.string_of_v v)
    end
  with Unzip.Error _err ->
    failwith "unzip error"
@



<<signature Dump.vof_obj>>=
val vof_obj: Objects.t -> Ocaml.v
@
<<constant Dump.vof_obj>>=
let vof_obj = Objects.vof_t
@


\section{[[ocamlgit test]]}

<<constant Cmd_test.cmd>>=
let cmd = { Cmd.
  name = "test";
  help = " ";
  options = [];
  f = (fun args ->
    match args with
    | ["sha1"] -> test_sha1 ()
    | ["unzip"] -> test_unzip ()
    | ["diff";file1;file2] -> test_diff file1 file2
    | ["diff"] -> failwith "missing arguments to diff (diff <file1> <file2>)"
    | _ -> failwith (spf "test command [%s] not supported"
                       (String.concat ";" args))
  );
}
@

<<function Cmd_test.test_sha1>>=
(* see https://git-scm.com/book/en/v2/Git-Internals-Git-Objects *)
let test_sha1 () =
  let content = "what is up, doc?"
    (*"test content\n"  *)
  in
  let header = "blob 16\000" in
  let store = header ^ content in

  let sha = Sha1.sha1 store in
  pr (spf "len = %d, raw = %s" (String.length sha) sha);
  let hexsha = Hexsha.of_sha sha in
  pr (spf "len = %d, str = %s" (String.length hexsha) hexsha);
  ()
@


\chapter{Profiling}
\label{chap:profiling-ocamlgit}

\chapter{Error Management}
\label{chap:error}
% centralize all errors? have a error.ml?

\chapter{Utilities}
\label{chap:utilities}

% Common.with_file_in, IO.input_channel (channel vs IO)

\section{Binary IO}

% Not lex/yacc here for git but low-level bytes reading.

% IO.ml and a few addons in IO_.ml

<<signature IO_.with_close_out>>=
val with_close_out: ('a IO.output -> unit) -> 'a IO.output -> 'a
@
<<function IO_.with_close_out>>=
let with_close_out f ch =
  f ch;
  let res = IO.close_out ch in
  res
@

<<signature IO_.read_string_and_stop_char>>=
val read_string_and_stop_char: 
  IO.input -> char -> string
@
<<function IO_.read_string_and_stop_char>>=
let read_string_and_stop_char ch stop_char =
  let b = Buffer.create 8 in
  let rec loop() =
    let c = IO.read ch in
    if c <> stop_char then begin
      Buffer.add_char b c;
      loop();
    end;
  in
  loop();
  Buffer.contents b
@

<<signature IO_.read_int_and_nullbyte>>=
val read_int_and_nullbyte: 
  IO.input -> int
@
<<function IO_.read_int_and_nullbyte>>=
let read_int_and_nullbyte ch =
  let str = IO.read_c_string ch in
  int_of_string str
@

<<signature IO_.read_key_space_value_newline>>=
val read_key_space_value_newline: 
  IO.input -> string (* key *) -> (IO.input -> 'a) -> 'a
@
<<function IO_.read_key_space_value_newline>>=
let read_key_space_value_newline ch k f =
  let str = read_string_and_stop_char ch ' ' in
  if str <> k
  then failwith (spf 
    "read_key_space_value_newline: wrong key got %s (expecting %s)"
    str k);
  let v = f ch in
  let c = IO.read ch in
  if c <> '\n'
  then failwith "read_key_space_value_newline: wrong format, no newline";
  v
@


\chapter{Algorithms}
\label{chap:algorithms}
\l put before Conclusion? instead of in appendix?

%pad: (** are my comments **)

\section{SHA1}
\label{sec:sha1-algo}

% Wikipedia says SHA1 follows the principles used for 
% MD4 and MD5 by Ronald Rivest.
% I can explain how it works, but not really why it works.
% Out of scope of this book.

% The MD4 Message Digest Algorithm - Ronald L. Rivest
% CRYPTO 90, Springer Verlag
% Define motivations (but old one), and design goals (good one),
% and implem, but does not explain why it works. Still the algorithm
% is simpler and use less weird constants, so maybe more intuitive to
% see why it works and why it's hard to reverse.


<<[[Sha1.sha1()]] operator shortcuts for Int32>>=
let ( lor )  = Int32.logor in
let ( lxor ) = Int32.logxor in
let ( land ) = Int32.logand in
let ( ++ )   = Int32.add in
let lnot     = Int32.lognot in
let sr       = Int32.shift_right in
let sl       = Int32.shift_left in
let cls n x = (sl x n) lor (Int32.shift_right_logical x (32 - n)) in
@

% simple algo: first pads input parameter to get multiple of 64, then
% for each block of 64 bytes, store numbers in array of 16 elements,
% and update h0/h1/h2/h3/h4 components of final SHA1 number.
% Finally combine those h0/... to form the final 20 bytes number.

<<function Sha1.sha1>>=
(* sha-1 digest. Based on pseudo-code of RFC 3174.
   Slow and ugly but does the job. *)
let sha1 s =
  <<function sha_1_pad>>
  let ( &&& ) = ( land ) in
  (* Operations on int32 *)
  <<[[Sha1.sha1()]] operator shortcuts for Int32>>
  (* Start *)
  let m = sha_1_pad s in
  let w = Array.make 16 0l in

  (** components of the 20 bytes SHA1 (5 * 4 bytes (Int32 with 'l' suffix)) **)
  let h0 = ref 0x67452301l in
  let h1 = ref 0xEFCDAB89l in
  let h2 = ref 0x98BADCFEl in
  let h3 = ref 0x10325476l in
  let h4 = ref 0xC3D2E1F0l in

  let a = ref 0l in
  let b = ref 0l in
  let c = ref 0l in
  let d = ref 0l in
  let e = ref 0l in

  (* For each block *)
  for i = 0 to ((Bytes.length m) / 64) - 1 do
    (* Fill w *)
    <<[[Sha1.sha1()]] fill [[w]] for each block [[i]]>>
    (* Loop *)
    a := !h0; b := !h1; c := !h2; d := !h3; e := !h4;
    <<[[Sha1.sha1()]] loop from 0 to 79 for each block [[i]]>>
    (* Update *)
    h0 := !h0 ++ !a;
    h1 := !h1 ++ !b;
    h2 := !h2 ++ !c;
    h3 := !h3 ++ !d;
    h4 := !h4 ++ !e
  done;

  (** the result hash number of 20 bytes *)
  let h = Bytes.create 20 in
  <<function i2s>>
  i2s h 0 !h0;
  i2s h 4 !h1;
  i2s h 8 !h2;
  i2s h 12 !h3;
  i2s h 16 !h4;
  Bytes.unsafe_to_string h
@

% most significant bit first (big-endian)
<<function i2s>>=
let i2s h k i =
  Bytes.set h k       (Char.unsafe_chr ((Int32.to_int (sr i 24)) &&& 0xFF));
  Bytes.set h (k + 1) (Char.unsafe_chr ((Int32.to_int (sr i 16)) &&& 0xFF));
  Bytes.set h (k + 2) (Char.unsafe_chr ((Int32.to_int (sr i 8))  &&& 0xFF));
  Bytes.set h (k + 3) (Char.unsafe_chr ((Int32.to_int i)         &&& 0xFF));
in
@
\l could reuse one of function used in assembler or linker that does same

%trans:
% and now the details:

<<[[Sha1.sha1()]] fill [[w]] for each block [[i]]>>=
let base = i * 64 in
for j = 0 to 15 do
  let k = base + (j * 4) in
  w.(j) <- sl (Int32.of_int (Char.code @@ Bytes.get m k)) 24 lor
           sl (Int32.of_int (Char.code @@ Bytes.get m (k + 1))) 16 lor
           sl (Int32.of_int (Char.code @@ Bytes.get m (k + 2))) 8 lor
           (Int32.of_int (Char.code @@ Bytes.get m (k + 3)))
done;
@
<<[[Sha1.sha1()]] loop from 0 to 79 for each block [[i]]>>=
for t = 0 to 79 do
  let f, k =
    if t <= 19 then (!b land !c) lor ((lnot !b) land !d), 0x5A827999l else
    if t <= 39 then !b lxor !c lxor !d, 0x6ED9EBA1l else
    if t <= 59 then
      (!b land !c) lor (!b land !d) lor (!c land !d), 0x8F1BBCDCl
    else
    !b lxor !c lxor !d, 0xCA62C1D6l
  in
  let s = t &&& 0xF in
  if (t >= 16) then begin
    w.(s) <- cls 1 begin
        w.((s + 13) &&& 0xF) lxor
        w.((s + 8) &&& 0xF) lxor
        w.((s + 2) &&& 0xF) lxor
        w.(s)
      end
  end;
  let temp = (cls 5 !a) ++ f ++ !e ++ w.(s) ++ k in
  e := !d;
  d := !c;
  c := cls 30 !b;
  b := !a;
  a := temp;
done;
@
% why 0 to 79? why magical 79?

<<function sha_1_pad>>=
let sha_1_pad s =
  let len = String.length s in
  let blen = 8 * len in
  let rem = len mod 64 in
  let mlen = if rem > 55 then len + 128 - rem else len + 64 - rem in
  let m = Bytes.create mlen in
  Bytes.blit_string s 0 m 0 len;
  Bytes.fill m len (mlen - len) '\x00';
  Bytes.set m len '\x80';
  if Sys.word_size > 32 then begin
    Bytes.set m (mlen - 8) (Char.unsafe_chr (blen lsr 56 land 0xFF));
    Bytes.set m (mlen - 7) (Char.unsafe_chr (blen lsr 48 land 0xFF));
    Bytes.set m (mlen - 6) (Char.unsafe_chr (blen lsr 40 land 0xFF));
    Bytes.set m (mlen - 5) (Char.unsafe_chr (blen lsr 32 land 0xFF));
  end;
  Bytes.set m (mlen - 4) (Char.unsafe_chr (blen lsr 24 land 0xFF));
  Bytes.set m (mlen - 3) (Char.unsafe_chr (blen lsr 16 land 0xFF));
  Bytes.set m (mlen - 2) (Char.unsafe_chr (blen lsr 8 land 0xFF));
  Bytes.set m (mlen - 1) (Char.unsafe_chr (blen land 0xFF));
  m
in
@

\section{Unzip}

% entry point:
<<signature Unzip.inflate>>=
val inflate : ?header:bool -> IO.input -> IO.input
(** wrap an input using "inflate" decompression algorithm. raises [Error] if
  an error occurs (this can only be caused by malformed input data). *)
@
% opposite of deflate.
\t remove ?header everywhere? useful?

\subsection{Overview}

%https://en.wikipedia.org/wiki/DEFLATE
%RFC 1951 for deflate file format (great)
%RFC 1950 for zlib format which adds adler-32 checksum for data corruption
% detection. zlib stream.
%http://zlib.net/feldspar.html great article on DEFLATE: 

% Deflate is a Mix of Huffman encoding with LZ77 sliding-window compression.
% Deflate is a very well engineered and optimized algorithm.

%https://www.cs.duke.edu/courses/spring03/cps296.5/papers/ziv_lempel_1977_universal_algorithm.pdf
% implemented in ocaml by Gazanaire (and used in decompress later)

% More efficient than 'compress' (which uses LZW)
% https://en.wikipedia.org/wiki/Lempel%E2%80%93Ziv%E2%80%93Welch
% Used by gzip, zlib library, GIF, PNG, and of course DOS pkzip.
% http://stackoverflow.com/questions/20762094/how-are-zlib-gzip-and-zip-related-what-do-they-have-in-common-and-how-are-they/20765054#20765054

% A nice implem in Python? covers also bzip2.
% http://www.paul.sladen.org/projects/pyflate/

% See also plan9 libflate/

% FIGURE with Head, Block, CData, and final block and end-of-block markers


\subsection{Data structures}

% huffman encoding
<<type Unzip.huffman>>=
type huffman =
  (** Leaf *)
  | Found of int (** 0..288 *)
  (** Node *)
  | NeedBit of huffman * huffman
  <<[[Unzip.huffman]] cases>>
@

% Alphabet is 0-288 (0-255 + 256 for end of block + 257..288 for lz77 backref)
% but 257..288 is not enough range to encode big distance, so need extra
% bits, and again specialized encoding so frequent distances take less space.
% In fact the 257..288 encodes the length of the backref, not the distance.
% The distance encoding can even use another huffman tree! wow.

% sliding window compression (lz77)
<<type Unzip.window>>=
type window = {
  mutable wbuffer : bytes;
  mutable wpos : int;
  <<[[Unzip.window]] other fields>>
}
@

<<constant Unzip.window_size>>=
let window_size = 1 lsl 15
@
% 32K
<<constant Unzip.buffer_size>>=
let buffer_size = 1 lsl 16
@
\l why double? cos will need to blit when reach buffer_size?
\t apparently not, so why?
%FIGURE

<<function Unzip.window_create>>=
let window_create () = {
    wbuffer = Bytes.create buffer_size;
    wpos = 0;
    <<[[Unzip.window_create()]] set other fields>>
  }
@
%old: was taking a size argument, but it was unused


% automata zstream
<<type Unzip.state>>=
type state =
  | Head

  | Block
  | CData

  | Done
  <<[[Unzip.state]] other cases>>
@

% zlib stream
<<type Unzip.t>>=
type t = {
  mutable zstate    : state;

  mutable zhuffman  : huffman;
  zwindow  : window;

  (** input *)
  zinput   : IO.input;
  mutable zneeded   : int;

  (** output *)
  mutable zoutput   : bytes;
  mutable zoutpos   : int;

  <<[[Unzip.t]] other fields>>
}
@

<<[[Unzip.t]] other fields>>=
mutable zfinal    : bool;
@
% final block (will do different things when read end-of-block if it
% is end-of-_final_-block


\subsection{Error management}

<<type Unzip.error_msg>>=
type error_msg =
  | Invalid_huffman
  | Invalid_data
  | Invalid_crc
  | Truncated_data
  | Unsupported_dictionary
@

<<exception Unzip.Error>>=
exception Error of error_msg
@
% classic Leroy style error management (except miss the [[ppf]] error printer)

<<function Unzip.error>>=
let error msg = raise (Error msg)
@

\subsection{IO helpers}

\subsubsection{Input bits helpers}

<<[[Unzip.t]] other fields>>=
(** usually a byte, but can contained more *)
mutable zbits     : int;
(** unread (not consumed) bits in zbits (usually 0..8, but can be more) *)
mutable znbits    : int;
@
\l could use byte type? (char)

<<function Unzip.reset_bits>>=
let reset_bits z =
  z.zbits <- 0;
  z.znbits <- 0
@



<<function Unzip.get_bit>>=
let get_bit z =
  if z.znbits = 0 then begin
    z.znbits <- 8;
    z.zbits <- IO.read_byte z.zinput;
  end;
  let b = z.zbits land 1 = 1 in
  z.znbits <- z.znbits - 1;
  z.zbits <- z.zbits lsr 1;
  b
@
\l again could just call get_bits z 1?

<<function Unzip.get_bits>>=
let get_bits z n =
  while z.znbits < n do
    z.zbits <- z.zbits lor ((IO.read_byte z.zinput) lsl z.znbits);
    z.znbits <- z.znbits + 8;
  done;
  let b = z.zbits land (1 lsl n - 1) in
  z.znbits <- z.znbits - n;
  z.zbits <- z.zbits lsr n;
  b
@
\l could sanity check n < Int.bit_size

% get_rev_bits later


\subsubsection{Output helpers}

<<function Unzip.add_char>>=
let add_char z c =
  <<[[Unzip.add_char()]] add character to window>>
  Bytes.unsafe_set z.zoutput z.zoutpos c;
  z.zneeded <- z.zneeded - 1;
  z.zoutpos <- z.zoutpos + 1
@
\l why not call add_bytes with 1?
\l could use safe version. No need optimize those Bytes.set

<<function Unzip.add_bytes>>=
let add_bytes z s p l =
  <<[[Unzip.add_bytes()]] add bytes to window>>
  Bytes.unsafe_blit s p z.zoutput z.zoutpos l;
  z.zneeded <- z.zneeded - l;
  z.zoutpos <- z.zoutpos + l
@

% will see window stuff later.

\subsection{Huffman trees}

<<function Unzip.apply_huffman>>=
let rec apply_huffman z = function
  | Found n -> n
  | NeedBit (a,b) -> apply_huffman z (if get_bit z then b else a)
 <<[[Unzip.apply_huffman()]] other cases>>
@

%\subsubsection{Building an huffman tree}

<<constant Unzip.fixed_huffman>>=
let fixed_huffman = 
  make_huffman (Array.init 288 (fun n ->
    if n <= 143 then 8
    else if n <= 255 then 9
    else if n <= 279 then 7
    else 8
  )) 0 288 10
@
% longer codelengths for chars between 144 and 255, because less used
% chars? and then use less bits for lz77 length/distance

% See deflate article, if put rules on how to build huffman tree, then
% an huffman tree can be encoded by just giving the codelengths for each
% character of the alphabet.

% pos is usually 0. Not 0 only for some calls for dynamic huffman.
<<function Unzip.make_huffman>>=
let make_huffman lengths pos nlengths maxbits =

  let counts = Array.make maxbits 0 in
  for i = 0 to nlengths - 1 do
    let p = Array.unsafe_get lengths (i + pos) in
    <<[[Unzip.make_huffman()]] sanity check codelength [[p]]>>
    Array.unsafe_set counts p (Array.unsafe_get counts p + 1);
  done;

  let code = ref 0 in
  let tmp = Array.make maxbits 0 in
  for i = 1 to maxbits - 2 do
    code := (!code + Array.unsafe_get counts i) lsl 1;
    Array.unsafe_set tmp i !code;
  done;

  let bits = Hashtbl.create 0 in
  for i = 0 to nlengths - 1 do
    let l = Array.unsafe_get lengths (i + pos) in
    if l <> 0 then begin
      let n = Array.unsafe_get tmp (l - 1) in
      Array.unsafe_set tmp (l - 1) (n + 1);
      Hashtbl.add bits (n,l) i;
    end;
  done;

  <<function Unzip.tree_make>>
    (NeedBit (tree_make 0 1, tree_make 1 1))
@
\t need more LP split, not trivial
%opti: tree_compress (NeedBit ...)

<<function Unzip.tree_make>>=
let rec tree_make v l =
  <<[[Unzip.tree_make()]] sanity check [[l]]>>
  try
    Found (Hashtbl.find bits (v,l))
  with
    Not_found ->
      NeedBit (tree_make (v lsl 1) (l + 1) , tree_make (v lsl 1 lor 1) (l + 1))
in
@

<<[[Unzip.tree_make()]] sanity check [[l]]>>=
if l > maxbits then error Invalid_huffman;
@

<<[[Unzip.make_huffman()]] sanity check codelength [[p]]>>=
if p >= maxbits then error Invalid_huffman;
@
\subsection{Sliding Window back references}

<<[[Unzip.add_char()]] add character to window>>=
window_add_char z.zwindow c;
@
<<[[Unzip.add_bytes()]] add bytes to window>>=
window_add_bytes z.zwindow s p l;
@

<<function Unzip.window_add_char>>=
let window_add_char w c =
  <<[[Unzip.window_add_char()]] slide window if reached end of buffer>>
  Bytes.unsafe_set w.wbuffer w.wpos c;
  w.wpos <- w.wpos + 1
@
<<function Unzip.window_add_bytes>>=
let window_add_bytes w s p len =
  <<[[Unzip.window_add_bytes()]] slide window if reached end of buffer>>
  Bytes.unsafe_blit s p w.wbuffer w.wpos len;
  w.wpos <- w.wpos + len
@


<<[[Unzip.window_add_char()]] slide window if reached end of buffer>>=
if w.wpos = buffer_size 
then window_slide w;
@
<<[[Unzip.window_add_bytes()]] slide window if reached end of buffer>>=
if w.wpos + len > buffer_size 
then window_slide w;
@

<<function Unzip.window_slide>>=
let window_slide w = 
  <<Unzip.window_slide()]] update crc before blit>>
  let b = Bytes.create buffer_size in
  w.wpos <- w.wpos - window_size;
  Bytes.unsafe_blit w.wbuffer window_size b 0 w.wpos;
  w.wbuffer <- b
@
\t why need 64K buffer then? if create new buffer each time anyway?

% inflate_loop (when in Block and n > 256) -> <>
<<function Unzip.window_available>>=
let window_available w =
  w.wpos
@

\subsection{Entry point}

%trans: now ready finally for full algorithm.

% inflate means decompress

<<function Unzip.inflate>>=
let inflate ?(header=true) ch =
  let z = inflate_init ~header ch in
  let s = Bytes.create 1 in
  IO.create_in
    ~input:(fun s p l ->
      let n = inflate_data z s p l in
      if n = 0 
      then raise IO.No_more_input;
      n
    )
    ~close:(fun () ->
      IO.close_in ch
    )
    (** special case of ~input for 1 byte *)
    ~read:(fun() ->
      let l = inflate_data z s 0 1 in
      if l = 1 
      then Bytes.unsafe_get s 0 
      else raise IO.No_more_input
    )
@
% IO.create_in use a growing byte buffer!

<<signature Unzip.inflate_init>>=
val inflate_init : ?header:bool -> IO.input -> t
@
<<function Unzip.inflate_init>>=
let inflate_init ?(header=true) ch = 
  {
    zstate = (if header then Head else Block);
    zinput = ch;
    zneeded = 0;
    zfinal = false;

    zoutput = Bytes.empty;
    zoutpos = 0;

    zhuffman = fixed_huffman;
    zhuffdist = None;

    zwindow = window_create ();

    zbits = 0;
    znbits = 0;

    zlen = 0;
    zdist = 0;
    zlengths = Array.make 19 (-1);
  }
@
%old:    zwindow = window_create (1 lsl 15) but argument was not used and
% anyway he should have used window_size instead of this hardcoded constant


<<signature Unzip.inflate_data>>=
val inflate_data : t -> bytes -> int -> int -> int
@
<<function Unzip.inflate_data>>=
let inflate_data z s pos len =
  <<[[Unzip.inflate_data()]] sanity check parameters>>
  z.zneeded <- len;
  z.zoutpos <- pos;
  z.zoutput <- s;
  try
    if len > 0 
    then inflate_loop z;
    len - z.zneeded
  with IO.No_more_input -> error Truncated_data
@
% return number of characters consumed, at the end
% zneeded should be 0 so we should return len (unless found
% end of block earlier than len)

<<[[Unzip.inflate_data()]] sanity check parameters>>=
if pos < 0 || len < 0 || pos + len > Bytes.length s 
then invalid_arg "inflate_data";
@


<<function Unzip.inflate_loop>>=
let rec inflate_loop z =
  match z.zstate with
  <<[[Unzip.inflate_loop()]] match state cases>>
@

\subsubsection{Head}

% See RFC1950 and zlib stream format
<<[[Unzip.inflate_loop()]] match state cases>>=
| Head ->
  let cmf = IO.read_byte z.zinput in
  <<[[Unzip.inflate_loop()]] when in Head state, sanity check [[cmf]]>>
  let flg = IO.read_byte z.zinput in
  <<[[Unzip.inflate_loop()]] when in Head state, sanity check [[flg]]>>
  z.zstate <- Block;
  inflate_loop z
@
%  (*let fcheck = flg land 31 in*)
%  (*let flevel = flg lsr 6 in*)

% cmf compression mode and flag?

<<[[Unzip.inflate_loop()]] when in Head state, sanity check [[cmf]]>>=
let cm     = cmf land 15 in
let cinfo  = cmf lsr 4 in
if cm <> 8 || cinfo <> 7 
then error Invalid_data;
@
% see RFC 1950? 
% cm for 'compression method'
% https://stackoverflow.com/questions/20762094/how-are-zlib-gzip-and-zip-related-what-do-they-have-in-common-and-how-are-they/20765054#20765054
% cm = 8 is for deflate format
% cinfo = 7 = window size? (32K)?

<<[[Unzip.inflate_loop()]] when in Head state, sanity check [[flg]]>>=
let fdict = flg land 32 <> 0 in
if (cmf lsl 8 + flg) mod 31 <> 0 
then error Invalid_data;
if fdict 
then error Unsupported_dictionary;
@
% see RFC 1950?

\subsubsection{Block}

<<[[Unzip.inflate_loop()]] match state cases>>=
| Block ->
  z.zfinal <- get_bit z;
  let btype = get_bits z 2 in
  (match btype with
  <<[[Unzip.inflate_loop()]] when in Block state, match block type cases>>
  | _ ->
    error Invalid_data
  )
@
% final block, useful when reach end of block in CData

% get_bit first call will set z.bits buffer.

<<[[Unzip.inflate_loop()]] when in Block state, match block type cases>>=
| 1 -> (* fixed Huffman *)
  if !debug then print_string "Unzip: Fixed Huffman\n";
  z.zhuffman <- fixed_huffman;
  z.zhuffdist <- None;
  z.zstate <- CData;
  inflate_loop z
@


\subsubsection{CData}

<<[[Unzip.inflate_loop()]] match state cases>>=
| CData ->
  (match apply_huffman z z.zhuffman with
  <<[[Unzip.inflate_loop()]] when in CData state, match apply huffman cases>>
  )
@
% So first compression here, huffman for alphabet encoding

<<[[Unzip.inflate_loop()]] when in CData state, match apply huffman cases>>=
| n when n < 256 ->
  add_char z (Char.unsafe_chr n);
  if z.zneeded > 0  
  then inflate_loop z
@
% byte as-is

<<[[Unzip.inflate_loop()]] when in CData state, match apply huffman cases>>=
| 256 ->
  z.zstate <- if z.zfinal then Crc else Block;
  inflate_loop z
@
% end of block character

% lz77 backref. more complex.
<<[[Unzip.inflate_loop()]] when in CData state, match apply huffman cases>>=
| n ->
  let n = n - 257 in
  <<[[Unzip.inflate_loop()]] when in CData state, when backref, compute zlen>>
  <<[[Unzip.inflate_loop()]] when in CData state, when backref, compute zdist>>

  if z.zdist > window_available z.zwindow 
  then error Invalid_data;
  z.zstate <- Dist;
  inflate_loop z
@
% So second compression here, lz77 sliding window backref
%opti:  z.zstate <- (if z.zdist = 1 then DistOne else Dist);

<<[[Unzip.t]] other fields>>=
mutable zlen      : int;
@
<<[[Unzip.t]] other fields>>=
mutable zdist     : int;
@

\paragraph{[[zlen]]}

<<[[Unzip.inflate_loop()]] when in CData state, when backref, compute zlen>>=
let extra_bits = Array.unsafe_get len_extra_bits_tbl n in
if extra_bits = -1 
then error Invalid_data;
z.zlen <- (Array.unsafe_get len_base_val_tbl n) + (get_bits z extra_bits);
@

<<constant Unzip.len_extra_bits_tbl>>=
let len_extra_bits_tbl = [|0;0;0;0;0;0;0;0;1;1;1;1;2;2;2;2;3;3;3;3;4;4;4;4;5;5;5;5;0;-1;-1|]
@

<<constant Unzip.len_base_val_tbl>>=
let len_base_val_tbl = [|3;4;5;6;7;8;9;10;11;13;15;17;19;23;27;31;35;43;51;59;67;83;99;115;131;163;195;227;258|]
@

\paragraph{[[zdist]]}

<<[[Unzip.inflate_loop()]] when in CData state, when backref, compute zdist>>=
let dist_code = 
  match z.zhuffdist with 
  | None -> get_rev_bits z 5 
  <<[[Unzip.inflate_loop()]] compute dist_code, match [[zhuffdist]] cases>>
in
let extra_bits = Array.unsafe_get dist_extra_bits_tbl dist_code in
if extra_bits = -1 
then error Invalid_data;
z.zdist <- (Array.unsafe_get dist_base_val_tbl dist_code) + (get_bits z extra_bits);
@

% for distance
<<function Unzip.get_rev_bits>>=
let rec get_rev_bits z n =
  if n = 0 then
    0
  else if get_bit z then
    (1 lsl (n - 1)) lor (get_rev_bits z (n-1))
  else
    get_rev_bits z (n-1)
@

<<constant Unzip.dist_extra_bits_tbl>>=
let dist_extra_bits_tbl = [|0;0;0;0;1;1;2;2;3;3;4;4;5;5;6;6;7;7;8;8;9;9;10;10;11;11;12;12;13;13;-1;-1|]
@

<<constant Unzip.dist_base_val_tbl>>=
let dist_base_val_tbl = [|1;2;3;4;5;7;9;13;17;25;33;49;65;97;129;193;257;385;513;769;1025;1537;2049;3073;4097;6145;8193;12289;16385;24577|]
@

\subsubsection{Dist}

<<[[Unzip.state]] other cases>>=
| Dist
@

<<[[Unzip.inflate_loop()]] match state cases>>=
| Dist ->
  while z.zlen > 0 && z.zneeded > 0 do
    let len = min z.zneeded (min z.zlen z.zdist) in
    add_dist z z.zdist len;
    z.zlen <- z.zlen - len;
  done;
  if z.zlen = 0 
  then z.zstate <- CData;
  if z.zneeded > 0 
  then inflate_loop z
@
% The loop is because zlen can be more than what is available in
% the sliding window when they use the trick of repeating sequence.

<<function Unzip.add_dist>>=
let add_dist z d l =
  add_bytes z z.zwindow.wbuffer (z.zwindow.wpos - d) l
@
% finally.



\subsubsection{CRC}

% when end of final block
<<[[Unzip.state]] other cases>>=
| Crc
@

<<[[Unzip.inflate_loop()]] match state cases>>=
| Crc ->
  <<[[Unzip.inflate_loop()]] when in Crc state, check adler32 checksum>>
  z.zstate <- Done;
  inflate_loop z
@

\subsubsection{Done}

<<[[Unzip.inflate_loop()]] match state cases>>=
| Done ->
  ()
@


\subsection{Advanced features}

\subsubsection{Adler32 CRC}

% Communication? Redundancy Check?

%A painless guide to CRC error detection algorithms
%http://www.zlib.net/crc_v3.txt

% Part of zlib, not deflate.

% faster than CRC32 algorithm and low probability of undetected errors
<<type Unzip.adler32>>=
type adler32 = {
  mutable a1 : int;
  mutable a2 : int;
}
@

<<[[Unzip.window]] other fields>>=
wcrc : adler32;
@
% See Appendix 9 of RFC 1950

<<[[Unzip.window_create()]] set other fields>>=
wcrc = adler32_create();
@

<<function Unzip.adler32_create>>=
let adler32_create() = {
  a1 = 1;
  a2 = 0;
}
@

<<Unzip.window_slide()]] update crc before blit>>=
adler32_update w.wcrc w.wbuffer 0 window_size;
@

% libflate contains more optimized code where some loops
% are probably unfolded.

<<function Unzip.adler32_update>>=
let adler32_update a s p l =
  let p = ref p in
  for i = 0 to l - 1 do
    let c = int_of_char (Bytes.unsafe_get s !p) in
    a.a1 <- (a.a1 + c) mod 65521;
    a.a2 <- (a.a2 + a.a1) mod 65521;
    incr p;
  done
@
% let base = 65521 largest primer smaller than 65536

% Logic behind those 2 numbers? Proof that it works better than other CRC?

<<[[Unzip.inflate_loop()]] when in Crc state, check adler32 checksum>>=
let calc = window_checksum z.zwindow in
let crc = adler32_read z.zinput in
if calc <> crc 
then error Invalid_crc;
@

<<function Unzip.window_checksum>>=
let window_checksum w =
  adler32_update w.wcrc w.wbuffer 0 w.wpos;
  w.wcrc
@


% IO in zlib stream
<<function Unzip.adler32_read>>=
let adler32_read ch =
  let a2a = IO.read_byte ch in
  let a2b = IO.read_byte ch in
  let a1a = IO.read_byte ch in
  let a1b = IO.read_byte ch in
  {
    a1 = (a1a lsl 8) lor a1b;
    a2 = (a2a lsl 8) lor a2b;
  }
@


\subsubsection{No compression block type}

<<[[Unzip.inflate_loop()]] when in Block state, match block type cases>>=
| 0 -> (* no compression *)
  if !debug then print_string "Unzip: no compression\n";
  z.zlen <- IO.LittleEndian.read_ui16 z.zinput;
  let nlen = IO.LittleEndian.read_ui16 z.zinput in
  if nlen <> 0xffff - z.zlen 
  then error Invalid_data;
  z.zstate <- Flat;
  inflate_loop z;
  reset_bits z
@

% compressed already compressed? will lose space, so better
% acknowledge that sometimes better not do anything

<<[[Unzip.state]] other cases>>=
| Flat
@

% uncompressed block
<<[[Unzip.inflate_loop()]] match state cases>>=
| Flat ->
  let rlen = min z.zlen z.zneeded in
  let str = IO.nread z.zinput rlen in
  let len = Bytes.length str in
  z.zlen <- z.zlen - len;
  add_bytes z str 0 len;
  if z.zlen = 0 
  then z.zstate <- (if z.zfinal then Crc else Block);
  if z.zneeded > 0 
  then inflate_loop z
@

\subsubsection{Specialized huffman tree}

% Maybe more complex part of DEFLATE, the way the huffman tree is encoded.

% Dynamic Huffman vs static huffman.
% This format is often used. 

<<[[Unzip.inflate_loop()]] when in Block state, match block type cases>>=
| 2 -> (* dynamic Huffman *)
  if !debug then print_string "Unzip: Dynamic Huffman\n";
  let hlit = get_bits z 5 + 257 in
  let hdist = get_bits z 5 + 1 in
  let hclen = get_bits z 4 + 4 in
  for i = 0 to hclen - 1 do
    Array.unsafe_set z.zlengths (Array.unsafe_get code_lengths_pos i) (get_bits z 3);
  done;
  for i = hclen to 18 do
    Array.unsafe_set z.zlengths (Array.unsafe_get code_lengths_pos i) 0;
  done;
  z.zhuffman <- make_huffman z.zlengths 0 19 8;
  let lengths = Array.make (hlit + hdist) 0 in
  inflate_lengths z lengths (hlit + hdist);
  z.zhuffdist <- Some (make_huffman lengths hlit hdist 16);
  z.zhuffman <- make_huffman lengths 0 hlit 16;      
  z.zstate <- CData;
  inflate_loop z
@

<<[[Unzip.t]] other fields>>=
zlengths : int array;
@

<<[[Unzip.t]] other fields>>=
mutable zhuffdist : huffman option;
@

<<[[Unzip.inflate_loop()]] compute dist_code, match [[zhuffdist]] cases>>=
| Some h -> 
  apply_huffman z h
@

<<constant Unzip.code_lengths_pos>>=
let code_lengths_pos = [|16;17;18;0;8;7;9;6;10;5;11;4;12;3;13;2;14;1;15|]
@

<<function Unzip.inflate_lengths>>=
let inflate_lengths z a max =
  let i = ref 0 in
  let prev = ref 0 in
  while !i < max do
    match apply_huffman z z.zhuffman with
    | n when n <= 15 ->
      prev := n;
      Array.unsafe_set a !i n;
      incr i
    | 16 ->
      let n = 3 + get_bits z 2 in
      if !i + n > max then error Invalid_data;
      for k = 0 to n - 1 do
        Array.unsafe_set a !i !prev;
        incr i;
      done;
    | 17 ->
      let n = 3 + get_bits z 3 in
      i := !i + n;
      if !i > max then error Invalid_data;
    | 18 ->
      let n = 11 + get_bits z 7 in
      i := !i + n;
      if !i > max then error Invalid_data;
    | _ ->
      error Invalid_data
  done
@

\subsection{Optimizations}

\subsubsection{[[NeedBits]]}

<<[[Unzip.huffman]] cases>>=
(** Opti *)
| NeedBits of int * huffman array
@
<<[[Unzip.apply_huffman()]] other cases>>=
| NeedBits (n,t) -> apply_huffman z (Array.unsafe_get t (get_bits z n))
@

<<function Unzip.tree_compress>>=
let rec tree_compress t =
  match tree_depth t with
  | 0 -> t
  | 1 ->
    (match t with
    | NeedBit (a,b) -> NeedBit (tree_compress a,tree_compress b)
    | _ -> assert false)
  | d ->
    let size = 1 lsl d in
    let tbl = Array.make size (Found (-1)) in
    tree_walk tbl 0 0 d t;
    NeedBits (d,tbl)

and tree_walk tbl p cd d = function
  | NeedBit (a,b) when d > 0 ->
    tree_walk tbl p (cd + 1) (d-1) a;
    tree_walk tbl (p lor (1 lsl cd)) (cd + 1) (d-1) b;
  | t ->
    Array.set tbl p (tree_compress t)
@

<<function Unzip.tree_depth>>=
let rec tree_depth = function
  | Found _ -> 0
  | NeedBit (a,b) ->
    1 + min (tree_depth a) (tree_depth b)
  | NeedBits _ -> assert false
@
% so NeedBits used only after tree_compress pass

\subsubsection{[[DistOne]]}

<<[[Unzip.state]] other cases>>=
| DistOne
@
% optimization?

<<[[Unzip.inflate_loop()]] match state cases>>=
| DistOne ->
  if !debug then print_string "Unzip: DistOne\n";
  let len = min z.zlen z.zneeded in
  add_dist_one z len;
  z.zlen <- z.zlen - len;
  if z.zlen = 0 
  then z.zstate <- CData;
  if z.zneeded > 0 
  then inflate_loop z
@

<<function Unzip.add_dist_one>>=
let add_dist_one z n =
  let c = window_get_last_char z.zwindow in
  let s = Bytes.make n c in
  add_bytes z s 0 n
@

<<function Unzip.window_get_last_char>>=
let window_get_last_char w =
  Bytes.unsafe_get w.wbuffer (w.wpos - 1)
@




\section{Zip}


% entry point:
<<signature Zlib.compress>>=
val compress:
  ?level: int -> ?header: bool -> 
  (bytes -> int) -> (bytes -> int -> unit) -> unit
@

<<function Zlib.compress>>=
let compress ?(level = 6) ?(header = true) refill flush =
  let inbuf = Bytes.create buffer_size
  and outbuf = Bytes.create buffer_size in
  let zs = deflate_init level header in
  let rec compr inpos inavail =
    if inavail = 0 then begin
      let incount = refill inbuf in
      if incount = 0 then compr_finish() else compr 0 incount
    end else begin
      let (_, used_in, used_out) =
        deflate zs inbuf inpos inavail outbuf 0 buffer_size Z_NO_FLUSH in
      flush outbuf used_out;
      compr (inpos + used_in) (inavail - used_in)
    end
  and compr_finish () =
    let (finished, _, used_out) =
       deflate zs inbuf 0 0 outbuf 0 buffer_size Z_FINISH in
    flush outbuf used_out;
    if not finished then compr_finish()
  in
    compr 0 0;
    deflate_end zs
@


<<exception Zlib.Error>>=
exception Error of string * string
@

<<toplevel Zlib._1>>=
let _ =
  Callback.register_exception "Zlib.Error" (Error("",""))
@

<<type Zlib.flush_command>>=
type flush_command =
    Z_NO_FLUSH
  | Z_SYNC_FLUSH
  | Z_FULL_FLUSH
  | Z_FINISH
@

<<constant Zlib.buffer_size>>=
let buffer_size = 1024
@




<<signature Zlib.compress_direct>>=
val compress_direct:
  ?level: int -> ?header: bool -> (bytes -> int -> unit) ->
  (bytes -> int -> int -> unit) * (unit -> unit)
@
<<function Zlib.compress_direct>>=
let compress_direct  ?(level = 6) ?(header = true) flush =
  let outbuf = Bytes.create buffer_size in
  let zs = deflate_init level header in
  let rec compr inbuf inpos inavail =
    if inavail = 0 then ()
    else begin
      let (_, used_in, used_out) =
        deflate zs inbuf inpos inavail outbuf 0 buffer_size Z_NO_FLUSH in
      flush outbuf used_out;
      compr inbuf (inpos + used_in) (inavail - used_in)
    end
  and compr_finish () =
    let (finished, _, used_out) =
      deflate zs (Bytes.unsafe_of_string "") 0 0
                 outbuf 0 buffer_size Z_FINISH in
    flush outbuf used_out;
    if not finished then compr_finish()
  in
  compr, compr_finish
@



<<signature Zlib.uncompress>>=
val uncompress:
  ?header: bool -> (bytes -> int) -> (bytes -> int -> unit) -> unit
@

<<function Zlib.uncompress>>=
let uncompress ?(header = true) refill flush =
  let inbuf = Bytes.create buffer_size
  and outbuf = Bytes.create buffer_size in
  let zs = inflate_init header in
  let rec uncompr inpos inavail =
    if inavail = 0 then begin
      let incount = refill inbuf in
      if incount = 0 then uncompr_finish true else uncompr 0 incount
    end else begin
      let (finished, used_in, used_out) =
        inflate zs inbuf inpos inavail outbuf 0 buffer_size Z_SYNC_FLUSH in
      flush outbuf used_out;
      if not finished then uncompr (inpos + used_in) (inavail - used_in)
    end
  and uncompr_finish first_finish =
    (* Gotcha: if there is no header, inflate requires an extra "dummy" byte
       after the compressed stream in order to complete decompression
       and return finished = true. *)
    let dummy_byte = if first_finish && not header then 1 else 0 in
    let (finished, _, used_out) =
       inflate zs inbuf 0 dummy_byte outbuf 0 buffer_size Z_SYNC_FLUSH in
    flush outbuf used_out;
    if not finished then uncompr_finish false
  in
    uncompr 0 0;
    inflate_end zs
@


\section{Diff}

\subsection{Overview}

% Basic edit distance algo (see Gusfield book)
% \cite{James and McIlroy - 1976}
% \cite{Myers - 1985}
%   https://blog.jcoglan.com/2017/02/12/the-myers-diff-algorithm-part-1/
% patience diff
%  https://blog.jcoglan.com/2017/09/19/the-patience-diff-algorithm/

<<signature Diff_basic.diff>>=
val diff: string array -> string array -> Diff.diff
@

<<signature Diff_myers.diff>>=
val diff: string array -> string array -> Diff.diff
@

\subsection{Data structures}

% Saw Diff.diff with Equal | Deleted | Added in chapter X.

\subsection{Edit distance basic algorithm}

<<function Diff_basic.diff>>=
let diff arr1 arr2 =
  (* opti: string to int *)

  let mat = matrix_distance arr1 arr2 in
  let trace = traceback_transcript arr1 arr2 mat in
  List.rev trace

  (* opti: get back string from int *)
(*
  let arr1, arr2, revh = hash_strings arr1 arr2 in
  |> List.map (function 
      | Diff.Added i   -> Diff.Added   (revh.(i))
      | Diff.Deleted i -> Diff.Deleted (revh.(i))
      | Diff.Equal i   -> Diff.Equal   (revh.(i))
  )
*)
@

% See comment in diff_basic.ml prelude for some comments

<<function Diff_basic.matrix_distance>>=
let matrix_distance arr1 arr2 = 
  let n = Array.length arr1 in
  let m = Array.length arr2 in 
  (* this can be big ... *)
  let mat = Array.make_matrix (n+1) (m+1) 0 in
  let t i j = 
    if Array.get arr1 (i-1) = Array.get arr2 (j-1)
    then 0
    else 1 
  in
  let min3 a b c = min (min a b) c in

  begin
    for i = 0 to n do
      mat.(i).(0) <- i
    done;
    for j = 0 to m do
      mat.(0).(j) <- j;
    done;
    (* this can be long ... *)
    for i = 1 to n do
      for j = 1 to m do
        mat.(i).(j) <- 
          min3 (mat.(i).(j-1) + 1) 
               (mat.(i-1).(j) + 1) 
               (mat.(i-1).(j-1) + t i j)
      done
    done;
    mat
  end
@

<<function Diff_basic.traceback_transcript>>=
(* extract the traceback from the matrice (Gusfield P221) *)
let traceback_transcript arr1 arr2 mat =
  let n = Array.length arr1 in
  let m = Array.length arr2 in 
  let get_orig_arr arr i = arr.(i-1) in
  (* you need Figure 11.3 P222 of Gusfield book to understand the code below *)
  let rec aux i j =
    let x = mat.(i).(j) in
    match () with
    | _ when i = 0 && j = 0 -> []
    | _ when i = 0 -> (Diff.Added (get_orig_arr arr2 j))::aux (i) (j-1)
    | _ when j = 0 -> (Diff.Deleted (get_orig_arr arr1 i))::aux (i-1) (j)
    | _ when x = mat.(i-1).(j) + 1 -> 
      (Diff.Deleted (get_orig_arr arr1 i))::aux (i-1) (j)
    | _ when x = mat.(i).(j-1) + 1 -> 
      (Diff.Added (get_orig_arr arr2 j))::aux (i) (j-1)
    | _ -> 
      if x = mat.(i-1).(j-1)
      then Diff.Equal (get_orig_arr arr1 (i))::aux (i-1) (j-1)
      else (Diff.Deleted (get_orig_arr arr1 i))::
           (Diff.Added (get_orig_arr arr2 j))::
           aux (i-1) (j-1)
  in
  aux n m
@

\subsection{Myers algorithm}

<<function Diff_myers.lcs>>=
let lcs a b =
  let n = Array.length a in
  let m = Array.length b in
  let mn = m + n in
  let sz = 2 * mn + 1 in
  let vd = Array.make sz 0 in
  let vl = Array.make sz 0 in
  let vr = Array.make sz [] in
  let get v i = v.(i + mn) in
  let set v i x = v.(i + mn) <- x in
  let finish () =
    let rec loop i maxl r =
      match () with
      | _ when i > mn -> List.rev r
      | _ when get vl i > maxl -> loop (i + 1) (get vl i) (get vr i)
      | _ -> loop (i + 1) maxl r
    in loop (- mn) 0 []
  in
  if mn = 0 
  then []
  else
    (* For d <- 0 to mn Do *)
    let rec dloop d =
      assert (d <= mn);
      (* For k <- -d to d in steps of 2 Do *)
      let rec kloop k =
        if k > d 
        then dloop (d + 1)
        else
          let x, l, r =
            if k = -d || (k <> d && get vd (k - 1) < get vd (k + 1)) 
            then get vd (k + 1), get vl (k + 1), get vr (k + 1)
            else get vd (k - 1) + 1, get vl (k - 1), get vr (k - 1)
          in
          let x, y, l, r =
            let rec xyloop x y l r =
              if x < n && y < m && equal a.(x) b.(y)
              then xyloop (x + 1) (y + 1) (l + 1) (`Common(x, y, a.(x))::r)
              else x, y, l, r
            in xyloop x (x - k) l r
          in
          set vd k x;
          set vl k l;
          set vr k r;
          if x >= n && y >= m 
          then
            (* Stop *)
            finish ()
          else
            kloop (k + 2)
      in kloop (-d)
    in dloop 0
@

<<function Diff_myers.fold_left>>=
let fold_left f init a b =
  let ff x y = f y x in
  let fold_map f g x from to_ init =
    let rec loop i init =
      if i >= to_ 
      then init
      else loop (i + 1) (f (g i (M.get x i)) init)
    in loop from init
  in
  let added _i x = Diff.Added x in
  let removed _i x = Diff.Deleted x in
  let rec loop cs apos bpos init =
    match cs with
    | [] ->
        init
        |> fold_map ff removed a apos (M.length a)
        |> fold_map ff added b bpos (M.length b)
    | `Common (aoff, boff, x) as e :: rest ->
        init
        |> fold_map ff removed a apos aoff
        |> fold_map ff added b bpos boff
        |> ff (Diff.Equal x)
        |> loop rest (aoff + 1) (boff + 1)
  in loop (lcs a b) 0 0 init
@

<<function Diff_myers.diff>>=
let diff a b =
  let append_map g arr from to_ init =
    let rec loop i init =
      if i >= to_ 
      then init
      else loop (i + 1) (g i (arr.(i)):: init)
    in loop from init
  in
  let added   _i x = Diff.Added x in
  let removed _i x = Diff.Deleted x in
  let rec loop cs apos bpos init =
    match cs with
    | [] ->
        init
        |> append_map removed a apos (Array.length a)
        |> append_map added   b bpos (Array.length b)
    | `Common (aoff, boff, x) :: rest ->
        init
        |> append_map removed a apos aoff
        |> append_map added   b bpos boff
        |> (fun y -> (Diff.Equal x)::y)
        |> loop rest (aoff + 1) (boff + 1)
  in loop (lcs a b) 0 0 []
@


\section{Diff3}
% aka merge

% No paper really explaining diff3 algorithm. There is the diffutils manual
% and some comments in the source code according to Pierce's Diff3 
% formalization paper.

% A Formal Investigation of Diff3 (Pierce et al.)

% https://blog.jcoglan.com/2017/05/08/merging-with-diff3/
\chapter{Extra Code}

\ifallcode
#include "VCS_extra.nw"
\fi

%\chapter{Changelog}
%\label{sec:changelog}

% code via mk loc = 6157 LOC (but miss advanced features of dulwich/git)
% orig VCS.nw = 6318, just lpized and few comments, 75 pages pdf
% now: =~ XX LOC so added XX LOE (Lines of explanations)
% dulwich: =~ 16 000 LOC 

\chapter{Glossary}
\label{sec:glossary}

\begin{verbatim}
VCS = Version Control System
SHA1 = Secure Hash Algorithm 1
\end{verbatim}

\chapter*{Indexes}
\addcontentsline{toc}{section}{Index}

%\chapter{References} 
\addcontentsline{toc}{section}{References}

\bibliography{../docs/latex/Principia}
\bibliographystyle{alpha}

%******************************************************************************
% Postlude
%******************************************************************************

\end{document}
