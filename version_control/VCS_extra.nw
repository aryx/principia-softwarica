\section{[[dulwich.py]]}

<<[[dulwich.py]] toplevel, interrupt signal>>=
def signal_int(signal, frame):
    sys.exit(1)

signal.signal(signal.SIGINT, signal_int)
@
%not equivalent to default behavior?

%bug? it's '.' not '>' below in the top comment.

%-------------------------------------------------------------------------
<<dulwich.py>>=
#!/usr/bin/python -u
#
# dulwich - Simple command-line interface to Dulwich
# Copyright (C) 2008-2011 Jelmer Vernooij <jelmer@samba.org>
# vim: expandtab
#
<<dulwich license>>
"""Simple command-line interface to Dulwich>

This is a very simple command-line wrapper for Dulwich. It is by
no means intended to be a full-blown Git command-line interface but just
a way to test Dulwich.
"""

import os
import sys
from getopt import getopt
import optparse
import signal

<<[[dulwich.py]] toplevel, interrupt signal>>

from dulwich import porcelain
from dulwich.client import get_transport_and_path
from dulwich.errors import ApplyDeltaError
from dulwich.index import Index
from dulwich.pack import Pack, sha_to_hex
from dulwich.patch import write_tree_diff
from dulwich.repo import Repo

<<class Command>>


<<function cmd_archive>>

<<function cmd_add>>

<<function cmd_rm>>

<<function cmd_fetch_pack>>

<<function cmd_fetch>>

<<function cmd_log>>

<<function cmd_diff>>

<<function cmd_dump_pack>>

<<function cmd_dump_index>>

<<function cmd_init>>

<<function cmd_clone>>

<<function cmd_commit>>

<<function cmd_commit_tree>>

<<function cmd_update_server_info>>

<<function cmd_symbolic_ref>>

<<function cmd_show>>

<<function cmd_diff_tree>>

<<function cmd_rev_list>>

<<function cmd_tag>>

<<function cmd_repack>>

<<function cmd_reset>>

<<function cmd_daemon>>

<<function cmd_web_daemon>>

<<function cmd_receive_pack>>

<<function cmd_upload_pack>>

<<function cmd_status>>

<<function cmd_ls_remote>>

<<function cmd_ls_tree>>

<<function cmd_pack_objects>>

<<function cmd_pull>>

<<function cmd_remote_add>>

<<function cmd_remote>>

<<function cmd_help>>

<<constant commands>>

<<toplevel main>>

@

\section{[[dulwich/]]}

\subsection{[[__init__.py]]}

<<dulwich/__init__.py>>=
# __init__.py -- The git module of dulwich
# Copyright (C) 2007 James Westby <jw+debian@jameswestby.net>
# Copyright (C) 2008 Jelmer Vernooij <jelmer@samba.org>
#
<<dulwich license>>

"""Python implementation of the Git file formats and protocols."""

__version__ = (0, 17, 4)
@
% purpose of this file?

\subsection{[[archive.py]]}

<<dulwich/archive.py>>=
# archive.py -- Creating an archive from a tarball
# Copyright (C) 2015 Jonas Haag <jonas@lophus.org>
# Copyright (C) 2015 Jelmer Vernooij <jelmer@jelmer.uk>
#
<<dulwich license>>
"""Generates tarballs for Git trees.

"""

import posixpath
import stat
import tarfile
from io import BytesIO
from contextlib import closing

<<class ChunkedBytesIO>>

<<function archive.tar_stream>>

<<function archive._walk_tree>>
@

\subsection{[[client.py]]}


%<<[[GitClient]] methods>>=
%def _parse_status_report(self, proto):
%    unpack = proto.read_pkt_line().strip()
%    if unpack != b'unpack ok':
%        st = True
%        # flush remaining error data
%        while st is not None:
%            st = proto.read_pkt_line()
%        raise SendPackError(unpack)
%    statuses = []
%    errs = False
%    ref_status = proto.read_pkt_line()
%    while ref_status:
%        ref_status = ref_status.strip()
%        statuses.append(ref_status)
%        if not ref_status.startswith(b'ok '):
%            errs = True
%        ref_status = proto.read_pkt_line()
%
%    if errs:
%        ref_status = {}
%        ok = set()
%        for status in statuses:
%            if b' ' not in status:
%                # malformed response, move on to the next one
%                continue
%            status, ref = status.split(b' ', 1)
%
%            if status == b'ng':
%                if b' ' in ref:
%                    ref, status = ref.split(b' ', 1)
%            else:
%                ok.add(ref)
%            ref_status[ref] = status
%        raise UpdateRefsError(', '.join([
%            ref for ref in ref_status if ref not in ok]) +
%            b' failed to update', ref_status=ref_status)
%
%@
% dead? deprecated by ReportStatusParser?

<<class SubprocessGitClient>>=
class SubprocessGitClient(TraditionalGitClient):
    """Git client that talks to a server using a subprocess."""

    def __init__(self, **kwargs):
        self._connection = None
        self._stderr = None
        self._stderr = kwargs.get('stderr')
        if 'stderr' in kwargs:
            del kwargs['stderr']
        super(SubprocessGitClient, self).__init__(**kwargs)

    @classmethod
    def from_parsedurl(cls, parsedurl, **kwargs):
        return cls(**kwargs)

    git_command = None

    def _connect(self, service, path):
        if not isinstance(service, bytes):
            raise TypeError(service)
        if isinstance(path, bytes):
            path = path.decode(self._remote_path_encoding)
        if self.git_command is None:
            git_command = find_git_command()
        argv = git_command + [service.decode('ascii'), path]
        p = SubprocessWrapper(
            subprocess.Popen(argv, bufsize=0, stdin=subprocess.PIPE,
                             stdout=subprocess.PIPE,
                             stderr=self._stderr))
        return Protocol(p.read, p.write, p.close,
                        report_activity=self._report_activity), p.can_read
@
%dead? used only in 1 test.

<<function find_git_command>>=
def find_git_command():
    """Find command to run for system Git (usually C Git).
    """
    if sys.platform == 'win32':  # support .exe, .bat and .cmd
        try:  # to avoid overhead
            import win32api
        except ImportError:  # run through cmd.exe with some overhead
            return ['cmd', '/c', 'git']
        else:
            status, git = win32api.FindExecutable('git')
            return [git]
    else:
        return ['git']
@

<<function ParamikoSSHVendor>>=
def ParamikoSSHVendor(**kwargs):
    import warnings
    warnings.warn(
        "ParamikoSSHVendor has been moved to dulwich.contrib.paramiko_vendor.",
        DeprecationWarning)
    from dulwich.contrib.paramiko_vendor import ParamikoSSHVendor
    return ParamikoSSHVendor(**kwargs)
@
%dead? used by contrib/ code. seems very specific.

% ----------------------------------------------------------------------
<<dulwich/client.py>>=
# client.py -- Implementation of the client side git protocols
# Copyright (C) 2008-2013 Jelmer Vernooij <jelmer@samba.org>
#
<<dulwich license>>
"""Client side support for the Git protocol.

The Dulwich client supports the following capabilities:

 * thin-pack
 * multi_ack_detailed
 * multi_ack
 * side-band-64k
 * ofs-delta
 * quiet
 * report-status
 * delete-refs

Known capabilities that are not supported:

 * shallow
 * no-progress
 * include-tag
"""

from contextlib import closing
from io import BytesIO, BufferedReader
import dulwich
import select
import socket
import subprocess
import sys

try:
    from urllib import quote as urlquote
    from urllib import unquote as urlunquote
except ImportError:
    from urllib.parse import quote as urlquote
    from urllib.parse import unquote as urlunquote

try:
    import urllib2
    import urlparse
except ImportError:
    import urllib.request as urllib2
    import urllib.parse as urlparse

from dulwich.errors import (
    GitProtocolError,
    NotGitRepository,
    SendPackError,
    UpdateRefsError,
    )
from dulwich.protocol import (
    _RBUFSIZE,
    capability_agent,
    CAPABILITY_DELETE_REFS,
    CAPABILITY_MULTI_ACK,
    CAPABILITY_MULTI_ACK_DETAILED,
    CAPABILITY_OFS_DELTA,
    CAPABILITY_QUIET,
    CAPABILITY_REPORT_STATUS,
    CAPABILITY_SIDE_BAND_64K,
    CAPABILITY_THIN_PACK,
    CAPABILITIES_REF,
    COMMAND_DONE,
    COMMAND_HAVE,
    COMMAND_WANT,
    SIDE_BAND_CHANNEL_DATA,
    SIDE_BAND_CHANNEL_PROGRESS,
    SIDE_BAND_CHANNEL_FATAL,
    PktLineParser,
    Protocol,
    ProtocolFile,
    TCP_GIT_PORT,
    ZERO_SHA,
    extract_capabilities,
    )
from dulwich.pack import (
    write_pack_objects,
    )
from dulwich.refs import (
    read_info_refs,
    )

<<function client._fileno_can_read>>

<<constant client.COMMON_CAPABILITIES>>
<<constant client.FETCH_CAPABILITIES>>
<<constant client.SEND_CAPABILITIES>>

<<class ReportStatusParser>>

<<function client.read_pkt_refs>>

<<class GitClient>>

<<class TraditionalGitClient>>

<<class TCPGitClient>>

<<class SubprocessWrapper>>

<<function find_git_command>>

<<class SubprocessGitClient>>

<<class LocalGitClient>>

<<class default_local_git_client_cls>>

<<class SSHVendor>>

<<class SubprocessSSHVendor>>

<<function ParamikoSSHVendor>>

<<global get_ssh_vendor>>

<<class SSHGitClient>>


<<function client.default_user_agent_string>>

<<function client.default_urllib2_opener>>

<<class HttpGitClient>>

<<function get_transport_and_path_from_url>>

<<function client.get_transport_and_path>>
@

\subsection{[[config.py]]}

<<dulwich/config.py>>=
# config.py - Reading and writing Git config files
# Copyright (C) 2011-2013 Jelmer Vernooij <jelmer@samba.org>
#
<<dulwich license>>
"""Reading and writing Git configuration files.

TODO:
 * preserve formatting when updating configuration files
 * treat subsection names as case-insensitive for [branch.foo] style
   subsections
"""

import errno
import os

from collections import (
    OrderedDict,
    MutableMapping,
    )

from dulwich.file import GitFile

<<class Config>>

<<class ConfigDict>>

<<function config._format_string>>

<<constant config._ESCAPE_TABLE>>
<<constant config._COMMENT_CHARS>>
<<constant config._WHITESPACE_CHARS>>

<<function config._parse_string>>

<<function config._escape_value>>

<<function config._check_variable_name>>

<<function config._check_section_name>>

<<function config._strip_comments>>


<<class ConfigFile>>

<<class StackedConfig>>

<<function config.parse_submodules>>

@

\subsection{[[diff_tree.py]]}

<<diff_tree.py>>=
# diff_tree.py -- Utilities for diffing files and trees.
# Copyright (C) 2010 Google, Inc.
#
<<dulwich license>>
"""Utilities for diffing files and trees."""

import sys
from collections import (
    defaultdict,
    namedtuple,
    )

from io import BytesIO
from itertools import chain
import stat

from dulwich.objects import (
    S_ISGITLINK,
    TreeEntry,
    )

<<type CHANGE>>

<<constant diff_tree.RENAME_CHANGE_TYPES>>

<<constant diff_tree._NULL_ENTRY>>

<<constant diff_tree._MAX_SCORE>>
<<constant diff_tree.RENAME_THRESHOLD>>
<<constant diff_tree.MAX_FILES>>
<<constant diff_tree.REWRITE_THRESHOLD>>

<<class TreeChange>>

<<constant diff_tree._tree_entries>>

<<constant diff_tree._merge_entries>>

<<function diff_tree._is_tree>>

<<function diff_tree.walk_trees>>

<<function diff_tree._skip_tree>>

<<function diff_tree.tree_changes>>


def _all_eq(seq, key, value):
    for e in seq:
        if key(e) != value:
            return False
    return True


def _all_same(seq, key):
    return _all_eq(seq[1:], key, key(seq[0]))

<<diff.tree_changes_for_merge>>

<<constant diff_tree._BLOCK_SIZE>>

<<function diff_tree._count_blocks>>

<<function diff_tree._common_bytes>>

<<function diff_tree._similarity_score>>

<<function diff_tree._tree_change_key>>

<<class RenameDetector>>

# Hold on to the pure-python implementations for testing.
_is_tree_py = _is_tree
_merge_entries_py = _merge_entries
_count_blocks_py = _count_blocks
try:
    # Try to import C versions
    from dulwich._diff_tree import _is_tree, _merge_entries, _count_blocks
except ImportError:
    pass
@

\subsection{[[errors.py]]}

<<dulwich/errors.py>>=
# errors.py -- errors for dulwich
# Copyright (C) 2007 James Westby <jw+debian@jameswestby.net>
# Copyright (C) 2009-2012 Jelmer Vernooij <jelmer@samba.org>
#
<<dulwich license>>
"""Dulwich-related exception classes and utility functions."""

import binascii

<<errors>>

<<exception WrongObjectException>>

<<[[WrongObjectException]] errors>>

<<exception GitProtocolError>>

<<[[GitProtocolError]] errors>>

<<exception FileFormatException>>

<<[[FileFormatException]] errors>>
@

\subsection{[[fastexport.py]]}

<<fastexport.py>>=
# __init__.py -- Fast export/import functionality
# Copyright (C) 2010-2013 Jelmer Vernooij <jelmer@samba.org>
#
<<dulwich license>>

"""Fast export/import functionality."""

import sys

from dulwich.index import (
    commit_tree,
    )
from dulwich.objects import (
    Blob,
    Commit,
    Tag,
    )
from fastimport import __version__ as fastimport_version
if fastimport_version <= (0, 9, 5) and sys.version_info[0] == 3 and sys.version_info[1] < 5:
    raise ImportError("Older versions of fastimport don't support python3<3.5")
from fastimport import (
    commands,
    errors as fastimport_errors,
    parser,
    processor,
    )

import stat

<<function fastexport.split_email>>

<<class GitFastExporter>>

<<class GitImportProcessor>>

@

\subsection{[[file.py]]}

%---------------------------------------------------------------------------
<<dulwich/file.py>>=
# file.py -- Safe access to git files
# Copyright (C) 2010 Google, Inc.
#
<<dulwich license>>
"""Safe access to git files."""

import errno
import io
import os
import sys
import tempfile

<<function file.ensure_dir_exists>>

<<function GitFile>>

<<class _GitFile>>
@


\subsection{[[greenthreads.py]]}

<<greenthreads.py>>=
# greenthreads.py -- Utility module for querying an ObjectStore with gevent
# Copyright (C) 2013 eNovance SAS <licensing@enovance.com>
#
# Author: Fabien Boucher <fabien.boucher@enovance.com>
#
<<dulwich license>>
"""Utility module for querying an ObjectStore with gevent."""

import gevent
from gevent import pool

from dulwich.objects import (
    Commit,
    Tag,
    )
from dulwich.object_store import (
    MissingObjectFinder,
    _collect_filetree_revs,
    ObjectStoreIterator,
    )


def _split_commits_and_tags(obj_store, lst,
                            ignore_unknown=False, pool=None):
    """Split object id list into two list with commit SHA1s and tag SHA1s.

    Same implementation as object_store._split_commits_and_tags
    except we use gevent to parallelize object retrieval.
    """
    commits = set()
    tags = set()

    def find_commit_type(sha):
        try:
            o = obj_store[sha]
        except KeyError:
            if not ignore_unknown:
                raise
        else:
            if isinstance(o, Commit):
                commits.add(sha)
            elif isinstance(o, Tag):
                tags.add(sha)
                commits.add(o.object[1])
            else:
                raise KeyError('Not a commit or a tag: %s' % sha)
    jobs = [pool.spawn(find_commit_type, s) for s in lst]
    gevent.joinall(jobs)
    return (commits, tags)


class GreenThreadsMissingObjectFinder(MissingObjectFinder):
    """Find the objects missing from another object store.

    Same implementation as object_store.MissingObjectFinder
    except we use gevent to parallelize object retrieval.
    """
    def __init__(self, object_store, haves, wants,
                 progress=None, get_tagged=None,
                 concurrency=1, get_parents=None):

        def collect_tree_sha(sha):
            self.sha_done.add(sha)
            cmt = object_store[sha]
            _collect_filetree_revs(object_store, cmt.tree, self.sha_done)

        self.object_store = object_store
        p = pool.Pool(size=concurrency)

        have_commits, have_tags = \
            _split_commits_and_tags(object_store, haves,
                                    True, p)
        want_commits, want_tags = \
            _split_commits_and_tags(object_store, wants,
                                    False, p)
        all_ancestors = object_store._collect_ancestors(have_commits)[0]
        missing_commits, common_commits = \
            object_store._collect_ancestors(want_commits, all_ancestors)

        self.sha_done = set()
        jobs = [p.spawn(collect_tree_sha, c) for c in common_commits]
        gevent.joinall(jobs)
        for t in have_tags:
            self.sha_done.add(t)
        missing_tags = want_tags.difference(have_tags)
        wants = missing_commits.union(missing_tags)
        self.objects_to_send = set([(w, None, False) for w in wants])
        if progress is None:
            self.progress = lambda x: None
        else:
            self.progress = progress
        self._tagged = get_tagged and get_tagged() or {}


class GreenThreadsObjectStoreIterator(ObjectStoreIterator):
    """ObjectIterator that works on top of an ObjectStore.

    Same implementation as object_store.ObjectStoreIterator
    except we use gevent to parallelize object retrieval.
    """
    def __init__(self, store, shas, finder, concurrency=1):
        self.finder = finder
        self.p = pool.Pool(size=concurrency)
        super(GreenThreadsObjectStoreIterator, self).__init__(store, shas)

    def retrieve(self, args):
        sha, path = args
        return self.store[sha], path

    def __iter__(self):
        for sha, path in self.p.imap_unordered(self.retrieve,
                                               self.itershas()):
            yield sha, path

    def __len__(self):
        if len(self._shas) > 0:
            return len(self._shas)
        while len(self.finder.objects_to_send):
            jobs = []
            for _ in range(0, len(self.finder.objects_to_send)):
                jobs.append(self.p.spawn(self.finder.next))
            gevent.joinall(jobs)
            for j in jobs:
                if j.value is not None:
                    self._shas.append(j.value)
        return len(self._shas)
@

\subsection{[[hooks.py]]}

<<dulwich/hooks.py>>=
# hooks.py -- for dealing with git hooks
# Copyright (C) 2012-2013 Jelmer Vernooij and others.
#
<<dulwich license>>
"""Access to hooks."""

import os
import subprocess
import sys
import tempfile

from dulwich.errors import (
    HookError,
)

<<class Hook>>

<<class ShellHook>>


<<class PreCommitShellHook>>

<<class PostCommitShellHook>>

<<class CommitMsgShellHook>>
@

\subsection{[[ignore.py]]}


<<function ignore.read_ignore_patterns>>=
def read_ignore_patterns(f):
    """Read a git ignore file.

    :param f: File-like object to read from
    :return: List of patterns
    """

    for l in f:
        l = l.rstrip(b"\n")

        # Ignore blank lines, they're used for readability.
        if not l:
            continue

        if l.startswith(b'#'):
            # Comment
            continue

        # Trailing spaces are ignored unless they are quoted with a backslash.
        while l.endswith(b' ') and not l.endswith(b'\\ '):
            l = l[:-1]
        l = l.replace(b'\\ ', b' ')

        yield l
@
%dead?

%-------------------------------------------------------------------------
<<ignore.py>>=
# Copyright (C) 2017 Jelmer Vernooij <jelmer@jelmer.uk>
#
<<dulwich license>>
"""Parsing of gitignore files.

For details for the matching rules, see https://git-scm.com/docs/gitignore
"""

import re

<<function ignore.translate>>

<<function ignore.read_ignore_patterns>>

<<function ignore.match_pattern>>

<<class IgnoreFilter>>

<<class IgnoreFilterStack>>
@

\subsection{[[index.py]]}


<<[[Index]] methods>>=
@property
def path(self):
    return self._filename

@

<<[[Index]] methods>>=
def __len__(self):
    """Number of entries in this index file."""
    return len(self._byname)
@

<<[[Index]] methods>>=
def __iter__(self):
    """Iterate over the paths in this index."""
    return iter(self._byname)
@

<<[[Index]] methods>>=
def get_sha1(self, path):
    """Return the (git object) SHA1 for the object at a path."""
    return self[path].sha
@

<<[[Index]] methods>>=
def get_mode(self, path):
    """Return the POSIX file mode for the object at a path."""
    return self[path].mode

@




<<[[Index]] methods>>=
def iteritems(self):
    return self._byname.items()

@

<<[[Index]] methods>>=
def update(self, entries):
    for name, value in entries.items():
        self[name] = value

@

<<function read_index_dict>>=
def read_index_dict(f):
    """Read an index file and return it as a dictionary.

    :param f: File object to read from
    """
    ret = {}
    for x in read_index(f):
        ret[x[0]] = IndexEntry(*x[1:])
    return ret
@
%dead?

%deprecated:
%def commit_index(object_store, index):
%    """Create a new tree from an index.
%
%    :param object_store: Object store to save the tree in
%    :param index: Index file
%    :note: This function is deprecated, use index.commit() instead.
%    :return: Root tree sha.
%    """
%    return commit_tree(object_store, index.iterblobs())

% -----------------------------------------------------------------------
<<dulwich/index.py>>=
# index.py -- File parser/writer for the git index file
# Copyright (C) 2008-2013 Jelmer Vernooij <jelmer@samba.org>
#
<<dulwich license>>
"""Parser for the git index file format."""

import collections
import errno
import os
import stat
import struct
import sys

from dulwich.file import GitFile
from dulwich.objects import (
    Blob,
    S_IFGITLINK,
    S_ISGITLINK,
    Tree,
    hex_to_sha,
    sha_to_hex,
    )
from dulwich.pack import (
    SHA1Reader,
    SHA1Writer,
    )

<<type IndexEntry>>

<<function index.pathsplit>>

<<function index.pathjoin>>

<<function index.read_cache_time>>

<<function index.write_cache_time>>

<<function index.read_cache_entry>>

<<function index.write_cache_entry>>

<<function read_index>>

<<function read_index_dict>>

<<function write_index>>

<<function write_index_dict>>

<<function index.cleanup_mode>>

<<class Index>>

<<function index.commit_tree>>

<<function index.changes_from_tree>>

<<function index.index_entry_from_stat>>


<<function build_file_from_blob>>

<<constant index.INVALID_DOTNAMES>>


<<function index.validate_path_element_default>>

<<function index.validate_path>>


<<function build_index_from_tree>>

<<function index.blob_from_path_and_stat>>

<<function index.get_unstaged_changes>>

<<function index._tree_to_fs_path>>

<<function index._fs_to_tree_path>>
@

\subsection{[[log_utils.py]]}

% used only for server

<<log_utils.py>>=
# log_utils.py -- Logging utilities for Dulwich
# Copyright (C) 2010 Google, Inc.
#
<<dulwich license>>
"""Logging utilities for Dulwich.

Any module that uses logging needs to do compile-time initialization to set up
the logging environment. Since Dulwich is also used as a library, clients may
not want to see any logging output. In that case, we need to use a special
handler to suppress spurious warnings like "No handlers could be found for
logger dulwich.foo".

For details on the _NullHandler approach, see:
http://docs.python.org/library/logging.html#configuring-logging-for-a-library

For many modules, the only function from the logging module they need is
getLogger; this module exports that function for convenience. If a calling
module needs something else, it can import the standard logging module
directly.
"""

import logging
import sys

getLogger = logging.getLogger


class _NullHandler(logging.Handler):
    """No-op logging handler to avoid unexpected logging warnings."""

    def emit(self, record):
        pass


_NULL_HANDLER = _NullHandler()
_DULWICH_LOGGER = getLogger('dulwich')
_DULWICH_LOGGER.addHandler(_NULL_HANDLER)


def default_logging_config():
    """Set up the default Dulwich loggers."""
    remove_null_handler()
    logging.basicConfig(level=logging.INFO, stream=sys.stderr,
                        format='%(asctime)s %(levelname)s: %(message)s')


def remove_null_handler():
    """Remove the null handler from the Dulwich loggers.

    If a caller wants to set up logging using something other than
    default_logging_config, calling this function first is a minor optimization
    to avoid the overhead of using the _NullHandler.
    """
    _DULWICH_LOGGER.removeHandler(_NULL_HANDLER)
@

\subsection{[[lru_cache.py]]}

<<dulwich/lru_cache.py>>=
# lru_cache.py -- Simple LRU cache for dulwich
# Copyright (C) 2006, 2008 Canonical Ltd
#
<<dulwich license>>
"""A simple least-recently-used (LRU) cache."""

<<constant lru_cache._null_key>>

<<class _LRUNode>>

<<class LRUCache>>

<<class LRUSizeCache>>

@

\subsection{[[object_store.py]]}

<<[[BaseObjectStore]] methods>>=
def __contains__(self, sha):
    """Check if a particular object is present by SHA1.

    This method makes no distinction between loose and packed objects.
    """
    return self.contains_packed(sha) or self.contains_loose(sha)
@

<<[[BaseObjectStore]] methods>>=
def __iter__(self):
    """Iterate over the SHAs that are present in this store."""
    raise NotImplementedError(self.__iter__)

@



<<class ObjectImporter>>=
class ObjectImporter(object):
    """Interface for importing objects."""

    def __init__(self, count):
        """Create a new ObjectImporter.

        :param count: Number of objects that's going to be imported.
        """
        self.count = count

    def add_object(self, object):
        """Add an object."""
        raise NotImplementedError(self.add_object)

    def finish(self, object):
        """Finish the import and write objects to disk."""
        raise NotImplementedError(self.finish)
@
%dead?

<<function object_store.tree_lookup_path>>=
def tree_lookup_path(lookup_obj, root_sha, path):
    """Look up an object in a Git tree.

    :param lookup_obj: Callback for retrieving object by SHA1
    :param root_sha: SHA1 of the root tree
    :param path: Path to lookup
    :return: A tuple of (mode, SHA) of the resulting path.
    """
    tree = lookup_obj(root_sha)
    if not isinstance(tree, Tree):
        raise NotTreeError(root_sha)
    return tree.lookup_path(lookup_obj, path)
@
%dead?

% ----------------------------------------------------------------------------

<<object_store.py>>=
# object_store.py -- Object store for git objects
# Copyright (C) 2008-2013 Jelmer Vernooij <jelmer@samba.org>
#                         and others
#
<<dulwich license>>

"""Git object store interfaces and implementation."""


from io import BytesIO
import errno
from itertools import chain
import os
import stat
import sys
import tempfile

from dulwich.diff_tree import (
    tree_changes,
    walk_trees,
    )
from dulwich.errors import (
    NotTreeError,
    )
from dulwich.file import GitFile
from dulwich.objects import (
    Commit,
    ShaFile,
    Tag,
    Tree,
    ZERO_SHA,
    hex_to_sha,
    sha_to_hex,
    hex_to_filename,
    S_ISGITLINK,
    object_class,
    )
from dulwich.pack import (
    Pack,
    PackData,
    PackInflater,
    iter_sha1,
    write_pack_header,
    write_pack_index_v2,
    write_pack_object,
    write_pack_objects,
    compute_file_sha,
    PackIndexer,
    PackStreamCopier,
    )

INFODIR = 'info'
<<constant object_store.PACKDIR>>

<<class BaseObjectStore>>

<<class PackBasedObjectStore>>

<<class DiskObjectStore>>

<<class MemoryObjectStore>>

<<class ObjectImporter>>

<<class ObjectIterator>>

<<class ObjectStoreIterator>>

<<function object_store.tree_lookup_path>>

<<function object_store._collect_filetree_revs>>

<<function object_store._split_commits_and_tags>>

<<class MissingObjectFinder>>

<<class ObjectStoreGraphWalker>>
@

\subsection{[[objects.py]]}


<<[[ShaFile]] methods>>=
def __str__(self):
    """Return raw string serialization of this object."""
    return self.as_raw_string()

@

<<[[ShaFile]] methods>>=
def __hash__(self):
    """Return unique hash for this object."""
    return hash(self.id)

@

<<[[ShaFile]] methods>>=
def as_pretty_string(self):
    """Return a string representing this object, fit for display."""
    return self.as_raw_string()
@
%dead?



%deprecated:
%<<[[ShaFile]] methods>>=
%def get_type(self):
%    """Return the type number for this object class."""
%    return self.type_num
%
%@
%<<[[ShaFile]] methods>>=
%def set_type(self, type):
%    """Set the type number for this object class."""
%    self.type_num = type
%
%@
%
%<<[[ShaFile]] methods>>=
%# DEPRECATED: use type_num or type_name as needed.
%type = property(get_type, set_type)
%@


<<[[ShaFile]] methods>>=
def __ne__(self, other):
    return not isinstance(other, ShaFile) or self.id != other.id

@

<<[[ShaFile]] methods>>=
def __eq__(self, other):
    """Return True if the SHAs of the two objects match.

    It doesn't make sense to talk about an order on ShaFiles, so we don't
    override the rich comparison methods (__le__, etc.).
    """
    return isinstance(other, ShaFile) and self.id == other.id

@

<<[[ShaFile]] methods>>=
def __lt__(self, other):
    if not isinstance(other, ShaFile):
        raise TypeError
    return self.id < other.id
@
<<[[ShaFile]] methods>>=
def __le__(self, other):
    if not isinstance(other, ShaFile):
        raise TypeError
    return self.id <= other.id
@
<<[[ShaFile]] methods>>=
def __cmp__(self, other):
    if not isinstance(other, ShaFile):
        raise TypeError
    return cmp(self.id, other.id)
@






<<[[Tree]] methods>>=
def __contains__(self, name):
    return name in self._entries

@


<<[[Tree]] methods>>=
def __len__(self):
    return len(self._entries)

@

<<[[Tree]] methods>>=
def __iter__(self):
    return iter(self._entries)

@



<<[[Tree]] methods>>=
def items(self):
    """Return the sorted entries in this tree.

    :return: List with (name, mode, sha) tuples
    """
    return list(self.iteritems())

@




<<[[Tree]] methods>>=
def as_pretty_string(self):
    text = []
    for name, mode, hexsha in self.iteritems():
        text.append(pretty_format_tree_entry(name, mode, hexsha))
    return "".join(text)
@
%dead?


%-----------------------------------------------------------------------
<<dulwich/objects.py>>=
# objects.py -- Access to base git objects
# Copyright (C) 2007 James Westby <jw+debian@jameswestby.net>
# Copyright (C) 2008-2013 Jelmer Vernooij <jelmer@samba.org>
#
<<dulwich license>>
"""Access to base git objects."""

import binascii
from io import BytesIO
from collections import namedtuple
import os
import posixpath
import stat
import warnings
import zlib
from hashlib import sha1

from dulwich.errors import (
    ChecksumMismatch,
    NotBlobError,
    NotCommitError,
    NotTagError,
    NotTreeError,
    ObjectFormatException,
    )
from dulwich.file import GitFile

<<constant objects.ZERO_SHA>>

<<constants objects.commits_HEADER>>

<<constants objects.objects_HEADER>>


<<constant S_IFGITLINK>>

<<function objects.S_ISGITLINK>>

<<function objects._decompress>>

<<function sha_to_hex>>

<<function hex_to_sha>>

<<function valid_hexsha>>

<<function hex_to_filename>>

<<function objects.object_header>>

<<function serializable_property>>

<<function objects.object_class>>

<<function objects.check_hexsha>>

<<function objects.check_identity>>

<<function objects.git_line>>

<<class FixedSha>>

<<class ShaFile>>

<<class Blob>>

<<function objects._parse_message>>

<<class Tag>>

<<class TreeEntry>>

<<function object.parse_tree>>

<<function object.serialize_tree>>

<<function object.sorted_tree_items>>

<<function object.key_entry>>

<<function object.key_entry_name_order>>

<<function object.pretty_format_tree_entry>>

<<class Tree>>


<<function objects.parse_timezone>>

<<function objects.format_timezone>>

<<function objects.parse_commit>>

<<class Commit>>


<<constant OBJECT_CLASSES>>

<<global _TYPE_MAP>>

<<[[objects.py]] toplevel>>


# Hold on to the pure-python implementations for testing
_parse_tree_py = parse_tree
_sorted_tree_items_py = sorted_tree_items
try:
    # Try to import C versions
    from dulwich._objects import parse_tree, sorted_tree_items
except ImportError:
    pass
@

\subsection{[[objectspec.py]]}

<<function objectspec.parse_refs>>=
def parse_refs(container, refspecs):
    """Parse a list of refspecs to a list of refs.

    :param container: A RefsContainer object
    :param refspecs: A list of refspecs or a string
    :return: A list of refs
    :raise KeyError: If one of the refs can not be found
    """
    # TODO: Support * in refspecs
    if not isinstance(refspecs, list):
        refspecs = [refspecs]
    ret = []
    for refspec in refspecs:
        ret.append(parse_ref(container, refspec))
    return ret
@
%dead?

<<function objectspec.parse_commit_range>>=
def parse_commit_range(repo, committishs):
    """Parse a string referring to a range of commits.

    :param repo: A `Repo` object
    :param committishs: A string referring to a range of commits.
    :return: An iterator over `Commit` objects
    :raise KeyError: When the reference commits can not be found
    :raise ValueError: If the range can not be parsed
    """
    committishs = to_bytes(committishs)
    # TODO(jelmer): Support more than a single commit..
    return iter([parse_commit(repo, committishs)])
@
%dead?

<<function objectspec.parse_commit>>=
def parse_commit(repo, committish):
    """Parse a string referring to a single commit.

    :param repo: A` Repo` object
    :param commitish: A string referring to a single commit.
    :return: A Commit object
    :raise KeyError: When the reference commits can not be found
    :raise ValueError: If the range can not be parsed
    """
    committish = to_bytes(committish)
    return repo[committish] # For now..
@
%dead? diff with Commit.parse_commit?

%------------------------------------------------------------------------
<<objectspec.py>>=
# objectspec.py -- Object specification
# Copyright (C) 2014 Jelmer Vernooij <jelmer@samba.org>
#
<<dulwich license>>
"""Object specification."""


<<function objectspec.to_bytes>>

<<function objectspec.parse_object>>

<<function objectspec.parse_ref>>

<<function objectspec.parse_reftuple>>

<<function objectspec.parse_reftuples>>

<<function objectspec.parse_refs>>

<<function objectspec.parse_commit_range>>

<<function objectspec.parse_commit>>

# TODO: parse_path_in_tree(), which handles e.g. v1.0:Documentation
@

\subsection{[[pack.py]]}

<<dulwich/pack.py>>=
# pack.py -- For dealing with packed git objects.
# Copyright (C) 2007 James Westby <jw+debian@jameswestby.net>
# Copyright (C) 2008-2013 Jelmer Vernooij <jelmer@samba.org>
#
<<dulwich license>>
"""Classes for dealing with packed git objects.

A pack is a compact representation of a bunch of objects, stored
using deltas where possible.

They have two parts, the pack file, which stores the data, and an index
that tells you where the data is.

To find an object you look in all of the index files 'til you find a
match for the object name. You then use the pointer got from this as
a pointer in to the corresponding packfile.
"""

from collections import defaultdict

import binascii
from io import BytesIO, UnsupportedOperation
from collections import (
    deque,
    )
import difflib
import struct

from itertools import chain
try:
    from itertools import imap, izip
except ImportError:
    # Python3
    imap = map
    izip = zip

import os
import sys

try:
    import mmap
except ImportError:
    has_mmap = False
else:
    has_mmap = True

# For some reason the above try, except fails to set has_mmap = False for plan9
if sys.platform == 'Plan9':
    has_mmap = False

from hashlib import sha1
from os import (
    SEEK_CUR,
    SEEK_END,
    )
from struct import unpack_from
import zlib

from dulwich.errors import (
    ApplyDeltaError,
    ChecksumMismatch,
    )
from dulwich.file import GitFile
from dulwich.lru_cache import (
    LRUSizeCache,
    )
from dulwich.objects import (
    ShaFile,
    hex_to_sha,
    sha_to_hex,
    object_header,
    )

<<constant pack.OFS_DELTA>>
<<constant pack.REF_DELTA>>

<<constant pack.DELTA_TYPES>>

<<constant pack.DEFAULT_PACK_DELTA_WINDOW_SIZE>>


<<function pack.take_msb_bytes>>

<<class UnpackedObject>>

<<constant pack._ZLIB_BUFSIZE>>

<<function pack.read_zlib_chunks>>

<<function pack.iter_sha1>>

<<function pack.load_pack_index>>

<<function pack._load_file_contents>>

<<function pack.load_pack_index_file>>

<<function pack.bisect_find_sha>>


<<class PackIndex>>

<<class MemoryPackIndex>>

<<class FilePackIndex>>

<<class PackIndex1>>

<<class PackIndex2>>

<<function read_pack_header>>

<<function pack.chunks_length>>

<<function unpack_object>>

<<function pack._compute_object_size>>


<<class PackStreamReader>>

<<class PackStreamCopier>>


<<function pack.obj_sha>>

<<function pack.compute_file_sha>>

<<class PackData>>

<<class DeltaChainIterator>>

<<class PackIndexer>>

<<class PackInflater>>

<<class SHA1Reader>>

<<class SHA1Writer>>


<<function pack_object_header>>

<<function pack.write_pack_object>>

<<function pack.write_pack>>

<<function pack.write_pack_header>>

<<function pack.deltify_pack_objects>>

<<function pack.write_pack_objects>>

<<function pack.write_pack_data>>


<<function write_pack_index_v1>>

<<function pack._delta_encode_size>>

<<constant pack._MAX_COPY_LEN>>


<<function pack._encode_copy_operation>>

<<function pack.create_delta>>

<<function pack.apply_delta>>

<<function write_pack_index_v2>>

<<function write_pack_index>>

<<class Pack>>


try:
    from dulwich._pack import apply_delta, bisect_find_sha
except ImportError:
    pass
@

\subsection{[[patch.py]]}

<<function patch.write_blob_diff>>=
# TODO(jelmer): Support writing unicode, rather than bytes.
def write_blob_diff(f, old_file, new_file):
    """Write blob diff.

    :param f: File-like object to write to
    :param old_file: (path, mode, hexsha) tuple (None if nonexisting)
    :param new_file: (path, mode, hexsha) tuple (None if nonexisting)

    :note: The use of write_object_diff is recommended over this function.
    """
    (old_path, old_mode, old_blob) = old_file
    (new_path, new_mode, new_blob) = new_file
    old_path = patch_filename(old_path, b"a")
    new_path = patch_filename(new_path, b"b")
    def lines(blob):
        if blob is not None:
            return blob.splitlines()
        else:
            return []
    f.writelines(gen_diff_header(
        (old_path, new_path), (old_mode, new_mode),
        (getattr(old_blob, "id", None), getattr(new_blob, "id", None))))
    old_contents = lines(old_blob)
    new_contents = lines(new_blob)
    f.writelines(unified_diff(old_contents, new_contents,
        old_path, new_path))
@
%dead?

<<[[Blob]] methods>>=
def splitlines(self):
    """Return list of lines in this blob.

    This preserves the original line endings.
    """
    chunks = self.chunked
    if not chunks:
        return []
    if len(chunks) == 1:
        return chunks[0].splitlines(True)
    remaining = None
    ret = []
    for chunk in chunks:
        lines = chunk.splitlines(True)
        if len(lines) > 1:
            ret.append((remaining or b"") + lines[0])
            ret.extend(lines[1:-1])
            remaining = lines[-1]
        elif len(lines) == 1:
            if remaining is None:
                remaining = lines.pop()
            else:
                remaining += lines.pop()
    if remaining is not None:
        ret.append(remaining)
    return ret
@
%dead?


<<function patch.git_am_patch_split>>=
def git_am_patch_split(f, encoding=None):
    """Parse a git-am-style patch and split it up into bits.

    :param f: File-like object to parse
    :param encoding: Encoding to use when creating Git objects
    :return: Tuple with commit object, diff contents and git version
    """
    encoding = encoding or getattr(f, "encoding", "ascii")
    contents = f.read()
    if isinstance(contents, bytes) and getattr(email.parser, "BytesParser", None):
        parser = email.parser.BytesParser()
        msg = parser.parsebytes(contents)
    else:
        parser = email.parser.Parser()
        msg = parser.parsestr(contents)
    return parse_patch_message(msg, encoding)
@
%dead?

<<function patch.write_commit_patch>>=
def write_commit_patch(f, commit, contents, progress, version=None, encoding=None):
    """Write a individual file patch.

    :param commit: Commit object
    :param progress: Tuple with current patch number and total.
    :return: tuple with filename and contents
    """
    encoding = encoding or getattr(f, "encoding", "ascii")
    if isinstance(contents, str):
        contents = contents.encode(encoding)
    (num, total) = progress
    f.write(b"From " + commit.id + b" " + time.ctime(commit.commit_time).encode(encoding) + b"\n")
    f.write(b"From: " + commit.author + b"\n")
    f.write(b"Date: " + time.strftime("%a, %d %b %Y %H:%M:%S %Z").encode(encoding) + b"\n")
    f.write(("Subject: [PATCH %d/%d] " % (num, total)).encode(encoding) + commit.message + b"\n")
    f.write(b"\n")
    f.write(b"---\n")
    try:
        import subprocess
        p = subprocess.Popen(["diffstat"], stdout=subprocess.PIPE,
                             stdin=subprocess.PIPE)
    except (ImportError, OSError):
        pass # diffstat not available?
    else:
        (diffstat, _) = p.communicate(contents)
        f.write(diffstat)
        f.write(b"\n")
    f.write(contents)
    f.write(b"-- \n")
    if version is None:
        from dulwich import __version__ as dulwich_version
        f.write(b"Dulwich %d.%d.%d\n" % dulwich_version)
    else:
        f.write(version.encode(encoding) + b"\n")
@
%dead?

<<function patch.get_summary>>=
def get_summary(commit):
    """Determine the summary line for use in a filename.

    :param commit: Commit
    :return: Summary string
    """
    return commit.message.splitlines()[0].replace(" ", "-")
@
%dead?

<<function patch.parse_patch_message>>=
def parse_patch_message(msg, encoding=None):
    """Extract a Commit object and patch from an e-mail message.

    :param msg: An email message (email.message.Message)
    :param encoding: Encoding to use to encode Git commits
    :return: Tuple with commit object, diff contents and git version
    """
    c = Commit()
    c.author = msg["from"].encode(encoding)
    c.committer = msg["from"].encode(encoding)
    try:
        patch_tag_start = msg["subject"].index("[PATCH")
    except ValueError:
        subject = msg["subject"]
    else:
        close = msg["subject"].index("] ", patch_tag_start)
        subject = msg["subject"][close+2:]
    c.message = (subject.replace("\n", "") + "\n").encode(encoding)
    first = True

    body = msg.get_payload(decode=True)
    lines = body.splitlines(True)
    line_iter = iter(lines)

    for l in line_iter:
        if l == b"---\n":
            break
        if first:
            if l.startswith(b"From: "):
                c.author = l[len(b"From: "):].rstrip()
            else:
                c.message += b"\n" + l
            first = False
        else:
            c.message += l
    diff = b""
    for l in line_iter:
        if l == b"-- \n":
            break
        diff += l
    try:
        version = next(line_iter).rstrip(b"\n")
    except StopIteration:
        version = None
    return c, diff, version
@
%dead?

%---------------------------------------------------------------------------
<<patch.py>>=
# patch.py -- For dealing with packed-style patches.
# Copyright (C) 2009-2013 Jelmer Vernooij <jelmer@samba.org>
#
<<dulwich license>>
"""Classes for dealing with git am-style patches.

These patches are basically unified diffs with some extra metadata tacked
on.
"""

from difflib import SequenceMatcher
import email.parser
import time

from dulwich.objects import (
    Blob,
    Commit,
    S_ISGITLINK,
    )

FIRST_FEW_BYTES = 8000

<<function patch.write_commit_patch>>

<<function patch.get_summary>>


<<function patch.unified_diff>>

<<function patch.is_binary>>

<<function patch.shortid>>

<<function patch.patch_filename>>

<<function patch.write_object_diff>>

<<function patch.gen_diff_header>>

<<function patch.write_blob_diff>>

<<function patch.write_tree_diff>>

<<function patch.git_am_patch_split>>

<<function patch.parse_patch_message>>
@

\subsection{[[porcelain.py]]}

%deprecated:
%def list_tags(*args, **kwargs):
%    import warnings
%    warnings.warn("list_tags has been deprecated in favour of tag_list.",
%                  DeprecationWarning)
%    return tag_list(*args, **kwargs)


<<function open_repo>>=
def open_repo(path_or_repo):
    """Open an argument that can be a repository or a path for a repository."""
    if isinstance(path_or_repo, BaseRepo):
        return path_or_repo
    return Repo(path_or_repo)
@
%dead?

%-------------------------------------------------------------------------
<<dulwich/porcelain.py>>=
# porcelain.py -- Porcelain-like layer on top of Dulwich
# Copyright (C) 2013 Jelmer Vernooij <jelmer@samba.org>
#
<<dulwich license>>
"""Simple wrapper that provides porcelain-like functions on top of Dulwich.

Currently implemented:
 * archive
 * add
 * branch{_create,_delete,_list}
 * clone
 * commit
 * commit-tree
 * daemon
 * diff-tree
 * fetch
 * init
 * ls-remote
 * ls-tree
 * pull
 * push
 * rm
 * remote{_add}
 * receive-pack
 * reset
 * rev-list
 * tag{_create,_delete,_list}
 * upload-pack
 * update-server-info
 * status
 * symbolic-ref

These functions are meant to behave similarly to the git subcommands.
Differences in behaviour are considered bugs.
"""

from collections import namedtuple
from contextlib import (
    closing,
    contextmanager,
)
import os
import posixpath
import stat
import sys
import time

from dulwich.archive import (
    tar_stream,
    )
from dulwich.client import (
    get_transport_and_path,
    )
from dulwich.diff_tree import (
    CHANGE_ADD,
    CHANGE_DELETE,
    CHANGE_MODIFY,
    CHANGE_RENAME,
    CHANGE_COPY,
    RENAME_CHANGE_TYPES,
    )
from dulwich.errors import (
    SendPackError,
    UpdateRefsError,
    )
from dulwich.index import get_unstaged_changes
from dulwich.objects import (
    Commit,
    Tag,
    format_timezone,
    parse_timezone,
    pretty_format_tree_entry,
    )
from dulwich.objectspec import (
    parse_object,
    parse_reftuples,
    )
from dulwich.pack import (
    write_pack_index,
    write_pack_objects,
    )
from dulwich.patch import write_tree_diff
from dulwich.protocol import (
    Protocol,
    ZERO_SHA,
    )
from dulwich.refs import ANNOTATED_TAG_SUFFIX
from dulwich.repo import (BaseRepo, Repo)
from dulwich.server import (
    FileSystemBackend,
    TCPGitServer,
    ReceivePackHandler,
    UploadPackHandler,
    update_server_info as server_update_server_info,
    )


<<type GitStatus>>

<<constant default_bytes_out_stream>>
<<constant default_bytes_err_stream>>

<<constant porcelain.DEFAULT_ENCODING>>

<<exception RemoteExists>>

<<function open_repo>>

<<function _noop_context_manager>>

<<function porcelain.open_repo_closing>>



<<function porcelain.archive>>

<<function porcelain.update_server_info>>

<<function porcelain.symbolic_ref>>

<<function porcelain.commit>>

<<function porcelain.commit_tree>>

<<function porcelain.init>>

<<function porcelain.clone>>

<<function porcelain.add>>

<<function porcelain.rm>>

<<function porcelain.commit_decode>>

<<function porcelain.print_commit>>

<<function porcelain.print_tag>>

<<function porcelain.show_blob>>

<<function porcelain.show_commit>>

<<function porcelain.show_tree>>

<<function porcelain.show_tag>>

<<function porcelain.show_object>>

<<function porcelain.print_name_status>>

<<function porcelain.log>>

<<function porcelain.show>>

<<function porcelain.diff_tree>>

<<function porcelain.rev_list>>

<<function porcelain.tag_create>>

<<function porcelain.tag_list>>

<<function porcelain.tag_delete>>

<<function porcelain.reset>>

<<function porcelain.push>>

<<function porcelain.pull>>

<<function porcelain.status>>

<<function porcelain.get_untracked_paths>>


<<function porcelain.get_tree_changes>>

<<function porcelain.daemon>>

<<function porcelain.web_daemon>>

<<function porcelain.upload_pack>>

<<function porcelain.receive_pack>>

<<function porcelain.branch_delete>>

<<function porcelain.branch_create>>

<<function porcelain.branch_list>>

<<function porcelain.fetch>>

<<function porcelain.ls_remote>>

<<function porcelain.repack>>

<<function porcelain.pack_objects>>

<<function porcelain.ls_tree>>

<<function porcelain.remote_add>>

@

\subsection{[[protocol.py]]}

<<protocol.py>>=
# protocol.py -- Shared parts of the git protocols
# Copyright (C) 2008 John Carr <john.carr@unrouted.co.uk>
# Copyright (C) 2008-2012 Jelmer Vernooij <jelmer@samba.org>
#
<<dulwich license>>
"""Generic functions for talking the git smart server protocol."""

from io import BytesIO
from os import (
    SEEK_END,
    )
import socket

import dulwich
from dulwich.errors import (
    HangupException,
    GitProtocolError,
    )

<<constant protocol.TCP_GIT_PORT>>

ZERO_SHA = b"0" * 40

SINGLE_ACK = 0
MULTI_ACK = 1
MULTI_ACK_DETAILED = 2

# pack data
SIDE_BAND_CHANNEL_DATA = 1
# progress messages
SIDE_BAND_CHANNEL_PROGRESS = 2
# fatal error message just before stream aborts
SIDE_BAND_CHANNEL_FATAL = 3

CAPABILITY_DELETE_REFS = b'delete-refs'
CAPABILITY_INCLUDE_TAG = b'include-tag'
CAPABILITY_MULTI_ACK = b'multi_ack'
CAPABILITY_MULTI_ACK_DETAILED = b'multi_ack_detailed'
CAPABILITY_NO_DONE = b'no-done'
CAPABILITY_NO_PROGRESS = b'no-progress'
CAPABILITY_OFS_DELTA = b'ofs-delta'
CAPABILITY_QUIET = b'quiet'
CAPABILITY_REPORT_STATUS = b'report-status'
CAPABILITY_SHALLOW = b'shallow'
CAPABILITY_SIDE_BAND_64K = b'side-band-64k'
CAPABILITY_THIN_PACK = b'thin-pack'
<<constant protocol.CAPABILITY_AGENT>>

# Magic ref that is used to attach capabilities to when
# there are no refs. Should always be ste to ZERO_SHA.
CAPABILITIES_REF = b'capabilities^{}'


<<function protocol.agent_string>>

<<function protocol.capability_agent>>

COMMAND_DEEPEN = b'deepen'
COMMAND_SHALLOW = b'shallow'
COMMAND_UNSHALLOW = b'unshallow'
COMMAND_DONE = b'done'
COMMAND_WANT = b'want'
COMMAND_HAVE = b'have'

<<class ProtocolFile>>

<<function pkt_line>>

<<class Protocol>>


_RBUFSIZE = 8192  # Default read buffer size.


class ReceivableProtocol(Protocol):
    """Variant of Protocol that allows reading up to a size without blocking.

    This class has a recv() method that behaves like socket.recv() in addition
    to a read() method.

    If you want to read n bytes from the wire and block until exactly n bytes
    (or EOF) are read, use read(n). If you want to read at most n bytes from the
    wire but don't care if you get less, use recv(n). Note that recv(n) will
    still block until at least one byte is read.
    """

    def __init__(self, recv, write, report_activity=None, rbufsize=_RBUFSIZE):
        super(ReceivableProtocol, self).__init__(self.read, write,
                                                 report_activity)
        self._recv = recv
        self._rbuf = BytesIO()
        self._rbufsize = rbufsize

    def read(self, size):
        # From _fileobj.read in socket.py in the Python 2.6.5 standard library,
        # with the following modifications:
        #  - omit the size <= 0 branch
        #  - seek back to start rather than 0 in case some buffer has been
        #    consumed.
        #  - use SEEK_END instead of the magic number.
        # Copyright (c) 2001-2010 Python Software Foundation; All Rights Reserved
        # Licensed under the Python Software Foundation License.
        # TODO: see if buffer is more efficient than cBytesIO.
        assert size > 0

        # Our use of BytesIO rather than lists of string objects returned by
        # recv() minimizes memory usage and fragmentation that occurs when
        # rbufsize is large compared to the typical return value of recv().
        buf = self._rbuf
        start = buf.tell()
        buf.seek(0, SEEK_END)
        # buffer may have been partially consumed by recv()
        buf_len = buf.tell() - start
        if buf_len >= size:
            # Already have size bytes in our buffer?  Extract and return.
            buf.seek(start)
            rv = buf.read(size)
            self._rbuf = BytesIO()
            self._rbuf.write(buf.read())
            self._rbuf.seek(0)
            return rv

        self._rbuf = BytesIO()  # reset _rbuf.  we consume it via buf.
        while True:
            left = size - buf_len
            # recv() will malloc the amount of memory given as its
            # parameter even though it often returns much less data
            # than that.  The returned data string is short lived
            # as we copy it into a BytesIO and free it.  This avoids
            # fragmentation issues on many platforms.
            data = self._recv(left)
            if not data:
                break
            n = len(data)
            if n == size and not buf_len:
                # Shortcut.  Avoid buffer data copies when:
                # - We have no data in our buffer.
                # AND
                # - Our call to recv returned exactly the
                #   number of bytes we were asked to read.
                return data
            if n == left:
                buf.write(data)
                del data  # explicit free
                break
            assert n <= left, "_recv(%d) returned %d bytes" % (left, n)
            buf.write(data)
            buf_len += n
            del data  # explicit free
            #assert buf_len == buf.tell()
        buf.seek(start)
        return buf.read()

    def recv(self, size):
        assert size > 0

        buf = self._rbuf
        start = buf.tell()
        buf.seek(0, SEEK_END)
        buf_len = buf.tell()
        buf.seek(start)

        left = buf_len - start
        if not left:
            # only read from the wire if our read buffer is exhausted
            data = self._recv(self._rbufsize)
            if len(data) == size:
                # shortcut: skip the buffer if we read exactly size bytes
                return data
            buf = BytesIO()
            buf.write(data)
            buf.seek(0)
            del data  # explicit free
            self._rbuf = buf
        return buf.read(size)


def extract_capabilities(text):
    """Extract a capabilities list from a string, if present.

    :param text: String to extract from
    :return: Tuple with text with capabilities removed and list of capabilities
    """
    if not b"\0" in text:
        return text, []
    text, capabilities = text.rstrip().split(b"\0")
    return (text, capabilities.strip().split(b" "))


def extract_want_line_capabilities(text):
    """Extract a capabilities list from a want line, if present.

    Note that want lines have capabilities separated from the rest of the line
    by a space instead of a null byte. Thus want lines have the form:

        want obj-id cap1 cap2 ...

    :param text: Want line to extract from
    :return: Tuple with text with capabilities removed and list of capabilities
    """
    split_text = text.rstrip().split(b" ")
    if len(split_text) < 3:
        return text, []
    return (b" ".join(split_text[:2]), split_text[2:])


def ack_type(capabilities):
    """Extract the ack type from a capabilities list."""
    if b'multi_ack_detailed' in capabilities:
        return MULTI_ACK_DETAILED
    elif b'multi_ack' in capabilities:
        return MULTI_ACK
    return SINGLE_ACK


class BufferedPktLineWriter(object):
    """Writer that wraps its data in pkt-lines and has an independent buffer.

    Consecutive calls to write() wrap the data in a pkt-line and then buffers it
    until enough lines have been written such that their total length (including
    length prefix) reach the buffer size.
    """

    def __init__(self, write, bufsize=65515):
        """Initialize the BufferedPktLineWriter.

        :param write: A write callback for the underlying writer.
        :param bufsize: The internal buffer size, including length prefixes.
        """
        self._write = write
        self._bufsize = bufsize
        self._wbuf = BytesIO()
        self._buflen = 0

    def write(self, data):
        """Write data, wrapping it in a pkt-line."""
        line = pkt_line(data)
        line_len = len(line)
        over = self._buflen + line_len - self._bufsize
        if over >= 0:
            start = line_len - over
            self._wbuf.write(line[:start])
            self.flush()
        else:
            start = 0
        saved = line[start:]
        self._wbuf.write(saved)
        self._buflen += len(saved)

    def flush(self):
        """Flush all data from the buffer."""
        data = self._wbuf.getvalue()
        if data:
            self._write(data)
        self._len = 0
        self._wbuf = BytesIO()


class PktLineParser(object):
    """Packet line parser that hands completed packets off to a callback.
    """

    def __init__(self, handle_pkt):
        self.handle_pkt = handle_pkt
        self._readahead = BytesIO()

    def parse(self, data):
        """Parse a fragment of data and call back for any completed packets.
        """
        self._readahead.write(data)
        buf = self._readahead.getvalue()
        if len(buf) < 4:
            return
        while len(buf) >= 4:
            size = int(buf[:4], 16)
            if size == 0:
                self.handle_pkt(None)
                buf = buf[4:]
            elif size <= len(buf):
                self.handle_pkt(buf[4:size])
                buf = buf[size:]
            else:
                break
        self._readahead = BytesIO()
        self._readahead.write(buf)

    def get_tail(self):
        """Read back any unused data."""
        return self._readahead.getvalue()
@

\subsection{[[reflog.py]]}

<<dulwich/reflog.py>>=
# reflog.py -- Parsing and writing reflog files
# Copyright (C) 2015 Jelmer Vernooij and others.
#
<<dulwich license>>
"""Utilities for reading and generating reflogs.
"""

import collections

from dulwich.objects import (
    format_timezone,
    parse_timezone,
    ZERO_SHA,
    )

<<type reflog.Entry>>

<<function format_reflog_line>>

<<function parse_reflog_line>>

<<function read_reflog>>
@

\subsection{[[refs.py]]}

%deprecated:
%<<[[RefsContainer]] methods>>=
%def _follow(self, name):
%    import warnings
%    warnings.warn(
%        "RefsContainer._follow is deprecated. Use RefsContainer.follow instead.",
%        DeprecationWarning)
%    refnames, contents = self.follow(name)
%    if not refnames:
%        return (None, contents)
%    return (refnames[-1], contents)
%@

<<[[RefsContainer]] methods>>=
def __contains__(self, refname):
    if self.read_ref(refname):
        return True
    return False

@


<<class InfoRefsContainer>>=
class InfoRefsContainer(RefsContainer):
    """Refs container that reads refs from a info/refs file."""

    def __init__(self, f):
        self._refs = {}
        self._peeled = {}
        for l in f.readlines():
            sha, name = l.rstrip(b'\n').split(b'\t')
            if name.endswith(ANNOTATED_TAG_SUFFIX):
                name = name[:-3]
                if not check_ref_format(name):
                    raise ValueError("invalid ref name %r" % name)
                self._peeled[name] = sha
            else:
                if not check_ref_format(name):
                    raise ValueError("invalid ref name %r" % name)
                self._refs[name] = sha

    def allkeys(self):
        return self._refs.keys()

    def read_loose_ref(self, name):
        return self._refs.get(name, None)

    def get_packed_refs(self):
        return {}

    def get_peeled(self, name):
        try:
            return self._peeled[name]
        except KeyError:
            return self._refs[name]
@
%dead?

<<constant refs.LOCAL_BRANCH_PREFIX>>=
LOCAL_BRANCH_PREFIX = b'refs/heads/'
@
%dead?

<<function is_local_branch>>=
is_local_branch = lambda x: x.startswith(b'refs/heads/')
@
%dead?

%--------------------------------------------------------------------------
<<refs.py>>=
# refs.py -- For dealing with git refs
# Copyright (C) 2008-2013 Jelmer Vernooij <jelmer@samba.org>
#
<<dulwich license>>

"""Ref handling.

"""
import errno
import os
import sys

from dulwich.errors import (
    PackedRefsException,
    RefFormatError,
    )
from dulwich.objects import (
    git_line,
    valid_hexsha,
    ZERO_SHA,
    )
from dulwich.file import (
    GitFile,
    ensure_dir_exists,
    )

<<constant refs.SYMREF>>
<<constant refs.LOCAL_BRANCH_PREFIX>>
<<constant refs.BAD_REF_CHARS>>
<<constant refs.ANNOTATED_TAG_SUFFIX>>

<<function refs.check_ref_format>>

<<class RefsContainer>>

<<class DictRefsContainer>>

<<class InfoRefsContainer>>

<<class DiskRefsContainer>>

<<function refs._split_ref_line>>

<<function refs.read_packed_refs>>

<<function refs.read_packed_refs_with_peeled>>

<<function refs.write_packed_refs>>

<<function refs.read_info_refs>>

<<function refs.write_info_refs>>

<<function is_local_branch>>
@

\subsection{[[repo.py]]}


<<[[Repo]] methods>>=
@classmethod
def discover(cls, start='.'):
    """Iterate parent directories to discover a repository

    Return a Repo object for the first parent directory that looks like a
    Git repository.

    :param start: The directory to start discovery from (defaults to '.')
    """
    remaining = True
    path = os.path.abspath(start)
    while remaining:
        try:
            return cls(path)
        except NotGitRepository:
            path, remaining = os.path.split(path)
    raise NotGitRepository(
        "No git repository was found at %(path)s" % dict(path=start)
    )
@
%dead?

<<[[Repo]] methods>>=
def controldir(self):
    """Return the path of the control directory."""
    return self._controldir
@



<<[[Repo]] methods>>=
def clone(self, target_path, mkdir=True, bare=False,
          origin=b"origin"):
    """Clone this repository.

    :param target_path: Target path
    :param mkdir: Create the target directory
    :param bare: Whether to create a bare repository
    :param origin: Base name for refs in target repository
        cloned from this repository
    :return: Created repository as `Repo`
    """
    if not bare:
        target = self.init(target_path, mkdir=mkdir)
    else:
        target = self.init_bare(target_path, mkdir=mkdir)
    self.fetch(target)
    target.refs.import_refs(
        b'refs/remotes/' + origin, self.refs.as_dict(b'refs/heads'))
    target.refs.import_refs(
        b'refs/tags', self.refs.as_dict(b'refs/tags'))
    try:
        target.refs.add_if_new(DEFAULT_REF, self.refs[DEFAULT_REF])
    except KeyError:
        pass
    target_config = target.get_config()
    encoded_path = self.path
    if not isinstance(encoded_path, bytes):
        encoded_path = encoded_path.encode(sys.getfilesystemencoding())
    target_config.set((b'remote', b'origin'), b'url', encoded_path)
    target_config.set((b'remote', b'origin'), b'fetch',
                      b'+refs/heads/*:refs/remotes/origin/*')
    target_config.write_to_path()

    # Update target head
    head_chain, head_sha = self.refs.follow(b'HEAD')
    if head_chain and head_sha is not None:
        target.refs.set_symbolic_ref(b'HEAD', head_chain[-1])
        target[b'HEAD'] = head_sha

        if not bare:
            # Checkout HEAD to target dir
            target.reset_index()

    return target
@
% dead? vs porcelain.clone?



<<[[Repo]] methods>>=
def get_description(self):
    """Retrieve the description of this repository.

    :return: A string describing the repository or None.
    """
    path = os.path.join(self._controldir, 'description')
    try:
        with GitFile(path, 'rb') as f:
            return f.read()
    except (IOError, OSError) as e:
        if e.errno != errno.ENOENT:
            raise
        return None
@


<<[[Repo]] methods>>=
def set_description(self, description):
    """Set the description for this repository.

    :param description: Text to set as description for this repository.
    """

    self._put_named_file('description', description)
@


<<constant repo.GITDIR>>=
GITDIR = 'gitdir'
@
<<constant repo.WORKTREES>>=
WORKTREES = 'worktrees'
@

<<[[Repo]] methods>>=
@classmethod
def _init_new_working_directory(cls, path, main_repo, identifier=None,
                                mkdir=False):
    """Create a new working directory linked to a repository.

    :param path: Path in which to create the working tree.
    :param main_repo: Main repository to reference
    :param identifier: Worktree identifier
    :param mkdir: Whether to create the directory
    :return: `Repo` instance
    """
    if mkdir:
        os.mkdir(path)
    if identifier is None:
        identifier = os.path.basename(path)
    main_worktreesdir = os.path.join(main_repo.controldir(), WORKTREES)
    worktree_controldir = os.path.join(main_worktreesdir, identifier)
    gitdirfile = os.path.join(path, CONTROLDIR)
    with open(gitdirfile, 'wb') as f:
        f.write(b'gitdir: ' +
                worktree_controldir.encode(sys.getfilesystemencoding()) +
                b'\n')
    try:
        os.mkdir(main_worktreesdir)
    except OSError as e:
        if e.errno != errno.EEXIST:
            raise
    try:
        os.mkdir(worktree_controldir)
    except OSError as e:
        if e.errno != errno.EEXIST:
            raise
    with open(os.path.join(worktree_controldir, GITDIR), 'wb') as f:
        f.write(gitdirfile.encode(sys.getfilesystemencoding()) + b'\n')
    with open(os.path.join(worktree_controldir, COMMONDIR), 'wb') as f:
        f.write(b'../..\n')
    with open(os.path.join(worktree_controldir, 'HEAD'), 'wb') as f:
        f.write(main_repo.head() + b'\n')
    r = cls(path)
    r.reset_index()
    return r
@
%dead?


<<[[Repo]] methods>>=
def __enter__(self):
    return self
@
<<[[Repo]] methods>>=
def __exit__(self, exc_type, exc_val, exc_tb):
    self.close()
@


<<[[BaseRepo]] methods>>=
def head(self):
    """Return the SHA1 pointed at by HEAD."""
    return self.refs[b'HEAD']

@
%dead?

<<[[BaseRepo]] methods>>=
def _get_object(self, sha, cls):
    assert len(sha) in (20, 40)
    ret = self.get_object(sha)
    if not isinstance(ret, cls):
        if cls is Commit:
            raise NotCommitError(ret)
        elif cls is Blob:
            raise NotBlobError(ret)
        elif cls is Tree:
            raise NotTreeError(ret)
        elif cls is Tag:
            raise NotTagError(ret)
        else:
            raise Exception("Type invalid: %r != %r" % (
              ret.type_name, cls.type_name))
    return ret
@
%dead?

<<[[BaseRepo]] methods>>=
def get_object(self, sha):
    """Retrieve the object with the specified SHA.

    :param sha: SHA to retrieve
    :return: A ShaFile object
    :raise KeyError: when the object can not be found
    """
    return self.object_store[sha]
@
%dead?



<<[[BaseRepo]] methods>>=
def get_description(self):
    """Retrieve the description for this repository.

    :return: String with the description of the repository
        as set by the user.
    """
    raise NotImplementedError(self.get_description)

@

<<[[BaseRepo]] methods>>=
def set_description(self, description):
    """Set the description for this repository.

    :param description: Text to set as description for this repository.
    """
    raise NotImplementedError(self.set_description)

@

<<[[BaseRepo]] methods>>=
def get_config_stack(self):
    """Return a config stack for this repository.

    This stack accesses the configuration for both this repository
    itself (.git/config) and the global configuration, which usually
    lives in ~/.gitconfig.

    :return: `Config` instance for this repository
    """
    from dulwich.config import StackedConfig
    backends = [self.get_config()] + StackedConfig.default_backends()
    return StackedConfig(backends, writable=backends[0])

@


<<[[BaseRepo]] methods>>=
def __contains__(self, name):
    """Check if a specific Git object or ref is present.

    :param name: Git object SHA1 or ref name
    """
    if len(name) in (20, 40):
        return name in self.object_store or name in self.refs
    else:
        return name in self.refs

@

%---------------------------------------------------------------------------

<<dulwich/repo.py>>=
# repo.py -- For dealing with git repositories.
# Copyright (C) 2007 James Westby <jw+debian@jameswestby.net>
# Copyright (C) 2008-2013 Jelmer Vernooij <jelmer@samba.org>
#
<<dulwich license>>

"""Repository access.

This module contains the base class for git repositories
(BaseRepo) and an implementation which uses a repository on
local disk (Repo).

"""

from io import BytesIO
import errno
import os
import sys
import stat

from dulwich.errors import (
    NoIndexPresent,
    NotBlobError,
    NotCommitError,
    NotGitRepository,
    NotTreeError,
    NotTagError,
    CommitError,
    RefFormatError,
    HookError,
    )
from dulwich.file import (
    GitFile,
    )
from dulwich.object_store import (
    DiskObjectStore,
    MemoryObjectStore,
    ObjectStoreGraphWalker,
    )
from dulwich.objects import (
    check_hexsha,
    Blob,
    Commit,
    ShaFile,
    Tag,
    Tree,
    )

from dulwich.hooks import (
    PreCommitShellHook,
    PostCommitShellHook,
    CommitMsgShellHook,
    )

from dulwich.refs import (
    check_ref_format,
    RefsContainer,
    DictRefsContainer,
    InfoRefsContainer,
    DiskRefsContainer,
    read_packed_refs,
    read_packed_refs_with_peeled,
    write_packed_refs,
    SYMREF,
    )


import warnings

<<constant repo.CONTROLDIR>>

<<constant repo.OBJECTDIR>>

<<constant repo.REFSDIR>>
<<constant repo.REFSDIR_TAGS>>
<<constant repo.REFSDIR_HEADS>>

<<constant repo.INDEX_FILENAME>>

<<constant repo.COMMONDIR>>
<<constant repo.GITDIR>>
<<constant repo.WORKTREES>>

<<constant repo.BASE_DIRECTORIES>>

<<constant repo.DEFAULT_REF>>

<<function parse_graftpoints>>

<<function serialize_graftpoints>>

<<class BaseRepo>>

<<function repo.read_gitfile>>

<<class Repo>>

<<class MemoryRepo>>
@


\subsection{[[server.py]]}

<<class BackendRepo>>=
class BackendRepo(object):
    """Repository abstraction used by the Git server.

    The methods required here are a subset of those provided by
    dulwich.repo.Repo.
    """

    object_store = None
    refs = None

    def get_refs(self):
        """
        Get all the refs in the repository

        :return: dict of name -> sha
        """
        raise NotImplementedError

    def get_peeled(self, name):
        """Return the cached peeled value of a ref, if available.

        :param name: Name of the ref to peel
        :return: The peeled value of the ref. If the ref is known not point to
            a tag, this will be the SHA the ref refers to. If no cached
            information about a tag is available, this method may return None,
            but it should attempt to peel the tag if possible.
        """
        return None

    def fetch_objects(self, determine_wants, graph_walker, progress,
                      get_tagged=None):
        """
        Yield the objects required for a list of commits.

        :param progress: is a callback to send progress messages to the client
        :param get_tagged: Function that returns a dict of pointed-to sha -> tag
            sha for including tags.
        """
        raise NotImplementedError
@
%dead?


%---------------------------------------------------------------------
<<dulwich/server.py>>=
# server.py -- Implementation of the server side git protocols
# Copyright (C) 2008 John Carr <john.carr@unrouted.co.uk>
# Coprygith (C) 2011-2012 Jelmer Vernooij <jelmer@samba.org>
#
<<dulwich license>>
"""Git smart network protocol server implementation.

For more detailed implementation on the network protocol, see the
Documentation/technical directory in the cgit distribution, and in particular:

* Documentation/technical/protocol-capabilities.txt
* Documentation/technical/pack-protocol.txt

Currently supported capabilities:

 * include-tag
 * thin-pack
 * multi_ack_detailed
 * multi_ack
 * side-band-64k
 * ofs-delta
 * no-progress
 * report-status
 * delete-refs
 * shallow
"""

import collections
import os
import socket
import sys
import zlib

try:
    import SocketServer
except ImportError:
    import socketserver as SocketServer

from dulwich.errors import (
    ApplyDeltaError,
    ChecksumMismatch,
    GitProtocolError,
    NotGitRepository,
    UnexpectedCommandError,
    ObjectFormatException,
    )
from dulwich import log_utils
from dulwich.objects import (
    Commit,
    valid_hexsha,
    )
from dulwich.pack import (
    write_pack_objects,
    )
from dulwich.protocol import (
    BufferedPktLineWriter,
    capability_agent,
    CAPABILITIES_REF,
    CAPABILITY_DELETE_REFS,
    CAPABILITY_INCLUDE_TAG,
    CAPABILITY_MULTI_ACK_DETAILED,
    CAPABILITY_MULTI_ACK,
    CAPABILITY_NO_DONE,
    CAPABILITY_NO_PROGRESS,
    CAPABILITY_OFS_DELTA,
    CAPABILITY_QUIET,
    CAPABILITY_REPORT_STATUS,
    CAPABILITY_SHALLOW,
    CAPABILITY_SIDE_BAND_64K,
    CAPABILITY_THIN_PACK,
    COMMAND_DEEPEN,
    COMMAND_DONE,
    COMMAND_HAVE,
    COMMAND_SHALLOW,
    COMMAND_UNSHALLOW,
    COMMAND_WANT,
    MULTI_ACK,
    MULTI_ACK_DETAILED,
    Protocol,
    ProtocolFile,
    ReceivableProtocol,
    SIDE_BAND_CHANNEL_DATA,
    SIDE_BAND_CHANNEL_PROGRESS,
    SIDE_BAND_CHANNEL_FATAL,
    SINGLE_ACK,
    TCP_GIT_PORT,
    ZERO_SHA,
    ack_type,
    extract_capabilities,
    extract_want_line_capabilities,
    )
from dulwich.refs import (
    ANNOTATED_TAG_SUFFIX,
    write_info_refs,
    )
from dulwich.repo import (
    Repo,
    )


logger = log_utils.getLogger(__name__)

<<class Backend>>

<<class BackendRepo>>

class DictBackend(Backend):
    """Trivial backend that looks up Git repositories in a dictionary."""

    def __init__(self, repos):
        self.repos = repos

    def open_repository(self, path):
        logger.debug('Opening repository at %s', path)
        try:
            return self.repos[path]
        except KeyError:
            raise NotGitRepository(
                "No git repository was found at %(path)s" % dict(path=path)
            )

<<class FileSystemBackend>>

<<class Handler>>

<<class PackHandler>>

<<class UploadPackHandler>>


def _split_proto_line(line, allowed):
    """Split a line read from the wire.

    :param line: The line read from the wire.
    :param allowed: An iterable of command names that should be allowed.
        Command names not listed below as possible return values will be
        ignored.  If None, any commands from the possible return values are
        allowed.
    :return: a tuple having one of the following forms:
        ('want', obj_id)
        ('have', obj_id)
        ('done', None)
        (None, None)  (for a flush-pkt)

    :raise UnexpectedCommandError: if the line cannot be parsed into one of the
        allowed return values.
    """
    if not line:
        fields = [None]
    else:
        fields = line.rstrip(b'\n').split(b' ', 1)
    command = fields[0]
    if allowed is not None and command not in allowed:
        raise UnexpectedCommandError(command)
    if len(fields) == 1 and command in (COMMAND_DONE, None):
        return (command, None)
    elif len(fields) == 2:
        if command in (COMMAND_WANT, COMMAND_HAVE, COMMAND_SHALLOW,
                       COMMAND_UNSHALLOW):
            if not valid_hexsha(fields[1]):
                raise GitProtocolError("Invalid sha")
            return tuple(fields)
        elif command == COMMAND_DEEPEN:
            return command, int(fields[1])
    raise GitProtocolError('Received invalid line from client: %r' % line)


def _find_shallow(store, heads, depth):
    """Find shallow commits according to a given depth.

    :param store: An ObjectStore for looking up objects.
    :param heads: Iterable of head SHAs to start walking from.
    :param depth: The depth of ancestors to include. A depth of one includes
        only the heads themselves.
    :return: A tuple of (shallow, not_shallow), sets of SHAs that should be
        considered shallow and unshallow according to the arguments. Note that
        these sets may overlap if a commit is reachable along multiple paths.
    """
    parents = {}
    def get_parents(sha):
        result = parents.get(sha, None)
        if not result:
            result = store[sha].parents
            parents[sha] = result
        return result

    todo = []  # stack of (sha, depth)
    for head_sha in heads:
        obj = store.peel_sha(head_sha)
        if isinstance(obj, Commit):
            todo.append((obj.id, 1))

    not_shallow = set()
    shallow = set()
    while todo:
        sha, cur_depth = todo.pop()
        if cur_depth < depth:
            not_shallow.add(sha)
            new_depth = cur_depth + 1
            todo.extend((p, new_depth) for p in get_parents(sha))
        else:
            shallow.add(sha)

    return shallow, not_shallow


def _want_satisfied(store, haves, want, earliest):
    o = store[want]
    pending = collections.deque([o])
    while pending:
        commit = pending.popleft()
        if commit.id in haves:
            return True
        if commit.type_name != b"commit":
            # non-commit wants are assumed to be satisfied
            continue
        for parent in commit.parents:
            parent_obj = store[parent]
            # TODO: handle parents with later commit times than children
            if parent_obj.commit_time >= earliest:
                pending.append(parent_obj)
    return False


def _all_wants_satisfied(store, haves, wants):
    """Check whether all the current wants are satisfied by a set of haves.

    :param store: Object store to retrieve objects from
    :param haves: A set of commits we know the client has.
    :param wants: A set of commits the client wants
    :note: Wants are specified with set_wants rather than passed in since
        in the current interface they are determined outside this class.
    """
    haves = set(haves)
    if haves:
        earliest = min([store[h].commit_time for h in haves])
    else:
        earliest = 0
    for want in wants:
        if not _want_satisfied(store, haves, want, earliest):
            return False

    return True


class ProtocolGraphWalker(object):
    """A graph walker that knows the git protocol.

    As a graph walker, this class implements ack(), next(), and reset(). It
    also contains some base methods for interacting with the wire and walking
    the commit tree.

    The work of determining which acks to send is passed on to the
    implementation instance stored in _impl. The reason for this is that we do
    not know at object creation time what ack level the protocol requires. A
    call to set_ack_level() is required to set up the implementation, before any
    calls to next() or ack() are made.
    """
    def __init__(self, handler, object_store, get_peeled):
        self.handler = handler
        self.store = object_store
        self.get_peeled = get_peeled
        self.proto = handler.proto
        self.http_req = handler.http_req
        self.advertise_refs = handler.advertise_refs
        self._wants = []
        self.shallow = set()
        self.client_shallow = set()
        self.unshallow = set()
        self._cached = False
        self._cache = []
        self._cache_index = 0
        self._impl = None

    def determine_wants(self, heads):
        """Determine the wants for a set of heads.

        The given heads are advertised to the client, who then specifies which
        refs he wants using 'want' lines. This portion of the protocol is the
        same regardless of ack type, and in fact is used to set the ack type of
        the ProtocolGraphWalker.

        If the client has the 'shallow' capability, this method also reads and
        responds to the 'shallow' and 'deepen' lines from the client. These are
        not part of the wants per se, but they set up necessary state for
        walking the graph. Additionally, later code depends on this method
        consuming everything up to the first 'have' line.

        :param heads: a dict of refname->SHA1 to advertise
        :return: a list of SHA1s requested by the client
        """
        values = set(heads.values())
        if self.advertise_refs or not self.http_req:
            for i, (ref, sha) in enumerate(sorted(heads.items())):
                line = sha + b' ' + ref
                if not i:
                    line += b'\x00' + self.handler.capability_line()
                self.proto.write_pkt_line(line + b'\n')
                peeled_sha = self.get_peeled(ref)
                if peeled_sha != sha:
                    self.proto.write_pkt_line(
                        peeled_sha + b' ' + ref + ANNOTATED_TAG_SUFFIX + b'\n')

            # i'm done..
            self.proto.write_pkt_line(None)

            if self.advertise_refs:
                return []

        # Now client will sending want want want commands
        want = self.proto.read_pkt_line()
        if not want:
            return []
        line, caps = extract_want_line_capabilities(want)
        self.handler.set_client_capabilities(caps)
        self.set_ack_type(ack_type(caps))
        allowed = (COMMAND_WANT, COMMAND_SHALLOW, COMMAND_DEEPEN, None)
        command, sha = _split_proto_line(line, allowed)

        want_revs = []
        while command == COMMAND_WANT:
            if sha not in values:
                raise GitProtocolError(
                  'Client wants invalid object %s' % sha)
            want_revs.append(sha)
            command, sha = self.read_proto_line(allowed)

        self.set_wants(want_revs)
        if command in (COMMAND_SHALLOW, COMMAND_DEEPEN):
            self.unread_proto_line(command, sha)
            self._handle_shallow_request(want_revs)

        if self.http_req and self.proto.eof():
            # The client may close the socket at this point, expecting a
            # flush-pkt from the server. We might be ready to send a packfile at
            # this point, so we need to explicitly short-circuit in this case.
            return []

        return want_revs

    def unread_proto_line(self, command, value):
        if isinstance(value, int):
            value = str(value).encode('ascii')
        self.proto.unread_pkt_line(command + b' ' + value)

    def ack(self, have_ref):
        if len(have_ref) != 40:
            raise ValueError("invalid sha %r" % have_ref)
        return self._impl.ack(have_ref)

    def reset(self):
        self._cached = True
        self._cache_index = 0

    def next(self):
        if not self._cached:
            if not self._impl and self.http_req:
                return None
            return next(self._impl)
        self._cache_index += 1
        if self._cache_index > len(self._cache):
            return None
        return self._cache[self._cache_index]

    __next__ = next

    def read_proto_line(self, allowed):
        """Read a line from the wire.

        :param allowed: An iterable of command names that should be allowed.
        :return: A tuple of (command, value); see _split_proto_line.
        :raise UnexpectedCommandError: If an error occurred reading the line.
        """
        return _split_proto_line(self.proto.read_pkt_line(), allowed)

    def _handle_shallow_request(self, wants):
        while True:
            command, val = self.read_proto_line((COMMAND_DEEPEN, COMMAND_SHALLOW))
            if command == COMMAND_DEEPEN:
                depth = val
                break
            self.client_shallow.add(val)
        self.read_proto_line((None,))  # consume client's flush-pkt

        shallow, not_shallow = _find_shallow(self.store, wants, depth)

        # Update self.shallow instead of reassigning it since we passed a
        # reference to it before this method was called.
        self.shallow.update(shallow - not_shallow)
        new_shallow = self.shallow - self.client_shallow
        unshallow = self.unshallow = not_shallow & self.client_shallow

        for sha in sorted(new_shallow):
            self.proto.write_pkt_line(COMMAND_SHALLOW + b' ' + sha)
        for sha in sorted(unshallow):
            self.proto.write_pkt_line(COMMAND_UNSHALLOW + b' ' + sha)

        self.proto.write_pkt_line(None)

    def notify_done(self):
        # relay the message down to the handler.
        self.handler.notify_done()

    def send_ack(self, sha, ack_type=b''):
        if ack_type:
            ack_type = b' ' + ack_type
        self.proto.write_pkt_line(b'ACK ' + sha + ack_type + b'\n')

    def send_nak(self):
        self.proto.write_pkt_line(b'NAK\n')

    def handle_done(self, done_required, done_received):
        # Delegate this to the implementation.
        return self._impl.handle_done(done_required, done_received)

    def set_wants(self, wants):
        self._wants = wants

    def all_wants_satisfied(self, haves):
        """Check whether all the current wants are satisfied by a set of haves.

        :param haves: A set of commits we know the client has.
        :note: Wants are specified with set_wants rather than passed in since
            in the current interface they are determined outside this class.
        """
        return _all_wants_satisfied(self.store, haves, self._wants)

    def set_ack_type(self, ack_type):
        impl_classes = {
          MULTI_ACK: MultiAckGraphWalkerImpl,
          MULTI_ACK_DETAILED: MultiAckDetailedGraphWalkerImpl,
          SINGLE_ACK: SingleAckGraphWalkerImpl,
          }
        self._impl = impl_classes[ack_type](self)


_GRAPH_WALKER_COMMANDS = (COMMAND_HAVE, COMMAND_DONE, None)


class SingleAckGraphWalkerImpl(object):
    """Graph walker implementation that speaks the single-ack protocol."""

    def __init__(self, walker):
        self.walker = walker
        self._common = []

    def ack(self, have_ref):
        if not self._common:
            self.walker.send_ack(have_ref)
            self._common.append(have_ref)

    def next(self):
        command, sha = self.walker.read_proto_line(_GRAPH_WALKER_COMMANDS)
        if command in (None, COMMAND_DONE):
            # defer the handling of done
            self.walker.notify_done()
            return None
        elif command == COMMAND_HAVE:
            return sha

    __next__ = next

    def handle_done(self, done_required, done_received):
        if not self._common:
            self.walker.send_nak()

        if done_required and not done_received:
            # we are not done, especially when done is required; skip
            # the pack for this request and especially do not handle
            # the done.
            return False

        if not done_received and not self._common:
            # Okay we are not actually done then since the walker picked
            # up no haves.  This is usually triggered when client attempts
            # to pull from a source that has no common base_commit.
            # See: test_server.MultiAckDetailedGraphWalkerImplTestCase.\
            #          test_multi_ack_stateless_nodone
            return False

        return True


class MultiAckGraphWalkerImpl(object):
    """Graph walker implementation that speaks the multi-ack protocol."""

    def __init__(self, walker):
        self.walker = walker
        self._found_base = False
        self._common = []

    def ack(self, have_ref):
        self._common.append(have_ref)
        if not self._found_base:
            self.walker.send_ack(have_ref, b'continue')
            if self.walker.all_wants_satisfied(self._common):
                self._found_base = True
        # else we blind ack within next

    def next(self):
        while True:
            command, sha = self.walker.read_proto_line(_GRAPH_WALKER_COMMANDS)
            if command is None:
                self.walker.send_nak()
                # in multi-ack mode, a flush-pkt indicates the client wants to
                # flush but more have lines are still coming
                continue
            elif command == COMMAND_DONE:
                self.walker.notify_done()
                return None
            elif command == COMMAND_HAVE:
                if self._found_base:
                    # blind ack
                    self.walker.send_ack(sha, b'continue')
                return sha

    __next__ = next

    def handle_done(self, done_required, done_received):
        if done_required and not done_received:
            # we are not done, especially when done is required; skip
            # the pack for this request and especially do not handle
            # the done.
            return False

        if not done_received and not self._common:
            # Okay we are not actually done then since the walker picked
            # up no haves.  This is usually triggered when client attempts
            # to pull from a source that has no common base_commit.
            # See: test_server.MultiAckDetailedGraphWalkerImplTestCase.\
            #          test_multi_ack_stateless_nodone
            return False

        # don't nak unless no common commits were found, even if not
        # everything is satisfied
        if self._common:
            self.walker.send_ack(self._common[-1])
        else:
            self.walker.send_nak()
        return True


class MultiAckDetailedGraphWalkerImpl(object):
    """Graph walker implementation speaking the multi-ack-detailed protocol."""

    def __init__(self, walker):
        self.walker = walker
        self._common = []

    def ack(self, have_ref):
        # Should only be called iff have_ref is common
        self._common.append(have_ref)
        self.walker.send_ack(have_ref, b'common')

    def next(self):
        while True:
            command, sha = self.walker.read_proto_line(_GRAPH_WALKER_COMMANDS)
            if command is None:
                if self.walker.all_wants_satisfied(self._common):
                    self.walker.send_ack(self._common[-1], b'ready')
                self.walker.send_nak()
                if self.walker.http_req:
                    # The HTTP version of this request a flush-pkt always
                    # signifies an end of request, so we also return
                    # nothing here as if we are done (but not really, as
                    # it depends on whether no-done capability was
                    # specified and that's handled in handle_done which
                    # may or may not call post_nodone_check depending on
                    # that).
                    return None
            elif command == COMMAND_DONE:
                # Let the walker know that we got a done.
                self.walker.notify_done()
                break
            elif command == COMMAND_HAVE:
                # return the sha and let the caller ACK it with the
                # above ack method.
                return sha
        # don't nak unless no common commits were found, even if not
        # everything is satisfied

    __next__ = next

    def handle_done(self, done_required, done_received):
        if done_required and not done_received:
            # we are not done, especially when done is required; skip
            # the pack for this request and especially do not handle
            # the done.
            return False

        if not done_received and not self._common:
            # Okay we are not actually done then since the walker picked
            # up no haves.  This is usually triggered when client attempts
            # to pull from a source that has no common base_commit.
            # See: test_server.MultiAckDetailedGraphWalkerImplTestCase.\
            #          test_multi_ack_stateless_nodone
            return False

        # don't nak unless no common commits were found, even if not
        # everything is satisfied
        if self._common:
            self.walker.send_ack(self._common[-1])
        else:
            self.walker.send_nak()
        return True

<<class ReceivePackHandler>>

class UploadArchiveHandler(Handler):

    def __init__(self, backend, proto, http_req=None):
        super(UploadArchiveHandler, self).__init__(backend, proto, http_req)

    def handle(self):
        # TODO(jelmer)
        raise NotImplementedError(self.handle)


<<constant DEFAULT_HANDLERS>>


<<class TCPGitRequestHandler>>

<<class TCPGitServer>>


def main(argv=sys.argv):
    """Entry point for starting a TCP git server."""
    import optparse
    parser = optparse.OptionParser()
    parser.add_option("-l", "--listen_address", dest="listen_address",
                      default="localhost",
                      help="Binding IP address.")
    parser.add_option("-p", "--port", dest="port", type=int,
                      default=TCP_GIT_PORT,
                      help="Binding TCP port.")
    options, args = parser.parse_args(argv)

    log_utils.default_logging_config()
    if len(args) > 1:
        gitdir = args[1]
    else:
        gitdir = '.'

    from dulwich import porcelain
    porcelain.daemon(gitdir, address=options.listen_address,
                     port=options.port)


def serve_command(handler_cls, argv=sys.argv, backend=None, inf=sys.stdin,
                  outf=sys.stdout):
    """Serve a single command.

    This is mostly useful for the implementation of commands used by e.g. git+ssh.

    :param handler_cls: `Handler` class to use for the request
    :param argv: execv-style command-line arguments. Defaults to sys.argv.
    :param backend: `Backend` to use
    :param inf: File-like object to read from, defaults to standard input.
    :param outf: File-like object to write to, defaults to standard output.
    :return: Exit code for use with sys.exit. 0 on success, 1 on failure.
    """
    if backend is None:
        backend = FileSystemBackend()
    def send_fn(data):
        outf.write(data)
        outf.flush()
    proto = Protocol(inf.read, send_fn)
    handler = handler_cls(backend, argv[1:], proto)
    # FIXME: Catch exceptions and write a single-line summary to outf.
    handler.handle()
    return 0


def generate_info_refs(repo):
    """Generate an info refs file."""
    refs = repo.get_refs()
    return write_info_refs(refs, repo.object_store)


def generate_objects_info_packs(repo):
    """Generate an index for for packs."""
    for pack in repo.object_store.packs:
        yield b'P ' + pack.data.filename.encode(sys.getfilesystemencoding()) + b'\n'


def update_server_info(repo):
    """Generate server info for dumb file access.

    This generates info/refs and objects/info/packs,
    similar to "git update-server-info".
    """
    repo._put_named_file(os.path.join('info', 'refs'),
        b"".join(generate_info_refs(repo)))

    repo._put_named_file(os.path.join('objects', 'info', 'packs'),
        b"".join(generate_objects_info_packs(repo)))


if __name__ == '__main__':
    main()
@

\subsection{[[walk.py]]}

<<[[Tree]] methods>>=
def lookup_path(self, lookup_obj, path):
    """Look up an object in a Git tree.

    :param lookup_obj: Callback for retrieving object by SHA1
    :param path: Path to lookup
    :return: A tuple of (mode, SHA) of the resulting path.
    """
    parts = path.split(b'/')
    sha = self.id
    mode = None
    for p in parts:
        if not p:
            continue
        obj = lookup_obj(sha)
        if not isinstance(obj, Tree):
            raise NotTreeError(sha)
        mode, sha = obj[p]
    return mode, sha
@
%dead?

%-------------------------------------------------------------------------

<<dulwich/walk.py>>=
# walk.py -- General implementation of walking commits and their contents.
# Copyright (C) 2010 Google, Inc.
#
<<dulwich license>>
"""General implementation of walking commits and their contents."""


from collections import defaultdict

import collections
import heapq
from itertools import chain

from dulwich.diff_tree import (
    RENAME_CHANGE_TYPES,
    tree_changes,
    tree_changes_for_merge,
    RenameDetector,
    )
from dulwich.errors import (
    MissingCommitError,
    )
from dulwich.objects import (
    Commit,
    Tag,
    )

<<type walk.ORDER>>

<<constant walk.ALL_ORDERS>>

<<constant walk._MAX_EXTRA_COMMITS>>

<<class WalkEntry>>

<<class _CommitTimeQueue>>

<<class Walker>>

<<function walk._topo_reorder>>
@

\subsection{[[web.py]]}

% Looks much simpler than server.py

<<dulwich/web.py>>=
# web.py -- WSGI smart-http server
# Copyright (C) 2010 Google, Inc.
# Copyright (C) 2012 Jelmer Vernooij <jelmer@samba.org>
#
<<dulwich license>>
"""HTTP server for dulwich that implements the git smart HTTP protocol."""

from io import BytesIO
import shutil
import tempfile
import gzip
import os
import re
import sys
import time
from wsgiref.simple_server import (
    WSGIRequestHandler,
    ServerHandler,
    WSGIServer,
    make_server,
    )

try:
    from urlparse import parse_qs
except ImportError:
    from urllib.parse import parse_qs


from dulwich import log_utils
from dulwich.protocol import (
    ReceivableProtocol,
    )
from dulwich.repo import (
    Repo,
    )
from dulwich.server import (
    DictBackend,
    DEFAULT_HANDLERS,
    generate_info_refs,
    generate_objects_info_packs,
    )


logger = log_utils.getLogger(__name__)


# HTTP error strings
HTTP_OK = '200 OK'
HTTP_NOT_FOUND = '404 Not Found'
HTTP_FORBIDDEN = '403 Forbidden'
HTTP_ERROR = '500 Internal Server Error'


def date_time_string(timestamp=None):
    # From BaseHTTPRequestHandler.date_time_string in BaseHTTPServer.py in the
    # Python 2.6.5 standard library, following modifications:
    #  - Made a global rather than an instance method.
    #  - weekdayname and monthname are renamed and locals rather than class
    #    variables.
    # Copyright (c) 2001-2010 Python Software Foundation; All Rights Reserved
    weekdays = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
    months = [None,
              'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
              'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
    if timestamp is None:
        timestamp = time.time()
    year, month, day, hh, mm, ss, wd, y, z = time.gmtime(timestamp)
    return '%s, %02d %3s %4d %02d:%02d:%02d GMD' % (
            weekdays[wd], day, months[month], year, hh, mm, ss)


def url_prefix(mat):
    """Extract the URL prefix from a regex match.

    :param mat: A regex match object.
    :returns: The URL prefix, defined as the text before the match in the
        original string. Normalized to start with one leading slash and end
        with zero.
    """
    return '/' + mat.string[:mat.start()].strip('/')


def get_repo(backend, mat):
    """Get a Repo instance for the given backend and URL regex match."""
    return backend.open_repository(url_prefix(mat))


def send_file(req, f, content_type):
    """Send a file-like object to the request output.

    :param req: The HTTPGitRequest object to send output to.
    :param f: An open file-like object to send; will be closed.
    :param content_type: The MIME type for the file.
    :return: Iterator over the contents of the file, as chunks.
    """
    if f is None:
        yield req.not_found('File not found')
        return
    try:
        req.respond(HTTP_OK, content_type)
        while True:
            data = f.read(10240)
            if not data:
                break
            yield data
        f.close()
    except IOError:
        f.close()
        yield req.error('Error reading file')
    except:
        f.close()
        raise


def _url_to_path(url):
    return url.replace('/', os.path.sep)


def get_text_file(req, backend, mat):
    req.nocache()
    path = _url_to_path(mat.group())
    logger.info('Sending plain text file %s', path)
    return send_file(req, get_repo(backend, mat).get_named_file(path),
                     'text/plain')


def get_loose_object(req, backend, mat):
    sha = (mat.group(1) + mat.group(2)).encode('ascii')
    logger.info('Sending loose object %s', sha)
    object_store = get_repo(backend, mat).object_store
    if not object_store.contains_loose(sha):
        yield req.not_found('Object not found')
        return
    try:
        data = object_store[sha].as_legacy_object()
    except IOError:
        yield req.error('Error reading object')
        return
    req.cache_forever()
    req.respond(HTTP_OK, 'application/x-git-loose-object')
    yield data


def get_pack_file(req, backend, mat):
    req.cache_forever()
    path = _url_to_path(mat.group())
    logger.info('Sending pack file %s', path)
    return send_file(req, get_repo(backend, mat).get_named_file(path),
                     'application/x-git-packed-objects')


def get_idx_file(req, backend, mat):
    req.cache_forever()
    path = _url_to_path(mat.group())
    logger.info('Sending pack file %s', path)
    return send_file(req, get_repo(backend, mat).get_named_file(path),
                     'application/x-git-packed-objects-toc')


def get_info_refs(req, backend, mat):
    params = parse_qs(req.environ['QUERY_STRING'])
    service = params.get('service', [None])[0]
    if service and not req.dumb:
        handler_cls = req.handlers.get(service.encode('ascii'), None)
        if handler_cls is None:
            yield req.forbidden('Unsupported service')
            return
        req.nocache()
        write = req.respond(
            HTTP_OK, 'application/x-%s-advertisement' % service)
        proto = ReceivableProtocol(BytesIO().read, write)
        handler = handler_cls(backend, [url_prefix(mat)], proto,
                              http_req=req, advertise_refs=True)
        handler.proto.write_pkt_line(
            b'# service=' + service.encode('ascii') + b'\n')
        handler.proto.write_pkt_line(None)
        handler.handle()
    else:
        # non-smart fallback
        # TODO: select_getanyfile() (see http-backend.c)
        req.nocache()
        req.respond(HTTP_OK, 'text/plain')
        logger.info('Emulating dumb info/refs')
        repo = get_repo(backend, mat)
        for text in generate_info_refs(repo):
            yield text


def get_info_packs(req, backend, mat):
    req.nocache()
    req.respond(HTTP_OK, 'text/plain')
    logger.info('Emulating dumb info/packs')
    return generate_objects_info_packs(get_repo(backend, mat))


class _LengthLimitedFile(object):
    """Wrapper class to limit the length of reads from a file-like object.

    This is used to ensure EOF is read from the wsgi.input object once
    Content-Length bytes are read. This behavior is required by the WSGI spec
    but not implemented in wsgiref as of 2.5.
    """

    def __init__(self, input, max_bytes):
        self._input = input
        self._bytes_avail = max_bytes

    def read(self, size=-1):
        if self._bytes_avail <= 0:
            return b''
        if size == -1 or size > self._bytes_avail:
            size = self._bytes_avail
        self._bytes_avail -= size
        return self._input.read(size)

    # TODO: support more methods as necessary


def handle_service_request(req, backend, mat):
    service = mat.group().lstrip('/')
    logger.info('Handling service request for %s', service)
    handler_cls = req.handlers.get(service.encode('ascii'), None)
    if handler_cls is None:
        yield req.forbidden('Unsupported service')
        return
    req.nocache()
    write = req.respond(HTTP_OK, 'application/x-%s-result' % service)
    proto = ReceivableProtocol(req.environ['wsgi.input'].read, write)
    handler = handler_cls(backend, [url_prefix(mat)], proto, http_req=req)
    handler.handle()


class HTTPGitRequest(object):
    """Class encapsulating the state of a single git HTTP request.

    :ivar environ: the WSGI environment for the request.
    """

    def __init__(self, environ, start_response, dumb=False, handlers=None):
        self.environ = environ
        self.dumb = dumb
        self.handlers = handlers
        self._start_response = start_response
        self._cache_headers = []
        self._headers = []

    def add_header(self, name, value):
        """Add a header to the response."""
        self._headers.append((name, value))

    def respond(self, status=HTTP_OK, content_type=None, headers=None):
        """Begin a response with the given status and other headers."""
        if headers:
            self._headers.extend(headers)
        if content_type:
            self._headers.append(('Content-Type', content_type))
        self._headers.extend(self._cache_headers)

        return self._start_response(status, self._headers)

    def not_found(self, message):
        """Begin a HTTP 404 response and return the text of a message."""
        self._cache_headers = []
        logger.info('Not found: %s', message)
        self.respond(HTTP_NOT_FOUND, 'text/plain')
        return message.encode('ascii')

    def forbidden(self, message):
        """Begin a HTTP 403 response and return the text of a message."""
        self._cache_headers = []
        logger.info('Forbidden: %s', message)
        self.respond(HTTP_FORBIDDEN, 'text/plain')
        return message.encode('ascii')

    def error(self, message):
        """Begin a HTTP 500 response and return the text of a message."""
        self._cache_headers = []
        logger.error('Error: %s', message)
        self.respond(HTTP_ERROR, 'text/plain')
        return message.encode('ascii')

    def nocache(self):
        """Set the response to never be cached by the client."""
        self._cache_headers = [
          ('Expires', 'Fri, 01 Jan 1980 00:00:00 GMT'),
          ('Pragma', 'no-cache'),
          ('Cache-Control', 'no-cache, max-age=0, must-revalidate'),
          ]

    def cache_forever(self):
        """Set the response to be cached forever by the client."""
        now = time.time()
        self._cache_headers = [
          ('Date', date_time_string(now)),
          ('Expires', date_time_string(now + 31536000)),
          ('Cache-Control', 'public, max-age=31536000'),
          ]


class HTTPGitApplication(object):
    """Class encapsulating the state of a git WSGI application.

    :ivar backend: the Backend object backing this application
    """

    services = {
      ('GET', re.compile('/HEAD$')): get_text_file,
      ('GET', re.compile('/info/refs$')): get_info_refs,
      ('GET', re.compile('/objects/info/alternates$')): get_text_file,
      ('GET', re.compile('/objects/info/http-alternates$')): get_text_file,
      ('GET', re.compile('/objects/info/packs$')): get_info_packs,
      ('GET', re.compile('/objects/([0-9a-f]{2})/([0-9a-f]{38})$')): get_loose_object,
      ('GET', re.compile('/objects/pack/pack-([0-9a-f]{40})\\.pack$')): get_pack_file,
      ('GET', re.compile('/objects/pack/pack-([0-9a-f]{40})\\.idx$')): get_idx_file,

      ('POST', re.compile('/git-upload-pack$')): handle_service_request,
      ('POST', re.compile('/git-receive-pack$')): handle_service_request,
    }

    def __init__(self, backend, dumb=False, handlers=None, fallback_app=None):
        self.backend = backend
        self.dumb = dumb
        self.handlers = dict(DEFAULT_HANDLERS)
        self.fallback_app = fallback_app
        if handlers is not None:
            self.handlers.update(handlers)

    def __call__(self, environ, start_response):
        path = environ['PATH_INFO']
        method = environ['REQUEST_METHOD']
        req = HTTPGitRequest(environ, start_response, dumb=self.dumb,
                             handlers=self.handlers)
        # environ['QUERY_STRING'] has qs args
        handler = None
        for smethod, spath in self.services.keys():
            if smethod != method:
                continue
            mat = spath.search(path)
            if mat:
                handler = self.services[smethod, spath]
                break

        if handler is None:
            if self.fallback_app is not None:
                return self.fallback_app(environ, start_response)
            else:
                return [req.not_found('Sorry, that method is not supported')]

        return handler(req, self.backend, mat)


class GunzipFilter(object):
    """WSGI middleware that unzips gzip-encoded requests before
    passing on to the underlying application.
    """

    def __init__(self, application):
        self.app = application

    def __call__(self, environ, start_response):
        if environ.get('HTTP_CONTENT_ENCODING', '') == 'gzip':
            try:
                environ['wsgi.input'].tell()
                wsgi_input = environ['wsgi.input']
            except (AttributeError, IOError, NotImplementedError):
                # The gzip implementation in the standard library of Python 2.x
                # requires working '.seek()' and '.tell()' methods on the input
                # stream.  Read the data into a temporary file to work around
                # this limitation.
                wsgi_input = tempfile.SpooledTemporaryFile(16 * 1024 * 1024)
                shutil.copyfileobj(environ['wsgi.input'], wsgi_input)
                wsgi_input.seek(0)

            environ['wsgi.input'] = gzip.GzipFile(
                filename=None, fileobj=wsgi_input, mode='r')
            del environ['HTTP_CONTENT_ENCODING']
            if 'CONTENT_LENGTH' in environ:
                del environ['CONTENT_LENGTH']

        return self.app(environ, start_response)


class LimitedInputFilter(object):
    """WSGI middleware that limits the input length of a request to that
    specified in Content-Length.
    """

    def __init__(self, application):
        self.app = application

    def __call__(self, environ, start_response):
        # This is not necessary if this app is run from a conforming WSGI
        # server. Unfortunately, there's no way to tell that at this point.
        # TODO: git may used HTTP/1.1 chunked encoding instead of specifying
        # content-length
        content_length = environ.get('CONTENT_LENGTH', '')
        if content_length:
            environ['wsgi.input'] = _LengthLimitedFile(
                environ['wsgi.input'], int(content_length))
        return self.app(environ, start_response)


def make_wsgi_chain(*args, **kwargs):
    """Factory function to create an instance of HTTPGitApplication,
    correctly wrapped with needed middleware.
    """
    app = HTTPGitApplication(*args, **kwargs)
    wrapped_app = LimitedInputFilter(GunzipFilter(app))
    return wrapped_app


class ServerHandlerLogger(ServerHandler):
    """ServerHandler that uses dulwich's logger for logging exceptions."""

    def log_exception(self, exc_info):
        if sys.version_info < (2, 7):
            logger.exception('Exception happened during processing of request')
        else:
            logger.exception('Exception happened during processing of request',
                             exc_info=exc_info)

    def log_message(self, format, *args):
        logger.info(format, *args)

    def log_error(self, *args):
        logger.error(*args)


class WSGIRequestHandlerLogger(WSGIRequestHandler):
    """WSGIRequestHandler that uses dulwich's logger for logging exceptions."""

    def log_exception(self, exc_info):
        logger.exception('Exception happened during processing of request',
                         exc_info=exc_info)

    def log_message(self, format, *args):
        logger.info(format, *args)

    def log_error(self, *args):
        logger.error(*args)

    def handle(self):
        """Handle a single HTTP request"""

        self.raw_requestline = self.rfile.readline()
        if not self.parse_request():  # An error code has been sent, just exit
            return

        handler = ServerHandlerLogger(
            self.rfile, self.wfile, self.get_stderr(), self.get_environ()
        )
        handler.request_handler = self      # backpointer for logging
        handler.run(self.server.get_app())


class WSGIServerLogger(WSGIServer):

    def handle_error(self, request, client_address):
        """Handle an error. """
        logger.exception(
            'Exception happened during processing of request from %s' %
            str(client_address))


def main(argv=sys.argv):
    """Entry point for starting an HTTP git server."""
    import optparse
    parser = optparse.OptionParser()
    parser.add_option("-l", "--listen_address", dest="listen_address",
                      default="localhost",
                      help="Binding IP address.")
    parser.add_option("-p", "--port", dest="port", type=int,
                      default=8000,
                      help="Port to listen on.")
    options, args = parser.parse_args(argv)

    if len(args) > 1:
        gitdir = args[1]
    else:
        gitdir = os.getcwd()

    log_utils.default_logging_config()
    backend = DictBackend({'/': Repo(gitdir)})
    app = make_wsgi_chain(backend)
    server = make_server(options.listen_address, options.port, app,
                         handler_class=WSGIRequestHandlerLogger,
                         server_class=WSGIServerLogger)
    logger.info('Listening for HTTP connections on %s:%d',
                options.listen_address, options.port)
    server.serve_forever()


if __name__ == '__main__':
    main()
@
