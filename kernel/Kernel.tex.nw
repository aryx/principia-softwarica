\documentclass[twocolumn]{report}
%CONFIG: landscape

%******************************************************************************
% Prelude
%******************************************************************************
\newif\iffinal
\newif\ifverbose
% see also other newif in Macros.tex
\finaltrue\verbosefalse

%------------------------------------------------------------------------------
%history: 
%------------------------------------------------------------------------------

%thx to LP, changed for the better a few things :)
% - introduced syssema.c (found while going through Kernel_extra.tex.nw)
% - removed deadcode (e.g. field Proc.qlock, semalock, ArchConf, etc)
% - moved code in init/user such as preboot vs boot vs init
% - introduced notion of IPC and Time
% - TODO better grouping of things in devcons.c, present together the Qxxx,
%   same for /proc/ and its many uses

%thx to codemap/codegraph:
% - see pad.txt#reorganization section

%thx to this manual, better understand unix:
%  - child/parent relation and zombie process, the fact that a parent
%    exiting does not mean it will kill its children
%  - strace
%  - SEMI malloc internals
%  - TODO time, user vs sys vs real
%  - TODO debugger

%history LP-ization:
% - skeleton; a not too bad TOC
% - put all content of files in the Extra section, via 'syncweb -lpize'
% - split the files in chunks (for type, helpers, ...), using
%   my emacs macro, and prefixing the chunk with special names:
%    * function, global, struct, enum
%    * method (for Dev), constructor, destructor, TODO class??(for xxxdevtab?)
%    * syscall, interrupt callback, clock callback, kernel process, hook, 
%      TODO dumper
%    * xxx decl, xxx.c forward decl, xxx.c debugging macro, xxx.c Exxx errors,
%    * [[xxx]] other fields, [[xxx]] extra fields, 
% - distribute parts of the file before
% - TODO add figures (hand made)

%TODO:
% - lots of things could be reduces if C had better support for lists or hash;
%   there are lots of duplicated code adding/removing stuff in list
%   (e.g. tdel(), tadd(), etc)

%------------------------------------------------------------------------------
% Packages
%------------------------------------------------------------------------------

\usepackage{noweb}
 \noweboptions{footnotesizecode,nomargintag}
 %note: allow chunk on different pages, less white space at bottom of pages
 \def\nwendcode{\endtrivlist \endgroup}
 \let\nwdocspar=\par
\usepackage{xspace}
\usepackage{verbatim}
%note: required by noweblatexpad for the \t \l \n in this file
\usepackage{fancyvrb}
\usepackage{url}
\iffinal
\usepackage{hyperref}
 \hypersetup{colorlinks=true}
\fi
\usepackage[pageref]{backref}
 \def\backref{{\footnotesize cited page(s)}~}
\usepackage{multirow}
\usepackage{booktabs} 
 \newcommand{\otoprule}{\midrule[\heavyrulewidth]}
\usepackage{graphicx}
 %\usepackage[margin=0.5in]{geometry}
 %  but eat the bottom when very low
 %\usepackage{fullpage} is deprecated 
 % => do the more manual below:
 \addtolength{\oddsidemargin}{-.850in}
 \addtolength{\evensidemargin}{-.850in}
 \addtolength{\textwidth}{1.70in}
 \addtolength{\topmargin}{-.850in}
 \addtolength{\textheight}{1.70in}
\usepackage{minitoc}

%------------------------------------------------------------------------------
% Macros
%------------------------------------------------------------------------------
\input{Macros}

%------------------------------------------------------------------------------
% Config
%------------------------------------------------------------------------------
\allcodefalse
% used for forward decl, pragmas, func decl, extern decl, stats, #ifdef,
% debugging macros

%\setcounter{tocdepth}{1}


%******************************************************************************
% Title
%******************************************************************************

\begin{document}

\title{
{\Huge 
The Plan9 Kernel
}\\
x86 (32 bits) edition\\
{version 0.1}
}

\author{
Yoann Padioleau\\
\texttt{yoann.padioleau@gmail.com}
}

\maketitle 
\onecolumn
\hrule
\begin{quote}
    Copyright \copyright{} 2014 Yoann Padioleau \\
    Permission is granted to copy, distribute and/or modify this document,
    except all the source code it contains, under the terms of the GNU Free
    Documentation License, Version 1.3.
\end{quote}
\hrule

%CONFIG: \dominitoc

\iffinal
\begingroup
\hypersetup{linkcolor=blue}
% need to s/onecolumn/twocolumn in report.cls :) for \tableofcontents
\twocolumn
\tableofcontents
\endgroup
\else
\tableofcontents
\fi

%******************************************************************************
% Body
%******************************************************************************

\chapter{Introduction}

\section{Motivations}

The goal of this book is to present in full details the source code of
a real operating system\footnote{and in later books to also cover the
compiler, assembler, linker, debugger, windowing system, network
stack, etc}. Why? Because I think it makes you a better programmer if
you fully understand how things work under the hood.
% a concrete companion to "Computer systems: a programmer's pespective"

% Also maybe to help people imagine a better system. Hard to invent
% something if have no clue that it's actually not that hard to build
% a complete thing.

The choice of plan9 may not be obvious, but it is IMHO
the simplest and at the same time fairly complete operating system.
% as simple as possible, but not simpler
If you look at the screenshot in Figure~\ref{fig:X}, you'll see
many features:
\begin{itemize}
\item multiple shells running multiple commands
\item a screen with basic graphics and windows managment
\item a simple clock graphical application
\item a simple program communicating through the network
\end{itemize}

By comparison if you look at the screenshot in Figure~\ref{fig:Y}
you'll see that Plan9 in essence provides the similar core services
of MacOS, Linux or Windows.
% multi tasking, graphics, windows, IO, etc

Here are other candidates that were considered but ultimately discarded:
\begin{itemize}
\item Unix V6 (or its modern incarnation xv6) is too simple;
there is no graphics, no network
\item XINU has a network stack but the operating system itself
is too simple with no virtual memory for instance
\item TECS, excellent for understanding hardware, assemblers,
and even compilers, but the operating system part is really too simple
\item MMIX, same issue than TECS
\item Alan's Kay STEPS project, far more ambitious as
the goal is to have a full system in 20 000 LOC, but it is not
finished yet
\item Minix is bigger and does not provide a simple windowing
system as it relies on X11 (which is far more complicated than plan9
Rio windowing system)
\item Gnu/Linux is far far bigger; if you take the source code of glibc,
the Linux kernel, and X11, you'll get at
least 2 orders of magnitude more source code than Plan9, even though
Plan9 provides in essence the same core services. 
\end{itemize}

Of course the Linux kernel contains thousands of specific drivers,
glibc handles many different architectures, and X11 can support lots
of graphic cards and all of those things could be discarded when
presenting the core of those software, but their core is still far
bigger than Plan9 equivalent core.

\section{Getting started}

To get started you first need to get the source of the plan9
version described in this book at: 
\url{https://github.com/aryx/fork-plan9}
% did modifs, renamed, mv around, add types (bool, kern_addr, error, etc)
% mostly to ease the presentation (and have ocaml spirit!)


Then you need to compile, using a regular C compiler (e.g. gcc),
and install the Plan9 C cross compilers written by Ken Thompson:
 \url{https://github.com/aryx/fork-kencc}.

Then you need to cross compile, e.g. from MacOS, the kernel
using the Plan9 C cross compilers installed in the previous step.
You can also cross compile the whole Plan9 operating
system with all its libraries and utilities.

Finally you can test this compiled kernel and utilities using
QEMU.

As a bonus step you can also now compile Plan9 under Plan9 itself!

\section{Requirements}

I assume you actually know a lot:
\begin{itemize}
\item C
% ref?
% see also comp.ps
\item an assembler
% ref?
% see also asm.ps
\item operating system (yep)
% ref?
\item familiarity with the PC architecture
\end{itemize}

This book is not an introduction to operating systems. The goal
of this book is to present in full details a kernel but we assume
you already have a vague idea of how an operating system
works and so that you are familiar with concepts such as 
virtual memory, critical regions, interrupts, system calls, etc.
We assume you already know most of the theory; this book is here to
cover the practice.

\section{About this document}
#include "About.tex.nw"

\section{Copyright}

Most of this document is actually source code from Plan9, so
those parts are copyright by Lucent Technologies Inc.
The prose is mine and is licensed under the GNU Free Documentation
License.

\section{Acknowledgments}

I would like to acknowledge of course Plan9's authors who wrote
most of this book: Ken Thompson, Rob Pike, Dave Presotto, Phil
Winterbottom, Russ Cox, and many other people from Bell Labs.

Thanks also to Federic Balesteros who wrote a lengthy note about
Plan9's kernel that was very useful.

\chapter{Overview}
\minitoc

\section{Operating system principles}

An operating system is a meta-program: A program that manages other
programs. 
It provides convenient abstractions of the hardware and multiplex
those hardware resources for the benefit of isolated user programs:
\begin{itemize}
\item a virtual CPU, so that each process thinks it has all the CPU 
for himself
\item a virtual memory, so that each process thinks it has all memory
for himself
\item a virtual screen, so that each process thinks it has all the screen
for himself (via the windowing system)
\item the file abstraction, so a process can read and store data
on a disk, network, floppy, etc
% continous even though spreaded on concrete disk (like mm)
\item the directory abstraction, so a process can organize data
on a disk, network, floppy, etc
% also continous, even though spread over network and devices
%\item a virtual storage (filesystem)
%\item a virtual network (NFS)
\end{itemize}

Entire books have been written on those subjects.
We assume you already know what is an operating system
and we will now focus on the concrete services (API) a kernel
provides to the user programs.

\section{Plan9 services}

% see 9.ps, excellent introduction to Plan9 advanced features
% see also docs/doc/ and docs/man/

% user point of view:
% - start the whole thing, first program!
% - process managment, shell, fork, exec, multi task
% - system calls, =~ APIs of user program
% - interrupt handling, =~ devices and also syscalls and preemptive multi task
% - IO operations, =~ devices and files
% - file managment, =~ filesystem

<<sys.h>>=
#define	NOP		0
<<sys.h process syscalls>>
<<sys.h memory syscalls>>
<<sys.h file syscalls>>
<<sys.h directory syscalls>>
<<sys.h namespace syscalls>>
<<sys.h time syscalls>>
<<sys.h ipc syscalls>>
<<sys.h concurrency syscalls>>
<<sys.h special file syscalls>>
<<sys.h security syscalls>>
#define	ERRSTR		40
@ 

<<sys.h process syscalls>>=
#define	RFORK		1
#define	EXEC		2
#define	EXITS		3
#define	AWAIT		25
@

% alternative to fork? just exec, but then fork allow easily to have
% pipe or things that adjust the environment before executing other programs.

<<sys.h memory syscalls>>=
#define	BRK		32
@ 

% alternative to brk? if were using full segmentation power a la multics
% then could have better scheme, and for instance hardware checked array
% bound! if the array was in his own segment!

<<sys.h file syscalls>>=
#define	OPEN		8
#define	CLOSE		9
#define	PREAD		10
#define	PWRITE		11
#define	SEEK		12
@

<<sys.h directory syscalls>>=
#define	CREATE		6
#define	REMOVE		7
#define	CHDIR		18
#define	FD2PATH		19
#define	STAT		14
#define	FSTAT		15
#define	WSTAT		16
#define	FWSTAT		17
@

<<sys.h namespace syscalls>>=
#define	BIND		22
#define	MOUNT		23
#define	UNMOUNT		24
@

<<sys.h time syscalls>>=
#define	SLEEP		4
#define	ALARM		5
@

<<sys.h ipc syscalls>>=
#define	NOTIFY		30
#define	NOTED		31
#define	PIPE		21
#define	SEGATTACH	33
#define	SEGDETACH	34
#define	SEGFREE		35
#define	SEGFLUSH	36
#define	SEGBRK		37
@

<<sys.h concurrency syscalls>>=
#define	RENDEZVOUS	26
#define	SEMACQUIRE	27
#define	SEMRELEASE	28
#define	TSEMACQUIRE	29
@

<<sys.h special file syscalls>>=
#define	DUP		    20
@

<<sys.h security syscalls>>=
#define	FVERSION	38
#define	FAUTH		39
@


% alternative to namespace and fileservers and uniondir?
% once go to a "device is a file", and want a clean /dev/cons and 
% clean xterm, that means you need to have programs that provides
% a fake /dev/cons so need easy fileservers and namespace. Union dir
% then is natural too, goes with having flexible namespace.
% alternative would be if /dev/cons


%plan9 specifics vs general os principles, e.g. namespace so have
% nice /dev/cons, /dev/draw, which enable easier network and graphics

%TODO
%things plan9 make so much easier to implement/understand:
% tty
% X11, xterm
% nfs
% fuse
% ioctl
%
%Plan9 approach is good? abuse files? could use different API?
%For instance /dev/draw has a very specific format, so it's
%a bit abusing files.
%But at the same time one for sure needs to store things in files,
%so one need files, at which point you want to define the minimum of 
%concepts and so make files more generic => device can be files,
%but also pipes, etc, and so plan9 just push to its conclusion
%this idea.

% missing stuff in plan9:
% - shared library (help save some memory, but complicated)
%   but: http://www.kix.in/2008/06/19/an-alternative-to-shared-libraries/ ??

\section{The [[x86]] machine}
%PC vs raspberry pi?

% actually will take 386, not 486, or x86_64 or amd64 so simpler.

% little endian, big endian, the le2xxx function?


\section{C and assembly}

% compilation scheme of kernel assumes pass parameters in stack,
% return value in ax, and caller save registers it needs
% after call before calling (so Label is simple)

% Kencc extension: anon field. e.g. Lock; 

% the lock+0(FP) is intriguing

\section{Code organization}
% codemap and codegraph screenshot?
% graph dependencies? (where remove artificial edges, or use thickness of edge?)

<<kernel basic includes>>=
#include <u.h>
#include "../port/lib.h"
#include "../port/error.h"
#include "mem.h"
#include "dat.h"
#include "fns.h"
@ 

% u.h for uchar, uint, ... can be seen also as universal :)
% lib.h =~ libc utilities, see Section XX
% error.h see Section YY

<<dat.h>>=

<<enum misc_constants>>
<<pad memory pointer types>>

#include "dat_forward.h"
#include "../port/portdat_forward.h"

// defines Lock (used inline in Cpu in portdat_core.h so must be before)
#include "../port/portdat_concurrency.h"

// defines Conf, Cpu
#include "dat_core.h"
#include "../port/portdat_core.h"

// defines Page, Segment, KImage
#include "dat_memory.h"
#include "../port/portdat_memory.h"

// defines Chan
#include "../port/portdat_files.h"

// defines PCArch
#include "dat_arch.h"

// defines Proc
#include "dat_processes.h"
#include "../port/portdat_processes.h"

// defines Cmd
#include "../port/portdat_misc.h"

// defines Uart
#include "dat_buses.h"
#include "../port/portdat_buses.h"

// defines keyboard queue
#include "../port/portdat_console.h"

// could be put in lib.h
<<portdat.h macros>>
<<portdat.h pragmas>>
@

<<fns.h>>=
#include "../port/portfns_core.h"
#include "../port/portfns_concurrency.h"
#include "../port/portfns_memory.h"
#include "../port/portfns_files.h"
#include "../port/portfns_processes.h"
#include "../port/portfns_misc.h"
#include "../port/portfns_console.h"
#include "../port/portfns_buses.h"
#include "../port/portfns_devices.h"
#include "../port/portfns_security.h"
#include "../port/portfns_network.h"
#include "../port/portfns_init.h"

<<fns.h declarations>>
@


\section{Booting overview}
% kernel that creates first user process!
% introduce dichotomy kernel/user

% there is booting the kernel, booting the kernel environment,
%  and then booting the user environment, and finally booting user programs

% see also:
% http://arjunsreedharan.org/post/82710718100/kernel-101-lets-write-a-kernel

% steps:
% - hardware detection, populate Conf
% - initialization, populate allocators
% - create first process

% then user/preboot setup env, boot is responbile to mount root
% and then init assumes a root and setup last things.
% show also rootfs and data2txt

\section{Memory overview}
% kernel vs user memory
% dynamic vs static (the static allocator so can bootstrap things)

%need precise physical map of memory
%
%with first empty page?, idtr, gdt, pdb intel, pte intel, 
%io RAM, vga ram,  then KZERO header, KTZERO, 
%code,  data with important globals like xlist, and array holes,
%palloc with pointer page, and then on top of that confmem area
%
%the data section of the kernel binary is as important as
%the code section. For the code section can also give name
%of procedures, and devtab (in data section) pointing back to it
%via the static "classes" in the data section again).
%
%need also precise virtual map of memory for regular process,
% actually for 2 processes
%
%need also precise virtual map of memory for first handcrafted process?
%

%binary image has been compiled with -TKZERO_AND_HEADER!! important
% and assume loading phase setup physical mapping from KZERO to 0 physical
% and so by having kernel at KTZERO beyond all special memory so no overlap
% with sensitive area.
% maybe figure with the binary composition (a.out header, multiboot header, 
%  code, data, empty bss, etc)

<<pad memory pointer types>>=
// physical address
typedef uintptr phys_addr;
// virtual address (which should be a user address)
typedef uintptr virt_addr;
// kernel address (mostly physical + KZERO)
typedef uintptr kern_addr;
@ 

\ifallcode
<<pad memory pointer types>>=
typedef ulong* kern_addr2;
typedef ulong* virt_addr2;
typedef void* virt_addr3;
typedef void* kern_addr3;
//#define nil (void*)0 in lib.h
#define nilptr 0
@
\fi

<<constant KZERO>>=
#define KZERO   0xF0000000    /* base of kernel address space */
@ 

% why not use different segment? because convenient to be in same
% virtual space, can read/write stuff on and from userspace

<<constant KTZERO>>=
#define KTZERO    (KZERO+0x100000)  /* first address in kernel text */
@


<<constant UZERO>>=
#define UZERO   0     /* base of user address space */
@


<<constant UTZERO>>=
#define UTZERO    (UZERO+BY2PG)   /* first address in user text */
@


<<function kaddr>>=
/*
 * These could go back to being macros once the kernel is debugged,
 * but the extra checking is nice to have.
 */
//todo: should return a kern_addr
kern_addr3
kaddr(phys_addr pa)
{
    if(pa > (ulong)-KZERO)
        panic("kaddr: pa=%#.8lux", pa);
    return (kern_addr3)(pa+KZERO);
}
@

<<function paddr>>=
kern_addr
paddr(kern_addr3 v)
{
    kern_addr va;
    
    va = (kern_addr)v;
    if(va < KZERO)
        panic("paddr: va=%#.8lux pc=%#p", va, getcallerpc(&v));
    return va-KZERO;
}
@

% why stupid macro? because in other archi can be different
<<function KADDR>>=
#define KADDR(a)  kaddr(a)
@

<<function PADDR>>=
#define PADDR(a)  paddr((void*)(a))
@


%CPUADDR here!! because we talk about it later with cpu and cpus
% also IDT, GDT, etc

\section{Syscall overview}
% kernel vs user code

% sequence diagram?

% use an enum instead in sys.h? but then the script that generates
%  the .s in libc/ will be more complicated



% show example of generated assembly code
% maybe can even show an example where abuse sysnop so can see things :)

<<typedef Syscall>>=
typedef long Syscall(ulong*);
@

<<systab.h>>=
// used by systab.c but also by trap.c for certain codes
#include "/sys/src/libc/9syscall/sys.h"

<<typedef Syscall>>

extern Syscall *systab[];
extern int nsyscall;
extern char *sysctab[];
@


<<global systab>>=
Syscall *systab[] = {
    [NOP]     sysnop,
<<systab process syscalls>>
<<systab memory syscalls>>
<<systab file syscalls>>
<<systab directory syscalls>>
<<systab namespace syscalls>>
<<systab time syscalls>>
<<systab ipc syscalls>>
<<systab concurrency syscalls>>
<<systab special file syscalls>>
<<systab security syscalls>>
    [ERRSTR]    syserrstr,
};
int nsyscall = nelem(systab);
@

<<syscall nop>>=
// void nop(void);
long
sysnop(ulong*)
{
    print("Hello World\n");
    return 0;
}
@ 

<<constant VectorSYSCALL>>=
//!!! int 64 (0x40), way to jump in plan9 OS !!!
#define VectorSYSCALL 64
@

% show small ex of asm that call this hello world

%\section{File overview}
% because everything is a fileserver can confuse things
%  many concepts aggregated: device, filesystem, server

\chapter{Core Data Structures}
\minitoc

% mini libc: bool, int, strings, Rune (unicode), etc

\section{[[Conf]] and [[conf]]}

<<struct Conf>>=
struct Conf
{
    ulong ncpu;    /* processors */
    Confmem mem[4];   /* physical memory */

    ulong nproc;    /* processes */
    <<[[Conf]] other fields>>
};
@ 
% mem[4] to allow to have up to 4 free not contiguous memory regions
% (on the PC we have 2, one in the low memory before the kernel, and
% one after the kernel bss. On the bcm they just have 1)

<<global conf>>=
Conf conf;
@ 

<<struct Confmem>>=
// memory "bank"
struct Confmem
{
    phys_addr base;
    ulong npage;
  
    kern_addr kbase; // KADDR(base)
    kern_addr klimit; // KADDR(base+npage*BY2PG)
};
@ 
% show concrete value for qemu! see C-t C-t m


<<globals confname and confvar>>=
// conf (boot) parameters *e.g. { "*kernelpercent*" => "60" }
// hash<string, string>
char *confname[MAXCONF];
char *confval[MAXCONF];
// Hashtbl.length(confname)
int nconf;
@ 

<<constant MAXCONF>>=
#define MAXCONF         64
@ 

<<function getconf>>=
char* getconf(char *name)
{
        int i;
        for(i = 0; i < nconf; i++)
                if(cistrcmp(confname[i], name) == 0)
                        return confval[i];
        return nil;
}
@


\section{[[Cpu]] and [[cpu]]}

<<struct Cpu>>=
struct Cpu
{
    int cpuno;     /* physical id of processor (KNOWN TO ASSEMBLY) */
    <<[[Cpu]] second field>>
  
    // ref<Proc>
    Proc* proc;     /* current process on this processor */

    ulong ticks;      /* of the clock since boot time */

    uvlong  cpuhz;
    int cpumhz; // cpuhz / 1_000_000
    // = cpuhz if havetsc, 0 otherwise
    uvlong  cyclefreq;    /* Frequency of user readable cycle counter */

    <<[[Cpu]] stat fields>>
    <<[[Cpu]] other fields>>
    struct ArchCpu;
  
    // must be at the end of the structure!
    int stack[1];
};
@ 
% not that the stack actually is until CPUSIZE

<<struct ArchCpu>>=
struct ArchCpu {
    <<[[Cpu]] [[Arch]] cpuid fields>>
    <<[[Cpu]] [[Arch]] other fields>>
};
@ 


%history:
% Cpu used to be called Mach, but in the end it didn't make sense.
% Maybe they originally used Mach for "machine" because back in the day
% there was only  monoprocessor machine, but now with multiprocessor
% machines having names like Mach to represent one cpu, or field names
% like machno, mach0init, etc seems wrong. So I've renamed it!
% A nice side effect is also that it avoids conflicts with libmach! 
% There it acually makes sense to use the Mach name because they speak 
% about a machine.

% more on ticks in Time chapter, number of clock interrupts
% in hzclock():    cpu->ticks++;


% cpu must be "something" that is local to each processor. How to achieve
%  that? if there was a special instruction like MYCPUID then could
%  make cpu a macro to cpus[MYCPUID()]. Could also use one register
%  to hold it and so have something like extern register Cpu* cpu;
%  This is actually the case on some archi like bcm. 
%     extern register Mach* m;			/* R10 */
%  for sure this is a technique leading to a local value and different
%  in each processor.
%  But on PC we can't do that because there is not enough registers to
%  spare. 
%  So cpu is a variable holding an addr that points to an area that
%  is different on each processor, thx to a trick involving the page table.
% note that cpuinit just set cpus[0], not cpu, cpu is set in clearbss
<<global cpu>>=
// ref<Cpu>, assigned to CPUADDR in _clearbss
Cpu *cpu;
@ 

<<global cpus>>=
/*
 * Each processor sees its own Cpu structure at address CPUADDR.
 * However, the Cpu structures must also be available via the per-processor
 * MMU information array cpus, mainly for disambiguation and access to
 * the clock which is only maintained by the bootstrap processor (0).
 */
// array<ref<Cpu>>
Cpu* cpus[MAXCPUS];
@
% note that cpus[0] will not be CPUADDR! it will be
% CPU0CPU (this will defeat the purpose otherwise)

% could have instead of cpu and cpus have cpus and a Int *mycpu; where
% mycpu points to the per-processor memory area and hold the value
% of the processor, but then each access to cpu will be more costly
% than a direct access as it's done above.

<<constant MAXCPUS>>=
/*
 * In 32-bit mode, the MAXCPUS limit is 32 without
 * changing the way active.cpus is defined and used
 * (unfortunately, it is also used in the port code).
 */
#define MAXCPUS   32      /* max # cpus system can run */
@

% why macro? because again in other archi it could be more complex
<<macro CPUS>>=
#define CPUS(n)  (cpus[n])
@


<<struct Active>>=
struct Active
{
    // array<bool> (coupling: sizeof(int) must be >= MAXCPUS)
    int cpus;      /* bitmap of active CPUs */
    bool exiting;    /* shutdown */
    <<[[Active]] other fields>>
    // extra
    Lock;
};
@ 

<<global active>>=
struct Active active;
@ 


\section{[[Proc]] and [[up]]}

<<struct Proc>>=
struct Proc
{
//--------------------------------------------------------------------
// Assembly requirements, Low level, have to be first
//--------------------------------------------------------------------
    <<[[Proc]] assembly fields>>
//--------------------------------------------------------------------
// State
//--------------------------------------------------------------------
    <<[[Proc]] state fields>>
//--------------------------------------------------------------------
// Memory
//--------------------------------------------------------------------
    <<[[Proc]] memory fields>>

    struct ArchProcMMU;
//--------------------------------------------------------------------
// Scheduling
//--------------------------------------------------------------------
    <<[[Proc]] scheduling fields>>
//--------------------------------------------------------------------
// Files
//--------------------------------------------------------------------
    <<[[Proc]] files fields>>
//--------------------------------------------------------------------
// Notes
//--------------------------------------------------------------------
    <<[[Proc]] notes fields>>
//--------------------------------------------------------------------
// Process hierarchy
//--------------------------------------------------------------------
    <<[[Proc]] hierarchy fields>>
//--------------------------------------------------------------------
// Synchronization
//--------------------------------------------------------------------
    <<[[Proc]] synchronization fields>>
//--------------------------------------------------------------------
// Error managment
//--------------------------------------------------------------------
    <<[[Proc]] error managment fields>>
//--------------------------------------------------------------------
// Stats, profiling
//--------------------------------------------------------------------
    <<[[Proc]] stats and profiling fields>>
//--------------------------------------------------------------------
// Debugging (the kernel itself)
//--------------------------------------------------------------------
    <<[[Proc]] debugging fields>>
//--------------------------------------------------------------------
// For debugger, strace
//--------------------------------------------------------------------
    <<[[Proc]] debugger fields>>
//--------------------------------------------------------------------
// Other
//--------------------------------------------------------------------
    <<[[Proc]] other fields>>

    struct ArchProcNotsave;
//--------------------------------------------------------------------
// Extra
//--------------------------------------------------------------------
    <<[[Proc]] extra fields>>
};
@ 

<<struct ArchProcMMU>>=
//@Scheck: not dead, unnamed substructure
struct ArchProcMMU
{
  <<[[Proc]] [[Arch]] memory fields>>
};
@


<<[[Proc]] state fields>>=
ulong pid;
ulong parentpid;

// enum<procstate> 
int state; // Dead, Queuing, etc, (used by /proc/#/status if psstate==nil)
// some debugging information, e.g. "New", "PageOut", or name of syscall
char  *psstate; /* used by /proc/#/status */
bool insyscall; // true when process inside a syscall

// e.g. "*init*", or name of executable
char  *text;
// e.g.. "eve" (no uid/gid in plan9, because of its distributed nature?)
char  *user;
@ 
% how can change user??? all the code here mostly duplicate the user
%  from a fork from eve. Can become none via userwrite() on /proc I think
% or via hostowner()

<<enum procstate>>=
/* Process states, Proc.state */
enum procstate
{
    Dead = 0,
    Running,
    <<enum procstate cases>>
};
@ 

% 
<<global statename>>=
// hash<enum<procstate>, string>, coupling: with enum procstate
char *statename[] =
{
    "Dead",
    "Running",
    "Queueing",
    "QueueingR",
    "QueueingW",
    "Moribund",
    "Ready",
    "Scheding",
    "Wakeme",
    "Broken",
    "Stopped",
    "Rendez",
    "Waitrelease",
};
@ 

<<macro up>>=
// up = user process
#define up (cpu->proc)
@
%history: 
% Just like for 'cpu', we want 'up' to be something local to each processor.
% up used to be '#define up ((MACH*)MACHADDR)->externup' because:
% - doing just (m->externup) was conflicting with some functions using
%   a local variables called 'm'. Indeed up is a macro, not a closure so
%   any code introducing a local variable 'm' will not be able to use up
% - => rename m to cpu so less conflict and can now do (cpu->externup)
% - why externup? because in other architectures such as bcm one can do
%     extern register Mach* m;			/* R10 */
%     extern register Proc* up;			/* R9 */
%   and so m and up are really extern registers (for sure local and different
%   in each processor). On the PC we don't have that many registers so
%   have to emulate per-processor data via the virtual memory and the CPUADDR
%   trick
% - => because in the end we don't use registers, there is no need
%   to have both a cpu->proc and cpu->externup field, one can just
%   use cpu->proc for up!

\section{[[Chan]]}
% everything is a file/Chan :)
% diff with file descriptor? fd = index in chan table (fgrp), chan = opened file

<<struct Chan>>=
struct Chan
{
    ushort type; // idx in devtab?
    ulong dev;
    Qid qid;

    Path* path;

    vlong offset;     /* in fd */
    ushort mode;     /* read/write */

    bool ismtpt; // is a mount point

    union {
       void* aux; // generic pointer, for specific usages
       <<[[Chan]] union other fields>>
    };
    <<[[Chan]] other fields>>

    // extra
    Ref; /* the Lock in this Ref is also Chan's lock */
    <<[[Chan]] extra fields>>
};
@ 

<<[[Proc]] files fields>>=
// ref<Chan>
Chan  *slash; // The root! used by namec()
// ref_counted<Chan>
Chan  *dot; // The current directory
@


% rob pike: "q for unique"
% qid =~ inode =~ internal representation of a file on a filesystem
<<struct Qid>>=
struct Qid
{
  // note that this is not a string, but an int! it's kind of an inode
  uvlong  path;
  // for cache invalidation
  ulong vers;
  // enum<qidtype>
  uchar type;
};
@ 

<<enum qidtype>>=
/* bits in Qid.type */
enum qidtype {
  QTFILE = 0x00,    /* plain file */
  QTDIR = 0x80,    /* type bit for directories */
  QTMOUNT = 0x10,    /* type bit for mounted channel */

  QTAUTH = 0x08,    /* type bit for authentication file */
  QTAPPEND = 0x40,    /* type bit for append only files */
  QTEXCL = 0x20,    /* type bit for exclusive use files */
};
@ 
%TODO: reaffect the bit? 1<<1, 1<<2, 1<<3, etc?


<<function eqqid>>=
bool
eqqid(Qid a, Qid b)
{
    return a.path==b.path && a.vers==b.vers;
}
@

<<function mkqid>>=
void
mkqid(Qid *q, vlong path, ulong vers, int type)
{
    q->type = type;
    q->vers = vers;
    q->path = path;
}
@


<<function eqchan>>=
bool
eqchan(Chan *a, Chan *b, int skipvers)
{
    if(a->qid.path != b->qid.path)
        return false;
    if(!skipvers && a->qid.vers!=b->qid.vers)
        return false;
    if(a->type != b->type)
        return false;
    if(a->dev != b->dev)
        return false;
    return true;
}
@


<<function eqchantdqid>>=
bool
eqchantdqid(Chan *a, int type, int dev, Qid qid, int skipvers)
{
    if(a->qid.path != qid.path)
        return false;
    if(!skipvers && a->qid.vers!=qid.vers)
        return false;
    if(a->type != type)
        return false;
    if(a->dev != dev)
        return false;
    return true;
}
@


\section{[[Dev]] and [[devtab]]}
% actually Device also plays the role of filesystem and even fileserver!
% everything is a file ... server!

% so devtab = major/minor + VFS +??? . Devices are often a special case
% of a one-level directory containing a single file and thx to union
% dir we can gather them in one directory such as /dev/

% concrete device like kbd, screen, are exported via the
%  read() method below from /dev/cons, write() method to /dev/cons, and then
%  fancy graphics are write() to /dev/vga!

% open take a Chan? how bootstrap? how to get an handle to a file
% you want to open? first attach to get Chan from root?

<<struct Dev>>=
struct Dev
{
    Rune dc; // dev character code, e.g. '/' (devroot), 'e' (devenv), ...
    char* name;
    
    void  (*reset)(void);
    void  (*init)(void);
    void  (*shutdown)(void);
    Chan* (*attach)(char*);

    Walkqid*(*walk)(Chan*, Chan*, char**, int);

    void  (*create)(Chan*, char*, int, ulong);
    void  (*remove)(Chan*);

    Chan* (*open)(Chan*, int);
    void  (*close)(Chan*);
    long  (*read)(Chan*, void*, long, vlong);
    long  (*write)(Chan*, void*, long, vlong);

    Block* (*bread)(Chan*, long, ulong);
    long  (*bwrite)(Chan*, Block*, ulong);

    int (*stat)(Chan*, uchar*, int);
    int (*wstat)(Chan*, uchar*, int);

    void  (*power)(bool);  /* power mgt: power(1) => on, power (0) => off */
    int (*config)(int, char*, DevConf*);  /* returns nil on error */
};
@ 

<<global devtab>>=
Dev** devtab = nil;
@

% ex of conf_devtab:
% Dev* conf_devtab[]={
%	&rootdevtab,
%	&consdevtab,
%       ...

\section{[[PCArch]] and [[arch]]}

<<struct PCArch>>=
struct PCArch
{
  char* id;

  int (*ident)(void);   /* this should be in the model */
  void  (*reset)(void);   /* this should be in the model */
  void  (*resetothers)(void); /* put other cpus into reset */

  // interrupts
  <<[[PCArch]] interrupt methods fields>>
  // clock, timer
  <<[[PCArch]] time methods fields>>
  // power
  <<[[PCArch]] power methods fields>>
};
@ 

% could add cycles and cmpswap here? and also pcmspecial, fps?

<<global arch>>=
PCArch* arch;
@ 

<<global archgeneric>>=
PCArch archgeneric = {
    .id=        "generic",
    .ident=     nil,
    .reset=     archreset,

    // interrupt: Intel i8259 controller
    <<[[archgeneric]] interrupt methods>>
    // clock: Intel i8253 controller
    <<[[archgeneric]] time methods>>
    // power: none
    <<[[archgeneric]] power methods>>
};
@

% SMP is more complex arch: 'archmp'

\chapter{Concurrency}
\minitoc

% when think about concurrency in a userspace program, one have
% shared memory of multiple program threads and need to mediate
% access to shared data via semaphore/lock/whatever.

% well an OS is a kind of program and it has also mutiple
% "threads" (different activities the processes) and lots of shared data
% (kernel meta data about user processes and its own data).
% This is why lots of the concurrency issues arised first
% for OS programmers long before the other.

% for userspace concurrency, see IPC chapter, here this is
% kernel concurrency!

\section{Critical regions}

% There are different code/data "regions": 
% - user code/data
% - kernel data about user process
% - kernel data
% - kernel init code
% - kernel code of syscalls (soft interrupt), acting on behalf of user process
% - kernel code of interrupt handlers (hard interrupt).
% - kernel code of kernel processes (e.g. the alarm kernel process)
%
% There is no mutual exclusion need between user and kernel code. 
% Same for init code as only one processor is used during the
% uninterrupted sequential initialization.
% There is also no need between different user processes.
%
% For the kernel code one wants mutual exclusion because of possible race 
% on shared data structures between the syscalls themselves when run
% on different processors (or even when run on one processor as one syscall
% can be interrupted causing a scheduling that will then lead later to
% another syscall), but also between the syscalls and interrupts.
% The flow of control on one processor can be 
%  - User -> Syscall, 
%  - User -> Interrupt,
%  - or even User -> Syscall -> Interrupt
%  - one can even have User -> Syscall -> Interrupt -> Interrupt!!
%
% This is on one processor. Multiple processors lead to more combinations
% where 2 processors can run at the same time 2 interrupt handlers for instance.
% 
% One must take care when using locks inside interrupts as one can deadlock
% if the same lock was used in the enclosing syscall (hence ilock/iunlock)
%
% For protecting kernel syscall code from interrupt kernel code: splhi(), splo()
% For very small critical region: taslock
% For bigger region, or when have lots of contention on a lock: qlock
%

\section{[[tas()]]}

<<function tas>>=
TEXT tas(SB), $0
        MOVL    $0xDEADDEAD, AX
        MOVL    lock+0(FP), BX
        // Exchange AX to lock->key. So:
        //  - if the lock was not held, lock->key was 0 and so AX will be 0
        //     and lock->key will be 0xdeaddead
        //  - if the lock was held, AX will be 0xdeaddead and lock->key will
        //    still be 0xdeaddead.
        XCHGL   AX, (BX)                        /* lock->key */
        RET
@ 
% TODO: movl lock+0(FP) ??? what means this lock+0?

\section{Atomic [[_xinc()]] and [[_xdec()]]}

% tas() is to make sure one arrive first on something
% another operation is increment/decrement atomically

<<function _xinc>>=
/* void _xinc(long*); */
TEXT _xinc(SB), $0
        MOVL    l+0(FP), AX
        LOCK;   INCL 0(AX)
        RET
@ 


<<function _xdec>>=
/* long _xdec(long*); */
TEXT _xdec(SB), $0
        MOVL    l+0(FP), BX
        XORL    AX, AX
        LOCK;   DECL 0(BX)
        JLT     _xdeclt
        JGT     _xdecgt
        RET
_xdecgt:
        INCL    AX
        RET
_xdeclt:
        DECL    AX
        RET
@ 

\section{[[splhi()]], [[spllo()]]}

<<[[Cpu]] second field>>=
// must be second field at 0x04, used by splhi()
ulong splpc;      /* pc of last caller to splhi */
@ 

<<function splhi>>=
// int   splhi(void);
TEXT splhi(SB), $0
shi:
        PUSHFL
        POPL    AX
        TESTL   $0x200, AX
        JZ      alreadyhi
        MOVL    $(CPUADDR+0x04), CX            /* save PC in cpu->splpc */
        MOVL    (SP), BX
        MOVL    BX, (CX)
alreadyhi:
        CLI
        RET
@ 

% this function is actually used quite a lot, not just internally in ilock

<<function spllo>>=
// int   spllo(void);
TEXT spllo(SB), $0
slo:
        PUSHFL
        POPL    AX
        TESTL   $0x200, AX
        JNZ     alreadylo
        MOVL    $(CPUADDR+0x04), CX            /* clear cpu->splpc */
        MOVL    $0, (CX)
alreadylo:
        STI
        RET
@ 


<<function splx>>=
// void    splx(int);
TEXT splx(SB), $0
        MOVL    s+0(FP), AX
        TESTL   $0x200, AX
        JNZ     slo
        JMP     shi
@ 


<<function islo>>=
// bool islo(void);
TEXT islo(SB), $0
        PUSHFL
        POPL    AX
        ANDL    $0x200, AX                      /* interrupt enable flag */
        RET
@ 
%$


\section{Spin [[Lock]]}

<<struct Lock>>=
struct Lock
{
    ulong key; // 0 when unset, 0xDEADDEAD when acquired, could be a bool
    <<[[Lock]] ilock fields>>
    <<[[Lock]] debugging fields>>
    <<[[Lock]] other fields>>
};
@ 

\ifallcode
<<[[Lock]] other fields>>=
// option<ref<Cpu>>, None when key = 0?
Cpu  *m; // not that used, only in iprintcanlock apparently
@
\fi

<<[[Lock]] debugging fields>>=
// option<ref<Proc>>, None when key == 0
Proc  *p; // the process who did the locking should be the same unlocking
// for debugging, the caller who did the lock()
kern_addr pc; 
@

<<[[Proc]] debugging fields>>=
Lock* lastlock;
@

<<[[Proc]] synchronization fields>>=
// As long as the current process hold spinlocks (to kernel data structures),
// we will not schedule another process in unlock(); only the last unlock
// will eventually cause a rescheduling.
Ref nlocks;   /* number of locks held by proc */
@ 

% actually returns ret_code, 1 means ok but there was some contention
%  but does not look used, so TODO return void?
<<function lock>>=
int
lock(Lock *l)
{
    int i;
    ulong pc;

    pc = getcallerpc(&l);

    lockstats.locks++;
    if(up)
        inccnt(&up->nlocks);    /* prevent being scheded */
    if(tas(&l->key) == 0){
        if(up)
            up->lastlock = l;
        l->pc = pc;
        l->p = up;
        l->isilock = false;
        //TODO: not setting l->m = ??
<<lock ifdef LOCKCYCLES>>
        return 0;
    }
    if(up)
        deccnt(&up->nlocks);

    lockstats.glare++;
    for(;;){
        lockstats.inglare++;
        i = 0;
        while(l->key){
           <<[[lock()]] optional priority-inversion for real-time process>>
            if(i++ > 100000000){
                i = 0;
                lockloop(l, pc);
            }
        }
        // try again
        if(up)
            inccnt(&up->nlocks);
        if(tas(&l->key) == 0){
            if(up)
                up->lastlock = l;
            l->pc = pc;
            l->p = up;
            l->isilock = false;
<<lock ifdef LOCKCYCLES>>
            return 1;
        }
        if(up)
            deccnt(&up->nlocks);
    }
}
@ 

\ifallcode
<<unlock ifdef LOCKCYCLES>>=
#ifdef LOCKCYCLES
    l->lockcycles += lcycles();
    cumlockcycles += l->lockcycles;
    if(l->lockcycles > maxlockcycles){
        maxlockcycles = l->lockcycles;
        maxlockpc = l->pc;
    }
#endif
@ 
\fi

<<function unlock>>=
void
unlock(Lock *l)
{
<<unlock ifdef LOCKCYCLES>>

    if(l->key == 0)
        print("unlock: not locked: pc %#p\n", getcallerpc(&l));
    if(l->isilock)
        print("unlock of ilock: pc %lux, held by %lux\n", getcallerpc(&l), l->pc);
    if(l->p != up)
        print("unlock: up changed: pc %#p, acquired at pc %lux, lock p %#p, unlock up %#p\n", getcallerpc(&l), l->pc, l->p, up);

    l->m = nil;
    l->key = 0;
    // for processor caches, to ensure the lock value is seen by other
    // processors so that if they were doing while(l->key) { ... } they
    // can finally exit the while loop.
    coherence();

    <<[[unlock()]] if delaysched>>
}
@ 
% the last if is very subtle, have to understand sched() and delaysched
% to understand. too early to show a scenario

% does not spin if it can not get it
% it can be used also to make sure your caller have the lock by doing
%  if(canlock(x)) panic("lock not held by caller")
<<function canlock>>=
bool
canlock(Lock *l)
{
    if(up)
        inccnt(&up->nlocks);
    if(tas(&l->key)){
        if(up)
            deccnt(&up->nlocks);
        return false;
    }

    if(up)
        up->lastlock = l;
    l->pc = getcallerpc(&l);
    l->p = up;
    l->m = CPUS(cpu->cpuno);
    l->isilock = false;
<<lock ifdef LOCKCYCLES>>
    return true;
}
@ 

% what about deadlock when need 2 locks? need to have
% an ordering! and use always the same! could use the
% address of the lock trick of linux? could also use the lexical ordering
% of the enclosing structure :) Palloc after Page!

\section{Uninterruptable [[Lock]]}
% can formalize a checking rule? if access any field
% accessed from a xxxintr, then need to use ilock

%ilock = interrupt safe version of lock (disable interruptions)

<<[[Lock]] ilock fields>>=
bool_ushort isilock; // false when from lock(), true when from ilock()
ulong sr; // saved priority level when using ilock() to restore in iunlock()
@ 

<<[[Proc]] debugging fields>>=
Lock  *lastilock;
@ 

<<[[Cpu]] other fields>>=
int ilockdepth;
@ 

<<function ilock>>=
// To provide mutual exclusion with interrupt code and avoiding deadlock.
// By using splhi() we disable interrupts while running the critical region
// code.
void
ilock(Lock *l)
{
    ulong x;
    ulong pc;

    pc = getcallerpc(&l);
    lockstats.locks++;

    x = splhi();
    // no need to take care of up->nlock++ here, we have disabled interrupt
    // so no risk of getting scheduled
    if(tas(&l->key) != 0){
        lockstats.glare++;
        /*
         * Cannot also check l->pc, l->m, or l->isilock here
         * because they might just not be set yet, or
         * (for pc and m) the lock might have just been unlocked.
         */
        for(;;){
            lockstats.inglare++;
            splx(x);
            while(l->key)
                ;
            // let's try again
            x = splhi();
            if(tas(&l->key) == 0)
                goto acquire;
        }
    }
acquire:
    cpu->ilockdepth++;
    if(up)
        up->lastilock = l;
    l->sr = x;
    l->pc = pc;
    l->p = up;
    l->isilock = true;
    //TODO: why not just l->m = m? 
    l->m = CPUS(cpu->cpuno);
<<lock ifdef LOCKCYCLES>>
}
@ 

\ifallcode
<<iunlock ifdef LOCKCYCLES>>=
#ifdef LOCKCYCLES
    l->lockcycles += lcycles();
    cumilockcycles += l->lockcycles;
    if(l->lockcycles > maxilockcycles){
        maxilockcycles = l->lockcycles;
        maxilockpc = l->pc;
    }
    if(l->lockcycles > 2400)
        ilockpcs[n++ & 0xff]  = l->pc;
#endif
@ 
\fi

<<function iunlock>>=
void
iunlock(Lock *l)
{
    ulong sr;

<<iunlock ifdef LOCKCYCLES>>
    if(l->key == 0)
        print("iunlock: not locked: pc %#p\n", getcallerpc(&l));
    if(!l->isilock)
        print("iunlock of lock: pc %#p, held by %#lux\n", getcallerpc(&l), l->pc);
    if(islo())
        print("iunlock while lo: pc %#p, held by %#lux\n", getcallerpc(&l), l->pc);

    sr = l->sr;
    l->m = nil;
    l->key = 0;
    coherence();
    cpu->ilockdepth--;
    if(up)
        up->lastilock = nil;
    splx(sr);
}
@ 

\section{Waiting [[QLock]]}
% can be seen also as a Waiting queue, Waiting lock? Sleepable Lock?

<<struct QLock>>=
// Kernel basic lock with Queue (renamed to avoid ambiguity with libc.h QLock)
struct KQLock
{
    bool  locked;   /* flag */
  
    // list<ref<Proc>> (next = Proc.qnext)
    Proc  *head;    /* next process waiting for object */
    // ref<Proc> (direct access to tail, queue)
    Proc  *tail;    /* last process waiting for object */
  
    kern_addr qpc;    /* pc of the holder */ // for debugging?
  
    Lock  use;    /* to access Qlock structure */
};
@ 

<<[[Proc]] debugging fields>>=
ulong qpc;    /* pc calling last blocking qlock */
@

<<[[Proc]] extra fields>>=
// list<ref<Proc>> KQlock.head or RWLock.head
Proc  *qnext;   /* next process on queue for a QLock */
@ 

<<enum procstate cases>>=
Queueing, // see qlock()
@

<<function qlock>>=
void
qlock(QLock *q)
{
    Proc *p;

    if(cpu->ilockdepth != 0)
        print("qlock: %#p: ilockdepth %d\n", getcallerpc(&q), cpu->ilockdepth);
    if(up != nil && up->nlocks.ref)
        print("qlock: %#p: nlocks %lud\n", getcallerpc(&q), up->nlocks.ref);
    if(q->use.key == 0x55555555) // dead code??
        panic("qlock: q %#p, key 5*\n", q);

    lock(&q->use);
    rwstats.qlock++;
    if(!q->locked) {
        q->locked = true;
        q->qpc = getcallerpc(&q);
        unlock(&q->use);
        return;
    }
    if(up == nil)
        panic("qlock");
    rwstats.qlockq++;

    // add_queue(q, up)
    p = q->tail;
    if(p == nil)
        q->head = up;
    else
        p->qnext = up;
    q->tail = up;
    // up->qnext could be non nil before? no otherwise that means
    // the process is already waiting for a lock and so had no occasion
    // to run another qlock() instruction.
    up->qnext = nil;

    up->state = Queueing;
    up->qpc = getcallerpc(&q);
    unlock(&q->use);
    // switch to another process! 
    sched(); 
    // will resume here when another process unlock() the lock and ready() us
    q->qpc = getcallerpc(&q);
}
@ 
% call to sched() function! = kinda of a sleep
% hmmm not dangerous? sched() sometimes if nlock > 0 actually returns!!

<<function qunlock>>=
void
qunlock(QLock *q)
{
    Proc *p;

    lock(&q->use);
    if (q->locked == false)
        print("qunlock called with qlock not held, from %#p\n",
            getcallerpc(&q));

    p = q->head;
    if(p){
        // dequeue(q)
        q->head = p->qnext;
        if(q->head == nil)
            q->tail = nil;

        unlock(&q->use);
        ready(p);
    }else{
        q->locked = false;
        q->qpc = nilptr;
        unlock(&q->use);
    }
}
@ 

%call to ready() function! could put the Ready state here then?

% does not sleep if can not get it (but if can get it then it does!)
% what is the point of using a qlock if everybody uses it via canqlock??
<<function canqlock>>=
bool
canqlock(QLock *q)
{
    if(!canlock(&q->use))
        return false;
    if(q->locked){
        unlock(&q->use);
        return false;
    }
    q->locked = true;
    q->qpc = getcallerpc(&q);
    unlock(&q->use);
    return true;
}
@ 

\section{[[RWLock]]}

<<struct RWlock>>=
struct RWlock
{
    int readers;  /* number of readers */
    bool writer;   /* have a writer? */
  
    // list<ref<Proc>> (next = Proc.qnext)
    Proc  *head;    /* list of waiting processes */
    // list<ref<Proc>> (direct access to tail, queue)
    Proc  *tail;
    // option<ref<Proc>> 
    Proc  *wproc;   /* writing proc */
  
    uintptr wpc;    /* pc of writer */
  
    Lock  use;
};
@ 

<<enum procstate cases>>=
QueueingR, // see rlock()
@

<<function rlock>>=
void
rlock(RWlock *q)
{
    Proc *p;

    lock(&q->use);
    rwstats.rlock++;
    if(q->writer == false && q->head == nil){
        /* no writer, go for it */
        q->readers++;
        unlock(&q->use);
        return;
    }

    if(up == nil)
        panic("rlock");
    rwstats.rlockq++;

    // add_queue(q, up)
    p = q->tail;
    if(p == nil)
        q->head = up;
    else
        p->qnext = up;
    q->tail = up;
    up->qnext = nil;

    up->state = QueueingR;
    unlock(&q->use);
    sched();
    // will resume here when another process unlock() the lock and ready() us
}
@ 

<<function runlock>>=
void
runlock(RWlock *q)
{
    Proc *p;

    lock(&q->use);
    p = q->head;
    if(--(q->readers) > 0 || p == nil){
        unlock(&q->use);
        return;
    }

    /* start waiting writer */
    if(p->state != QueueingW)
        panic("runlock");

    // dequeue(q)
    q->head = p->qnext;
    if(q->head == nil)
        q->tail = nil;

    q->writer = true;
    unlock(&q->use);
    ready(p);
}
@ 

<<enum procstate cases>>=
QueueingW, // see wlock()
@

<<function wlock>>=
void
wlock(RWlock *q)
{
    Proc *p;

    lock(&q->use);
    rwstats.wlock++;
    if(q->readers == 0 && q->writer == false){
        /* noone waiting, go for it */
        q->wpc = getcallerpc(&q);
        q->wproc = up;
        q->writer = true;
        unlock(&q->use);
        return;
    }

    /* wait */
    if(up == nil)
        panic("wlock");
    rwstats.wlockq++;

    // add_queue(q, up)
    p = q->tail;
    if(p == nil)
        q->head = up;
    else
        p->qnext = up;
    q->tail = up;
    up->qnext = nil;

    up->state = QueueingW;
    unlock(&q->use);
    sched();
}
@ 


<<function wunlock>>=
void
wunlock(RWlock *q)
{
    Proc *p;

    lock(&q->use);
    p = q->head;
    if(p == nil){
        q->writer = false;
        unlock(&q->use);
        return;
    }
    if(p->state == QueueingW){
        /* start waiting writer */
        // dequeue(q)
        q->head = p->qnext;
        if(q->head == nil)
            q->tail = nil;

        unlock(&q->use);
        ready(p);
        return;
    }

    if(p->state != QueueingR)
        panic("wunlock");

    /* waken waiting readers */
    while(q->head != nil && q->head->state == QueueingR){
        p = q->head;
        q->head = p->qnext;
        q->readers++;
        ready(p);
    }

    if(q->head == nil)
        q->tail = nil;
    q->writer = false;
    unlock(&q->use);
}
@ 


<<function canrlock>>=
/* same as rlock but punts if there are any writers waiting */
bool
canrlock(RWlock *q)
{
    lock(&q->use);
    rwstats.rlock++;
    if(q->writer == false && q->head == nil){
        /* no writer, go for it */
        q->readers++;
        unlock(&q->use);
        return true;
    }
    unlock(&q->use);
    return false;
}
@ 

\section{Atomic [[Ref]]erences and [[Counter]]}

<<struct Ref>>=
// For reference counting shared things (e.g. a Page)
struct Ref
{
    long  ref;
    Lock;
};
@ 

<<function incref>>=
long
incref(Ref *r)
{
    long x;

    lock(r);
    x = ++r->ref;
    unlock(r);
    return x;
}
@ 


<<function decref>>=
long
decref(Ref *r)
{
    long x;

    lock(r);
    x = --r->ref;
    unlock(r);
    if(x < 0)
        panic("decref pc=%#p", getcallerpc(&r));
    return x;
}
@ 

<<struct Counter>>=
typedef struct Ref Counter;
@ 


<<function inccnt>>=
// See also ref.c incref() and decref(), but we can't use them here as they
// themselves rely on lock() and unlock(). 
static void
inccnt(Ref *r)
{
    _xinc(&r->ref);
}
@ 


<<function deccnt>>=
static int
deccnt(Ref *r)
{
    int x;

    x = _xdec(&r->ref);
    if(x < 0)
        panic("deccnt pc=%#p", getcallerpc(&r));
    return x;
}
@ 


\section{Synchronization}
% different from critical regions

% see sleep.ps in plan9 documents

% already have seen kinda of with sched()/ready()

\subsection{Rendez-vous}
% sleep/wakeup?

\subsection{Producer/Consumer Queue}
%IO Queue

\subsection{Semaphore}
% those are actually used for user-level locks, see libcore/libc/port/lock.c

\chapter{Memory}
\minitoc

<<systab memory syscalls>>=
    [BRK]      sysbrk,
@ 

\section{Overview}
% kernel vs user memory

%allocation memory kinds:
% - static and initialized (data) in binary itself! "allocated" by 
%    kernel loader
% - static and unitiliaized (bss), "allocated" by kernel loader again,
%   initialized to zero in asm (via 'edata', 'end' linker info)
% - dynamic
%    - via static arena (and trick to maintain free list)
%    - via malloc (heap)

% malloc/free memory does not appear from thin air, need data structure
% to remember what was malloced, where, how much memory remains,
% so need memory to talk about memory ... chichen and egg.

% approach: 
% - end, edata fixed area
% - confmem detection
% - xalloc static metadata about mem
%  - then from it build pools
%    - then from it get malloc
%  - orthogonally also use xalloc for procs, pages, more??

% then for user, pages is the granularity. see brk too.

% => figure of physical memory with zoom on kernel data and bss section,
%   conf.confmem, xalloc metadata, procallocs and pageallog, all procs,
%   all pages,  and then kernel memory area malloc. The user memory area
%   is made of all those pages.
% get the actual number (and try optimize? less % for kernel more for user,
%  reduce Page data structure? less conf.nproc?

\section{[[xalloc()]]}

% start with Confmem, huge bank, now we want to use some memory.
% draw figure with idea. Draw also figures with many holes in memory. 
% Can't support too much fragmentation (no compact() function)

<<constants holes>>=
enum
{
    Nhole   = 128,
    Magichole = 0x484F4C45,     /* HOLE */
};
@

<<struct Hole>>=
struct Hole
{
    // between addr and top the memory is free, this is the "hole"
    phys_addr addr; 
    phys_addr top; 
    ulong size; // top - addr
    // extra
    <<[[Hole]] extra fields>>
};
@

<<struct Xalloc>>=
// Long lived data structure allocator (singleton)
struct Xalloc
{
    // array<Hole> where each Hole is linked to another hole
    Hole  hole[Nhole];
  
    // list<ref<Hole>> (next = Hole.link) list of free hole entries (addr=top=size=0)
    Hole* flist; 
    // list<ref<Hole>> (next = Hole.link) memory holes, sorted by their top addr
    Hole* table; 
  
    // extra
    Lock;
};
@
% note that the hole entry is free means the metadata is free.
% a used hole in table means actually the hole entry is valid
% and describe some free memory there
%TODO: rename flist and table? to free_hole_entries, and sorted_used_holes?


<<[[Hole]] extra fields>>=
Hole* link; // list<ref<Hole>> of Xalloc.flist or Xalloc.table
@

<<global xlists>>=
static Xalloc   xlists;
@

% complex data structure, show concrete example, C-t C-t x
% where does xalloc(1000); xalloc(1000) and then free first => new hole used
%  see complex linking and role of table and flist,
% recall what confmem was so can understand the small split of the first
%  bank and then the huge bank

% this does not handle well many alloc/free, each free in the middle
% will allocate a new hole. Does not handle fragmentation.
% example of bad case: if does 12 * 2 xalloc, and then free
% one in two, then will use all the holes. Which is why xalloc
% is really used as the building block for the other memory allocators
% for things that are never free (long-lived data structures e.g. procs,
% pages, etc)


<<function xalloc>>=
void*
xalloc(ulong size)
{
    return xallocz(size, true);
}
@


<<struct Xhdr>>=
// What is the connection with Hole? A Hole that get used will gets
// its top and size decremented, and this newly allocated part will describe
// a portion of used memory, and at this memory there will be a header
// and then just after the actual memory xalloc'ed by someone
struct Xhdr
{
    // bookkeeping area
    ulong size;
    ulong magix;
  
    char  data[]; // memory pointer returned by xalloc
};
@

% can show a config where have big hole and then do 2 xalloc so that
% this same hole will be smaller but have multiple xhdr inside it
% in spirit (and if xfree the top one then hole gets bigger, and if
% free lower one, then a new hole is used (because of top addr sorted
% requirment)

<<function xallocz>>=
kern_addr3
xallocz(ulong size, bool zero)
{
    Xhdr *p;
    Hole *h, **l;

    /* add room for magix & size overhead, round up to nearest vlong */
    size += BY2V + offsetof(Xhdr, data[0]);
    size &= ~(BY2V-1);

    ilock(&xlists);
    l = &xlists.table;
    for(h = *l; h; h = h->link) {
        // found an appropriate hole
        if(h->size >= size) {
            p = (Xhdr*)KADDR(h->addr);
            h->addr += size; // shrink towards top
            h->size -= size;

            // This hole is now fully used (which is rare because one
            // rarely does an xalloc with the remaining size of a hole).
            // We can put it back in the list of free hole entries.
            if(h->size == 0) {
                *l = h->link;
                h->link = xlists.flist;
                xlists.flist = h;
            }

            iunlock(&xlists);
            if(zero)
                memset(p, 0, size);
            p->magix = Magichole;
            p->size = size;
            return p->data;
        }
        l = &h->link;
    }
    iunlock(&xlists);
    return nil;
}
@

% this is very rarely used in the kernel
% why use it at all? apparently in intrdisable, but why they dont
% use malloc/free? because in interrupt code?
% actually this is so rarely used that we could simplify even more
% and have a alloc-only thing with just confmem that get reduces
% gradually.
<<function xfree>>=
void
xfree(kern_addr3 p)
{
    Xhdr *x;

    x = (Xhdr*)((ulong)p - offsetof(Xhdr, data[0]));
    if(x->magix != Magichole) {
        xsummary();
        panic("xfree(%#p) %#ux != %#lux", p, Magichole, x->magix);
    }
    xhole(PADDR((uintptr)x), x->size);
}
@

% this may have to allocate a new Hole from the free list
<<function xhole>>=
void
xhole(phys_addr addr, ulong size)
{
    phys_addr top;
    Hole *h, *c, **l;

    if(size == 0)
        return;

    top = addr + size;
    ilock(&xlists);
    l = &xlists.table;
    for(h = *l; h; h = h->link) {
        if(h->top == addr) {
            h->size += size;
            h->top = h->addr+h->size;
            c = h->link;
            if(c && h->top == c->addr) {
                h->top += c->size;
                h->size += c->size;
                h->link = c->link;
                c->link = xlists.flist;
                xlists.flist = c;
            }
            iunlock(&xlists);
            return;
        }
        if(h->addr > addr)
            break;
        l = &h->link;
    }
    if(h && top == h->addr) {
        h->addr -= size;
        h->size += size;
        iunlock(&xlists);
        return;
    }

    if(xlists.flist == nil) {
        iunlock(&xlists);
        print("xfree: no free holes, leaked %lud bytes\n", size);
        return;
    }

    h = xlists.flist;
    xlists.flist = h->link;
    h->addr = addr;
    h->top = top;
    h->size = size;
    h->link = *l;
    *l = h;
    iunlock(&xlists);
}
@


<<function xmerge>>=
bool
xmerge(void *vp, void *vq)
{
    Xhdr *p, *q;

    p = (Xhdr*)(((ulong)vp - offsetof(Xhdr, data[0])));
    q = (Xhdr*)(((ulong)vq - offsetof(Xhdr, data[0])));

    if(p->magix != Magichole || q->magix != Magichole) {
        <<[[xmerge()]] debug info when not magichole>>
        panic("xmerge(%#p, %#p) bad magic %#lux, %#lux",
            vp, vq, p->magix, q->magix);
    }
    if((uchar*)p+p->size == (uchar*)q) {
        p->size += q->size;
        return true;
    }
    return false;
}
@

\ifallcode
<<[[xmerge()]] debug info when not magichole>>=
        int i;
        ulong *wd;
        void *badp;

        xsummary();
        badp = (p->magix != Magichole? p: q);
        wd = (ulong *)badp - 12;
        for (i = 24; i-- > 0; ) {
            print("%#p: %lux", wd, *wd);
            if (wd == badp)
                print(" <-");
            print("\n");
            wd++;
        }
@
\fi

%??
<<function xspanalloc>>=
void*
xspanalloc(ulong size, int align, ulong span)
{
    ulong a, v, t;
    a = (ulong)xalloc(size+align+span);
    if(a == 0)
        panic("xspanalloc: %lud %d %lux", size, align, span);

    if(span > 2) {
        v = (a + span) & ~(span-1);
        t = v - a;
        if(t > 0)
            xhole(PADDR(a), t);
        t = a + span - v;
        if(t > 0)
            xhole(PADDR(v+size+align), t);
    }
    else
        v = a;

    if(align > 1)
        v = (v + align) & ~(align-1);

    return (void*)v;
}
@



\section{[[Pool]]}
% pool allocation, aka arena?

\begin{verbatim}

// from pool.h
//struct Pool {
//  char* name;
//  ulong maxsize;
//
//  ulong cursize;
//  ulong curfree;
//  ulong curalloc;
//
//  ulong minarena; /* smallest size of new arena */
//  ulong quantum;  /* allocated blocks should be multiple of */
//  ulong minblock; /* smallest newly allocated block */
//
//  void* freeroot; /* actually Free* */
//  void* arenalist;  /* actually Arena* */
//
//  void* (*alloc)(ulong);
//  int (*merge)(void*, void*);
//  void  (*move)(void* from, void* to);
//
//  int flags;
//  int nfree;
//  int lastcompact;
//
//  void  (*lock)(Pool*);
//  void  (*unlock)(Pool*);
//  void  (*print)(Pool*, char*, ...);
//  void  (*panic)(Pool*, char*, ...);
//  void  (*logstack)(Pool*);
//
//  void* private;
//};
\end{verbatim}

<<pool.c struct Private>>=
struct Private {
    Lock        lk;
    char        msg[256]; /* a rock for messages to be printed at unlock */
};
@

<<function plock>>=
static void
plock(Pool *p)
{
    Private *pv;

    pv = p->private;
    ilock(&pv->lk);
    pv->lk.pc = getcallerpc(&p);
    pv->msg[0] = 0;
}
@


<<function punlock>>=
static void
punlock(Pool *p)
{
    Private *pv;
    char msg[sizeof pv->msg];

    pv = p->private;
    if(pv->msg[0] == 0){
        iunlock(&pv->lk);
        return;
    }

    memmove(msg, pv->msg, sizeof msg);
    iunlock(&pv->lk);
    iprint("%.*s", sizeof pv->msg, msg);
}
@

% note that no xfree or xhole here ... so it always grow
% (which is good for the fragmentation issue of xalloc anyway)
<<global pmainmem>>=
static Private pmainpriv;
static Pool pmainmem = {
    .name=  "Main",
    .maxsize=   4*1024*1024,
    .minarena=  128*1024,
    .quantum=   32,
    .alloc= xalloc,
    .merge= xmerge,
    .flags= POOL_TOLERANCE,

    .lock=plock,
    .unlock= punlock,
    .print= poolprint,
    .panic= ppanic,

    .private=   &pmainpriv,
};
@


<<global pimagmem>>=
static Private pimagpriv;
static Pool pimagmem = {
    .name=  "Image",
    .maxsize=   16*1024*1024,
    .minarena=  2*1024*1024,
    .quantum=   32,
    .alloc= xalloc,
    .merge= xmerge,
    .flags= 0,

    .lock= plock,
    .unlock= punlock,
    .print= poolprint,
    .panic= ppanic,

    .private=   &pimagpriv,
};
@


<<global mainmem and imagmem>>=
// exported in include/pool.h, defined here!
Pool*   mainmem = &pmainmem;
Pool*   imagmem = &pimagmem;
@


\section{Kernel [[malloc()]]}

% the memcpy, memmove, functions of libc use malloc?

<<function malloc>>=
void*
malloc(ulong size)
{
    void *v;

    v = poolalloc(mainmem, size+Npadlong*sizeof(ulong));
    if(v == nil)
        return nil;
    if(Npadlong){
        v = (ulong*)v+Npadlong;
        setmalloctag(v, getcallerpc(&size));
        setrealloctag(v, 0);
    }
    memset(v, 0, size);
    return v;
}
@

<<function free>>=
void
free(void *v)
{
    if(v != nil)
        poolfree(mainmem, (ulong*)v-Npadlong);
}
@


<<function setmalloctag>>=
void
setmalloctag(void *v, ulong pc)
{
    ulong *u;
    USED(v, pc);
    if(Npadlong <= MallocOffset || v == nil)
        return;
    u = v;
    u[-Npadlong+MallocOffset] = pc;
}
@


<<function setrealloctag>>=
void
setrealloctag(void *v, ulong pc)
{
    ulong *u;
    USED(v, pc);
    if(Npadlong <= ReallocOffset || v == nil)
        return;
    u = v;
    u[-Npadlong+ReallocOffset] = pc;
}
@


% sleep malloc, probably can't be called from interrupt code!
<<function smalloc>>=
// non failing malloc! will repeat until it can
void*
smalloc(ulong size)
{
    void *v;

    for(;;) {
        v = poolalloc(mainmem, size + Npadlong*sizeof(ulong));
        if(v != nil)
            break;
        tsleep(&up->sleepr, returnfalse, 0, 100);
    }
    if(Npadlong){
        v = (ulong*)v+Npadlong;
        setmalloctag(v, getcallerpc(&size));
    }
    memset(v, 0, size);
    return v;
}
@




<<function mallocz>>=
void*
mallocz(ulong size, int clr)
{
    void *v;

    v = poolalloc(mainmem, size+Npadlong*sizeof(ulong));
    if(Npadlong && v != nil){
        v = (ulong*)v+Npadlong;
        setmalloctag(v, getcallerpc(&size));
        setrealloctag(v, 0);
    }
    if(clr && v != nil)
        memset(v, 0, size);
    return v;
}
@


<<function mallocalign>>=
void*
mallocalign(ulong size, ulong align, long offset, ulong span)
{
    void *v;

    v = poolallocalign(mainmem, size+Npadlong*sizeof(ulong), align, 
                           offset-Npadlong*sizeof(ulong), span);
    if(Npadlong && v != nil){
        v = (ulong*)v+Npadlong;
        setmalloctag(v, getcallerpc(&size));
        setrealloctag(v, 0);
    }
    if(v)
        memset(v, 0, size);
    return v;
}
@

<<function realloc>>=
void*
realloc(void *v, ulong size)
{
    void *nv;

    if(v != nil)
        v = (ulong*)v-Npadlong;
    if(Npadlong !=0 && size != 0)
        size += Npadlong*sizeof(ulong);

    if(nv = poolrealloc(mainmem, v, size)){
        nv = (ulong*)nv+Npadlong;
        setrealloctag(nv, getcallerpc(&v));
        if(v == nil)
            setmalloctag(nv, getcallerpc(&v));
    }       
    return nv;
}
@


<<function msize>>=
ulong
msize(void *v)
{
    return poolmsize(mainmem, (ulong*)v-Npadlong)-Npadlong*sizeof(ulong);
}
@



\section{User [[malloc()]]}
%actually brk

% from OS point of view the user malloc granularity is
% done via brk at a page level. malloc is actually
% done in libc on top of brk (cf insa and aubourg :) )

% in lib_core/libc/port/malloc.c 

%Pool *mainmem = &sbrkmem;
%Pool *imagmem = &sbrkmem;

% note also here that it always grow! brk always bigger.

\section{[[Page]]}

% TODO: lots of code is related to KImage, like cachedel, etc
% so should move this code in the KImage section

% will be used to share, copy on write!

%TODO LP: split [[Page]] extra fields and distribute later
<<struct Page>>=
// Page metadata. We will allocate as many Page as to cover all physical memory
// + swap "address space". Either pa or daddr should be valid at one time.
// Should have been xalloc'ed in Palloc.pages
struct Page
{
    phys_addr pa;     /* Physical address in memory */
    virt_addr va;     /* Virtual address for user */
  
    // option<ref<Kimage>>
    KImage  *image;     /* Associated text or swap image */
    ulong daddr;      /* Disc address on swap */
    ulong gen;      /* Generation counter for swap */
  
    // Why not Ref? to save space probably (same reason they use char below)
    // but that means needs to use Lock below to access this non-atomic ref.
    ushort  ref;      /* Reference count */
    // set<enum<modref>>
    char  modref;     /* Simulated modify/reference bits */
    // enum<cachectl>??
    char  color;      /* Cache coloring */
    // array<enum<cachectl>>
    char  cachectl[MAXCPUS];  /* Cache flushing control for putmmu */

    // extra
    Lock;
    // list<ref<Page>> Palloc.head
    Page  *next; /* Lru free list */ 
    // list<ref<Page>> Palloc.tail
    Page  *prev; 
    // hash<daddr, list<ref<Page>>> Palloc.hash
    Page  *hash; /* Image hash chains */ 

};
@

% put kmap, kunmap here? apparently they are used when copying from
% one another or doing memset 0. just to get pa -> kern_addr?

<<enum cachectl>>=
enum cachectl
{
    PG_NOFLUSH  = 0,
    PG_TXTFLUSH = 1,    /* flush dcache and invalidate icache */
    PG_NEWCOL = 3,    /* page has been recolored */
};
@
% todo: use 2 above for PG_NEWCOL?
%    //  PG_DATFLUSH = 2,    /* flush both i & d caches (UNUSED) */

<<enum modref>>=
enum modref 
{
    PG_MOD    = 0x01,   /* software modified bit */
    PG_REF    = 0x02,   /* software referenced bit */
};
@


<<struct Palloc>>=
// Page Allocator (singleton)
struct Palloc
{
    Pallocmem mem[4]; // essentially the same as Conf.mem
    // sum of mem.npage (which should be conf.upages)
    ulong user;     /* how many user pages */
  
    // array<Page>, xalloc'ed in pageinit() (huge) cover physical+swap space???
    Page  *pages; /* array of all pages */ 
  
    // list<ref<Page>> (next = Page.next), list of free pages
    Page  *head;      /* most recently used */
    // list<ref<Page>> (prev = Page.prev), list of free pages (backward)
    Page  *tail;      /* least recently used */

    //Does it cover also the pages on the swap?
    ulong freecount;    /* how many pages on free list now */
  
    // hash<?pghash(Page.daddr?), list<ref<Page>> (next = Page.hash)>
    Page  *hash[PGHSIZE];
    Lock  hashlock;
  
    // extra
    Lock; // LOCK ORDERING: always do lock(&palloc); lock(p)!!
    Rendez  freememr; /* Sleep for free mem */ // ispages()
    QLock pwait; /* Queue of procs waiting for memory */
};
@

<<function pagenumber>>=
ulong
pagenumber(Page *p)
{
    return p-palloc.pages;
}
@


%TODO: could merge with Confmem?
<<struct Pallocmem>>=
// memory banks, similar to RMap, and Confmem, but page oriented, and portable
struct Pallocmem
{
    phys_addr base;
    ulong npage;
};
@


% can set s to nil at exit in case of ???
<<constructor newpage>>=
Page*
newpage(bool clear, Segment **s, ulong va)
{
    Page *p;
    KMap *k;
    uchar ct;
    int i, hw, color;
    bool dontalloc;

    lock(&palloc);
    color = getpgcolor(va);
    hw = swapalloc.highwater;
    for(;;) {
        if(palloc.freecount > hw)
            break;
        if(up->kp && palloc.freecount > 0)
            break;

        unlock(&palloc);
        dontalloc = false;
        if(s && *s) {
            qunlock(&((*s)->lk));
            *s = nil;// !!
            dontalloc = true;
        }
        qlock(&palloc.pwait);   /* Hold memory requesters here */

        while(waserror())   /* Ignore interrupts */
            ;

        kickpager();
        tsleep(&palloc.freememr, ispages, 0, 1000);

        poperror();

        qunlock(&palloc.pwait);

        /*
         * If called from fault and we lost the segment from
         * underneath don't waste time allocating and freeing
         * a page. Fault will call newpage again when it has
         * reacquired the segment locks
         */
        if(dontalloc)
            return nil;

        lock(&palloc);
    }

    /* First try for our colour */
    for(p = palloc.head; p; p = p->next)
        if(p->color == color)
            break;

    ct = PG_NOFLUSH;
    if(p == nil) {
        p = palloc.head;
        p->color = color;
        ct = PG_NEWCOL;
    }

    pageunchain(p);

    lock(p);
    if(p->ref != 0)
        panic("newpage: p->ref %d != 0", p->ref);

    uncachepage(p);
    p->ref++;
    p->va = va;
    p->modref = 0;
    for(i = 0; i < MAXCPUS; i++)
        p->cachectl[i] = ct;
    unlock(p);
    unlock(&palloc);

    if(clear) {
        k = kmap(p);
        memset((void*)VA(k), 0, BY2PG);
        kunmap(k);
    }

    return p;
}
@

<<function pageunchain>>=
// assumes palloc is held
static void
pageunchain(Page *p)
{
    if(canlock(&palloc))
        panic("pageunchain (palloc %p)", &palloc);

    // remove(p, palloc);
    if(p->prev)
        p->prev->next = p->next;
    else
        palloc.head = p->next;
    if(p->next)
        p->next->prev = p->prev;
    else
        palloc.tail = p->prev;
    p->prev = p->next = nil;
    palloc.freecount--;
}
@


<<function pagechaintail>>=
// assumes palloc is held
void
pagechaintail(Page *p)
{
    if(canlock(&palloc))
        panic("pagechaintail");

    // add_tail(p, palloc)
    if(palloc.tail) {
        p->prev = palloc.tail;
        palloc.tail->next = p;
    }
    else {
        palloc.head = p;
        p->prev = 0;
    }
    palloc.tail = p;
    p->next = nil;
    palloc.freecount++;
}
@


<<function pagechainhead>>=
// assumes palloc is held
void
pagechainhead(Page *p)
{
    if(canlock(&palloc))
        panic("pagechainhead");
    // add_head(p, palloc)
    if(palloc.head) {
        p->next = palloc.head;
        palloc.head->prev = p;
    }
    else {
        palloc.tail = p;
        p->next = nil;
    }
    palloc.head = p;
    p->prev = nil;
    palloc.freecount++;
}
@



% rename hasfreepages?
<<function ispages>>=
int
ispages(void*)
{
    return palloc.freecount >= swapalloc.highwater;
}
@


<<destructor putpage>>=
void
putpage(Page *p)
{
    if(onswap(p)) {
        putswap(p);
        return;
    }

    lock(&palloc);
    lock(p);

    if(p->ref == 0)
        panic("putpage");

    if(--p->ref > 0) {
        unlock(p);
        unlock(&palloc);
        return;
    }

    if(p->image && p->image != &swapimage)
        pagechaintail(p);
    else 
        pagechainhead(p);

    if(palloc.freememr.p != nil)
        wakeup(&palloc.freememr);

    unlock(p);
    unlock(&palloc);
}
@

\ifallcode
% used only by cache.c, could be moved there, also should be renamed, aux??
<<function auxpage>>=
Page*
auxpage(void)
{
    Page *p;

    lock(&palloc);
    p = palloc.head;
    if(palloc.freecount < swapalloc.highwater) {
        unlock(&palloc);
        return nil;
    }
    pageunchain(p);

    lock(p);
    if(p->ref != 0)
        panic("auxpage");
    p->ref++;
    uncachepage(p);
    unlock(p);
    unlock(&palloc);

    return p;
}
@
\fi



%\section{page copy?} for copy on write?

% memmove? should be called memcopy no?
<<function copypage>>=
void
copypage(Page *f, Page *t)
{
    KMap *ks, *kd;

    ks = kmap(f);
    kd = kmap(t);
    memmove((void*)VA(kd), (void*)VA(ks), BY2PG);
    kunmap(ks);
    kunmap(kd);
}
@


<<global dupretries>>=
static int dupretries = 15000;
@


% called only from fixfault, move close to it? for copy-on-write?
% type: ret_code?
<<function duppage>>=
/* Always call with p locked */
int
duppage(Page *p)
{
    Page *np;
    int color;
    int retries;

    retries = 0;
retry:

    if(retries++ > dupretries){
        print("duppage %d, up %p\n", retries, up);
        dupretries += 100;
        if(dupretries > 100000)
            panic("duppage\n");
        uncachepage(p);
        return 1;
    }
        

    /* don't dup pages with no image */
    if(p->ref == 0 || p->image == nil || p->image->notext)
        return 0;

    /*
     *  normal lock ordering is to call
     *  lock(&palloc) before lock(p).
     *  To avoid deadlock, we have to drop
     *  our locks and try again.
     */
    if(!canlock(&palloc)){
        unlock(p);
        if(up)
            sched();
        lock(p);
        goto retry;
    }

    /* No freelist cache when memory is very low */
    if(palloc.freecount < swapalloc.highwater) {
        unlock(&palloc);
        uncachepage(p);
        return 1;
    }

    color = getpgcolor(p->va);
    for(np = palloc.head; np; np = np->next)
        if(np->color == color)
            break;

    /* No page of the correct color */
    if(np == nil) {
        unlock(&palloc);
        uncachepage(p);
        return 1;
    }

    pageunchain(np);
    pagechaintail(np);
/*
* XXX - here's a bug? - np is on the freelist but it's not really free.
* when we unlock palloc someone else can come in, decide to
* use np, and then try to lock it.  they succeed after we've 
* run copypage and cachepage and unlock(np).  then what?
* they call pageunchain before locking(np), so it's removed
* from the freelist, but still in the cache because of
* cachepage below.  if someone else looks in the cache
* before they remove it, the page will have a nonzero ref
* once they finally lock(np).
*/
    lock(np);
    unlock(&palloc);

    /* Cache the new version */
    uncachepage(np);
    np->va = p->va;
    np->daddr = p->daddr;
    copypage(p, np);
    cachepage(np, p->image);
    unlock(np);
    uncachepage(p);

    return 0;
}
@


<<function pghash>>=
enum
{
    PGHLOG  = 9, // 2^9 = 512
    PGHSIZE = 1<<PGHLOG,  /* Page hash for image lookup */
};
#define pghash(daddr) palloc.hash[(daddr>>PGSHIFT)&(PGHSIZE-1)]
@




% should be called swappage? but Kimage can be a swapimage or a text binary?
<<function cachepage>>=
void
cachepage(Page *p, KImage *i)
{
    Page **l;

    /* If this ever happens it should be fixed by calling
     * uncachepage instead of panic. I think there is a race
     * with pio in which this can happen. Calling uncachepage is
     * correct - I just wanted to see if we got here.
     */
    if(p->image)
        panic("cachepage");

    incref(i);
    lock(&palloc.hashlock);
    p->image = i;
    // add_hash(palloc.hash, p->daddr, p)
    l = &pghash(p->daddr);
    p->hash = *l;
    *l = p;
    unlock(&palloc.hashlock);
}
@


<<function uncachepage>>=
/* Always called with a locked page */
void
uncachepage(Page *p)
{
    Page **l, *f;

    if(p->image == nil)
        return;

    lock(&palloc.hashlock);
    // remove_hash(palloc.hash, p->daddr, p)
    l = &pghash(p->daddr);
    for(f = *l; f; f = f->hash) {
        if(f == p) {
            *l = p->hash;
            break;
        }
        l = &f->hash;
    }
    unlock(&palloc.hashlock);
    putimage(p->image);
    p->image = nil;
    p->daddr = 0;
}
@




<<function cachedel>>=
void
cachedel(KImage *i, ulong daddr)
{
    Page *f, **l;

    lock(&palloc.hashlock);
    l = &pghash(daddr);
    for(f = *l; f; f = f->hash) {
        if(f->image == i && f->daddr == daddr) {
            lock(f);
            // can have a race? things could have changed, so rested under lock
            if(f->image == i && f->daddr == daddr){
                *l = f->hash;
                putimage(f->image); // =~ decref
                f->image = nil;
                f->daddr = 0;
            }
            unlock(f);
            break;
        }
        l = &f->hash;
    }
    unlock(&palloc.hashlock);
}
@


<<function lookpage>>=
Page *
lookpage(KImage *i, ulong daddr)
{
    Page *f;

    lock(&palloc.hashlock);
    for(f = pghash(daddr); f; f = f->hash) {
        if(f->image == i && f->daddr == daddr) {
            unlock(&palloc.hashlock);

            lock(&palloc);
            lock(f);
            if(f->image != i || f->daddr != daddr) {
                unlock(f);
                unlock(&palloc);
                return nil;
            }
            if(++f->ref == 1)
                pageunchain(f);
            unlock(&palloc);
            unlock(f);

            return f;
        }
    }
    unlock(&palloc.hashlock);

    return nil;
}
@














<<struct Pte>>=
// ptealloc'ed (malloc'ed)
struct Pte
{
    //array<option<ref<Page>> will map 1M of memory
    Page  *pages[PTEPERTAB];  /* Page map for this chunk of pte */
  
    //to avoid iterate over all pages
    // ref<ref<Page>> in Pte.pages
    Page  **first;    /* First used entry */
    // ref<ref<Page>> in Pte.pages
    Page  **last;     /* Last used entry */
};
@
% the pages can be really sparse, but first and last optimize a bit

<<constant PTEMAPMEM>>=
#define PTEMAPMEM (1024*1024) // 1MB
@

<<constant PTEPERTAB>>=
#define PTEPERTAB (PTEMAPMEM/BY2PG)
@


<<constructor ptealloc>>=
Pte*
ptealloc(void)
{
    Pte *new;

    new = smalloc(sizeof(Pte));
    new->first = &new->pages[PTEPERTAB];
    new->last = new->pages;
    return new;
}
@

<<destructor freepte>>=
void
freepte(Segment *s, Pte *p)
{
    int ref;
    void (*fn)(Page*);
    Page *pt, **pg, **ptop;

    switch(s->type&SG_TYPE) {
    case SG_PHYSICAL:
        fn = s->pseg->pgfree;
        ptop = &p->pages[PTEPERTAB];
        if(fn) {
            for(pg = p->pages; pg < ptop; pg++) {
                if(*pg == 0)
                    continue;
                (*fn)(*pg);
                *pg = 0;
            }
            break;
        }
        for(pg = p->pages; pg < ptop; pg++) {
            pt = *pg;
            if(pt == 0)
                continue;
            lock(pt);
            ref = --pt->ref;
            unlock(pt);
            if(ref == 0)
                free(pt);
        }
        break;
    default:
        for(pg = p->first; pg <= p->last; pg++)
            if(*pg) {
                putpage(*pg);
                *pg = 0;
            }
    }
    free(p);
}
@


<<function ptecpy>>=
Pte*
ptecpy(Pte *old)
{
    Pte *new;
    Page **src, **dst;

    new = ptealloc();
    dst = &new->pages[old->first-old->pages];
    new->first = dst;
    for(src = old->first; src <= old->last; src++, dst++)
        if(*src) {
            if(onswap(*src))
                dupswap(*src);
            else {
                lock(*src);
                (*src)->ref++;
                unlock(*src);
            }
            new->last = dst;
            *dst = *src;
        }

    return new;
}
@


// called? mv in debugging section? with C-t C-t stuff?
<<function checkpagerefs>>=
void
checkpagerefs(void)
{
    int s;
    ulong i, np, nwrong;
    ulong *ref;
    
    np = palloc.user;
    ref = malloc(np*sizeof ref[0]);
    if(ref == nil){
        print("checkpagerefs: out of memory\n");
        return;
    }
    
    /*
     * This may not be exact if there are other processes
     * holding refs to pages on their stacks.  The hope is
     * that if you run it on a quiescent system it will still
     * be useful.
     */
    s = splhi();
    lock(&palloc);
    countpagerefs(ref, 0);
    portcountpagerefs(ref, 0);
    nwrong = 0;
    for(i=0; i<np; i++){
        if(palloc.pages[i].ref != ref[i]){
            iprint("page %#.8lux ref %d actual %lud\n", 
                palloc.pages[i].pa, palloc.pages[i].ref, ref[i]);
            ref[i] = 1;
            nwrong++;
        }else
            ref[i] = 0;
    }
    countpagerefs(ref, 1);
    portcountpagerefs(ref, 1);
    iprint("%lud mistakes found\n", nwrong);
    unlock(&palloc);
    splx(s);
}
@


<<function portcountpagerefs>>=
void
portcountpagerefs(ulong *ref, int print)
{
    ulong i, j, k, ns, n;
    Page **pg, *entry;
    Proc *p;
    Pte *pte;
    Segment *s;

    /*
     * Pages in segments.  s->mark avoids double-counting.
     */
    n = 0;
    ns = 0;
    for(i=0; i<conf.nproc; i++){
        p = proctab(i);
        for(j=0; j<NSEG; j++){
            s = p->seg[j];
            if(s)
                s->mark = 0;
        }
    }
    for(i=0; i<conf.nproc; i++){
        p = proctab(i);
        for(j=0; j<NSEG; j++){
            s = p->seg[j];
            if(s == nil || s->mark++)
                continue;
            ns++;
            for(k=0; k<s->mapsize; k++){
                pte = s->map[k];
                if(pte == nil)
                    continue;
                for(pg = pte->first; pg <= pte->last; pg++){
                    entry = *pg;
                    if(pagedout(entry))
                        continue;
                    if(print){
                        if(ref[pagenumber(entry)])
                            iprint("page %#.8lux in segment %#p\n", entry->pa, s);
                        continue;
                    }
                    if(ref[pagenumber(entry)]++ == 0)
                        n++;
                }
            }
        }
    }
    if(!print){
        iprint("%lud pages in %lud segments\n", n, ns);
        for(i=0; i<conf.nproc; i++){
            p = proctab(i);
            for(j=0; j<NSEG; j++){
                s = p->seg[j];
                if(s == nil)
                    continue;
                if(s->ref != s->mark){
                    iprint("segment %#p (used by proc %lud pid %lud) has bad ref count %lud actual %lud\n",
                        s, i, p->pid, s->ref, s->mark);
                }
            }
        }
    }
}
@




\section{[[Segment]]}

<<enum segtype>>=
/* Segment types */
enum segtype
{
    SG_TYPE   = 07,   /* Mask type of segment */
    SG_TEXT   = 00,
    SG_DATA   = 01,
    SG_BSS    = 02,
    SG_STACK  = 03,
    SG_SHARED = 04,
    SG_PHYSICAL = 05,
  
    SG_RONLY  = 0040,   /* Segment is read only */
    SG_CEXEC  = 0100,   /* Detach at exec */
};
@

<<struct Segment>>=
// smalloc'ed by newseg()
struct Segment
{
    // enum<segtype>
    ushort  type;   /* segment type */
  
    virt_addr base;   /* virtual base */
    virt_addr top;    /* virtual top */
    ulong size;   /* size in pages */ // top - base / BY2PG?
  
    // Kind of a page directory table (and pte = page table)
    // max is SEGMAPSIZE max so 1984 * 1M via PTE =~ 2Go virtual mem per seg!
    // array<option<ref<Pte>>>, smalloc'ed, point to ssegmap if small enough
    Pte **map; 
    // small seg map, used instead of map if segment small enough
    // array<ref<Pte>>
    Pte *ssegmap[SSEGMAPSIZE]; // 16
    int mapsize; // nelem(map)
  
    KImage  *image;   /* text in file attached to this segment */
    ulong fstart;   /* start address in file for demand load */
    ulong flen;   /* length of segment in file */
  
    bool flushme;  /* maintain icache for this segment */
    Physseg *pseg;
    ulong*  profile;  /* Tick profile area */
    ulong mark;   /* portcountrefs */
    ushort  steal;    /* Page stealer lock */
  
    // extra
    Ref;
    QLock lk;
    Sema  sema;
};
@

<<constant SEGMAPSIZE>>=
#define SEGMAPSIZE  1984
@

<<constant SSEGMAPSIZE>>=
#define SSEGMAPSIZE 16 // small segmap
@


% size is in pages?
<<constructor newseg>>=
Segment *
newseg(int type, virt_addr base, ulong size)
{
    Segment *s;
    int mapsize;

    if(size > (SEGMAPSIZE*PTEPERTAB))
        error(Enovmem);

    s = smalloc(sizeof(Segment));
    s->ref = 1;
    s->type = type;
    s->base = base;
    s->top = base+(size*BY2PG);
    s->size = size;

    // no list, just one sema
    s->sema.prev = &s->sema;
    s->sema.next = &s->sema;

    mapsize = ROUND(size, PTEPERTAB)/PTEPERTAB;
    if(mapsize > nelem(s->ssegmap)){
        mapsize *= 2;
        if(mapsize > (SEGMAPSIZE*PTEPERTAB))
            mapsize = (SEGMAPSIZE*PTEPERTAB);
        s->map = smalloc(mapsize*sizeof(Pte*));
        s->mapsize = mapsize;
    }
    else{
        s->map = s->ssegmap;
        s->mapsize = nelem(s->ssegmap);
    }

    return s;
}
@


<<destructor putseg>>=
void
putseg(Segment *s)
{
    Pte **pp, **emap;
    KImage *i;

    if(s == nil)
        return; // TODO: panic("putset") instead?

    i = s->image;
    if(i != nil) {
        lock(i);
        lock(s);
        if(i->s == s && s->ref == 1)
            i->s = 0;
        unlock(i);
    }
    else
        lock(s);

    s->ref--;
    if(s->ref != 0) {
        unlock(s);
        return;
    }
    unlock(s);

    qlock(&s->lk);
    if(i)
        putimage(i);

    emap = &s->map[s->mapsize];
    for(pp = s->map; pp < emap; pp++)
        if(*pp)
            freepte(s, *pp);

    qunlock(&s->lk);
    if(s->map != s->ssegmap)
        free(s->map);
    if(s->profile != nil)
        free(s->profile);
    free(s);
}
@



% todo: remove LSEG, and use _SEG1, _SEG2, etc
<<enum procseg>>=
/*
 *  process memory segments - NSEG always last !
 */
enum procseg
{
    SSEG, TSEG, DSEG, BSEG, // Stack, Text, Data, Bss
    ESEG, LSEG, // E = Extra (used for temporary stack segment), L?
    SEG1, SEG2, SEG3, SEG4, // free slots for for segattach
    NSEG // to count, see Proc.seg array
};
@ 

<<struct Physseg>>=
struct Physseg
{
    ulong attr;     /* Segment attributes */
    char  *name;      /* Attach name */
    phys_addr pa;     /* Physical address */
    ulong size;     /* Maximum segment size in pages */

    Page  *(*pgalloc)(Segment*, ulong); /* Allocation if we need it */
    void  (*pgfree)(Page*);
};
@


<<[[Proc]] memory fields>>=
// hash<enum<procseg>, option<ref_own<Segment>>>, elt smalloc'ed?
Segment *seg[NSEG];
QLock seglock;  /* locked whenever seg[] changes */
@ 


<<function seg>>=
Segment*
seg(Proc *p, virt_addr addr, bool dolock)
{
    Segment **s, **et, *n;

    et = &p->seg[NSEG];
    for(s = p->seg; s < et; s++) {
        n = *s;
        if(n == nil)
            continue;
        if(addr >= n->base && addr < n->top) {
            if(dolock == false)
                return n;

            qlock(&n->lk);
            // can have a race, need to check again
            if(addr >= n->base && addr < n->top)
                return n;
            qunlock(&n->lk);
        }
    }
    return nil;
}
@

<<function okaddr>>=
/*
 * Called only in a system call
 */
bool
okaddr(virt_addr addr, ulong len, bool write)
{
    Segment *s;

    if((long)len >= 0) {
        for(;;) {
            s = seg(up, addr, false);
            if(s == nil || (write && (s->type&SG_RONLY)))
                break;

            if(addr+len > s->top) {
                len -= s->top - addr;
                addr = s->top;
                continue;
            }
            return true;
        }
    }
    pprint("suicide: invalid address %#lux/%lud in sys call pc=%#lux\n", addr, len, userpc());
    return false;
}
@


<<function validaddr>>=
void
validaddr(virt_addr addr, ulong len, bool write)
{
    if(!okaddr(addr, len, write)){
        postnote(up, 1, "sys: bad address in syscall", NDebug);
        error(Ebadarg);
    }
}
@

% memchr on virtual address? and so that can span different pages, and 
% even different segments!
<<function vmemchr>>=
/*
 * &s[0] is known to be a valid address.
 */
void*
vmemchr(virt_addr3 s, int c, int n)
{
    int m;
    virt_addr a;
    virt_addr3 t;

    a = (virt_addr)s;
    while(PGROUND(a) != PGROUND(a+n-1)){
        /* spans pages; handle this page */
        m = BY2PG - (a & (BY2PG-1));
        t = memchr((void*)a, c, m);
        if(t)
            return t;
        a += m;
        n -= m;
        if(a < KZERO)
            validaddr(a, 1, false);
    }

    /* fits in one page */
    return memchr((void*)a, c, n);
}
@


% used by sysexec()
<<function relocateseg>>=
void
relocateseg(Segment *s, ulong offset)
{
    Page **pg, *x;
    Pte *pte, **p, **endpte;

    endpte = &s->map[s->mapsize];
    for(p = s->map; p < endpte; p++) {
        if(*p == 0)
            continue;
        pte = *p;
        for(pg = pte->first; pg <= pte->last; pg++) {
            if(x = *pg)
                x->va += offset;
        }
    }
}
@

% used by sysfork()
<<function dupseg>>=
Segment*
dupseg(Segment **seg, int segno, bool share)
{
    int i, size;
    Pte *pte;
    Segment *n, *s;

    SET(n); //????

    s = seg[segno];

    qlock(&s->lk);
    if(waserror()){
        qunlock(&s->lk);
        nexterror();
    }
    switch(s->type&SG_TYPE) {
    case SG_TEXT:       /* New segment shares pte set */
    case SG_SHARED:
    case SG_PHYSICAL:
        goto sameseg;

    case SG_STACK:
        n = newseg(s->type, s->base, s->size);
        break;

    case SG_BSS:        /* Just copy on write */
        if(share)
            goto sameseg;
        n = newseg(s->type, s->base, s->size);
        break;

    case SG_DATA:       /* Copy on write plus demand load info */
        if(segno == TSEG){
            poperror();
            qunlock(&s->lk);
            return data2txt(s);// ????
        }

        if(share)
            goto sameseg;
        n = newseg(s->type, s->base, s->size);

        incref(s->image);
        n->image = s->image;
        n->fstart = s->fstart;
        n->flen = s->flen;
        break;
    }
    size = s->mapsize;
    for(i = 0; i < size; i++)
        if(pte = s->map[i])
            n->map[i] = ptecpy(pte);

    n->flushme = s->flushme;
    if(s->ref > 1)
        procflushseg(s);
    poperror();
    qunlock(&s->lk);
    return n;

sameseg:
    incref(s);
    poperror();
    qunlock(&s->lk);
    return s;
}
@

% used by userinit
<<function segpage>>=
void
segpage(Segment *s, Page *p)
{
    Pte **pte;
    ulong off;
    Page **pg;

    if(p->va < s->base || p->va >= s->top)
        panic("segpage");

    off = p->va - s->base;
    pte = &s->map[off/PTEMAPMEM];
    if(*pte == 0)
        *pte = ptealloc();

    pg = &(*pte)->pages[(off&(PTEMAPMEM-1))/BY2PG];
    *pg = p;
    if(pg < (*pte)->first)
        (*pte)->first = pg;
    if(pg > (*pte)->last)
        (*pte)->last = pg;
}
@

<<function mfreeseg>>=
/*
 *  called with s->lk locked
 */
void
mfreeseg(Segment *s, ulong start, int pages)
{
    int i, j, size;
    ulong soff;
    Page *pg;
    Page *list;

    soff = start-s->base;
    j = (soff&(PTEMAPMEM-1))/BY2PG;

    size = s->mapsize;
    list = nil;
    for(i = soff/PTEMAPMEM; i < size; i++) {
        if(pages <= 0)
            break;
        if(s->map[i] == 0) {
            pages -= PTEPERTAB-j;
            j = 0;
            continue;
        }
        while(j < PTEPERTAB) {
            pg = s->map[i]->pages[j];
            /*
             * We want to zero s->map[i]->page[j] and putpage(pg),
             * but we have to make sure other processors flush the
             * entry from their TLBs before the page is freed.
             * We construct a list of the pages to be freed, zero
             * the entries, then (below) call procflushseg, and call
             * putpage on the whole list.
             *
             * Swapped-out pages don't appear in TLBs, so it's okay
             * to putswap those pages before procflushseg.
             */
            if(pg){
                if(onswap(pg))
                    putswap(pg);
                else{
                    pg->next = list;
                    list = pg;
                }
                s->map[i]->pages[j] = 0;
            }
            if(--pages == 0)
                goto out;
            j++;
        }
        j = 0;
    }
out:
    /* flush this seg in all other processes */
    if(s->ref > 1)
        procflushseg(s);

    /* free the pages */
    for(pg = list; pg != nil; pg = list){
        list = list->next;
        putpage(pg);
    }
}
@


\section{[[KImage]]}

<<struct KImage>>=
// a KImage is essentially a channel to a text file (an image of a binary)
// the image in memory for a portion of a given file.
// (renamed KImage to avoid name conflict with memdraw Image (picture) and avoid
//  ugly #define Image IMAGE each time one wants to use draw.h from a device driver)
struct KImage
{
    Chan  *c;     /* channel to text file */

    Qid   qid;      /* Qid for page cache coherence */

    Qid mqid;
    Chan  *mchan;
    ushort  type;     /* Device type of owning channel */
  
    bool  notext;     /* no file associated */
  
    // extra
    Ref;
    // list<ref<Kimage>> of Imagealloc.free?
    KImage  *next; /* Free list */ 
    // hash<?, list<ref<Kimage>>> Imagealloc.hash?
    KImage  *hash; /* Qid hash chains */ 
    // option<ref<Segment>>?
    Segment *s;     /* TEXT segment for image if running */
};
@

<<struct Imagealloc>>=
// Image allocator (internal to segment.c, but important so here, singleton)
struct Imagealloc
{
    // array<Kimage>?  xalloc'ed in initimage() (conf.nimage)
    KImage  *free; 
    // hash<?ihash(??), list<ref<Kimage>>
    KImage  *hash[IHASHSIZE];
    QLock ireclaim; /* mutex on reclaiming free images */
  
    Chan  **freechan; /* free image channels */
    int nfreechan;  /* number of free channels */
    int szfreechan; /* size of freechan array */
    QLock fcreclaim;  /* mutex on reclaiming free channels */
  
    // extra
    Lock;

};
@

<<global imagealloc>>=
static struct Imagealloc imagealloc;
@



<<function ihash>>=
#define IHASHSIZE 64
// actually internal to page.c, but important so here
#define ihash(s)  imagealloc.hash[s%IHASHSIZE]
@

<<function attachimage>>=
KImage*
attachimage(int type, Chan *c, ulong base, ulong len)
{
    KImage *i, **l;

    /* reclaim any free channels from reclaimed segments */
    if(imagealloc.nfreechan)
        imagechanreclaim();

    lock(&imagealloc);

    /*
     * Search the image cache for remains of the text from a previous
     * or currently running incarnation
     */
    for(i = ihash(c->qid.path); i; i = i->hash) {
        if(c->qid.path == i->qid.path) {
            lock(i);
            if(eqqid(c->qid, i->qid) &&
               eqqid(c->mqid, i->mqid) &&
               c->mchan == i->mchan &&
               c->type == i->type) {
                goto found;
            }
            unlock(i);
        }
    }

    /*
     * imagereclaim dumps pages from the free list which are cached by image
     * structures. This should free some image structures.
     */
    while(!(i = imagealloc.free)) {
        unlock(&imagealloc);
        imagereclaim();
        sched();
        lock(&imagealloc);
    }

    imagealloc.free = i->next;

    lock(i);
    incref(c);
    i->c = c;
    i->type = c->type;
    i->qid = c->qid;
    i->mqid = c->mqid;
    i->mchan = c->mchan;
    l = &ihash(c->qid.path);
    i->hash = *l;
    *l = i;
found:
    unlock(&imagealloc);

    if(i->s == 0) {
        /* Disaster after commit in exec */
        if(waserror()) {
            unlock(i);
            pexit(Enovmem, true);
        }
        i->s = newseg(type, base, len);
        i->s->image = i;
        i->ref++;
        poperror();
    }
    else
        incref(i->s);

    return i;
}
@


<<function imagereclaim>>=
static void
imagereclaim(void)
{
    int n;
    Page *p;
    uvlong ticks;

    irstats.calls++;
    /* Somebody is already cleaning the page cache */
    if(!canqlock(&imagealloc.ireclaim))
        return;

    lock(&palloc);
    ticks = fastticks(nil);
    n = 0;
    /*
     * All the pages with images backing them are at the
     * end of the list (see putpage) so start there and work
     * backward.
     */
    for(p = palloc.tail; p && p->image && n<1000; p = p->prev) {
        if(p->ref == 0 && canlock(p)) {
            if(p->ref == 0) {
                n++;
                uncachepage(p);
            }
            unlock(p);
        }
    }
    ticks = fastticks(nil) - ticks;
    unlock(&palloc);
    irstats.loops++;
    irstats.ticks += ticks;
    if(ticks > irstats.maxt)
        irstats.maxt = ticks;
    //print("T%llud+", ticks);
    qunlock(&imagealloc.ireclaim);
}
@


<<function imagechanreclaim>>=
/*
 *  since close can block, this has to be called outside of
 *  spin locks.
 */
static void
imagechanreclaim(void)
{
    Chan *c;

    /* Somebody is already cleaning the image chans */
    if(!canqlock(&imagealloc.fcreclaim))
        return;

    /*
     * We don't have to recheck that nfreechan > 0 after we
     * acquire the lock, because we're the only ones who decrement 
     * it (the other lock contender increments it), and there's only
     * one of us thanks to the qlock above.
     */
    while(imagealloc.nfreechan > 0){
        lock(&imagealloc);
        imagealloc.nfreechan--;
        c = imagealloc.freechan[imagealloc.nfreechan];
        unlock(&imagealloc);
        cclose(c);
    }

    qunlock(&imagealloc.fcreclaim);
}
@


<<destructor putimage>>=
void
putimage(KImage *i)
{
    Chan *c, **cp;
    KImage *f, **l;

    if(i->notext)
        return;

    lock(i);
    if(--i->ref == 0) {
        l = &ihash(i->qid.path);
        mkqid(&i->qid, ~0, ~0, QTFILE);
        unlock(i);
        c = i->c;

        lock(&imagealloc);
        for(f = *l; f; f = f->hash) {
            if(f == i) {
                *l = i->hash;
                break;
            }
            l = &f->hash;
        }

        i->next = imagealloc.free;
        imagealloc.free = i;

        /* defer freeing channel till we're out of spin lock's */
        if(imagealloc.nfreechan == imagealloc.szfreechan){
            imagealloc.szfreechan += NFREECHAN;
            cp = malloc(imagealloc.szfreechan*sizeof(Chan*));
            if(cp == nil)
                panic("putimage");
            memmove(cp, imagealloc.freechan, imagealloc.nfreechan*sizeof(Chan*));
            free(imagealloc.freechan);
            imagealloc.freechan = cp;
        }
        imagealloc.freechan[imagealloc.nfreechan++] = c;
        unlock(&imagealloc);

        return;
    }
    unlock(i);
}
@


\section{[[sysbrk()]]}

<<syscall brk>>=
// int brk(void*);
long
sysbrk(ulong *arg)
{
    return ibrk(arg[0], BSEG);
}
@ 

<<function ibrk>>=
long
ibrk(ulong addr, int seg)
{
    Segment *s, *ns;
    ulong newtop, newsize;
    int i, mapsize;
    Pte **map;

    s = up->seg[seg];
    if(s == 0)
        error(Ebadarg);

    if(addr == nilptr)
        return s->base;

    qlock(&s->lk);

    /* We may start with the bss overlapping the data */
    if(addr < s->base) {
        if(seg != BSEG || up->seg[DSEG] == 0 || addr < up->seg[DSEG]->base) {
            qunlock(&s->lk);
            error(Enovmem);
        }
        addr = s->base;
    }

    newtop = PGROUND(addr);
    newsize = (newtop-s->base)/BY2PG;
    if(newtop < s->top) {
        /*
         * do not shrink a segment shared with other procs, as the
         * to-be-freed address space may have been passed to the kernel
         * already by another proc and is past the validaddr stage.
         */
        if(s->ref > 1){
            qunlock(&s->lk);
            error(Einuse);
        }
        mfreeseg(s, newtop, (s->top-newtop)/BY2PG);
        s->top = newtop;
        s->size = newsize;
        qunlock(&s->lk);
        flushmmu();
        return 0;
    }

    for(i = 0; i < NSEG; i++) {
        ns = up->seg[i];
        if(ns == 0 || ns == s)
            continue;
        if(newtop >= ns->base && newtop < ns->top) {
            qunlock(&s->lk);
            error(Esoverlap);
        }
    }

    if(newsize > (SEGMAPSIZE*PTEPERTAB)) {
        qunlock(&s->lk);
        error(Enovmem);
    }
    mapsize = ROUND(newsize, PTEPERTAB)/PTEPERTAB;
    if(mapsize > s->mapsize){
        map = smalloc(mapsize*sizeof(Pte*));
        memmove(map, s->map, s->mapsize*sizeof(Pte*));
        if(s->map != s->ssegmap)
            free(s->map);
        s->map = map;
        s->mapsize = mapsize;
    }

    s->top = newtop;
    s->size = newsize;
    qunlock(&s->lk);
    return 0;
}
@

\chapter{Processes}
\minitoc

<<systab process syscalls>>=
    [RFORK]     sysrfork,
    [EXEC]      sysexec,
    [EXITS]     sysexits,
    [AWAIT]     sysawait,
@ 

\section{Overview}

\section{[[Proc]]}

<<struct Procalloc>>=
struct Procalloc
{
    // array<Proc>, xalloc'ed in procinit() (conf.nproc)
    Proc* arena;
  
    // list<ref<Proc>> (next = ?)
    Proc* free;
    // hash<Proc.pid?, list<ref<Proc>> (next = Proc.pidhash)>
    Proc* ht[128];
  
    // extra
    Lock;
};
@ 

<<[[Proc]] extra fields>>=
// hash<?, list<ref<Proc>> Procalloc.ht
Proc  *pidhash; /* next proc in pid hash */ 
@

<<global procalloc>>=
static struct Procalloc procalloc;
@ 

<<function pidhash>>=
static void
pidhash(Proc *p)
{
    int h;

    h = p->pid % nelem(procalloc.ht);
    lock(&procalloc);
    p->pidhash = procalloc.ht[h];
    procalloc.ht[h] = p;
    unlock(&procalloc);
}
@ 


<<function pidunhash>>=
static void
pidunhash(Proc *p)
{
    int h;
    Proc **l;

    h = p->pid % nelem(procalloc.ht);
    lock(&procalloc);
    for(l = &procalloc.ht[h]; *l != nil; l = &(*l)->pidhash)
        if(*l == p){
            *l = p->pidhash;
            break;
        }
    unlock(&procalloc);
}
@ 


<<function procindex>>=
int
procindex(ulong pid)
{
    Proc *p;
    int h;
    int s;

    s = -1;
    h = pid % nelem(procalloc.ht);
    lock(&procalloc);
    for(p = procalloc.ht[h]; p != nil; p = p->pidhash)
        if(p->pid == pid){
            s = p - procalloc.arena;
            break;
        }
    unlock(&procalloc);
    return s;
}
@ 


<<global pidalloc>>=
static Counter  pidalloc;
@ 

<<global noteidalloc>>=
// also used by sysrfork()
Counter noteidalloc;
@ 

<<enum procstate cases>>=
Scheding,
@

% dtor = pexit() + schedinit
<<constructor newproc>>=
Proc*
newproc(void)
{
    char msg[64];
    Proc *p;

    lock(&procalloc);
    while((p = procalloc.free) == nil) {
        unlock(&procalloc);

        snprint(msg, sizeof msg, "no procs; %s forking",
            up? up->text: "kernel");
        /*
         * the situation is unlikely to heal itself.
         * dump the proc table and restart by default.
         * *noprocspersist in plan9.ini will yield the old
         * behaviour of trying forever.
         */
        if(getconf("*noprocspersist") == nil)
            noprocpanic(msg);
        resrcwait(msg);
        lock(&procalloc);
    }
    procalloc.free = p->qnext;
    unlock(&procalloc);

    p->state = Scheding;
    p->psstate = "New";
    p->cpu = nil;
    p->qnext = 0;
    p->nchild = 0;
    p->nwait = 0;
    p->waitq = 0;
    p->parent = nil;
    p->pgrp = nil;
    p->egrp = nil;
    p->fgrp = nil;
    p->rgrp = nil;
    p->pdbg = nil;
    p->fpstate = FPinit;
    p->kp = 0;
    <<[[newproc()]] inherit Proc_tracesyscall>>
    p->syscalltrace = nil;    
    p->notepending = false;
    p->ureg = 0;
    p->privatemem = false;
    p->noswap = false;
    p->errstr = p->errbuf0;
    p->syserrstr = p->errbuf1;
    p->errbuf0[0] = '\0';
    p->errbuf1[0] = '\0';
    p->nlocks.ref = 0;
    p->delaysched = 0;
    p->trace = false;
    kstrdup(&p->user, "*nouser");
    kstrdup(&p->text, "*notext");
    kstrdup(&p->args, "");
    p->nargs = 0;
    p->setargs = false;
    memset(p->seg, 0, sizeof p->seg);
    p->pid = incref(&pidalloc);
    pidhash(p);
    p->noteid = incref(&noteidalloc);
    if(p->pid==0 || p->noteid==0)
        panic("pidalloc");
    if(p->kstack == nil)
        p->kstack = smalloc(KSTACK);

    /* sched params */
    p->lastcpu = nil;
    p->wired = nil;
    procpriority(p, PriNormal, false);
    p->cpuavg = 0;
    p->lastupdate = CPUS(0)->ticks*Scaling;
    p->edf = nil;

    return p;
}
@ 

<<function noprocpanic>>=
void
noprocpanic(char *msg)
{
    /*
     * setting exiting will make hzclock() on each processor call exit(0).
     * clearing our bit in cpus avoids calling exit(0) from hzclock()
     * on this processor.
     */
    lock(&active);
    active.cpus &= ~(1<<cpu->cpuno);
    active.exiting = true;
    unlock(&active);

    procdump();
    delay(1000);
    panic(msg);
}
@ 


\section{The user}

\section{[[sysfork()]]}

<<enum rfork>>=
//coupling: with libc.h
enum rfork
{
    RFNAMEG     = (1<<0),
    RFENVG      = (1<<1),
    RFFDG       = (1<<2),
    RFNOTEG     = (1<<3),
    RFPROC      = (1<<4),
    RFMEM       = (1<<5),
    RFNOWAIT    = (1<<6),
    RFCNAMEG    = (1<<10),
    RFCENVG     = (1<<11),
    RFCFDG      = (1<<12),
    RFREND      = (1<<13),
    RFNOMNT     = (1<<14),
};
@ 


<<function forkchild>>=
void
forkchild(Proc *p, Ureg *ureg)
{
    Ureg *cureg;

    /*
     * Add 2*BY2WD to the stack to account for
     *  - the return PC
     *  - trap's argument (ur)
     */
    p->sched.sp = (ulong)p->kstack+KSTACK-(sizeof(Ureg)+2*BY2WD);
    p->sched.pc = (ulong)forkret;

    cureg = (Ureg*)(p->sched.sp+2*BY2WD);
    memmove(cureg, ureg, sizeof(Ureg));
    /* return value of syscall in child */
    cureg->ax = 0;

    /* Things from bottom of syscall which were never executed */
    p->psstate = nil;
    p->insyscall = false;
}
@ 

<<function forkret>>=
TEXT forkret(SB), $0
        POPL    AX
        POPAL
        POPL    GS
        POPL    FS
        POPL    ES
        POPL    DS
        ADDL    $8, SP                  /* pop error code and trap type */
        IRETL
@ 

<<syscall rfork>>=
// int rfork(int flags);
long
sysrfork(ulong *arg)
{
    Proc *p;
    int n, i;
    Fgrp *ofg;
    Pgrp *opg;
    Rgrp *org;
    Egrp *oeg;
    ulong pid, flag;
    Cpu *wm;

    flag = arg[0];
    /* Check flags before we commit */
    if((flag & (RFFDG|RFCFDG)) == (RFFDG|RFCFDG))
        error(Ebadarg);
    if((flag & (RFNAMEG|RFCNAMEG)) == (RFNAMEG|RFCNAMEG))
        error(Ebadarg);
    if((flag & (RFENVG|RFCENVG)) == (RFENVG|RFCENVG))
        error(Ebadarg);

    if((flag&RFPROC) == 0) {
        if(flag & (RFMEM|RFNOWAIT))
            error(Ebadarg);
        if(flag & (RFFDG|RFCFDG)) {
            ofg = up->fgrp;
            if(flag & RFFDG)
                up->fgrp = dupfgrp(ofg);
            else
                up->fgrp = dupfgrp(nil);
            closefgrp(ofg);
        }
        if(flag & (RFNAMEG|RFCNAMEG)) {
            opg = up->pgrp;
            up->pgrp = newpgrp();
            if(flag & RFNAMEG)
                pgrpcpy(up->pgrp, opg);
            /* inherit noattach */
            up->pgrp->noattach = opg->noattach;
            closepgrp(opg);
        }
        if(flag & RFNOMNT)
            up->pgrp->noattach = 1;
        if(flag & RFREND) {
            org = up->rgrp;
            up->rgrp = newrgrp();
            closergrp(org);
        }
        if(flag & (RFENVG|RFCENVG)) {
            oeg = up->egrp;
            up->egrp = smalloc(sizeof(Egrp));
            up->egrp->ref = 1;
            if(flag & RFENVG)
                envcpy(up->egrp, oeg);
            closeegrp(oeg);
        }
        if(flag & RFNOTEG)
            up->noteid = incref(&noteidalloc);
        return 0;
    }

    p = newproc();

    p->fpsave = up->fpsave;
    p->sargs = up->sargs;
    p->nerrlab = 0;
    p->slash = up->slash;
    p->dot = up->dot;
    incref(p->dot);

    memmove(p->note, up->note, sizeof(p->note));
    p->privatemem = up->privatemem;
    p->noswap = up->noswap;
    p->nnote = up->nnote;
    p->notified = 0;
    p->lastnote = up->lastnote;
    p->notify = up->notify;
    p->ureg = up->ureg;
    p->dbgreg = nil;

    /* Make a new set of memory segments */
    n = flag & RFMEM;
    qlock(&p->seglock);
    if(waserror()){
        qunlock(&p->seglock);
        nexterror();
    }
    for(i = 0; i < NSEG; i++)
        if(up->seg[i])
            p->seg[i] = dupseg(up->seg, i, n);
    qunlock(&p->seglock);
    poperror();

    /* File descriptors */
    if(flag & (RFFDG|RFCFDG)) {
        if(flag & RFFDG)
            p->fgrp = dupfgrp(up->fgrp);
        else
            p->fgrp = dupfgrp(nil);
    }
    else {
        p->fgrp = up->fgrp;
        incref(p->fgrp);
    }

    /* Process groups */
    if(flag & (RFNAMEG|RFCNAMEG)) {
        p->pgrp = newpgrp();
        if(flag & RFNAMEG)
            pgrpcpy(p->pgrp, up->pgrp);
        /* inherit noattach */
        p->pgrp->noattach = up->pgrp->noattach;
    }
    else {
        p->pgrp = up->pgrp;
        incref(p->pgrp);
    }
    if(flag & RFNOMNT)
        p->pgrp->noattach = 1;

    if(flag & RFREND)
        p->rgrp = newrgrp();
    else {
        incref(up->rgrp);
        p->rgrp = up->rgrp;
    }

    /* Environment group */
    if(flag & (RFENVG|RFCENVG)) {
        p->egrp = smalloc(sizeof(Egrp));
        p->egrp->ref = 1;
        if(flag & RFENVG)
            envcpy(p->egrp, up->egrp);
    }
    else {
        p->egrp = up->egrp;
        incref(p->egrp);
    }
    <<[[sysfork()]] inherit hang>>
    p->procmode = up->procmode;

    /* Craft a return frame which will cause the child to pop out of
     * the scheduler in user mode with the return register zero
     */
    forkchild(p, up->dbgreg);

    p->parent = up;
    p->parentpid = up->pid;
    if(flag&RFNOWAIT)
        p->parentpid = 0;
    else {
        lock(&up->exl);
        up->nchild++;
        unlock(&up->exl);
    }
    if((flag&RFNOTEG) == 0)
        p->noteid = up->noteid;

    /* don't penalize the child, it hasn't done FP in a note handler. */
    p->fpstate = up->fpstate & ~FPillegal;
    pid = p->pid;
    memset(p->time, 0, sizeof(p->time));
    p->time[TReal] = CPUS(0)->ticks;

    kstrdup(&p->text, up->text);
    kstrdup(&p->user, up->user);
    /*
     *  since the bss/data segments are now shareable,
     *  any mmu info about this process is now stale
     *  (i.e. has bad properties) and has to be discarded.
     */
    flushmmu();
    p->basepri = up->basepri;
    p->priority = up->basepri;
    p->fixedpri = up->fixedpri;
    p->lastcpu = up->lastcpu;
    wm = up->wired;
    if(wm)
        procwired(p, wm->cpuno);
    ready(p);
    sched();
    return pid;
}
@ 


\section{[[sysexec()]]}

<<constant AOUT_MAGIC>>=
/*
 *  parameters for sysproc.c
 */
// I_MAGIC is defined in include/a.out.h
#define AOUT_MAGIC  (I_MAGIC)
@

<<[[Proc]] state fields>>=
char  *args;
int nargs;    /* number of bytes of args */
@

<<syscall exec>>=
// void* exec(char *name, char* argv[]);
long
sysexec(ulong *arg)
{
    Segment *s, *ts;
    ulong t, d, b;
    int i;
    Chan *tc;
    char **argv, **argp;
    char *a, *charp, *args, *file, *file0;
    char *progarg[sizeof(Exec)/2+1], *elem, progelem[64];
    ulong ssize, spage, nargs, nbytes, n, bssend;
    int indir;
    Exec exec;
    char line[sizeof(Exec)];
    Fgrp *f;
    KImage *img;
    ulong magic, text, entry, data, bss;
    Tos *tos;

    indir = 0;
    elem = nil;
    validaddr(arg[0], 1, 0);
    file0 = validnamedup((char*)arg[0], 1);
    if(waserror()){
        free(file0);
        free(elem);
        nexterror();
    }
    file = file0;
    for(;;){
        tc = namec(file, Aopen, OEXEC, 0);
        if(waserror()){
            cclose(tc);
            nexterror();
        }
        if(!indir)
            kstrdup(&elem, up->genbuf);

        n = devtab[tc->type]->read(tc, &exec, sizeof(Exec), 0);
        if(n < 2)
            error(Ebadexec);
        magic = l2be(exec.magic);
        text = l2be(exec.text);
        entry = l2be(exec.entry);
        if(n==sizeof(Exec) && (magic == AOUT_MAGIC)){
            if(text >= USTKTOP-UTZERO
            || entry < UTZERO+sizeof(Exec)
            || entry >= UTZERO+sizeof(Exec)+text)
                error(Ebadexec);
            break; /* for binary */
        }

        /*
         * Process #! /bin/sh args ...
         */
        memmove(line, &exec, sizeof(Exec));
        if(indir || line[0]!='#' || line[1]!='!')
            error(Ebadexec);
        n = shargs(line, n, progarg);
        if(n == 0)
            error(Ebadexec);
        indir = 1;
        /*
         * First arg becomes complete file name
         */
        progarg[n++] = file;
        progarg[n] = 0;
        validaddr(arg[1], BY2WD, 1);
        arg[1] += BY2WD;
        file = progarg[0];
        if(strlen(elem) >= sizeof progelem)
            error(Ebadexec);
        strcpy(progelem, elem);
        progarg[0] = progelem;
        poperror();
        cclose(tc);
    }

    data = l2be(exec.data);
    bss = l2be(exec.bss);
    t = UTROUND(UTZERO+sizeof(Exec)+text);
    d = (t + data + (BY2PG-1)) & ~(BY2PG-1);
    bssend = t + data + bss;
    b = (bssend + (BY2PG-1)) & ~(BY2PG-1);
    if(t >= KZERO || d >= KZERO || b >= KZERO)
        error(Ebadexec);

    /*
     * Args: pass 1: count
     */
    nbytes = sizeof(Tos);       /* hole for profiling clock at top of stack (and more) */
    nargs = 0;
    if(indir){
        argp = progarg;
        while(*argp){
            a = *argp++;
            nbytes += strlen(a) + 1;
            nargs++;
        }
    }
    evenaddr(arg[1]);
    argp = (char**)arg[1];
    validaddr((ulong)argp, BY2WD, 0);
    while(*argp){
        a = *argp++;
        if(((ulong)argp&(BY2PG-1)) < BY2WD)
            validaddr((ulong)argp, BY2WD, 0);
        validaddr((ulong)a, 1, 0);
        nbytes += ((char*)vmemchr(a, 0, 0x7FFFFFFF) - a) + 1;
        nargs++;
    }
    ssize = BY2WD*(nargs+1) + ((nbytes+(BY2WD-1)) & ~(BY2WD-1));

    /*
     * 8-byte align SP for those (e.g. sparc) that need it.
     * execregs() will subtract another 4 bytes for argc.
     */
    if((ssize+4) & 7)
        ssize += 4;
    spage = (ssize+(BY2PG-1)) >> PGSHIFT;

    /*
     * Build the stack segment, putting it in kernel virtual for the moment
     */
    if(spage > TSTKSIZ)
        error(Enovmem);

    qlock(&up->seglock);
    if(waserror()){
        qunlock(&up->seglock);
        nexterror();
    }
    up->seg[ESEG] = newseg(SG_STACK, TSTKTOP-USTKSIZE, USTKSIZE/BY2PG);

    /*
     * Args: pass 2: assemble; the pages will be faulted in
     */
    tos = (Tos*)(TSTKTOP - sizeof(Tos));
    tos->cyclefreq = cpu->cyclefreq;
    cycles((uvlong*)&tos->pcycles);
    tos->pcycles = -tos->pcycles;
    tos->kcycles = tos->pcycles;
    tos->clock = 0;
    argv = (char**)(TSTKTOP - ssize);
    charp = (char*)(TSTKTOP - nbytes);
    args = charp;
    if(indir)
        argp = progarg;
    else
        argp = (char**)arg[1];

    for(i=0; i<nargs; i++){
        if(indir && *argp==0) {
            indir = 0;
            argp = (char**)arg[1];
        }
        *argv++ = charp + (USTKTOP-TSTKTOP);
        n = strlen(*argp) + 1;
        memmove(charp, *argp++, n);
        charp += n;
    }
    free(file0);

    free(up->text);
    up->text = elem;
    elem = nil; /* so waserror() won't free elem */
    USED(elem);

    /* copy args; easiest from new process's stack */
    n = charp - args;
    if(n > 128) /* don't waste too much space on huge arg lists */
        n = 128;
    a = up->args;
    up->args = nil;
    free(a);
    up->args = smalloc(n);
    memmove(up->args, args, n);
    if(n>0 && up->args[n-1]!='\0'){
        /* make sure last arg is NUL-terminated */
        /* put NUL at UTF-8 character boundary */
        for(i=n-1; i>0; --i)
            if(fullrune(up->args+i, n-i))
                break;
        up->args[i] = 0;
        n = i+1;
    }
    up->nargs = n;

    /*
     * Committed.
     * Free old memory.
     * Special segments are maintained across exec
     */
    for(i = SSEG; i <= BSEG; i++) {
        putseg(up->seg[i]);
        /* prevent a second free if we have an error */
        up->seg[i] = 0;
    }
    for(i = BSEG+1; i < NSEG; i++) {
        s = up->seg[i];
        if(s != 0 && (s->type&SG_CEXEC)) {
            putseg(s);
            up->seg[i] = 0;
        }
    }

    /*
     * Close on exec
     */
    f = up->fgrp;
    for(i=0; i<=f->maxfd; i++)
        fdclose(i, CCEXEC);

    /* Text.  Shared. Attaches to cache image if possible */
    /* attachimage returns a locked cache image */
    img = attachimage(SG_TEXT|SG_RONLY, tc, UTZERO, (t-UTZERO)>>PGSHIFT);
    ts = img->s;
    up->seg[TSEG] = ts;
    ts->flushme = 1;
    ts->fstart = 0;
    ts->flen = sizeof(Exec)+text;
    unlock(img);

    /* Data. Shared. */
    s = newseg(SG_DATA, t, (d-t)>>PGSHIFT);
    up->seg[DSEG] = s;

    /* Attached by hand */
    incref(img);
    s->image = img;
    s->fstart = ts->fstart+ts->flen;
    s->flen = data;

    /* BSS. Zero fill on demand */
    up->seg[BSEG] = newseg(SG_BSS, d, (b-d)>>PGSHIFT);

    /*
     * Move the stack
     */
    s = up->seg[ESEG];
    up->seg[ESEG] = 0;
    up->seg[SSEG] = s;
    qunlock(&up->seglock);
    poperror(); /* seglock */
    poperror(); /* elem */
    s->base = USTKTOP-USTKSIZE;
    s->top = USTKTOP;
    relocateseg(s, USTKTOP-TSTKTOP);

    /*
     *  '/' processes are higher priority (hack to make /ip more responsive).
     */
    if(devtab[tc->type]->dc == L'/')
        up->basepri = PriRoot;
    up->priority = up->basepri;
    poperror();
    cclose(tc);

    /*
     *  At this point, the mmu contains info about the old address
     *  space and needs to be flushed
     */
    flushmmu();

    qlock(&up->debug);
    up->nnote = 0;
    up->notify = 0;
    up->notified = 0;
    up->privatemem = false;
    procsetup(up);
    qunlock(&up->debug);

    <<[[sysexec()]] if hang>>

    return execregs(entry, ssize, nargs);
}
@ 

<<function l2be>>=
ulong
l2be(long l)
{
    uchar *cp;

    cp = (uchar*)&l;
    return (cp[0]<<24) | (cp[1]<<16) | (cp[2]<<8) | cp[3];
}
@ 
% >> >> >>

<<function execregs>>=
long
execregs(ulong entry, ulong ssize, ulong nargs)
{
    ulong *sp;
    Ureg *ureg;

    up->fpstate = FPinit;
    fpoff();

    sp = (ulong*)(USTKTOP - ssize);
    *--sp = nargs;

    ureg = up->dbgreg;
    ureg->usp = (ulong)sp;
    ureg->pc = entry;
    return USTKTOP-sizeof(Tos);     /* address of kernel/user shared data */
}
@ 

<<function shargs>>=
int
shargs(char *s, int n, char **ap)
{
    int i;

    s += 2;
    n -= 2;     /* skip #! */
    for(i=0; s[i]!='\n'; i++)
        if(i == n-1)
            return 0;
    s[i] = 0;
    *ap = 0;
    i = 0;
    for(;;) {
        while(*s==' ' || *s=='\t')
            s++;
        if(*s == 0)
            break;
        i++;
        *ap++ = s;
        *ap = 0;
        while(*s && *s!=' ' && *s!='\t')
            s++;
        if(*s == 0)
            break;
        else
            *s++ = 0;
    }
    return i;
}
@ 



\section{[[sysawait()]]}
% better show sysawait before sysexits, parent point of view, then child pov

% can have zombies in plan9? no ... if parent exit
% and have blocked children (on a pipe) then those children
% will never finish? no they should finish because the fd of the pipe
% will have been closed

<<[[Proc]] hierarchy fields>>=
Proc  *parent;
int nchild;   /* Number of living children */
@
% subtle: I think it's useful to also have parentpid field because
% the parent may have died, and so freed in procalloc and then
% reused for another process!

<<[[Proc]] hierarchy fields>>=
// list<ref_own<Waitq>>> =~ list<ref_own<Waitmsg>>
Waitq *waitq;   /* Exited processes wait children */
int nwait;    /* Number of uncollected wait records */ // len(waitq)
Lock  exl;    /* Lock count and waitq */
@

<<struct Waitmsg>>=
struct Waitmsg
{
  int pid;    /* of loved one */ // pid of the child
  ulong time[3];  /* of loved one and descendants */
  char  msg[ERRMAX];  /* actually variable-size in user mode */
};
@ 

<<struct Waitq>>=
// essentially a stack<ref_own<Waitmsg>>
struct Waitq
{
    Waitmsg w;
  
    // extra
    // list<ref_own<Waitq>> Proc.waitq
    Waitq *next;
};
@ 

<<[[Proc]] hierarchy fields>>=
Rendez  waitr;    /* Place to hang out in wait */
@ 

% when canqlock return false? who else access qwaitr? users via /proc/!
% seems too subtle the need for this
% put with the code for Qwait if want to talk about it
<<[[Proc]] hierarchy fields>>=
QLock qwaitr;
@

<<syscall await>>=
// int await(char *s, int n);
long
sysawait(ulong *arg)
{
    int i;
    int pid;
    Waitmsg w; // allocated in stack!
    ulong n;

    n = arg[1];
    validaddr(arg[0], n, 1);
    pid = pwait(&w);
    if(pid < 0)
        return -1;
    i = snprint((char*)arg[0], n, "%d %lud %lud %lud %q",
        w.pid,
        w.time[TUser], w.time[TSys], w.time[TReal],
        w.msg);

    return i;
}
@ 

<<function pwait>>=
ulong
pwait(Waitmsg *w)
{
    ulong cpid; // child pid
    Waitq *wq;

    if(!canqlock(&up->qwaitr))
        error(Einuse); // someone is reading /proc/pid/wait?

    if(waserror()) {
        qunlock(&up->qwaitr);
        nexterror();
    }

    lock(&up->exl);
    if(up->nchild == 0 && up->waitq == nil) {
        unlock(&up->exl);
        error(Enochild);
    }
    unlock(&up->exl);

    sleep(&up->waitr, haswaitq, up); // qwaitr is still locked

    // wq = pop(up->waitq), // can't be null, see haswaitq()
    lock(&up->exl);
    wq = up->waitq; 
    up->waitq = wq->next;
    up->nwait--;
    unlock(&up->exl);

    qunlock(&up->qwaitr);
    poperror();

    if(w)
        memmove(w, &wq->w, sizeof(Waitmsg));
    cpid = wq->w.pid;
    free(wq);
    return cpid;
}
@ 


<<function haswaitq>>=
int
haswaitq(void *x)
{
    Proc *p;
    p = (Proc *)x;
    return p->waitq != nil;
}
@ 


\section{[[sysexits()]]}

% semantic of exits? what happens if still have children?
% the children will still be there! the parent closes all its
% filedescriptor but if have pipe with children, then the pipe
% will still be there and have hanging process?

<<syscall exits>>=
// void exits(char *msg);
long
sysexits(ulong *arg)
{
    char *status;
    char *inval = "invalid exit string";
    char buf[ERRMAX];

    status = (char*)arg[0];
    if(status){
        if(waserror())
            status = inval;
        else{
            validaddr((ulong)status, 1, 0);
            if(vmemchr(status, 0, ERRMAX) == 0){
                memmove(buf, status, ERRMAX);
                buf[ERRMAX-1] = 0;
                status = buf;
            }
            poperror();
        }

    }
    pexit(status, true);
    panic("pexit: should never reach this point");
}
@ 

% != Dead. Why the logic of killing process is split in pexit()
% here and schedinit()? Because to kill a process we need to free
% everything, but right now we are executing code using the per-process
% kernel stack itself, so by going to schedinit() we switch to
% the main kernel stack which is exterior to the process.
% Note that we never free the per-process kernel stack so we could
% in theory get rid of schedinit, but maybe it's more elegant that way.

<<enum procstate cases>>=
Moribund,
@

% todo: split in purely deallocate stuff and then the children/parent part
% todo: rename freemem to addbroken? and reverse true to false and false to true
<<function pexit>>=
void
proc_pexit(char *exitstr, bool freemem)
{
    Proc *p; // parent
    Segment **s, **es;
    long utime, stime;
    Waitq *wq, *f, *next;
    Fgrp *fgrp;
    Egrp *egrp;
    Rgrp *rgrp;
    Pgrp *pgrp;
    Chan *dot;
    void (*pt)(Proc*, int, vlong);

    if(up->syscalltrace)
        free(up->syscalltrace);
    up->alarm = 0;
    if (up->tt)
        timerdel(up);

    <<[[pexit()]] hook proctrace>>

    /* nil out all the resources under lock (free later) */
    qlock(&up->debug);
    fgrp = up->fgrp;
    up->fgrp = nil;
    egrp = up->egrp;
    up->egrp = nil;
    rgrp = up->rgrp;
    up->rgrp = nil;
    pgrp = up->pgrp;
    up->pgrp = nil;
    dot = up->dot;
    up->dot = nil;
    qunlock(&up->debug);

    if(fgrp)
        closefgrp(fgrp);
    if(egrp)
        closeegrp(egrp);
    if(rgrp)
        closergrp(rgrp);
    if(dot)
        cclose(dot);
    if(pgrp)
        closepgrp(pgrp);

    /*
     * if not a kernel process and have a parent,
     * do some housekeeping.
     */
    if(up->kp == false) {
        p = up->parent;
        // no parent pointer, must be the very first process
        if(p == nil) {
            if(exitstr == 0)
                exitstr = "unknown";
            panic("boot process died: %s", exitstr);
        }

        while(waserror())
            ;

        wq = smalloc(sizeof(Waitq));
        poperror();

        wq->w.pid = up->pid;
        utime = up->time[TUser] + up->time[TCUser];
        stime = up->time[TSys] + up->time[TCSys];
        wq->w.time[TUser] = tk2ms(utime);
        wq->w.time[TSys] = tk2ms(stime);
        wq->w.time[TReal] = tk2ms(CPUS(0)->ticks - up->time[TReal]);
        if(exitstr && exitstr[0])
            snprint(wq->w.msg, sizeof(wq->w.msg), "%s %lud: %s", up->text, up->pid, exitstr);
        else
            wq->w.msg[0] = '\0';

        lock(&p->exl);
        /*
         * Check that parent is still alive.
         */
        // the parent pointer may not be your parent anymore, the parent
        // could have died and its slot reallocated to another process
        if(p->pid == up->parentpid && p->state != Broken) {
            p->nchild--;
            p->time[TCUser] += utime;
            p->time[TCSys] += stime;
            /*
             * If there would be more than 128 wait records
             * processes for my parent, then don't leave a wait
             * record behind.  This helps prevent badly written
             * daemon processes from accumulating lots of wait
             * records.
             */
            if(p->nwait < 128) {
                // push(wq, p->waitq)
                wq->next = p->waitq;
                p->waitq = wq;
                p->nwait++;

                wq = nil; // the parent will do the free
                wakeup(&p->waitr); // haswaitq() is true now
            }
        }
        unlock(&p->exl);
        if(wq)
            free(wq);
    }

    //?
    if(!freemem)
        addbroken(up); // will call sched()

    qlock(&up->seglock);
    //todo: rewrite using nelem(seg?)
    es = &up->seg[NSEG];
    for(s = up->seg; s < es; s++) {
        if(*s) {
            putseg(*s);
            *s = nil;
        }
    }
    qunlock(&up->seglock);

    lock(&up->exl);     /* Prevent my children from leaving waits */
    pidunhash(up);
    // so my children will not generate a waitq, I will not be here anymore
    up->pid = 0; 
    wakeup(&up->waitr); // wakeup process reading /proc/pid/wait
    unlock(&up->exl);

    for(f = up->waitq; f; f = next) {
        next = f->next;
        free(f);
    }

    /* release debuggers */
    qlock(&up->debug);
    if(up->pdbg) {
        wakeup(&up->pdbg->sleepr);
        up->pdbg = nil;
    }
    qunlock(&up->debug);

    /* Sched must not loop for these locks */
    lock(&procalloc);
    lock(&palloc);

    <<[[pexit()]] optional [[edfstop()]] for real-time scheduling>>
    up->state = Moribund;
    // will gotolabel() to schedinit() which has special code around Moribund
    sched(); 
    panic("pexit: should never reach this point"); 
}
@ 
% (why not doing more simply gotolabel(cpu->sched)? to reuse some of
%  sched() code?)

% What about zombie process? There is no zombie in plan9!
% Nicer design! the child write in the parent (if it has still one)
% the information the parent may need and then die!

\section{Broken processes}
% zombie processes? no, it's different.

<<enum procstate cases>>=
Broken,
@

<<struct Broken>>=
/*
 * weird thing: keep at most NBROKEN around
 */
#define NBROKEN 4
struct Broken
{
    // array<ref<Proc>>
    Proc    *p[NBROKEN];
    // number of entries used in p
    int n;

    // extra
    QLock;
};
@ 

<<global broken>>=
struct Broken broken;
@ 

<<function addbroken>>=
void
addbroken(Proc *p)
{
    qlock(&broken);
    if(broken.n == NBROKEN) {
        ready(broken.p[0]);
        memmove(&broken.p[0], &broken.p[1], sizeof(Proc*)*(NBROKEN-1));
        --broken.n;
    }
    broken.p[broken.n++] = p;
    qunlock(&broken);

    edfstop(up);
    p->state = Broken;
    p->psstate = nil;
    sched();
}
@ 


<<function unbreak>>=
void
unbreak(Proc *p)
{
    int b;

    qlock(&broken);
    for(b=0; b < broken.n; b++)
        if(broken.p[b] == p) {
            broken.n--;
            memmove(&broken.p[b], &broken.p[b+1],
                    sizeof(Proc*)*(NBROKEN-(b+1)));
            ready(p);
            break;
        }
    qunlock(&broken);
}
@ 


<<function freebroken>>=
int
freebroken(void)
{
    int i, n;

    qlock(&broken);
    n = broken.n;
    for(i=0; i<n; i++) {
        ready(broken.p[i]);
        broken.p[i] = nil;
    }
    broken.n = 0;
    qunlock(&broken);
    return n;
}
@ 

\section{Kernel processes}

<<[[Proc]] other fields>>=
bool kp;   /* true if a kernel process */
void  (*kpfun)(void*);
void  *kparg;
@

<<function kproc>>=
// kernel process (aka kernel_thread in Linux?)
void
kproc(char *name, void (*func)(void *), void *arg)
{
    Proc *p;
    static Pgrp *kpgrp;

    p = newproc();
    p->psstate = nil;
    p->procmode = 0640;
    p->kp = true; // Kernel Process
    p->noswap = true;

    p->fpsave = up->fpsave;
    p->sargs = up->sargs;
    p->nerrlab = 0;
    p->slash = up->slash;
    p->dot = up->dot;
    if(p->dot)
        incref(p->dot);

    memmove(p->note, up->note, sizeof(p->note));
    p->nnote = up->nnote;
    p->notified = 0;
    p->lastnote = up->lastnote;
    p->notify = up->notify;
    p->ureg = 0;
    p->dbgreg = nil;

    procpriority(p, PriKproc, false);

    kprocchild(p, func, arg);

    kstrdup(&p->user, eve);
    kstrdup(&p->text, name);
    if(kpgrp == 0)
        kpgrp = newpgrp();
    p->pgrp = kpgrp;
    incref(kpgrp);

    memset(p->time, 0, sizeof(p->time));
    p->time[TReal] = CPUS(0)->ticks;
    ready(p);
}
@ 

<<function linkproc>>=
static void
linkproc(void)
{
    spllo();
    up->kpfun(up->kparg);
    // should never reach this place?? kernel processes are supposed
    // to run forever??

    pexit("kproc dying", false); 
}
@ 


<<function kprocchild>>=
void
kprocchild(Proc* p, void (*func)(void*), void* arg)
{
    /*
     * gotolabel() needs a word on the stack in
     * which to place the return PC used to jump
     * to linkproc().
     */
    p->sched.pc = (ulong)linkproc;
    p->sched.sp = (ulong)p->kstack+KSTACK-BY2WD;

    p->kpfun = func;
    p->kparg = arg;
}
@ 

\chapter{Interrupts}
\minitoc

\section{Overview}

\section{[[Vctl]]}


<<struct Vctl>>=
struct Vctl {

    bool isintr;     /* interrupt or fault/trap */
    int irq;
  
    void  (*f)(Ureg*, void*); /* handler to call */
    void* a;      /* argument to call it with */
  
    char  name[KNAMELEN];   /* of driver */
    int tbdf; // /* type+bus+device+function */ ??
  
    // interrupt service routine
    int (*isr)(int);    /* get isr bit for this irq */
    int (*eoi)(int);    /* eoi */
  
    // extra
  
    // list<Vctl> of vctl[vno], xalloc'ed (should not have that many so ok)
    Vctl* next;     /* handlers on this vector */
};
@

<<global vctl>>=
static Vctl *vctl[256];
@ 

<<global vctllock>>=
static Lock vctllock;
@ 

<<function intrenable>>=
void
intrenable(int irq, void (*f)(Ureg*, void*), void* a, int tbdf, char *name)
{
    int vno;
    Vctl *v;

    if(f == nil){
        print("intrenable: nil handler for %d, tbdf 0x%uX for %s\n",
            irq, tbdf, name);
        return;
    }

    v = xalloc(sizeof(Vctl));
    v->isintr = true;
    v->irq = irq;
    v->tbdf = tbdf;
    v->f = f;
    v->a = a;
    strncpy(v->name, name, KNAMELEN-1);
    v->name[KNAMELEN-1] = 0;

    ilock(&vctllock);
    vno = arch->intrenable(v);
    if(vno == -1){
        iunlock(&vctllock);
        print("intrenable: couldn't enable irq %d, tbdf 0x%uX for %s\n",
            irq, tbdf, v->name);
        xfree(v);
        return;
    }
    if(vctl[vno]){
        if(vctl[vno]->isr != v->isr || vctl[vno]->eoi != v->eoi)
            panic("intrenable: handler: %s %s %#p %#p %#p %#p",
                vctl[vno]->name, v->name,
                vctl[vno]->isr, v->isr, vctl[vno]->eoi, v->eoi);
        v->next = vctl[vno];
    }
    vctl[vno] = v;
    iunlock(&vctllock);
}
@ 


<<function intrdisable>>=
int
intrdisable(int irq, void (*f)(Ureg *, void *), void *a, int tbdf, char *name)
{
    Vctl **pv, *v;
    int vno;

    /*
     * For now, none of this will work with the APIC code,
     * there is no mapping between irq and vector as the IRQ
     * is pretty meaningless.
     */
    if(arch->intrvecno == nil)
        return -1;
    vno = arch->intrvecno(irq);
    ilock(&vctllock);
    pv = &vctl[vno];
    while (*pv &&
          ((*pv)->irq != irq || (*pv)->tbdf != tbdf || (*pv)->f != f || (*pv)->a != a ||
           strcmp((*pv)->name, name)))
        pv = &((*pv)->next);
    assert(*pv);

    v = *pv;
    *pv = (*pv)->next;  /* Link out the entry */

    if(vctl[vno] == nil && arch->intrdisable != nil)
        arch->intrdisable(irq);
    iunlock(&vctllock);
    xfree(v);
    return 0;
}
@ 


<<function irqallocread>>=
static long
irqallocread(Chan*, void *vbuf, long n, vlong offset)
{
    char *buf, *p, str[2*(11+1)+KNAMELEN+1+1];
    int m, vno;
    long oldn;
    Vctl *v;

    if(n < 0 || offset < 0)
        error(Ebadarg);

    oldn = n;
    buf = vbuf;
    for(vno=0; vno<nelem(vctl); vno++){
        for(v=vctl[vno]; v; v=v->next){
            m = snprint(str, sizeof str, "%11d %11d %.*s\n", vno, v->irq, KNAMELEN, v->name);
            if(m <= offset) /* if do not want this, skip entry */
                offset -= m;
            else{
                /* skip offset bytes */
                m -= offset;
                p = str+offset;
                offset = 0;

                /* write at most max(n,m) bytes */
                if(m > n)
                    m = n;
                memmove(buf, p, m);
                n -= m;
                buf += m;

                if(n == 0)
                    return oldn;
            }
        }
    }
    return oldn - n;
}
@ 

<<function trapenable>>=
void
trapenable(int vno, void (*f)(Ureg*, void*), void* a, char *name)
{
    Vctl *v;

    if(vno < 0 || vno >= VectorPIC)
        panic("trapenable: vno %d", vno);
    v = xalloc(sizeof(Vctl));
    v->tbdf = BUSUNKNOWN;
    v->f = f;
    v->a = a;
    strncpy(v->name, name, KNAMELEN);
    v->name[KNAMELEN-1] = 0;

    ilock(&vctllock);
    v->next = vctl[vno];
    vctl[vno] = v;
    iunlock(&vctllock);
}
@ 

\section{Interrupt table [[vectortable]] and [[idt]]}

<<constant IDTADDR>>=
#define IDTADDR   (KZERO+0x10800)   /* idt */
@

<<global vectortable>>=
TEXT vectortable(SB), $0
        CALL _strayintr(SB); BYTE $0x00         /* divide error */
        CALL _strayintr(SB); BYTE $0x01         /* debug exception */
        CALL _strayintr(SB); BYTE $0x02         /* NMI interrupt */
        CALL _strayintr(SB); BYTE $0x03         /* breakpoint */
        CALL _strayintr(SB); BYTE $0x04         /* overflow */
        CALL _strayintr(SB); BYTE $0x05         /* bound */
        CALL _strayintr(SB); BYTE $0x06         /* invalid opcode */
        CALL _strayintr(SB); BYTE $0x07         /* no coprocessor available */
        CALL _strayintrx(SB); BYTE $0x08        /* double fault */
        CALL _strayintr(SB); BYTE $0x09         /* coprocessor segment overflow */
        CALL _strayintrx(SB); BYTE $0x0A        /* invalid TSS */
        CALL _strayintrx(SB); BYTE $0x0B        /* segment not available */
        CALL _strayintrx(SB); BYTE $0x0C        /* stack exception */
        CALL _strayintrx(SB); BYTE $0x0D        /* general protection error */
        CALL _strayintrx(SB); BYTE $0x0E        /* page fault */
        CALL _strayintr(SB); BYTE $0x0F         /*  */
        CALL _strayintr(SB); BYTE $0x10         /* coprocessor error */
        CALL _strayintrx(SB); BYTE $0x11        /* alignment check */
        CALL _strayintr(SB); BYTE $0x12         /* machine check */
        CALL _strayintr(SB); BYTE $0x13
        CALL _strayintr(SB); BYTE $0x14
        CALL _strayintr(SB); BYTE $0x15
        CALL _strayintr(SB); BYTE $0x16
        CALL _strayintr(SB); BYTE $0x17
        CALL _strayintr(SB); BYTE $0x18
        CALL _strayintr(SB); BYTE $0x19
        CALL _strayintr(SB); BYTE $0x1A
        CALL _strayintr(SB); BYTE $0x1B
        CALL _strayintr(SB); BYTE $0x1C
        CALL _strayintr(SB); BYTE $0x1D
        CALL _strayintr(SB); BYTE $0x1E
        CALL _strayintr(SB); BYTE $0x1F
        CALL _strayintr(SB); BYTE $0x20         /* VectorLAPIC */
        CALL _strayintr(SB); BYTE $0x21
        CALL _strayintr(SB); BYTE $0x22
        CALL _strayintr(SB); BYTE $0x23
        CALL _strayintr(SB); BYTE $0x24
        CALL _strayintr(SB); BYTE $0x25
        CALL _strayintr(SB); BYTE $0x26
        CALL _strayintr(SB); BYTE $0x27
        CALL _strayintr(SB); BYTE $0x28
        CALL _strayintr(SB); BYTE $0x29
        CALL _strayintr(SB); BYTE $0x2A
        CALL _strayintr(SB); BYTE $0x2B
        CALL _strayintr(SB); BYTE $0x2C
        CALL _strayintr(SB); BYTE $0x2D
        CALL _strayintr(SB); BYTE $0x2E
        CALL _strayintr(SB); BYTE $0x2F
        CALL _strayintr(SB); BYTE $0x30
        CALL _strayintr(SB); BYTE $0x31
        CALL _strayintr(SB); BYTE $0x32
        CALL _strayintr(SB); BYTE $0x33
        CALL _strayintr(SB); BYTE $0x34
        CALL _strayintr(SB); BYTE $0x35
        CALL _strayintr(SB); BYTE $0x36
        CALL _strayintr(SB); BYTE $0x37
        CALL _strayintr(SB); BYTE $0x38
        CALL _strayintr(SB); BYTE $0x39
        CALL _strayintr(SB); BYTE $0x3A
        CALL _strayintr(SB); BYTE $0x3B
        CALL _strayintr(SB); BYTE $0x3C
        CALL _strayintr(SB); BYTE $0x3D
        CALL _strayintr(SB); BYTE $0x3E
        CALL _strayintr(SB); BYTE $0x3F
        CALL _syscallintr(SB); BYTE $0x40       /* VectorSYSCALL */
        CALL _strayintr(SB); BYTE $0x41
        CALL _strayintr(SB); BYTE $0x42
        CALL _strayintr(SB); BYTE $0x43
        CALL _strayintr(SB); BYTE $0x44
        CALL _strayintr(SB); BYTE $0x45
        CALL _strayintr(SB); BYTE $0x46
        CALL _strayintr(SB); BYTE $0x47
        CALL _strayintr(SB); BYTE $0x48
        CALL _strayintr(SB); BYTE $0x49
        CALL _strayintr(SB); BYTE $0x4A
        CALL _strayintr(SB); BYTE $0x4B
        CALL _strayintr(SB); BYTE $0x4C
        CALL _strayintr(SB); BYTE $0x4D
        CALL _strayintr(SB); BYTE $0x4E
        CALL _strayintr(SB); BYTE $0x4F
        CALL _strayintr(SB); BYTE $0x50
        CALL _strayintr(SB); BYTE $0x51
        CALL _strayintr(SB); BYTE $0x52
        CALL _strayintr(SB); BYTE $0x53
        CALL _strayintr(SB); BYTE $0x54
        CALL _strayintr(SB); BYTE $0x55
        CALL _strayintr(SB); BYTE $0x56
        CALL _strayintr(SB); BYTE $0x57
        CALL _strayintr(SB); BYTE $0x58
        CALL _strayintr(SB); BYTE $0x59
        CALL _strayintr(SB); BYTE $0x5A
        CALL _strayintr(SB); BYTE $0x5B
        CALL _strayintr(SB); BYTE $0x5C
        CALL _strayintr(SB); BYTE $0x5D
        CALL _strayintr(SB); BYTE $0x5E
        CALL _strayintr(SB); BYTE $0x5F
        CALL _strayintr(SB); BYTE $0x60
        CALL _strayintr(SB); BYTE $0x61
        CALL _strayintr(SB); BYTE $0x62
        CALL _strayintr(SB); BYTE $0x63
        CALL _strayintr(SB); BYTE $0x64
        CALL _strayintr(SB); BYTE $0x65
        CALL _strayintr(SB); BYTE $0x66
        CALL _strayintr(SB); BYTE $0x67
        CALL _strayintr(SB); BYTE $0x68
        CALL _strayintr(SB); BYTE $0x69
        CALL _strayintr(SB); BYTE $0x6A
        CALL _strayintr(SB); BYTE $0x6B
        CALL _strayintr(SB); BYTE $0x6C
        CALL _strayintr(SB); BYTE $0x6D
        CALL _strayintr(SB); BYTE $0x6E
        CALL _strayintr(SB); BYTE $0x6F
        CALL _strayintr(SB); BYTE $0x70
        CALL _strayintr(SB); BYTE $0x71
        CALL _strayintr(SB); BYTE $0x72
        CALL _strayintr(SB); BYTE $0x73
        CALL _strayintr(SB); BYTE $0x74
        CALL _strayintr(SB); BYTE $0x75
        CALL _strayintr(SB); BYTE $0x76
        CALL _strayintr(SB); BYTE $0x77
        CALL _strayintr(SB); BYTE $0x78
        CALL _strayintr(SB); BYTE $0x79
        CALL _strayintr(SB); BYTE $0x7A
        CALL _strayintr(SB); BYTE $0x7B
        CALL _strayintr(SB); BYTE $0x7C
        CALL _strayintr(SB); BYTE $0x7D
        CALL _strayintr(SB); BYTE $0x7E
        CALL _strayintr(SB); BYTE $0x7F
        CALL _strayintr(SB); BYTE $0x80         /* Vector[A]PIC */
        CALL _strayintr(SB); BYTE $0x81
        CALL _strayintr(SB); BYTE $0x82
        CALL _strayintr(SB); BYTE $0x83
        CALL _strayintr(SB); BYTE $0x84
        CALL _strayintr(SB); BYTE $0x85
        CALL _strayintr(SB); BYTE $0x86
        CALL _strayintr(SB); BYTE $0x87
        CALL _strayintr(SB); BYTE $0x88
        CALL _strayintr(SB); BYTE $0x89
        CALL _strayintr(SB); BYTE $0x8A
        CALL _strayintr(SB); BYTE $0x8B
        CALL _strayintr(SB); BYTE $0x8C
        CALL _strayintr(SB); BYTE $0x8D
        CALL _strayintr(SB); BYTE $0x8E
        CALL _strayintr(SB); BYTE $0x8F
        CALL _strayintr(SB); BYTE $0x90
        CALL _strayintr(SB); BYTE $0x91
        CALL _strayintr(SB); BYTE $0x92
        CALL _strayintr(SB); BYTE $0x93
        CALL _strayintr(SB); BYTE $0x94
        CALL _strayintr(SB); BYTE $0x95
        CALL _strayintr(SB); BYTE $0x96
        CALL _strayintr(SB); BYTE $0x97
        CALL _strayintr(SB); BYTE $0x98
        CALL _strayintr(SB); BYTE $0x99
        CALL _strayintr(SB); BYTE $0x9A
        CALL _strayintr(SB); BYTE $0x9B
        CALL _strayintr(SB); BYTE $0x9C
        CALL _strayintr(SB); BYTE $0x9D
        CALL _strayintr(SB); BYTE $0x9E
        CALL _strayintr(SB); BYTE $0x9F
        CALL _strayintr(SB); BYTE $0xA0
        CALL _strayintr(SB); BYTE $0xA1
        CALL _strayintr(SB); BYTE $0xA2
        CALL _strayintr(SB); BYTE $0xA3
        CALL _strayintr(SB); BYTE $0xA4
        CALL _strayintr(SB); BYTE $0xA5
        CALL _strayintr(SB); BYTE $0xA6
        CALL _strayintr(SB); BYTE $0xA7
        CALL _strayintr(SB); BYTE $0xA8
        CALL _strayintr(SB); BYTE $0xA9
        CALL _strayintr(SB); BYTE $0xAA
        CALL _strayintr(SB); BYTE $0xAB
        CALL _strayintr(SB); BYTE $0xAC
        CALL _strayintr(SB); BYTE $0xAD
        CALL _strayintr(SB); BYTE $0xAE
        CALL _strayintr(SB); BYTE $0xAF
        CALL _strayintr(SB); BYTE $0xB0
        CALL _strayintr(SB); BYTE $0xB1
        CALL _strayintr(SB); BYTE $0xB2
        CALL _strayintr(SB); BYTE $0xB3
        CALL _strayintr(SB); BYTE $0xB4
        CALL _strayintr(SB); BYTE $0xB5
        CALL _strayintr(SB); BYTE $0xB6
        CALL _strayintr(SB); BYTE $0xB7
        CALL _strayintr(SB); BYTE $0xB8
        CALL _strayintr(SB); BYTE $0xB9
        CALL _strayintr(SB); BYTE $0xBA
        CALL _strayintr(SB); BYTE $0xBB
        CALL _strayintr(SB); BYTE $0xBC
        CALL _strayintr(SB); BYTE $0xBD
        CALL _strayintr(SB); BYTE $0xBE
        CALL _strayintr(SB); BYTE $0xBF
        CALL _strayintr(SB); BYTE $0xC0
        CALL _strayintr(SB); BYTE $0xC1
        CALL _strayintr(SB); BYTE $0xC2
        CALL _strayintr(SB); BYTE $0xC3
        CALL _strayintr(SB); BYTE $0xC4
        CALL _strayintr(SB); BYTE $0xC5
        CALL _strayintr(SB); BYTE $0xC6
        CALL _strayintr(SB); BYTE $0xC7
        CALL _strayintr(SB); BYTE $0xC8
        CALL _strayintr(SB); BYTE $0xC9
        CALL _strayintr(SB); BYTE $0xCA
        CALL _strayintr(SB); BYTE $0xCB
        CALL _strayintr(SB); BYTE $0xCC
        CALL _strayintr(SB); BYTE $0xCD
        CALL _strayintr(SB); BYTE $0xCE
        CALL _strayintr(SB); BYTE $0xCF
        CALL _strayintr(SB); BYTE $0xD0
        CALL _strayintr(SB); BYTE $0xD1
        CALL _strayintr(SB); BYTE $0xD2
        CALL _strayintr(SB); BYTE $0xD3
        CALL _strayintr(SB); BYTE $0xD4
        CALL _strayintr(SB); BYTE $0xD5
        CALL _strayintr(SB); BYTE $0xD6
        CALL _strayintr(SB); BYTE $0xD7
        CALL _strayintr(SB); BYTE $0xD8
        CALL _strayintr(SB); BYTE $0xD9
        CALL _strayintr(SB); BYTE $0xDA
        CALL _strayintr(SB); BYTE $0xDB
        CALL _strayintr(SB); BYTE $0xDC
        CALL _strayintr(SB); BYTE $0xDD
        CALL _strayintr(SB); BYTE $0xDE
        CALL _strayintr(SB); BYTE $0xDF
        CALL _strayintr(SB); BYTE $0xE0
        CALL _strayintr(SB); BYTE $0xE1
        CALL _strayintr(SB); BYTE $0xE2
        CALL _strayintr(SB); BYTE $0xE3
        CALL _strayintr(SB); BYTE $0xE4
        CALL _strayintr(SB); BYTE $0xE5
        CALL _strayintr(SB); BYTE $0xE6
        CALL _strayintr(SB); BYTE $0xE7
        CALL _strayintr(SB); BYTE $0xE8
        CALL _strayintr(SB); BYTE $0xE9
        CALL _strayintr(SB); BYTE $0xEA
        CALL _strayintr(SB); BYTE $0xEB
        CALL _strayintr(SB); BYTE $0xEC
        CALL _strayintr(SB); BYTE $0xED
        CALL _strayintr(SB); BYTE $0xEE
        CALL _strayintr(SB); BYTE $0xEF
        CALL _strayintr(SB); BYTE $0xF0
        CALL _strayintr(SB); BYTE $0xF1
        CALL _strayintr(SB); BYTE $0xF2
        CALL _strayintr(SB); BYTE $0xF3
        CALL _strayintr(SB); BYTE $0xF4
        CALL _strayintr(SB); BYTE $0xF5
        CALL _strayintr(SB); BYTE $0xF6
        CALL _strayintr(SB); BYTE $0xF7
        CALL _strayintr(SB); BYTE $0xF8
        CALL _strayintr(SB); BYTE $0xF9
        CALL _strayintr(SB); BYTE $0xFA
        CALL _strayintr(SB); BYTE $0xFB
        CALL _strayintr(SB); BYTE $0xFC
        CALL _strayintr(SB); BYTE $0xFD
        CALL _strayintr(SB); BYTE $0xFE
        CALL _strayintr(SB); BYTE $0xFF
@ 

%$


\section{Exceptions}

<<enum vector>>=
enum {
    VectorNMI = 2,    /* non-maskable interrupt */
    VectorBPT = 3,    /* breakpoint */
    VectorUD  = 6,    /* invalid opcode exception */
    VectorCNA = 7,    /* coprocessor not available */
    Vector2F  = 8,    /* double fault */
    VectorCSO = 9,    /* coprocessor segment overrun */
    VectorPF  = 14,   /* page fault */
    Vector15  = 15,   /* reserved */
    VectorCERR  = 16,   /* coprocessor error */
  
    VectorPIC = 32,   /* external i8259 interrupts */
    VectorLAPIC = VectorPIC+16, /* local APIC interrupts */

    //!!! int 64 = way to jump in plan9 OS !!!
    // VectorSYSCALL = 64, in mem.h because used by Assembly too
  
    VectorAPIC  = 65,   /* external APIC interrupts */
    MaxVectorAPIC = 255,
};
@

\section{Hardware interrupts}

<<enum irq>>=
enum {
    IrqCLOCK  = 0,
    IrqKBD    = 1,
    IrqUART1  = 3,
    IrqUART0  = 4,
    IrqPCMCIA = 5,
    IrqFLOPPY = 6,
    IrqLPT    = 7,
    IrqIRQ7   = 7,
    IrqAUX    = 12,   /* PS/2 port */
    IrqIRQ13  = 13,   /* coprocessor on 386 */
    IrqATA0   = 14,
    IrqATA1   = 15,
    MaxIrqPIC = 15,
  
    IrqLINT0  = 16,   /* LINT[01] must be offsets 0 and 1 */
    IrqLINT1  = 17,
    IrqTIMER  = 18,
    IrqERROR  = 19,
    IrqPCINT  = 20,
    IrqSPURIOUS = 31,   /* must have bits [3-0] == 0x0F */

    MaxIrqLAPIC = 31,
};
@

<<[[PCArch]] interrupt methods fields>>=
void  (*intrinit)(void);
int (*intrenable)(Vctl*);
int (*intrvecno)(int);
int (*intrdisable)(int);
void  (*introff)(void);
void  (*intron)(void);
@

<<[[archgeneric]] interrupt methods>>=
.intrinit=  i8259init,
.intrenable=    i8259enable,
.intrvecno= i8259vecno,
.intrdisable=   i8259disable,
.intron=    i8259on,
.introff=   i8259off,
@

<<function i8259init>>=
void
i8259init(void)
{
    int x;

    ioalloc(Int0ctl, 2, 0, "i8259.0");
    ioalloc(Int1ctl, 2, 0, "i8259.1");
    ilock(&i8259lock);

    /*
     *  Set up the first 8259 interrupt processor.
     *  Make 8259 interrupts start at CPU vector VectorPIC.
     *  Set the 8259 as master with edge triggered
     *  input with fully nested interrupts.
     */
    outb(Int0ctl, (1<<4)|(0<<3)|(1<<0));    /* ICW1 - master, edge triggered,
                           ICW4 will be sent */
    outb(Int0aux, VectorPIC);       /* ICW2 - interrupt vector offset */
    outb(Int0aux, 0x04);            /* ICW3 - have slave on level 2 */
    outb(Int0aux, 0x01);            /* ICW4 - 8086 mode, not buffered */

    /*
     *  Set up the second 8259 interrupt processor.
     *  Make 8259 interrupts start at CPU vector VectorPIC+8.
     *  Set the 8259 as slave with edge triggered
     *  input with fully nested interrupts.
     */
    outb(Int1ctl, (1<<4)|(0<<3)|(1<<0));    /* ICW1 - master, edge triggered,
                           ICW4 will be sent */
    outb(Int1aux, VectorPIC+8);     /* ICW2 - interrupt vector offset */
    outb(Int1aux, 0x02);            /* ICW3 - I am a slave on level 2 */
    outb(Int1aux, 0x01);            /* ICW4 - 8086 mode, not buffered */
    outb(Int1aux, (i8259mask>>8) & 0xFF);

    /*
     *  pass #2 8259 interrupts to #1
     */
    i8259mask &= ~0x04;
    outb(Int0aux, i8259mask & 0xFF);

    /*
     * Set Ocw3 to return the ISR when ctl read.
     * After initialisation status read is set to IRR.
     * Read IRR first to possibly deassert an outstanding
     * interrupt.
     */
    inb(Int0ctl);
    outb(Int0ctl, Ocw3|0x03);
    inb(Int1ctl);
    outb(Int1ctl, Ocw3|0x03);

    /*
     * Check for Edge/Level register.
     * This check may not work for all chipsets.
     * First try a non-intrusive test - the bits for
     * IRQs 13, 8, 2, 1 and 0 must be edge (0). If
     * that's OK try a R/W test.
     */
    x = (inb(Elcr2)<<8)|inb(Elcr1);
    if(!(x & 0x2107)){
        outb(Elcr1, 0);
        if(inb(Elcr1) == 0){
            outb(Elcr1, 0x20);
            if(inb(Elcr1) == 0x20)
                i8259elcr = x;
            outb(Elcr1, x & 0xFF);
            print("ELCR: %4.4uX\n", i8259elcr);
        }
    }
    iunlock(&i8259lock);
}
@


<<global i8259lock>>=
static Lock i8259lock;
@

<<function i8259isr>>=
int
i8259isr(int vno)
{
    int irq, isr;

    if(vno < VectorPIC || vno > VectorPIC+MaxIrqPIC)
        return 0;
    irq = vno-VectorPIC;

    /*
     *  tell the 8259 that we're done with the
     *  highest level interrupt (interrupts are still
     *  off at this point)
     */
    ilock(&i8259lock);
    isr = inb(Int0ctl);
    outb(Int0ctl, EOI);
    if(irq >= 8){
        isr |= inb(Int1ctl)<<8;
        outb(Int1ctl, EOI);
    }
    iunlock(&i8259lock);

    return isr & (1<<irq);
}
@
% >> >>

<<function i8259enable>>=
int
i8259enable(Vctl* v)
{
    int irq, irqbit;

    /*
     * Given an IRQ, enable the corresponding interrupt in the i8259
     * and return the vector to be used. The i8259 is set to use a fixed
     * range of vectors starting at VectorPIC.
     */
    irq = v->irq;
    if(irq < 0 || irq > MaxIrqPIC){
        print("i8259enable: irq %d out of range\n", irq);
        return -1;
    }
    irqbit = 1<<irq;

    ilock(&i8259lock);
    if(!(i8259mask & irqbit) && !(i8259elcr & irqbit)){
        print("i8259enable: irq %d shared but not level\n", irq);
        iunlock(&i8259lock);
        return -1;
    }
    i8259mask &= ~irqbit;
    if(irq < 8)
        outb(Int0aux, i8259mask & 0xFF);
    else
        outb(Int1aux, (i8259mask>>8) & 0xFF);

    if(i8259elcr & irqbit)
        v->eoi = i8259isr;
    else
        v->isr = i8259isr;
    iunlock(&i8259lock);

    return VectorPIC+irq;
}
@

<<function i8259vecno>>=
int
i8259vecno(int irq)
{
    return VectorPIC+irq;
}
@

<<function i8259disable>>=
int
i8259disable(int irq)
{
    int irqbit;

    /*
     * Given an IRQ, disable the corresponding interrupt
     * in the 8259.
     */
    if(irq < 0 || irq > MaxIrqPIC){
        print("i8259disable: irq %d out of range\n", irq);
        return -1;
    }
    irqbit = 1<<irq;

    ilock(&i8259lock);
    if(!(i8259mask & irqbit)){
        i8259mask |= irqbit;
        if(irq < 8)
            outb(Int0aux, i8259mask & 0xFF);
        else
            outb(Int1aux, (i8259mask>>8) & 0xFF);
    }
    iunlock(&i8259lock);
    return 0;
}
@

<<function i8259on>>=
void
i8259on(void)
{
    outb(Int0aux, i8259mask&0xFF);
    outb(Int1aux, (i8259mask>>8)&0xFF);
}
@


<<function i8259off>>=
void
i8259off(void)
{
    outb(Int0aux, 0xFF);
    outb(Int1aux, 0xFF);
}
@


\section{Software interrupts (a.k.a syscalls)}

<<constant MAXSYSARG>>=
// used in Proc
MAXSYSARG = 5, /* for mount(fd, afd, mpt, flag, arg) */
@

<<struct Sargs>>=
// syscall arguments passed in kernel stack
struct Sargs
{
    ulong args[MAXSYSARG];
};
@ 

<<[[Proc]] other fields>>=
Sargs sargs;    /* address of this is known by db */
@ 


<<function _syscallintr>>=
/*
 * This is merely _strayintr from l.s optimised to vector
 * to syscall() without going through trap().
 */
TEXT _syscallintr(SB), $0
        PUSHL   $VectorSYSCALL                  /* trap type */

        PUSHL   DS
        PUSHL   ES
        PUSHL   FS
        PUSHL   GS
        PUSHAL
        MOVL    $(KDSEL), AX
        MOVW    AX, DS
        MOVW    AX, ES
        PUSHL   SP
        CALL    syscall(SB)

        POPL    AX
        POPAL
        POPL    GS
        POPL    FS
        POPL    ES
        POPL    DS
        ADDL    $8, SP                          /* pop error code and trap type */
        IRETL
@ 

<<function syscall>>=
/*
 *  Syscall is called directly from assembler without going through trap().
 */
//@Scheck: not dead, called from assembly by _syscallintr
void
syscall(Ureg* ureg)
{
    char *e;
    ulong   sp;
    long    ret;
    int i, s;
    ulong scallnr;
    vlong startns, stopns;

    if((ureg->cs & 0xFFFF) != UESEL)
        panic("syscall: cs 0x%4.4luX", ureg->cs);

    cycles(&up->kentry);

    cpu->syscall++;
    up->insyscall = true;
    up->pc = ureg->pc;
    up->dbgreg = ureg;

    sp = ureg->usp;
    // syscall number
    scallnr = ureg->ax;

    <<[[syscall()]] Proc_tracesyscall if, syscall entry>>

    if(scallnr == RFORK && up->fpstate == FPactive){
        fpsave(&up->fpsave);
        up->fpstate = FPinactive;
    }
    spllo();

    up->nerrlab = 0;
    ret = -1;

    if(!waserror()){
        if(scallnr >= nsyscall || systab[scallnr] == 0){
            pprint("bad sys call number %lud pc %lux\n",
                scallnr, ureg->pc);
            postnote(up, 1, "sys: bad sys call", NDebug);
            error(Ebadarg);
        }

        if(sp<(USTKTOP-BY2PG) || sp>(USTKTOP-sizeof(Sargs)-BY2WD))
            validaddr(sp, sizeof(Sargs)+BY2WD, 0);

        up->sargs = *((Sargs*)(sp+BY2WD));
        up->psstate = sysctab[scallnr];

        //!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
        //IMPORTANT: The actual system call
        ret = systab[scallnr](up->sargs.args);
        //!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

        poperror();
    }else{
        /* failure: save the error buffer for errstr */
        e = up->syserrstr;
        up->syserrstr = up->errstr;
        up->errstr = e;
        //if(0 && up->pid == 1)
        //    print("syscall %lud error %s\n", scallnr, up->syserrstr);
    }

    if(up->nerrlab){
        print("bad errstack [%lud]: %d extra\n", scallnr, up->nerrlab);
        for(i = 0; i < NERR; i++)
            print("sp=%lux pc=%lux\n",
                up->errlab[i].sp, up->errlab[i].pc);
        panic("error stack");
    }

    /*
     *  Put return value in frame.  On the x86 the syscall is
     *  just another trap and the return value from syscall is
     *  ignored.  On other machines the return value is put into
     *  the results register by caller of syscall.
     */
    ureg->ax = ret;

    <<[[syscall()]] Proc_tracesyscall if, syscall exit>>

    up->insyscall = false;
    up->psstate = nil;

    if(scallnr == NOTED)
        noted(ureg, *(ulong*)(sp+BY2WD));

    if(scallnr!=RFORK && (up->procctl || up->nnote)){
        splhi();
        notify(ureg);
    }
    <<[[syscall()]] if delaysched>>
    kexit(ureg);
}
@ 

\section{[[trap()]]}

<<function _strayintr>>=
/*
 * Interrupt/exception handling.
 * Each entry in the vector table calls either _strayintr or _strayintrx depending
 * on whether an error code has been automatically pushed onto the stack
 * (_strayintrx) or not, in which case a dummy entry must be pushed before retrieving
 * the trap type from the vector table entry and placing it on the stack as part
 * of the Ureg structure.
 * The size of each entry in the vector table (6 bytes) is known in trapinit().
 */
TEXT _strayintr(SB), $0
        PUSHL   AX                      /* save AX */
        MOVL    4(SP), AX               /* return PC from vectortable(SB) */
        JMP     intrcommon
@


<<function _strayintrx>>=
TEXT _strayintrx(SB), $0
        XCHGL   AX, (SP)                /* swap AX with vectortable CALL PC */
intrcommon:
        PUSHL   DS                      /* save DS */
        PUSHL   $(KDSEL)
        POPL    DS                      /* fix up DS */
        MOVBLZX (AX), AX                /* trap type -> AX */
        XCHGL   AX, 4(SP)               /* exchange trap type with saved AX */

        PUSHL   ES                      /* save ES */
        PUSHL   $(KDSEL)
        POPL    ES                      /* fix up ES */

        PUSHL   FS                      /* save the rest of the Ureg struct */
        PUSHL   GS
        PUSHAL

        PUSHL   SP                      /* Ureg* argument to trap */
        CALL    trap(SB)
@ 

% todo: [[Cpu]] debugging fields?
<<[[Cpu]] other fields>>=
int lastintr; // debugging
@

<<function trap>>=
/*
 *  All traps come here.  It is slower to have all traps call trap()
 *  rather than directly vectoring the handler. However, this avoids a
 *  lot of code duplication and possible bugs. The only exception is
 *  VectorSYSCALL.
 *  Trap is called with interrupts disabled via interrupt-gates.
 */
//@Scheck: not dead, called from assembly by _strayintr
void
trap(Ureg* ureg)
{
    bool clockintr;
    bool user;
    int i, vno;
    char buf[ERRMAX];
    Vctl *ctl, *v;
    Cpu *mach;

    if(!trapinited){
        /* fault386 can give a better error message */
        if(ureg->trap == VectorPF)
            fault386(ureg, nil);
        panic("trap %lud: not ready", ureg->trap);
    }

    cpu->perf.intrts = perfticks();
    user = (ureg->cs & 0xFFFF) == UESEL;
    if(user){
        up->dbgreg = ureg;
        cycles(&up->kentry);
    }

    clockintr = false;

    vno = ureg->trap;
    if(ctl = vctl[vno]){
        if(ctl->isintr){
            cpu->intr++;
            if(vno >= VectorPIC && vno != VectorSYSCALL)
                cpu->lastintr = ctl->irq;
        }

        if(ctl->isr)
            ctl->isr(vno);
        for(v = ctl; v != nil; v = v->next){
            if(v->f)
                v->f(ureg, v->a);
        }
        if(ctl->eoi)
            ctl->eoi(vno);

        if(ctl->isintr){
            intrtime(cpu, vno);

            if(ctl->irq == IrqCLOCK || ctl->irq == IrqTIMER)
                clockintr = true;

            if(up && !clockintr)
                preempt();
        }
    }
    else if(vno < nelem(excname) && user){
        spllo();
        snprint(buf, sizeof buf, "sys: trap: %s", excname[vno]);
        postnote(up, 1, buf, NDebug);
    }
    else if(vno >= VectorPIC && vno != VectorSYSCALL){
        /*
         * An unknown interrupt.
         * Check for a default IRQ7. This can happen when
         * the IRQ input goes away before the acknowledge.
         * In this case, a 'default IRQ7' is generated, but
         * the corresponding bit in the ISR isn't set.
         * In fact, just ignore all such interrupts.
         */

        /* call all interrupt routines, just in case */
        for(i = VectorPIC; i <= MaxIrqLAPIC; i++){
            ctl = vctl[i];
            if(ctl == nil)
                continue;
            if(!ctl->isintr)
                continue;
            for(v = ctl; v != nil; v = v->next){
                if(v->f)
                    v->f(ureg, v->a);
            }
            /* should we do this? */
            if(ctl->eoi)
                ctl->eoi(i);
        }

        /* clear the interrupt */
        i8259isr(vno);
        <<[[trap()]] debugging>>
        cpu->spuriousintr++;
        if(user)
            kexit(ureg);
        return;
    }
    else{
        if(vno == VectorNMI){
            /*
             * Don't re-enable, it confuses the crash dumps.
            nmienable();
             */
            iprint("cpu%d: NMI PC %#8.8lux\n", cpu->cpuno, ureg->pc);
            while(cpu->cpuno != 0)
                ;
        }
        dumpregs(ureg);
        if(!user){
            ureg->sp = (ulong)&ureg->sp;
            _dumpstack(ureg);
        }
        if(vno < nelem(excname))
            panic("%s", excname[vno]);
        panic("unknown trap/intr: %d", vno);
    }
    splhi();

    <<[[trap()]] if delaysched>>

    if(user){
        if(up->procctl || up->nnote)
            notify(ureg);
        kexit(ureg);
    }
}
@ 

<<function kexit>>=
/* go to user space */
void
kexit(Ureg*)
{
    uvlong t;
    Tos *tos;

    /* precise time accounting, kernel exit */
    tos = (Tos*)(USTKTOP-sizeof(Tos));
    cycles(&t);
    tos->kcycles += t - up->kentry;
    tos->pcycles = up->pcycles;
    tos->pid = up->pid;
}
@ 


\ifallcode
<<[[trap()]] debugging>>=
        if(0)print("cpu%d: spurious interrupt %d, last %d\n",
            cpu->cpuno, vno, cpu->lastintr);
        if(0)if(conf.ncpu > 1){
            for(i = 0; i < 32; i++){
                if(!(active.cpus & (1<<i)))
                    continue;
                mach = CPUS(i);
                if(cpu->cpuno == mach->cpuno)
                    continue;
                print(" cpu%d: last %d",
                    mach->cpuno, mach->lastintr);
            }
            print("\n");
        }
@
\fi


\chapter{Virtual Memory}

\section{Overview}

% What a system would look like (including for a programmer) without VM?
% Virtual memory enables many things:
% - isolated processes, safer! (see DOS ...) a malicious/buggy process 
%   can't harm
% - can access more than physical, hence virtual in some sense
% - easier for loading programs, no need relocation, they all
%   start at 0

\section{Segmentation and [[gdt]]}

% could be an enum, but has to be used from assembly too
<<constant x86 segments>>=
/*
 *  known x86 segments (in GDT) and their selectors
 */
#define NULLSEG 0 /* null segment */
#define KDSEG 1 /* kernel data/stack */
#define KESEG 2 /* kernel executable */ 
#define UDSEG 3 /* user data/stack */
#define UESEG 4 /* user executable */
#define TSSSEG  5 /* task segment */
<<constant x86 other segments>>
#define NGDT    10  /* number of GDT entries required */
@


% also used for IDT
<<struct Segdesc>>=
struct Segdesc
{
    ulong d0; // ??
    ulong d1; // ??
};
@ 
<<global gdt>>=
Segdesc gdt[NGDT] =
{
[NULLSEG]   { 0, 0},        /* null descriptor */
[KDSEG]     DATASEGM(0),        /* kernel data/stack */
[KESEG]     EXECSEGM(0),        /* kernel code */
[UDSEG]     DATASEGM(3),        /* user data/stack */
[UESEG]     EXECSEGM(3),        /* user code */
[TSSSEG]    TSSSEGM(0,0),       /* tss segment */
<<[[gdt]] other elements>>
};
@

<<constant segment field extractors>>=
/*
 *  fields in segment descriptors
 */
#define SEGDATA (0x10<<8) /* data/stack segment */
#define SEGEXEC (0x18<<8) /* executable segment */
#define SEGTSS  (0x9<<8)  /* TSS segment */
#define SEGCG (0x0C<<8) /* call gate */
#define SEGIG (0x0E<<8) /* interrupt gate */
#define SEGTG (0x0F<<8) /* trap gate */
#define SEGTYPE (0x1F<<8)

#define SEGP  (1<<15)   /* segment present */
#define SEGPL(x) ((x)<<13)  /* priority level */
#define SEGB  (1<<22)   /* granularity 1==4k (for expand-down) */
#define SEGG  (1<<23)   /* granularity 1==4k (for other) */
#define SEGE  (1<<10)   /* expand down */
#define SEGW  (1<<9)    /* writable (for data/stack) */
#define SEGR  (1<<9)    /* readable (for code) */
#define SEGD  (1<<22)   /* default 1==32bit (for code) */
@


<<macros xxxSEGM>>=
/*
 * Simple segment descriptors with no translation.
 */
#define DATASEGM(p)     { 0xFFFF, SEGG|SEGB|(0xF<<16)|SEGP|SEGPL(p)|SEGDATA|SEGW }
#define EXECSEGM(p)     { 0xFFFF, SEGG|SEGD|(0xF<<16)|SEGP|SEGPL(p)|SEGEXEC|SEGR }
#define TSSSEGM(b,p)    { ((b)<<16)|sizeof(Tss),\
              ((b)&0xFF000000)|(((b)>>16)&0xFF)|SEGTSS|SEGPL(p)|SEGP }
<<macros other xxxSEGM>>
@


<<[[Cpu]] [[Arch]] other fields>>=
// array<Segdesc>
Segdesc *gdt;     /* gdt for this processor */
@


<<constant x86 segment selectors>>=
#define NULLSEL SELECTOR(NULLSEG, SELGDT, 0)
#define KDSEL SELECTOR(KDSEG, SELGDT, 0)
#define KESEL SELECTOR(KESEG, SELGDT, 0)
#define UESEL SELECTOR(UESEG, SELGDT, 3)
#define UDSEL SELECTOR(UDSEG, SELGDT, 3)
#define TSSSEL  SELECTOR(TSSSEG, SELGDT, 0)
<<constant x86 other segment selectors>>
@

<<macro SELECTOR>>=
#define SELECTOR(i, t, p) (((i)<<3) | (t) | (p))
@

% could put code of tgdt of initialization here? but the real gdt
% is the one above, the tgdt is just used at the beginning

\section{Pagination and [[pdb]]} 

<<[[Cpu]] [[Arch]] other fields>>=
kern_addr2  pdb;      /* page directory base for this processor (va) */
Page* pdbpool;
int pdbcnt;
@
%// TODO: have a ArchCpuMMU like in bcm/


<<[[Proc]] [[Arch]] memory fields>>=
Page* mmupdb;     /* page directory base */
Page* mmufree;    /* unused page table pages */
Page* mmuused;    /* used page table pages */

Page* kmaptable;    /* page table used by kmap */
uint  lastkmap;   /* last entry used by kmap */
int nkmap;      /* number of current kmaps */
@

<<[[Proc]] memory fields>>=
bool newtlb;   /* Pager has changed my pte's, I must flush */
@ 




<<function mmuwalk>>=
/*
 * Walk the page-table pointed to by pdb and return a pointer
 * to the entry for virtual address va at the requested level.
 * If the entry is invalid and create isn't requested then bail
 * out early. Otherwise, for the 2nd level walk, allocate a new
 * page-table page and register it in the 1st level.  This is used
 * only to edit kernel mappings, which use pages from kernel memory,
 * so it's okay to use KADDR to look at the tables.
 */
ulong*
mmuwalk(ulong* pdb, ulong va, int level, int create)
{
    ulong *table;
    void *map;

    table = &pdb[PDX(va)];
    if(!(*table & PTEVALID) && create == 0)
        return nil;

    switch(level){

    default:
        return nil;

    case 1:
        return table;

    case 2:
        if(*table & PTESIZE)
            panic("mmuwalk2: va %luX entry %luX", va, *table);
        if(!(*table & PTEVALID)){
            /*
             * Have to call low-level allocator from
             * memory.c if we haven't set up the xalloc
             * tables yet.
             */
            if(didmmuinit)
                map = xspanalloc(BY2PG, BY2PG, 0);
            else
                map = rampage();
            if(map == nil)
                panic("mmuwalk xspanalloc failed");
            *table = PADDR(map)|PTEWRITE|PTEVALID;
        }
        table = KADDR(PPN(*table));
        return &table[PTX(va)];
    }
}
@




<<struct KMap>>=
/*
 * KMap the structure doesn't exist, but the functions do.
 */
typedef struct KMap   KMap;
@


<<macro VA>>=
#define VA(k)   ((void*)(k))
@


<<function flushmmu>>=
/*
 * Flush all the user-space and device-mapping mmu info
 * for this process, because something has been deleted.
 * It will be paged back in on demand.
 */
void
flushmmu(void)
{
    int s;

    s = splhi();
    up->newtlb = true;
    mmuswitch(up);
    splx(s);
}
@


<<function flushpg>>=
/*
 * Flush a single page mapping from the tlb.
 */
void
flushpg(ulong va)
{
    if(X86FAMILY(cpu->cpuidax) >= 4)
        invlpg(va);
    else
        putcr3(getcr3());
}
@


<<function mmupdballoc>>=
/*
 * Allocate a new page for a page directory. 
 * We keep a small cache of pre-initialized
 * page directories in each cpu.
 */
static Page*
mmupdballoc(void)
{
    int s;
    Page *page;
    ulong *pdb;

    s = splhi();
    cpu->pdballoc++;
    if(cpu->pdbpool == 0){
        spllo();
        page = newpage(0, 0, 0);
        page->va = (ulong)vpd;
        splhi();
        pdb = tmpmap(page);
        memmove(pdb, cpu->pdb, BY2PG);
        pdb[PDX(VPT)] = page->pa|PTEWRITE|PTEVALID; /* set up VPT */
        tmpunmap(pdb);
    }else{
        page = cpu->pdbpool;
        cpu->pdbpool = page->next;
        cpu->pdbcnt--;
    }
    splx(s);
    return page;
}
@


<<function mmupdbfree>>=
//@Scheck: not dead
static void
mmupdbfree(Proc *proc, Page *p)
{
    if(islo())
        panic("mmupdbfree: islo");
    cpu->pdbfree++;
    if(cpu->pdbcnt >= 10){
        p->next = proc->mmufree;
        proc->mmufree = p;
    }else{
        p->next = cpu->pdbpool;
        cpu->pdbpool = p;
        cpu->pdbcnt++;
    }
}
@


<<function mmuptefree>>=
/*
 * A user-space memory segment has been deleted, or the
 * process is exiting.  Clear all the pde entries for user-space
 * memory mappings and device mappings.  Any entries that
 * are needed will be paged back in as necessary.
 */
static void
mmuptefree(Proc* proc)
{
    int s;
    ulong *pdb;
    Page **last, *page;

    if(proc->mmupdb == nil || proc->mmuused == nil)
        return;
    s = splhi();
    pdb = tmpmap(proc->mmupdb);
    last = &proc->mmuused;
    for(page = *last; page; page = page->next){
        pdb[page->daddr] = 0;
        last = &page->next;
    }
    tmpunmap(pdb);
    splx(s);
    *last = proc->mmufree;
    proc->mmufree = proc->mmuused;
    proc->mmuused = 0;
}
@


<<function mmurelease>>=
/*
 * Release any pages allocated for a page directory base or page-tables
 * for this process:
 *   switch to the prototype pdb for this processor (cpu->pdb);
 *   call mmuptefree() to place all pages used for page-tables (proc->mmuused)
 *   onto the process' free list (proc->mmufree). This has the side-effect of
 *   cleaning any user entries in the pdb (proc->mmupdb);
 *   if there's a pdb put it in the cache of pre-initialised pdb's
 *   for this processor (cpu->pdbpool) or on the process' free list;
 *   finally, place any pages freed back into the free pool (palloc).
 * This routine is only called from schedinit() with palloc locked.
 */
void
mmurelease(Proc* proc)
{
    Page *page, *next;
    ulong *pdb;

    if(islo())
        panic("mmurelease: islo");
    taskswitch(PADDR(cpu->pdb), (ulong)cpu + BY2PG);
    if(proc->kmaptable){
        if(proc->mmupdb == nil)
            panic("mmurelease: no mmupdb");
        if(--proc->kmaptable->ref)
            panic("mmurelease: kmap ref %d", proc->kmaptable->ref);
        if(proc->nkmap)
            panic("mmurelease: nkmap %d", proc->nkmap);
        /*
         * remove kmaptable from pdb before putting pdb up for reuse.
         */
        pdb = tmpmap(proc->mmupdb);
        if(PPN(pdb[PDX(KMAP)]) != proc->kmaptable->pa)
            panic("mmurelease: bad kmap pde %#.8lux kmap %#.8lux",
                pdb[PDX(KMAP)], proc->kmaptable->pa);
        pdb[PDX(KMAP)] = 0;
        tmpunmap(pdb);
        /*
         * move kmaptable to free list.
         */
        pagechainhead(proc->kmaptable);
        proc->kmaptable = 0;
    }
    if(proc->mmupdb){
        mmuptefree(proc);
        mmupdbfree(proc, proc->mmupdb);
        proc->mmupdb = 0;
    }
    for(page = proc->mmufree; page; page = next){
        next = page->next;
        if(--page->ref)
            panic("mmurelease: page->ref %d", page->ref);
        pagechainhead(page);
    }
    if(proc->mmufree && palloc.freememr.p)
        wakeup(&palloc.freememr);
    proc->mmufree = 0;
}
@


<<function upallocpdb>>=
/*
 * Allocate and install pdb for the current process.
 */
//@Scheck: no dead, called bellow
static void
upallocpdb(void)
{
    int s;
    ulong *pdb;
    Page *page;
    
    if(up->mmupdb != nil)
        return;
    page = mmupdballoc();
    s = splhi();
    if(up->mmupdb != nil){
        /*
         * Perhaps we got an interrupt while
         * mmupdballoc was sleeping and that
         * interrupt allocated an mmupdb?
         * Seems unlikely.
         */
        mmupdbfree(up, page);
        splx(s);
        return;
    }
    pdb = tmpmap(page);
    pdb[PDX(CPUADDR)] = cpu->pdb[PDX(CPUADDR)];
    tmpunmap(pdb);
    up->mmupdb = page;
    putcr3(up->mmupdb->pa);
    splx(s);
}
@


<<function putmmu>>=
/*
 * Update the mmu in response to a user fault.  pa may have PTEWRITE set.
 */
void
putmmu(ulong va, ulong pa, Page*)
{
    int old, s;
    Page *page;

    if(up->mmupdb == nil)
        upallocpdb();

    /*
     * We should be able to get through this with interrupts
     * turned on (if we get interrupted we'll just pick up 
     * where we left off) but we get many faults accessing
     * vpt[] near the end of this function, and they always happen
     * after the process has been switched out and then 
     * switched back, usually many times in a row (perhaps
     * it cannot switch back successfully for some reason).
     * 
     * In any event, I'm tired of searching for this bug.  
     * Turn off interrupts during putmmu even though
     * we shouldn't need to.        - rsc
     */
    
    s = splhi();
    if(!(vpd[PDX(va)]&PTEVALID)){
        if(up->mmufree == 0){
            spllo();
            page = newpage(0, 0, 0);
            splhi();
        }
        else{
            page = up->mmufree;
            up->mmufree = page->next;
        }
        vpd[PDX(va)] = PPN(page->pa)|PTEUSER|PTEWRITE|PTEVALID;
        /* page is now mapped into the VPT - clear it */
        memset((void*)(VPT+PDX(va)*BY2PG), 0, BY2PG);
        page->daddr = PDX(va);
        page->next = up->mmuused;
        up->mmuused = page;
    }
    old = vpt[VPTX(va)];
    vpt[VPTX(va)] = pa|PTEUSER|PTEVALID;
    if(old&PTEVALID)
        flushpg(va);
    if(getcr3() != up->mmupdb->pa)
        print("bad cr3 %#.8lux %#.8lux\n", getcr3(), up->mmupdb->pa);
    splx(s);
}
@


<<function checkmmu>>=
/*
 * Double-check the user MMU.
 * Error checking only.
 */
void
checkmmu(ulong va, ulong pa)
{
    if(up->mmupdb == 0)
        return;
    if(!(vpd[PDX(va)]&PTEVALID) || !(vpt[VPTX(va)]&PTEVALID))
        return;
    if(PPN(vpt[VPTX(va)]) != pa)
        print("%ld %s: va=%#08lux pa=%#08lux pte=%#08lux\n",
            up->pid, up->text,
            va, pa, vpt[VPTX(va)]);
}
@




<<global vmaplock>>=
static Lock vmaplock;
@


<<function vmap>>=
/*
 * Add a device mapping to the vmap range.
 */
void*
vmap(ulong pa, int size)
{
    int osize;
    ulong o, va;
    
    /*
     * might be asking for less than a page.
     */
    osize = size;
    o = pa & (BY2PG-1);
    pa -= o;
    size += o;

    size = ROUND(size, BY2PG);
    if(pa == 0){
        print("vmap pa=0 pc=%#p\n", getcallerpc(&pa));
        return nil;
    }
    ilock(&vmaplock);
    if((va = vmapalloc(size)) == 0 
    || pdbmap(CPUS(0)->pdb, pa|PTEUNCACHED|PTEWRITE, va, size) < 0){
        iunlock(&vmaplock);
        return nil;
    }
    iunlock(&vmaplock);
    /* avoid trap on local processor
    for(i=0; i<size; i+=4*MB)
        vmapsync(va+i);
    */
    USED(osize);
//  print("  vmap %#.8lux %d => %#.8lux\n", pa+o, osize, va+o);
    return (void*)(va + o);
}
@


<<function findhole>>=
static int
findhole(ulong *a, int n, int count)
{
    int have, i;
    
    have = 0;
    for(i=0; i<n; i++){
        if(a[i] == 0)
            have++;
        else
            have = 0;
        if(have >= count)
            return i+1 - have;
    }
    return -1;
}
@


<<function vmapalloc>>=
/*
 * Look for free space in the vmap.
 */
static ulong
vmapalloc(ulong size)
{
    int i, n, o;
    ulong *vpdb;
    int vpdbsize;
    
    vpdb = &CPUS(0)->pdb[PDX(VMAP)];
    vpdbsize = VMAPSIZE/(4*MB);

    if(size >= 4*MB){
        n = (size+4*MB-1) / (4*MB);
        if((o = findhole(vpdb, vpdbsize, n)) != -1)
            return VMAP + o*4*MB;
        return 0;
    }
    n = (size+BY2PG-1) / BY2PG;
    for(i=0; i<vpdbsize; i++)
        if((vpdb[i]&PTEVALID) && !(vpdb[i]&PTESIZE))
            if((o = findhole(KADDR(PPN(vpdb[i])), WD2PG, n)) != -1)
                return VMAP + i*4*MB + o*BY2PG;
    if((o = findhole(vpdb, vpdbsize, 1)) != -1)
        return VMAP + o*4*MB;
        
    /*
     * could span page directory entries, but not worth the trouble.
     * not going to be very much contention.
     */
    return 0;
}
@

<<[[Cpu]] other fields>>=
bool flushmmu;   /* make current proc flush it's mmu state */
@

<<function vunmap>>=
/*
 * Remove a device mapping from the vmap range.
 * Since pdbunmap does not remove page tables, just entries,
 * the call need not be interlocked with vmap.
 */
void
vunmap(void *v, int size)
{
    int i;
    ulong va, o;
    Cpu *nm;
    Proc *p;
    
    /*
     * might not be aligned
     */
    va = (ulong)v;
    o = va&(BY2PG-1);
    va -= o;
    size += o;
    size = ROUND(size, BY2PG);
    
    if(size < 0 || va < VMAP || va+size > VMAP+VMAPSIZE)
        panic("vunmap va=%#.8lux size=%#x pc=%#.8lux",
            va, size, getcallerpc(&v));

    pdbunmap(CPUS(0)->pdb, va, size);
    
    /*
     * Flush mapping from all the tlbs and copied pdbs.
     * This can be (and is) slow, since it is called only rarely.
     * It is possible for vunmap to be called with up == nil,
     * e.g. from the reset/init driver routines during system
     * boot. In that case it suffices to flush the CPUS(0) TLB
     * and return.
     */
    if(!active.main_reached_sched){
        putcr3(PADDR(CPUS(0)->pdb));
        return;
    }
    for(i=0; i<conf.nproc; i++){
        p = proctab(i);
        if(p->state == Dead)
            continue;
        if(p != up)
            p->newtlb = true;
    }
    for(i=0; i<conf.ncpu; i++){
        nm = CPUS(i);
        if(nm != cpu)
            nm->flushmmu = true;
    }
    flushmmu();
    for(i=0; i<conf.ncpu; i++){
        nm = CPUS(i);
        if(nm != cpu)
            while((active.cpus&(1<<nm->cpuno)) && nm->flushmmu)
                ;
    }
}
@

<<function pdbmap>>=
/*
 * Add kernel mappings for pa -> va for a section of size bytes.
 */
int
pdbmap(ulong *pdb, ulong pa, ulong va, int size)
{
    int pse;
    ulong pgsz, *pte, *table;
    ulong flag, off;
    
    flag = pa&0xFFF;
    pa &= ~0xFFF;

    if((CPUS(0)->cpuiddx & Pse) && (getcr4() & 0x10))
        pse = 1;
    else
        pse = 0;

    for(off=0; off<size; off+=pgsz){
        table = &pdb[PDX(va+off)];
        if((*table&PTEVALID) && (*table&PTESIZE))
            panic("vmap: va=%#.8lux pa=%#.8lux pde=%#.8lux",
                va+off, pa+off, *table);

        /*
         * Check if it can be mapped using a 4MB page:
         * va, pa aligned and size >= 4MB and processor can do it.
         */
        if(pse && (pa+off)%(4*MB) == 0 && (va+off)%(4*MB) == 0 && (size-off) >= 4*MB){
            *table = (pa+off)|flag|PTESIZE|PTEVALID;
            pgsz = 4*MB;
        }else{
            pte = mmuwalk(pdb, va+off, 2, 1);
            if(*pte&PTEVALID)
                panic("vmap: va=%#.8lux pa=%#.8lux pte=%#.8lux",
                    va+off, pa+off, *pte);
            *pte = (pa+off)|flag|PTEVALID;
            pgsz = BY2PG;
        }
    }
    return 0;
}
@


<<function pdbunmap>>=
/*
 * Remove mappings.  Must already exist, for sanity.
 * Only used for kernel mappings, so okay to use KADDR.
 */
static void
pdbunmap(ulong *pdb, ulong va, int size)
{
    ulong vae;
    ulong *table;
    
    vae = va+size;
    while(va < vae){
        table = &pdb[PDX(va)];
        if(!(*table & PTEVALID)){
            panic("vunmap: not mapped");
            /* 
            va = (va+4*MB-1) & ~(4*MB-1);
            continue;
            */
        }
        if(*table & PTESIZE){
            *table = 0;
            va = (va+4*MB-1) & ~(4*MB-1);
            continue;
        }
        table = KADDR(PPN(*table));
        if(!(table[PTX(va)] & PTEVALID))
            panic("vunmap: not mapped");
        table[PTX(va)] = 0;
        va += BY2PG;
    }
}
@


<<function vmapsync>>=
/*
 * Handle a fault by bringing vmap up to date.
 * Only copy pdb entries and they never go away,
 * so no locking needed.
 */
int
vmapsync(ulong va)
{
    ulong entry, *table;

    if(va < VMAP || va >= VMAP+VMAPSIZE)
        return 0;

    entry = CPUS(0)->pdb[PDX(va)];
    if(!(entry&PTEVALID))
        return 0;
    if(!(entry&PTESIZE)){
        /* make sure entry will help the fault */
        table = KADDR(PPN(entry));
        if(!(table[PTX(va)]&PTEVALID))
            return 0;
    }
    vpd[PDX(va)] = entry;
    /*
     * TLB doesn't cache negative results, so no flush needed.
     */
    return 1;
}
@


<<function kmap>>=
KMap*
kmap(Page *page)
{
    int i, o, s;

    if(up == nil)
        panic("kmap: up=0 pc=%#.8lux", getcallerpc(&page));
    if(up->mmupdb == nil)
        upallocpdb();
    if(up->nkmap < 0)
        panic("kmap %lud %s: nkmap=%d", up->pid, up->text, up->nkmap);
    
    /*
     * Splhi shouldn't be necessary here, but paranoia reigns.
     * See comment in putmmu above.
     */
    s = splhi();
    up->nkmap++;
    if(!(vpd[PDX(KMAP)]&PTEVALID)){
        /* allocate page directory */
        if(KMAPSIZE > BY2XPG)
            panic("bad kmapsize");
        if(up->kmaptable != nil)
            panic("kmaptable");
        spllo();
        up->kmaptable = newpage(0, 0, 0);
        splhi();
        vpd[PDX(KMAP)] = up->kmaptable->pa|PTEWRITE|PTEVALID;
        flushpg((ulong)kpt);
        memset(kpt, 0, BY2PG);
        kpt[0] = page->pa|PTEWRITE|PTEVALID;
        up->lastkmap = 0;
        splx(s);
        return (KMap*)KMAP;
    }
    if(up->kmaptable == nil)
        panic("no kmaptable");
    o = up->lastkmap+1;
    for(i=0; i<NKPT; i++){
        if(kpt[(i+o)%NKPT] == 0){
            o = (i+o)%NKPT;
            kpt[o] = page->pa|PTEWRITE|PTEVALID;
            up->lastkmap = o;
            splx(s);
            return (KMap*)(KMAP+o*BY2PG);
        }
    }
    panic("out of kmap");
    return nil;
}
@


<<function kunmap>>=
void
kunmap(KMap *k)
{
    ulong va;

    va = (ulong)k;
    if(up->mmupdb == nil || !(vpd[PDX(KMAP)]&PTEVALID))
        panic("kunmap: no kmaps");
    if(va < KMAP || va >= KMAP+KMAPSIZE)
        panic("kunmap: bad address %#.8lux pc=%#p", va, getcallerpc(&k));
    if(!(vpt[VPTX(va)]&PTEVALID))
        panic("kunmap: not mapped %#.8lux pc=%#p", va, getcallerpc(&k));
    up->nkmap--;
    if(up->nkmap < 0)
        panic("kunmap %lud %s: nkmap=%d", up->pid, up->text, up->nkmap);
    vpt[VPTX(va)] = 0;
    flushpg(va);
}
@


<<function tmpmap>>=
void*
tmpmap(Page *p)
{
    ulong i;
    ulong *entry;
    
    if(islo())
        panic("tmpaddr: islo");

    if(fasttmp && p->pa < -KZERO)
        return KADDR(p->pa);

    /*
     * PDX(TMPADDR) == PDX(CPUADDR), so this
     * entry is private to the processor and shared 
     * between up->mmupdb (if any) and cpu->pdb.
     */
    entry = &vpt[VPTX(TMPADDR)];
    if(!(*entry&PTEVALID)){
        for(i=KZERO; i<=CPU0CPU; i+=BY2PG)
            print("%#p: *%#p=%#p (vpt=%#p index=%#p)\n", i, &vpt[VPTX(i)], vpt[VPTX(i)], vpt, VPTX(i));
        panic("tmpmap: no entry");
    }
    if(PPN(*entry) != PPN(TMPADDR-KZERO))
        panic("tmpmap: already mapped entry=%#.8lux", *entry);
    *entry = p->pa|PTEWRITE|PTEVALID;
    flushpg(TMPADDR);
    return (void*)TMPADDR;
}
@


<<function tmpunmap>>=
void
tmpunmap(void *v)
{
    ulong *entry;
    
    if(islo())
        panic("tmpaddr: islo");
    if(fasttmp && (ulong)v >= KZERO && v != (void*)TMPADDR)
        return;
    if(v != (void*)TMPADDR)
        panic("tmpunmap: bad address");
    entry = &vpt[VPTX(TMPADDR)];
    if(!(*entry&PTEVALID) || PPN(*entry) == PPN(PADDR(TMPADDR)))
        panic("tmpmap: not mapped entry=%#.8lux", *entry);
    *entry = PPN(TMPADDR-KZERO)|PTEWRITE|PTEVALID;
    flushpg(TMPADDR);
}
@





\section{Page fault}

% split copy-on-write feature in another section?
% have also demand-loading here

% see also trapinit

<<function fault386>>=
static void
fault386(Ureg* ureg, void*)
{
    ulong addr; // could be kernel (virtual) address or user (virtual) address
    bool read, insyscall, user;
    int n; // ret_code
    char buf[ERRMAX];

    addr = getcr2();
    read = !(ureg->ecode & 2);

    user = (ureg->cs & 0xFFFF) == UESEL;
    if(!user){
        if(vmapsync(addr))
            return;
        if(addr >= USTKTOP)
            panic("kernel fault: bad address pc=0x%.8lux addr=0x%.8lux", ureg->pc, addr);
        if(up == nil)
            panic("kernel fault: no user process pc=0x%.8lux addr=0x%.8lux", ureg->pc, addr);
    }
    if(up == nil)
        panic("user fault: up=0 pc=0x%.8lux addr=0x%.8lux", ureg->pc, addr);

    insyscall = up->insyscall;
    up->insyscall = true; // really?

    n = fault(addr, read); // portable code

    if(n < 0){
        if(!user){
            dumpregs(ureg);
            panic("fault: 0x%lux", addr);
        }
        checkpages();
        //checkfault(addr, ureg->pc);
        snprint(buf, sizeof buf, "sys: trap: fault %s addr=0x%lux",
            read ? "read" : "write", addr);
        postnote(up, 1, buf, NDebug);
    }
    up->insyscall = insyscall;
}
@ 



<<function checkpages>>=
void
checkpages(void)
{
    int checked;
    ulong addr, off;
    Pte *p;
    Page *pg;
    Segment **sp, **ep, *s;
    
    if(up == nil)
        return;

    checked = 0;
    // foreach(up->seg)
    for(sp=up->seg, ep=&up->seg[NSEG]; sp<ep; sp++){
        s = *sp;
        if(s == nil)
            continue;
        qlock(&s->lk);
        for(addr=s->base; addr<s->top; addr+=BY2PG){
            off = addr - s->base;
            p = s->map[off/PTEMAPMEM];
            if(p == nil)
                continue;
            pg = p->pages[(off&(PTEMAPMEM-1))/BY2PG];
            if(pg == nil || pagedout(pg))
                continue;
            checkmmu(addr, pg->pa);
            checked++;
        }
        qunlock(&s->lk);
    }
    print("%ld %s: checked %d page table entries\n", up->pid, up->text, checked);
}
@



% ret_code2?
<<function fault>>=
int
fault(virt_addr addr, bool read)
{
    Segment *s;
    char *sps;

    if(up == nil)
        panic("fault: nil up");
    if(up->nlocks.ref)
        print("fault: addr %#p: nlocks %ld\n", addr, up->nlocks.ref);

    sps = up->psstate;
    up->psstate = "Fault";
    spllo();

    cpu->pfault++;
    for(;;) {
        s = seg(up, addr, /*dolock*/true); /* leaves s->lk qlocked if seg != nil */
        if(s == nil) {
            up->psstate = sps;
            return -1;
        }

        if(!read && (s->type&SG_RONLY)) {
            qunlock(&s->lk);
            up->psstate = sps;
            return -1;
        }

        if(fixfault(s, addr, read, /*putmmu*/true) == 0) /* qunlocks s->lk */
            break;

        // else? try again?
    }

    up->psstate = sps;
    return 0;
}
@


<<[[Conf]] other fields>>=
bool copymode; /* 0 is copy on write, 1 is copy on reference */
@

% The big one! very important function!
%ret_code
<<function fixfault>>=
int
fixfault(Segment *s, virt_addr addr, bool read, bool doputmmu)
{
    int type;
    int ref;
    Pte **p, *etp;
    ulong mmuphys=0;
    ulong soff;
    Page **pg, *lkp, *new;
    Page *(*fn)(Segment*, ulong);

    addr &= ~(BY2PG-1);
    soff = addr - s->base;
    p = &s->map[soff/PTEMAPMEM];
    if(*p == 0)
        *p = ptealloc();

    etp = *p;
    pg = &etp->pages[(soff&(PTEMAPMEM-1))/BY2PG];
    type = s->type&SG_TYPE;

    if(pg < etp->first)
        etp->first = pg;
    if(pg > etp->last)
        etp->last = pg;

    switch(type) {
    default:
        panic("fault");
        break;

    case SG_TEXT:           /* Demand load */
        if(pagedout(*pg))
            pio(s, addr, soff, pg);

        mmuphys = PPN((*pg)->pa) | PTERONLY|PTEVALID;
        (*pg)->modref = PG_REF;
        break;

    case SG_BSS:
    case SG_SHARED:         /* Zero fill on demand */
    case SG_STACK:
        if(*pg == 0) {
            new = newpage(1, &s, addr);
            if(s == nil) //?? when can be nil at exit?
                return -1;
            *pg = new;
        }
        goto common;

    case SG_DATA:
    common:         /* Demand load/pagein/copy on write */
        if(pagedout(*pg))
            pio(s, addr, soff, pg);

        /*
         *  It's only possible to copy on write if
         *  we're the only user of the segment.
         */
        if(read && conf.copymode == false && s->ref == 1) {
            mmuphys = PPN((*pg)->pa)|PTERONLY|PTEVALID;
            (*pg)->modref |= PG_REF;
            break;
        }

        lkp = *pg;
        lock(lkp);

        if(lkp->image == &swapimage)
            ref = lkp->ref + swapcount(lkp->daddr);
        else
            ref = lkp->ref;
        if(ref == 1 && lkp->image){
            /* save a copy of the original for the image cache */
            duppage(lkp);
            ref = lkp->ref;
        }
        unlock(lkp);
        if(ref > 1){
            new = newpage(0, &s, addr);
            if(s == nil)
                return -1;
            *pg = new;
            copypage(lkp, *pg);
            putpage(lkp);
        }
        mmuphys = PPN((*pg)->pa) | PTEWRITE | PTEVALID;
        (*pg)->modref = PG_MOD|PG_REF;
        break;

    case SG_PHYSICAL:
        if(*pg == 0) {
            fn = s->pseg->pgalloc;
            if(fn)
                *pg = (*fn)(s, addr);
            else {
                new = smalloc(sizeof(Page));
                new->va = addr;
                new->pa = s->pseg->pa+(addr-s->base);
                new->ref = 1;
                *pg = new;
            }
        }

        if (checkaddr && addr == addr2check)
            (*checkaddr)(addr, s, *pg);
        mmuphys = PPN((*pg)->pa) |PTEWRITE|PTEUNCACHED|PTEVALID;
        (*pg)->modref = PG_MOD|PG_REF;
        break;
    }
    qunlock(&s->lk);

    if(doputmmu)
        putmmu(addr, mmuphys, *pg);

    return 0; // OK
}
@


<<function pio>>=
// page io on the text segment
void
pio(Segment *s, ulong addr, ulong soff, Page **p)
{
    Page *new;
    KMap *k;
    Chan *c;
    int n, ask;
    char *kaddr;
    ulong daddr; // disk address
    Page *loadrec;

retry:
    loadrec = *p;
    if(loadrec == nil) {  /* from a text/data image */
        daddr = s->fstart+soff;
        new = lookpage(s->image, daddr);
        if(new != nil) {
            *p = new;
            return;
        }

        c = s->image->c;
        ask = s->flen-soff;
        if(ask > BY2PG)
            ask = BY2PG;
    }
    else {          /* from a swap image */
        daddr = swapaddr(loadrec);
        new = lookpage(&swapimage, daddr);
        if(new != nil) {
            putswap(loadrec);
            *p = new;
            return;
        }

        c = swapimage.c;
        ask = BY2PG;
    }
    qunlock(&s->lk);

    new = newpage(0, 0, addr);
    k = kmap(new);
    kaddr = (char*)VA(k);

    while(waserror()) {
        if(strcmp(up->errstr, Eintr) == 0)
            continue;
        kunmap(k);
        putpage(new);
        faulterror(Eioload, c, 0);
    }

    n = devtab[c->type]->read(c, kaddr, ask, daddr);
    if(n != ask)
        faulterror(Eioload, c, 0);
    if(ask < BY2PG)
        memset(kaddr+ask, 0, BY2PG-ask);

    poperror();
    kunmap(k);
    qlock(&s->lk);
    if(loadrec == 0) {  /* This is demand load */
        /*
         *  race, another proc may have gotten here first while
         *  s->lk was unlocked
         */
        if(*p == 0) { 
            new->daddr = daddr;
            cachepage(new, s->image);
            *p = new;
        }
        else
            putpage(new);
    }
    else {          /* This is paged out */
        /*
         *  race, another proc may have gotten here first
         *  (and the pager may have run on that page) while
         *  s->lk was unlocked
         */
        if(*p != loadrec){
            if(!pagedout(*p)){
                /* another process did it for me */
                putpage(new);
                goto done;
            } else {
                /* another process and the pager got in */
                putpage(new);
                goto retry;
            }
        }

        new->daddr = daddr;
        cachepage(new, &swapimage);
        *p = new;
        putswap(loadrec);
    }

done:
    if(s->flushme)
        memset((*p)->cachectl, PG_TXTFLUSH, sizeof((*p)->cachectl));
}
@


<<function faulterror>>=
static void
faulterror(char *s, Chan *c, bool freemem)
{
    char buf[ERRMAX];

    if(c && c->path){
        snprint(buf, sizeof buf, "%s accessing %s: %s", s, c->path->s, up->errstr);
        s = buf;
    }
    if(up->nerrlab) {
        postnote(up, 1, s, NDebug);
        error(s);
    }
    pexit(s, freemem);
}
@



\section{Swapping}

<<struct Swapalloc>>=
// Swap allocator (singleton)
struct Swapalloc
{
    int free;     /* currently free swap pages */
    uchar*  swmap;      /* Base of swap map in memory */
    uchar*  alloc;      /* Round robin allocator */
    uchar*  last;     /* Speed swap allocation */
    uchar*  top;      /* Top of swap map */
    Rendez r;      /* Pager kproc idle sleep */ // needpages()
    ulong highwater;    /* Pager start threshold */
    ulong headroom;   /* Space pager frees under highwater */
  
    //extra
    Lock;       /* Free map lock */
};
@


<<[[Conf]] other fields>>=
ulong nswap;    /* number of swap pages */
int nswppo;   /* max # of pageouts per segment pass */
@


<<function newswap>>=
ulong
newswap(void)
{
    uchar *look;

    lock(&swapalloc);

    if(swapalloc.free == 0){
        unlock(&swapalloc);
        return ~0;
    }

    look = memchr(swapalloc.last, 0, swapalloc.top-swapalloc.last);
    if(look == 0)
        panic("inconsistent swap");

    *look = 1;
    swapalloc.last = look;
    swapalloc.free--;
    unlock(&swapalloc);
    return (look-swapalloc.swmap) * BY2PG;
}
@


<<function putswap>>=
void
putswap(Page *p)
{
    uchar *idx;

    lock(&swapalloc);
    idx = &swapalloc.swmap[((ulong)p)/BY2PG];
    if(--(*idx) == 0) {
        swapalloc.free++;
        if(idx < swapalloc.last)
            swapalloc.last = idx;
    }
    if(*idx >= 254)
        panic("putswap %#p == %ud", p, *idx);
    unlock(&swapalloc);
}
@


<<function dupswap>>=
void
dupswap(Page *p)
{
    lock(&swapalloc);
    if(++swapalloc.swmap[((ulong)p)/BY2PG] == 0)
        panic("dupswap");
    unlock(&swapalloc);
}
@


<<function swapcount>>=
int
swapcount(ulong daddr)
{
    return swapalloc.swmap[daddr/BY2PG];
}
@


<<function kickpager>>=
void
kickpager(void)
{
    static bool started;

    if(started)
        wakeup(&swapalloc.r);
    else {
        kproc("pager", pager, 0);
        started = true;
    }
}
@

<<[[Proc]] memory fields>>=
bool noswap;   /* process is not swappable */
@


<<function pager>>=
static void
pager(void *junk)
{
    int i;
    Segment *s;
    Proc *p, *ep;

    if(waserror())
        panic("pager: os error");

    p = proctab(0);
    ep = &p[conf.nproc];

loop:
    up->psstate = "Idle";
    wakeup(&palloc.freememr);
    sleep(&swapalloc.r, needpages, 0);

    while(needpages(junk)) {
        if(swapimage.c) {
            p++;
            if(p >= ep){
                p = proctab(0);
                gentick();          
            }

            if(p->state == Dead || p->noswap)
                continue;

            if(!canqlock(&p->seglock))
                continue;       /* process changing its segments */

            for(i = 0; i < NSEG; i++) {
                if(!needpages(junk)){
                    qunlock(&p->seglock);
                    goto loop;
                }

                if(s = p->seg[i]) {
                    switch(s->type&SG_TYPE) {
                    default:
                        break;
                    case SG_TEXT:
                        pageout(p, s);
                        break;
                    case SG_DATA:
                    case SG_BSS:
                    case SG_STACK:
                    case SG_SHARED:
                        up->psstate = "Pageout";
                        pageout(p, s);
                        if(ioptr != 0) {
                            up->psstate = "I/O";
                            executeio();
                        }
                        break;
                    }
                }
            }
            qunlock(&p->seglock);
        } else {
            print("out of memory\n");
            killbig("out of memory");
            freebroken();       /* can use the memory */

            /* Emulate the old system if no swap channel */
            if(!swapimage.c)
                tsleep(&up->sleepr, returnfalse, 0, 5000);
        }
    }
    goto loop;
}
@


<<function pageout>>=
static void
pageout(Proc *p, Segment *s)
{
    int type, i, size;
    ulong age;
    Pte *l;
    Page **pg, *entry;

    if(!canqlock(&s->lk))   /* We cannot afford to wait, we will surely deadlock */
        return;

    if(s->steal) {      /* Protected by /dev/proc */
        qunlock(&s->lk);
        return;
    }

    if(!canflush(p, s)) {   /* Able to invalidate all tlbs with references */
        qunlock(&s->lk);
        putseg(s);
        return;
    }

    if(waserror()) {
        qunlock(&s->lk);
        putseg(s);
        return;
    }

    /* Pass through the pte tables looking for memory pages to swap out */
    type = s->type&SG_TYPE;
    size = s->mapsize;
    for(i = 0; i < size; i++) {
        l = s->map[i];
        if(l == 0)
            continue;
        for(pg = l->first; pg < l->last; pg++) {
            entry = *pg;
            if(pagedout(entry))
                continue;

            if(entry->modref & PG_REF) {
                entry->modref &= ~PG_REF;
                entry->gen = genclock;
            }

            if(genclock < entry->gen)
                age = ~(entry->gen - genclock);
            else
                age = genclock - entry->gen;
            gensum += age;
            gencount++;
            if(age <= genage)
                continue;

            pagepte(type, pg);

            if(ioptr >= conf.nswppo)
                goto out;
        }
    }
out:
    poperror();
    qunlock(&s->lk);
    putseg(s);
}
@


<<function canflush>>=
static bool
canflush(Proc *p, Segment *s)
{
    int i;
    Proc *ep;

    lock(s);
    if(s->ref == 1) {       /* Easy if we are the only user */
        s->ref++;
        unlock(s);
        return canpage(p);
    }
    s->ref++;
    unlock(s);

    /* Now we must do hardwork to ensure all processes which have tlb
     * entries for this segment will be flushed if we succeed in paging it out
     */
    p = proctab(0);
    ep = &p[conf.nproc];
    while(p < ep) {
        if(p->state != Dead) {
            for(i = 0; i < NSEG; i++)
                if(p->seg[i] == s)
                    if(!canpage(p))
                        return false;
        }
        p++;
    }
    return true;
}
@


<<function pagepte>>=
static void
pagepte(int type, Page **pg)
{
    ulong daddr;
    Page *outp;

    outp = *pg;
    switch(type) {
    case SG_TEXT:               /* Revert to demand load */
        putpage(outp);
        *pg = 0;
        break;

    case SG_DATA:
    case SG_BSS:
    case SG_STACK:
    case SG_SHARED:
        /*
         *  get a new swap address and clear any pages
         *  referring to it from the cache
         */
        daddr = newswap();
        if(daddr == ~0)
            break;
        cachedel(&swapimage, daddr);

        lock(outp);

        /* forget anything that it used to cache */
        uncachepage(outp);

        /*
         *  incr the reference count to make sure it sticks around while
         *  being written
         */
        outp->ref++;

        /*
         *  enter it into the cache so that a fault happening
         *  during the write will grab the page from the cache
         *  rather than one partially written to the disk
         */
        outp->daddr = daddr;
        cachepage(outp, &swapimage);
        *pg = (Page*)(daddr|PG_ONSWAP);
        unlock(outp);

        /* Add page to IO transaction list */
        iolist[ioptr++] = outp;
        break;
    }
}
@



<<function pageiocomp>>=
static int
pageiocomp(void *a, void *b)
{
    Page *p1, *p2;

    p1 = *(Page **)a;
    p2 = *(Page **)b;
    if(p1->daddr > p2->daddr)
        return 1;
    else
        return -1;
}
@

<<global iolist>>=
static  Page    **iolist;
@

<<globa ioptr>>=
static  int ioptr;
@


<<function executeio>>=
static void
executeio(void)
{
    Page *out;
    int i, n;
    Chan *c;
    char *kaddr;
    KMap *k;

    c = swapimage.c;
    qsort(iolist, ioptr, sizeof iolist[0], pageiocomp);
    for(i = 0; i < ioptr; i++) {
        if(ioptr > conf.nswppo)
            panic("executeio: ioptr %d > %d", ioptr, conf.nswppo);
        out = iolist[i];
        k = kmap(out);
        kaddr = (char*)VA(k);

        if(waserror())
            panic("executeio: page out I/O error");

        n = devtab[c->type]->write(c, kaddr, BY2PG, out->daddr);
        if(n != BY2PG)
            nexterror();

        kunmap(k);
        poperror();

        /* Free up the page after I/O */
        lock(out);
        out->ref--;
        unlock(out);
        putpage(out);
    }
    ioptr = 0;
}
@


<<function needpages>>=
static bool
needpages(void*)
{
    return palloc.freecount < swapalloc.headroom;
}
@


<<function setswapchan>>=
void
setswapchan(Chan *c)
{
    uchar dirbuf[sizeof(Dir)+100];
    Dir d;
    int n;

    if(swapimage.c) {
        if(swapalloc.free != conf.nswap){
            cclose(c);
            error(Einuse);
        }
        cclose(swapimage.c);
    }

    /*
     *  if this isn't a file, set the swap space
     *  to be at most the size of the partition
     */
    if(devtab[c->type]->dc != L'M'){
        n = devtab[c->type]->stat(c, dirbuf, sizeof dirbuf);
        if(n <= 0){
            cclose(c);
            error("stat failed in setswapchan");
        }
        convM2D(dirbuf, n, &d, nil);
        if(d.length < conf.nswap*BY2PG){
            conf.nswap = d.length/BY2PG;
            swapalloc.top = &swapalloc.swmap[conf.nswap];
            swapalloc.free = conf.nswap;
        }
    }

    swapimage.c = c;
}
@

%\section{Demand loading}
% KImage is demand loading? or just a form of sharing? so that 10 bash
% dont pay for it
% but no shared libs


\chapter{Scheduling}
% virtual CPU?

\section{Overview}

% in essence the main role of an OS is to manage programs and so in essence
% it is first and foremost a scheduler! 

% first part is cooperative scheduling, with sleep/wakeup
%  and people calling sched themselves
% then will see preemptive scheduling with interrupt clock


% What a system would look like without (preemptive) scheduling?
%  - a malicious/buggy process could never yield (see MacOS 9 ... windows 3.1)
%  - DOS didn't even offer cooperative scheduling, so could just have one
%    process at a time (at least windows 3.1 improved a bit on that)

% see also section in Debugging about /bin/trace that allows to
% trace scheduler events

\section{Process priority}
%adjustable priority actually

<<constant Npriq>>=
Npriq   = 20,   /* number of scheduler priority levels */
@

<<enum priority>>=
enum priority 
{
    PriNormal = 10,   /* base priority for normal processes */
    PriKproc  = 13,   /* base priority for kernel processes */
    PriRoot   = 13,   /* base priority for root processes */

    <<constants for real-time priority>>
};
@ 

<<[[Proc]] scheduling fields>>=
// enum<priority>
ulong priority; /* priority level */

ulong basepri;  /* base priority level */
bool fixedpri; /* priority level doesn't change */
@ 


<<function procpriority>>=
void
procpriority(Proc *p, int pri, bool fixed)
{
    if(pri >= Npriq)
        pri = Npriq - 1;
    else if(pri < 0)
        pri = 0;

    p->basepri = pri;
    p->priority = pri;
    p->fixedpri = fixed;
}
@ 


\section{The [[runq]]ueue}

<<constant Nrq>>=
Nrq   = Npriq+2,  /* number of priority levels including real time */
@

<<global runq>>=
// The run queue!!
// hash<enum<priority>, queue<ref<Proc>>>
Schedq  runq[Nrq];
@ 

<<struct Schedq>>=
// essentially a queue<ref<Proc>>
struct Schedq
{
    // list<ref<Proc>> (next = Proc.rnext)
    Proc* head;
    // ref<Proc>, the tail
    Proc* tail;
    // size of list
    int n; 
  
    // extra
    Lock;
};
@ 

<<[[Proc]] extra fields>>=
// list<ref<Proc>> of Schedq.head
Proc  *rnext;   /* next process in run queue */
@



<<global runveq>>=
// array<bool>, each bit i represents whether the runq at pri i has processes
ulong   runvec; // coupling: sizeof(ulong) must be >= Nrq
@ 

<<function anyready>>=
bool
anyready(void)
{
    return runvec;
}
@ 

<<global nrdy>>=
int nrdy;
@ 

<<function queueproc>>=
/*
 * add a process to a scheduling queue
 */
void
queueproc(Schedq *rq, Proc *p)
{
    int pri;

    pri = rq - runq;
    lock(runq);
    p->priority = pri;

    // add_queue(p, rq)
    p->rnext = nil;
    if(rq->tail)
        rq->tail->rnext = p;
    else
        rq->head = p;
    rq->tail = p;
    rq->n++;

    nrdy++;
    runvec |= 1<<pri;
    unlock(runq);
}
@ 

<<function dequeueproc>>=
/*
 *  try to remove a process from a scheduling queue (called splhi)
 */
// tp should belong to the queue
Proc*
dequeueproc(Schedq *rq, Proc *tp)
{
    Proc *l, *p;

    if(!canlock(runq))
        return nil;

    /*
     *  the queue may have changed before we locked runq,
     *  refind the target process.
     */
    l = nil;
    for(p = rq->head; p; p = p->rnext){
        if(p == tp)
            break;
        l = p;
    }
    // l should be nil most of the time, the queue probably didn't change

    /*
     *  p->cpu==nil only when process state is saved
     */
    if(p == nil || p->cpu){
        unlock(runq);
        return nil;
    }

    // remove_queue(p, rq)
    if(p->rnext == nil)
        rq->tail = l;
    if(l)
        l->rnext = p->rnext;
    else
        rq->head = p->rnext;
    if(rq->head == nil)
        runvec &= ~(1<<(rq-runq));
    rq->n--;

    nrdy--;

    if(p->state != Ready)
        print("dequeueproc %s %lud %s\n", p->text, p->pid, statename[p->state]);

    unlock(runq);
    return p;
}
@ 

\section{[[sched()]]}

% address from cpus, not MACHADDR, could have used cpuno, don't want 0
<<[[Proc]] scheduling fields>>=
// option<ref<Cpu>>, null when not associated to a processor
Cpu  *cpu;    /* processor running this proc */
@

% and more importantly cpu->proc!!  (so have proc->cpu and cpu->proc)
% sched() will essentially do cpu->proc = newp; (or up = newp)


% actually why could not factorize code with sleep()?
<<function sched>>=
/*
 *  If changing this routine, look also at sleep().  It
 *  contains a copy of the guts of sched().
 */
void
proc_sched(void)
{
    Proc *p;

    if(cpu->ilockdepth)
        panic("cpu%d: ilockdepth %d, last lock %#p at %#p, sched called from %#p",
            cpu->cpuno, cpu->ilockdepth, up? up->lastilock: nil,
            (up && up->lastilock)? up->lastilock->pc: 0, getcallerpc(&p+2));
    if(up){
        <<[[sched()]] if complex condition increment delaysched and return>>
        splhi(); // schedinit requires this
        cpu->cs++;

        procsave(up);
        if(setlabel(&up->sched)){
            //
            // here when the process has been scheduled back
            // from a gotolabel(up->sched) by another process, see below
            //
            procrestore(up);
            spllo();
            return;
        } else {
            //
            // here to go to schedinit() (which will call sched() back)
            //
            gotolabel(&cpu->sched); // goto schedinit()
            panic("sched: should never reach this point");
        }
    }
    // We should execute this code using the main kernel stack, as
    // we should arrive here from schedinit().

    p = runproc();
    <<[[sched()]] optional guard for real-time process>>
    {
        updatecpu(p);
        p->priority = reprioritize(p);
    }
    if(p != cpu->readied)
        cpu->schedticks = cpu->ticks + HZ/10; // 100ms of allocated time
    cpu->readied = nil;

    cpu->proc = p;
    up = p; // same instruction than previous line on some archi (e.g. PC)

    up->state = Running;
    up->cpu = CPUS(cpu->cpuno);

    mmuswitch(up);
    gotolabel(&up->sched);
}
@ 

% Why going to schedinit()? Why not call sched() recursively? or goto common:
% where we would do the p = runproc() ...? See below.


% less: have a [[Cpu]] scheduler fields? 
% this not really related to contextswitch
% the sched of the Cpu is to jump to schedinit that eventually calls sched()
<<[[Cpu]] other fields>>=
Label sched;      /* scheduler wakeup */ // address of schedinit()
@

<<function schedinit>>=
/*
 * Always splhi()'ed.
 */
void
schedinit(void)     /* never returns */
{
    Edf *e;

    setlabel(&cpu->sched);

    if(up) {
        <<[[schedinit()]] optional real-time [[edfrecord()]]>>
        //old: cpu->proc = nil;
        // but now that on PC up = cpu->proc and not cpu->externup
        // we can't do that anymore. Is there a place that rely on
        // cpu->proc and cpu-externup to not be in sync?
        switch(up->state) {
        case Running:
            ready(up);
            break;
        case Moribund:
            up->state = Dead;
            <<[[schedinit()]] optional real-time [[edfstop()]]>>
            /*
             * Holding locks from pexit:
             *  procalloc
             *  palloc
             */
            mmurelease(up);

            up->qnext = procalloc.free;
            procalloc.free = up;

            unlock(&palloc);
            unlock(&procalloc);
            break;
        }

        up->cpu = nil;
        updatecpu(up);

        cpu->proc = nil;
        up = nil; // same instruction than previous line on some archi (e.g. PC)
    }
    // ok at this point up is nil
    sched();
}
@ 
% Why the logic of scheduling is splitted between sched() and schedinit()?
% could not gather? And doing so remove the need for Cpu->label?
% I think it's related to the per-process stack.
% Once you've called setlabel(), that means you saved the kernel context
% of a certain process, you should not use the kernel stack of
% this process for other things, you should switch to an exterior 
% process-indepent task, that is the main() kernel stack!
% Also the dying code is there in schedinit(), maybe because when
% we are releasing the memory of a process, we need a stack ... and we 
% can't use anymore the stack of the process! so have to switch to the
% stack of main()!! (hmmm but actually we never free Proc->kstack ... so
% we could for a few more instructions use it)
% todo: look in balestero's notes



<<function runproc>>=
/*
 *  pick a process to run
 */
Proc*
runproc(void)
{
    Schedq *rq;
    Proc *p;
    ulong start, now;
    int i;
    void (*pt)(Proc*, int, vlong);

    start = perfticks();

    /* cooperative scheduling until the clock ticks */
    if((p=cpu->readied) && p->cpu==nil && p->state==Ready && 
      (p->wired == nil || p->wired == cpu) && 
      <<[[runproc()]] test for empty real-time scheduling queue>>
    ){
        skipscheds++;
        rq = &runq[p->priority];
        goto found;
    }

    preempts++;

loop:
    /*
     *  find a process that last ran on this processor (affinity),
     *  or one that hasn't moved in a while (load balancing). Every
     *  time around the loop affinity goes down.
     */
    spllo();
    for(i = 0;; i++){
        /*
         *  find the highest priority target process that this
         *  processor can run given affinity constraints.
         *
         */
        for(rq = &runq[Nrq-1]; rq >= runq; rq--){
            for(p = rq->head; p; p = p->rnext){
                if(p->lastcpu == nil || p->lastcpu == CPUS(cpu->cpuno)
                || (!p->wired && i > 0))
                    goto found;
            }
        }
        // nothing found
        /* waste time or halt the CPU */
        idlehands();

        /* remember how much time we're here */
        now = perfticks();
        cpu->perf.inidle += now-start;
        start = now;
    }

found:
    splhi();
    p = dequeueproc(rq, p);
    if(p == nil)
        goto loop;

    p->state = Scheding;
    p->lastcpu = CPUS(cpu->cpuno);

    <<[[runproc()]] test if p is a real-time process>>
    <<[[runproc()]] hook proctrace>>
    return p;
}
@ 


<<[[Proc]] scheduling fields>>=
Cpu *lastcpu;    /* processor this process last ran on */
@




% new typedef? Ttick_scaled?
<<[[Proc]] scheduling fields>>=
ulong lastupdate; // dimension?? ticks * Scaling;
ulong cpuavg;    /* cpu average */
@

<<constant Scaling>>=
Scaling=2,
@
<<constant Schedagain>>=
schedgain = 30, /* units in seconds */
@


<<function updatecpu>>=
/*
 * Update the cpu time average for this particular process,
 * which is about to change from up -> not up or vice versa.
 * p->lastupdate is the last time an updatecpu happened.
 *
 * The cpu time average is a decaying average that lasts
 * about D clock ticks.  D is chosen to be approximately
 * the cpu time of a cpu-intensive "quick job".  A job has to run
 * for approximately D clock ticks before we home in on its 
 * actual cpu usage.  Thus if you manage to get in and get out
 * quickly, you won't be penalized during your burst.  Once you
 * start using your share of the cpu for more than about D
 * clock ticks though, your p->cpu hits 1000 (1.0) and you end up 
 * below all the other quick jobs.  Interactive tasks, because
 * they basically always use less than their fair share of cpu,
 * will be rewarded.
 *
 * If the process has not been running, then we want to
 * apply the filter
 *
 *  cpu = cpu * (D-1)/D
 *
 * n times, yielding 
 * 
 *  cpu = cpu * ((D-1)/D)^n
 *
 * but D is big enough that this is approximately 
 *
 *  cpu = cpu * (D-n)/D
 *
 * so we use that instead.
 * 
 * If the process has been running, we apply the filter to
 * 1 - cpu, yielding a similar equation.  Note that cpu is 
 * stored in fixed point (* 1000).
 *
 * Updatecpu must be called before changing up, in order
 * to maintain accurate cpu usage statistics.  It can be called
 * at any time to bring the stats for a given proc up-to-date.
 */
void
updatecpu(Proc *p)
{
    int n, t, ocpu;
    int D = schedgain*HZ*Scaling;

    if(p->edf)
        return;

    t = CPUS(0)->ticks*Scaling + Scaling/2;
    n = t - p->lastupdate;
    p->lastupdate = t;

    if(n == 0)
        return;
    if(n > D)
        n = D;

    ocpu = p->cpuavg;
    if(p != up)
        p->cpuavg = (ocpu*(D-n))/D;
    else{
        t = 1000 - ocpu;
        t = (t*(D-n))/D;
        p->cpuavg = 1000 - t;
    }

//iprint("pid %d %s for %d cpu %d -> %d\n", p->pid,p==up?"active":"inactive",n, ocpu,p->cpuavg);
}
@ 


<<function reprioritize>>=
/*
 * On average, p has used p->cpuavg of a cpu recently.
 * Its fair share is conf.ncpu/cpu->load of a cpu.  If it has been getting
 * too much, penalize it.  If it has been getting not enough, reward it.
 * I don't think you can get much more than your fair share that 
 * often, so most of the queues are for using less.  Having a priority
 * of 3 means you're just right.  Having a higher priority (up to p->basepri) 
 * means you're not using as much as you could.
 */
int
reprioritize(Proc *p)
{
    int fairshare, n, load, ratio;

    load = CPUS(0)->load;
    if(load == 0)
        return p->basepri;

    /*
     *  fairshare = 1.000 * conf.nproc * 1.000/load,
     * except the decimal point is moved three places
     * on both load and fairshare.
     */
    fairshare = (conf.ncpu*1000*1000)/load;
    n = p->cpuavg;
    if(n == 0)
        n = 1;
    ratio = (fairshare+n/2) / n;
    if(ratio > p->basepri)
        ratio = p->basepri;
    if(ratio < 0)
        panic("reprioritize");
//iprint("pid %d cpu %d load %d fair %d pri %d\n", p->pid, p->cpuavg, load, fairshare, ratio);
    return ratio;
}
@ 



\subsection{Delayed [[sched()]]}

% when can have this situation? up->delaysched < 20
% means sched() got called like 20 times, but impossible no?

<<[[Proc]] scheduling fields>>=
ulong delaysched;
@

<<[[sched()]] if complex condition increment delaysched and return>>=
/*
 * Delay the sched until the process gives up the locks
 * it is holding.  This avoids dumb lock loops.
 *
 * But don't delay if the process is Moribund.
 * It called sched to die.
 * But do sched eventually. This avoids a missing unlock
 * from hanging the entire kernel. 
 * But don't reschedule procs holding palloc or procalloc.
 * Those are far too important to be holding while asleep.
 *
 * This test is not exact.  There can still be a few instructions
 * in the middle of taslock when a process holds a lock
 * but Lock.p has not yet been initialized.
 */
if(up->nlocks.ref)
  if(up->state != Moribund)
    if(up->delaysched < 20
      || palloc.Lock.p == up
      || procalloc.Lock.p == up){

        up->delaysched++;
        delayedscheds++; // stats
        return;
    }
up->delaysched = 0;
@


<<[[trap()]] if delaysched>>=
/* delaysched set because we held a lock or because our quantum ended */
if(up && up->delaysched && clockintr){
    sched();
    splhi();
}
@

<<[[syscall()]] if delaysched>>=
/* if we delayed sched because we held a lock, sched now */
if(up->delaysched)
    sched();
@

<<[[unlock()]] if delaysched>>=
if(up && deccnt(&up->nlocks) == 0 && up->delaysched && islo()){
    /*
     * Call sched if the need arose while locks were held
     * But, don't do it from interrupt routines, hence the islo() test
     */
    sched();
}
@


\section{Context switch}
% probably needs to see this section before sched()

<<struct Label>>=
// =~ a jumpbuf in C, for coroutines
struct Label
{
    // or virt_addr? used also for saving context of user code?
    kern_addr sp; 
    kern_addr pc; 
};
@ 

% is this enough? what about the other registers? the kernel code assumes
% compiles with kencc, so the only context we need is this.
% no need save registers, the caller compiled code should have done
% that before calling setlabel(). Note that this is ok because
% gotolabel assumes we jump to other kernel code compiled via kencc!
% for the user switch, this is not the same (also because can
% be interrupted in the middle of anything) and so we save
% everything.

% cflow of syscall e.g. syssleep is: user -> kernel -> sleep ->
% kernel switch gotolabel -> return from kernel code (syscall or trap)
% restore registers back from kernel code to user.

<<[[Proc]] assembly fields>>=
Label sched;    /* known to l.s */
char  *kstack;  /* known to l.s */
@ 

<<constant KSTACK>>=
#define KSTACK    4096      /* Size of kernel stack */
@

% TSS, mmu, sched labels, ... many switches

<<function gotolabel>>=
/*
 *  label consists of a stack pointer and a PC
 */
TEXT gotolabel(SB), $0
        MOVL    label+0(FP), AX
        MOVL    0(AX), SP                       /* restore sp */
        MOVL    4(AX), AX                       /* put return pc on the stack */
        MOVL    AX, 0(SP)
        MOVL    $1, AX                          /* return true */
        RET
@


<<function setlabel>>=
TEXT setlabel(SB), $0
        MOVL    label+0(FP), AX
        MOVL    SP, 0(AX)                       /* store sp */
        MOVL    0(SP), BX                       /* store return pc */
        MOVL    BX, 4(AX)
        MOVL    $0, AX                          /* return false */
        RET

@


<<function mmuswitch>>=
void
mmuswitch(Proc* proc)
{
    ulong *pdb;

    if(proc->newtlb){
        mmuptefree(proc);
        proc->newtlb = false;
    }

    if(proc->mmupdb){
        pdb = tmpmap(proc->mmupdb);
        pdb[PDX(CPUADDR)] = cpu->pdb[PDX(CPUADDR)];
        tmpunmap(pdb);
        taskswitch(proc->mmupdb->pa, (ulong)(proc->kstack+KSTACK));
    }else
        taskswitch(PADDR(cpu->pdb), (ulong)(proc->kstack+KSTACK));
}
@



<<struct Tss>>=
struct Tss {
    ulong link;     /* link (old TSS selector) */
    ulong esp0;     /* privilege level 0 stack pointer */
    ulong ss0;      /* privilege level 0 stack selector */
    ulong esp1;     /* privilege level 1 stack pointer */
    ulong ss1;      /* privilege level 1 stack selector */
    ulong esp2;     /* privilege level 2 stack pointer */
    ulong ss2;      /* privilege level 2 stack selector */
    ulong xcr3;     /* page directory base register - not used because we don't use trap gates */
    ulong eip;      /* instruction pointer */
    ulong eflags;     /* flags register */
    ulong eax;      /* general registers */
    ulong   ecx;
    ulong edx;
    ulong ebx;
    ulong esp;
    ulong ebp;
    ulong esi;
    ulong edi;
    ulong es;     /* segment selectors */
    ulong cs;
    ulong ss;
    ulong ds;
    ulong fs;
    ulong gs;
    ulong ldt;      /* selector for task's LDT */
    ulong iomap;      /* I/O map base address + T-bit */
};
@ 

<<[[Cpu]] [[Arch]] other fields>>=
Tss*  tss;      /* tss for this processor */
@

<<function taskswitch>>=
static void
taskswitch(ulong pdb, ulong stack)
{
    Tss *tss;

    tss = cpu->tss;
    tss->ss0 = KDSEL;
    tss->esp0 = stack;
    tss->ss1 = KDSEL;
    tss->esp1 = stack;
    tss->ss2 = KDSEL;
    tss->esp2 = stack;
    putcr3(pdb);
}
@


\section{Cooperative scheduling}

%  sleep(similar to sched)/wakeup(calls ready)
%  sleep/wakeup have a condition attached to it, and so a rendez vous,
%  sched and ready are just altruistic, give back without asking

<<function yield>>=
/*
 *  yield the processor and drop our priority
 */
void
yield(void)
{
    if(anyready()){
        /* pretend we just used 1/2 tick */
        up->lastupdate -= Scaling/2;  
        sched();
    }
}
@ 


<<enum procstate cases>>=
Ready,
@

<<[[Cpu]] other fields>>=
Proc* readied;    /* for runproc */
@

<<function ready>>=
/*
 *  ready(p) picks a new priority for a process and sticks it in the
 *  runq for that priority.
 */
void
proc_ready(Proc *p)
{
    int s, pri;
    Schedq *rq;
    void (*pt)(Proc*, int, vlong);

    s = splhi();
    <<[[ready()]] optional [[edfready()]] for real-time scheduling>>

    if(up != p && (p->wired == nil || p->wired == cpu))
        cpu->readied = p; /* group scheduling */

    updatecpu(p);
    pri = reprioritize(p);
    p->priority = pri;
    rq = &runq[pri];
    p->state = Ready;
    queueproc(rq, p);
    <<ready()]] hook proctrace>>
    splx(s);
}
@ 



<<struct Rendez>>=
struct Rendez
{
    // option<ref<Proc>>
    Proc  *p; // sleeping process
    Lock;
};
@ 

% those one are kind of scheduling fields, because they are about
% cooperative scheduling, not so much about inter process synchro via
% sysrendezvous
<<[[Proc]] synchronization fields>>=
// option<ref<Rendez>>, can point to waitr, freememr, sleepr, etc
Rendez  *r;   /* rendezvous point slept on */
Lock  rlock;    /* sync sleep/wakeup with postnote */
@

% p->r, r->p


<<enum procstate cases>>=
Wakeme,
@

<<function sleep>>=
/*
 *  sleep if a condition is not true.  Another process will
 *  awaken us after it sets the condition.  When we awaken
 *  the condition may no longer be true.
 *
 *  we lock both the process and the rendezvous to keep r->p
 *  and p->r synchronized.
 */
void
proc_sleep(Rendez *r, bool (*f)(void*), void *arg)
{
    int s;
    void (*pt)(Proc*, int, vlong);

    s = splhi();

    if(up->nlocks.ref)
        print("process %lud sleeps with %lud locks held, last lock %#p locked at pc %#lux, sleep called from %#p\n",
            up->pid, up->nlocks.ref, up->lastlock, up->lastlock->pc, getcallerpc(&r));

    lock(r);
    lock(&up->rlock);

    if(r->p){
        print("double sleep called from %#p, %lud %lud\n", getcallerpc(&r), r->p->pid, up->pid);
        dumpstack();
    }

    /*
     *  Wakeup only knows there may be something to do by testing
     *  r->p in order to get something to lock on.
     *  Flush that information out to memory in case the sleep is
     *  committed.
     */
    r->p = up;

    if((*f)(arg) || up->notepending){
        /*
         *  if condition happened or a note is pending
         *  never mind
         */
        r->p = nil;
        unlock(&up->rlock);
        unlock(r);
    } else {
        /*
         *  now we are committed to
         *  change state and call scheduler
         */
        <<[[sleep()]] hook proctrace>>

        up->state = Wakeme;
        up->r = r;

        // similar code to sched(), why not call sched()?
        /* statistics */
        cpu->cs++;

        procsave(up);
        if(setlabel(&up->sched)) {
            /*
             *  here when the process is awakened
             */
            procrestore(up);
            spllo();
        } else {
            /*
             *  here to go to sleep (i.e. stop Running)
             */
            unlock(&up->rlock);
            unlock(r);
            gotolabel(&cpu->sched);
            panic("sleep: should never reach this point");
        }
    }

    if(up->notepending) {
        up->notepending = false;
        splx(s);
        if(up->procctl == Proc_exitme && up->closingfgrp)
            forceclosefgrp();
        error(Eintr);
    }

    splx(s);
}
@ 

<<function wakeup>>=
/*
 *  Expects that only one process can call wakeup for any given Rendez.
 *  We hold both locks to ensure that r->p and p->r remain consistent.
 *  Richard Miller has a better solution that doesn't require both to
 *  be held simultaneously, but I'm a paranoid - presotto.
 */
Proc*
proc_wakeup(Rendez *r)
{
    Proc *p;
    int s;

    s = splhi();
    lock(r);
    p = r->p;

    if(p != nil){
        lock(&p->rlock);
        if(p->state != Wakeme || p->r != r){
            iprint("%p %p %d\n", p->r, r, p->state);
            panic("wakeup: state");
        }
        r->p = nil;
        p->r = nil;
        ready(p);
        unlock(&p->rlock);
    }
    unlock(r);
    splx(s);
    return p;
}
@ 



\section{Preemptive scheduling}

<<[[Cpu]] other fields>>=
ulong schedticks;   /* next forced context switch */
@

<<function hzsched>>=
/*
 *  here once per clock tick to see if we should resched
 */
void
hzsched(void)
{
    /* once a second, rebalance will reprioritize ready procs */
    if(cpu->cpuno == 0)
        rebalance();

    /* unless preempted, get to run for at least 100ms */
    if(anyhigher()
    || (!up->fixedpri && cpu->ticks > cpu->schedticks && anyready())){

        cpu->readied = nil;   /* avoid cooperative scheduling */
        up->delaysched++;
    }
}
@ 



<<function anyhigher>>=
int
anyhigher(void)
{
    return runvec & ~((1<<(up->priority+1))-1);
}
@ 
% >>


<<global balancetime>>=
/*
 *  recalculate priorities once a second.  We need to do this
 *  since priorities will otherwise only be recalculated when
 *  the running process blocks.
 */
ulong balancetime;
@ 

<<function rebalance>>=
static void
rebalance(void)
{
    int pri, npri, t, x;
    Schedq *rq;
    Proc *p;

    t = cpu->ticks;
    if(t - balancetime < HZ)
        return;
    balancetime = t;

    for(pri=0, rq=runq; pri<Npriq; pri++, rq++){
another:
        p = rq->head;
        if(p == nil)
            continue;
        if(p->lastcpu != CPUS(cpu->cpuno))
            continue;
        if(pri == p->basepri)
            continue;
        updatecpu(p);
        npri = reprioritize(p);
        if(npri != pri){
            x = splhi();
            p = dequeueproc(rq, p);
            if(p)
                queueproc(&runq[npri], p);
            splx(x);
            goto another;
        }
    }
}
@ 



<<[[Proc]] scheduling fields>>=
bool preempted;  /* true if this process hasn't finished the interrupt
       *  that last preempted it
       */
@

<<function preempt>>=
/*
 *  here at the end of non-clock interrupts to see if we should preempt the
 *  current process.
 */
void
preempt(void)
{
    if(up && up->state == Running)
      if(up->preempted == false)
        if(anyhigher())
          if(!active.exiting){
              cpu->readied = nil;   /* avoid cooperative scheduling */
              up->preempted = true;
              sched();
              splhi(); // still in interrupt context
              up->preempted = false;
          }
    return;
}
@ 

\subsection{Clock interrupt}

% number of times per second we want to get a clock interrupt, called
% also a tick
<<constant HZ>>=
#define HZ    (100)     /* clock frequency */
@

<<constant Freq>>=
Freq=   1193182,    /* Real clock frequency */
@

<<struct I8253>>=
struct I8253
{
    ulong   period;     /* current clock period */
    bool    enabled;

    uvlong  hz;

    ushort  last;       /* last value of clock 1 */
    uvlong  ticks;      /* cumulative ticks of counter 1 */

    ulong   periodset;

    // extra
    Lock;
};
@


<<global i8253>>=
I8253 i8253;
@

<<function i8253init>>=
void
i8253init(void)
{
    int loops, x;

    ioalloc(T0cntr, 4, 0, "i8253");
    ioalloc(T2ctl, 1, 0, "i8253.cntr2ctl");

    i8253.period = Freq/HZ;

    /*
     *  enable a 1/HZ interrupt for providing scheduling interrupts
     */
    outb(Tmode, Load0|Square);
    outb(T0cntr, (Freq/HZ));    /* low byte */
    outb(T0cntr, (Freq/HZ)>>8); /* high byte */

    /*
     *  enable a longer period counter to use as a clock
     */
    outb(Tmode, Load2|Square);
    outb(T2cntr, 0);        /* low byte */
    outb(T2cntr, 0);        /* high byte */
    x = inb(T2ctl);
    x |= T2gate;
    outb(T2ctl, x);
    
    /*
     * Introduce a little delay to make sure the count is
     * latched and the timer is counting down; with a fast
     * enough processor this may not be the case.
     * The i8254 (which this probably is) has a read-back
     * command which can be used to make sure the counting
     * register has been written into the counting element.
     */
    x = (Freq/HZ);
    for(loops = 0; loops < 100000 && x >= (Freq/HZ); loops++){
        outb(Tmode, Latch0);
        x = inb(T0cntr);
        x |= inb(T0cntr)<<8;
    }
}
@

<<function i8253enable>>=
void
i8253enable(void)
{
    i8253.enabled = true;
    i8253.period = Freq/HZ;
    intrenable(IrqCLOCK, i8253clock, 0, BUSUNKNOWN, "clock");
}
@

<<interrupt callback i8253clock>>=
static void
i8253clock(Ureg* ureg, void*)
{
    timerintr(ureg, 0);
}
@



<<clock callback hzclock>>=
void
hzclock(Ureg *ur)
{
    cpu->ticks++;
    if(cpu->proc) // why not using up here? why cpu->proc?
        cpu->proc->pc = ur->pc;

    if(cpu->flushmmu){
        if(up)
            flushmmu();
        cpu->flushmmu = false;
    }

    accounttime();
    kmapinval();

    if(kproftimer != nil)
        kproftimer(ur->pc);

    if((active.cpus&(1<<cpu->cpuno)) == 0)
        return;

    if(active.exiting) {
        print("someone's exiting\n");
        exit(0);
    }

    checkalarms();

    if(up && up->state == Running)
        hzsched();  /* in proc.c */
}
@ 
% //todo: can be not Running? maybe if checkalarms resched?



<<function accounttime>>=
/*
 *  time accounting called by clock() splhi'd
 */
void
accounttime(void)
{
    Proc *p;
    ulong n, per;
    static ulong nrun;

    p = cpu->proc; // why not p = up?
    if(p) {
        nrun++;
        p->time[p->insyscall]++;
    }

    /* calculate decaying duty cycles */
    n = perfticks();
    per = n - cpu->perf.last;
    cpu->perf.last = n;
    per = (cpu->perf.period*(HZ-1) + per)/HZ;
    if(per != 0)
        cpu->perf.period = per;

    cpu->perf.avg_inidle = (cpu->perf.avg_inidle*(HZ-1)+cpu->perf.inidle)/HZ;
    cpu->perf.inidle = 0;

    cpu->perf.avg_inintr = (cpu->perf.avg_inintr*(HZ-1)+cpu->perf.inintr)/HZ;
    cpu->perf.inintr = 0;

    /* only one processor gets to compute system load averages */
    if(cpu->cpuno != 0)
        return;

    /*
     * calculate decaying load average.
     * if we decay by (n-1)/n then it takes
     * n clock ticks to go from load L to .36 L once
     * things quiet down.  it takes about 5 n clock
     * ticks to go to zero.  so using HZ means this is
     * approximately the load over the last second,
     * with a tail lasting about 5 seconds.
     */
    n = nrun;
    nrun = 0;
    n = (nrdy+n)*1000;
    cpu->load = (cpu->load*(HZ-1)+n)/HZ;
}
@ 

\section{Customized scheduling}

% put /dev/proc things here?

<<[[Proc]] scheduling fields>>=
Cpu  *wired;
@

<<function procwired>>=
/*
 * wire this proc to a processor
 */
void
procwired(Proc *p, int bm)
{
    Proc *pp;
    int i;
    char nwired[MAXCPUS];
    Cpu *wm;

    if(bm < 0){
        /* pick a processor to wire to */
        memset(nwired, 0, sizeof(nwired));
        p->wired = 0;
        pp = proctab(0);
        for(i=0; i<conf.nproc; i++, pp++){
            wm = pp->wired;
            if(wm && pp->pid)
                nwired[wm->cpuno]++;
        }
        bm = 0;
        for(i=0; i<conf.ncpu; i++)
            if(nwired[i] < nwired[bm])
                bm = i;
    } else {
        /* use the virtual processor requested */
        bm = bm % conf.ncpu;
    }

    p->wired = CPUS(bm);
    p->lastcpu = p->wired;
}
@ 



\section{Real-time scheduling}
% see EDF section


\section{Halting}

<<function idlehands>>=
// current configuration
static bool idle_spin = false;
static int idle_if_nproc = 0;


/*
 *  put the processor in the halt state if we've no processes to run.
 *  an interrupt will get us going again.
 */
void
idlehands(void)
{
    /*
     * we used to halt only on single-core setups. halting in an SMP system 
     * can result in a startup latency for processes that become ready.
     * if idle_spin is false, we care more about saving energy
     * than reducing this latency.
     *
     * the performance loss with idle_spin == false seems to be slight
     * and it reduces lock contention (thus system time and real time)
     * on many-core systems with large values of NPROC.
     */
    if(conf.ncpu == 1 || idle_spin == false ||
        (idle_if_nproc && conf.ncpu >= idle_if_nproc))
        halt();
}
@ 

<<function halt>>=
/*
 * Attempt at power saving. -rsc
 */
TEXT halt(SB), $0
        CLI
        CMPL    nrdy(SB), $0
        JEQ     _nothingready
        STI
        RET

_nothingready:
        STI
        HLT
        RET
@


\chapter{Initialization}
\minitoc

\section{Booting the kernel}

\subsection{Loading the kernel in physical memory}

% rename _startKADDR? just _start? it's true
% that the label is in in KADDR space as we call ld with -TKZERO...

<<l_multiboot.s>>=
#include "mem.h"
        
TEXT _startKADDR(SB), $0

<<global _multibootheader>>

<<function _multibootentry>>

<<global multiboot>>
@

<<global _multibootheader>>=
/*
 * Must be 4-byte aligned.
 */
TEXT _multibootheader(SB), $0
        LONG    $0x1BADB002                     /* magic */
        LONG    $0x00010003                     /* flags */
        LONG    $-(0x1BADB002 + 0x00010003)     /* checksum */
        
        LONG    $_multibootheader-KZERO(SB)     /* header_addr */
        LONG    $_startKADDR-KZERO(SB)          /* load_addr */
        LONG    $edata-KZERO(SB)                /* load_end_addr */
        LONG    $end-KZERO(SB)                  /* bss_end_addr */
        
//      !!!entry point specification!!!
        LONG    $_multibootentry-KZERO(SB)              /* entry_addr */
        
        LONG    $0                              /* mode_type */
        LONG    $0                              /* width */
        LONG    $0                              /* height */
        LONG    $0                              /* depth */
@

% about the page-aligned requirment:
% indeed, as we will see later binaries when exec'd are
% mapped to memory and we want the data section to be
% separate from text section so they can have different
% property for their segments

<<function _multibootentry>>=
/* 
 * the kernel expects the data segment to be page-aligned
 * multiboot bootloaders put the data segment right behind text
 */
TEXT _multibootentry(SB), $0
        MOVL    $etext-KZERO(SB), SI
        MOVL    SI, DI
        ADDL    $0xfff, DI
        ANDL    $~0xfff, DI
        MOVL    $edata-KZERO(SB), CX
        SUBL    DI, CX
        ADDL    CX, SI
        ADDL    CX, DI
        STD
        REP; MOVSB
        CLD
        ADDL    $KZERO, BX
        MOVL    BX, multiboot-KZERO(SB)
//      !!! Jump to _startPADDR (not _startKADDR anymore)!!!
        MOVL    $_startPADDR(SB), AX
        ANDL    $~KZERO, AX
        JMP*    AX
@

<<lib.h exxx decl>>=
extern  char  etext[];
//@Scheck: Assembly, not dead used by 386/l.s
extern  char  edata[];
extern  char  end[];
@ 


<<global multiboot>>=
/* multiboot structure pointer */
TEXT multiboot(SB), $0
        LONG    $0
@


\subsection{Basic segmentation}

% this comment below is still valid??? not when come from multiboot header
% maybe should be rename this _startPADDR as it's not a physical addr
% anyway
% rename? setup_segmentation_KADDR
<<function _startPADDR>>=
/*
 * In protected mode with paging turned off and segment registers setup
 * to linear map all memory. Entered via a jump to PADDR(entry),
 * the physical address of the virtual kernel entry point of KADDR(entry).
 * Make the basic page tables for processor 0. Six pages are needed for
 * the basic set:
 *      a page directory;
 *      page tables for mapping the first 8MB of physical memory to KZERO;
 *      a page for the GDT;
 *      virtual and physical pages for mapping the Cpu structure.
 * The remaining PTEs will be allocated later when memory is sized.
 * An identity mmu map is also needed for the switch to virtual mode.
 * This identity mapping is removed once the MMU is going and the JMP has
 * been made to virtual memory.
 */
TEXT _startPADDR(SB), $0
        CLI                     /* make sure interrupts are off */

        /* set up the gdt so we have sane plan 9 style gdts. */
        MOVL    $tgdtptr(SB), AX
        ANDL    $~KZERO, AX
        MOVL    (AX), GDTR
        MOVW    $1, AX
        MOVW    AX, MSW

        /* clear prefetch queue (weird code to avoid optimizations) */
        DELAY

        /* set segs to something sane (avoid traps later) */
        MOVW    $(1<<3), AX
        MOVW    AX, DS
        MOVW    AX, SS
        MOVW    AX, ES
        MOVW    AX, FS
        MOVW    AX, GS

/*      JMP     $(2<<3):$mode32bit(SB) /**/
         BYTE   $0xEA
         LONG   $mode32bit-KZERO(SB)
         WORD   $(2<<3)
@




<<global tgdt>>=
/*
 *  gdt to get us to 32-bit/segmented/unpaged mode
 */
TEXT tgdt(SB), $0

        /* null descriptor */
        LONG    $0
        LONG    $0

        /* data segment descriptor for 4 gigabytes (PL 0) */
        LONG    $(0xFFFF)
        LONG    $(SEGG|SEGB|(0xF<<16)|SEGP|SEGPL(0)|SEGDATA|SEGW)

        /* exec segment descriptor for 4 gigabytes (PL 0) */
        LONG    $(0xFFFF)
        LONG    $(SEGG|SEGD|(0xF<<16)|SEGP|SEGPL(0)|SEGEXEC|SEGR)
@

<<global tgdtptr>>=
/*
 *  pointer to initial gdt
 *  Note the -KZERO which puts the physical address in the gdtptr. 
 *  that's needed as we start executing in physical addresses. 
 */
TEXT tgdtptr(SB), $0
        WORD    $(3*8)
        LONG    $tgdt-KZERO(SB)
@


\subsection{Basic pagination}

% again, rename? setup_pagination_KADDR?
<<function mode32bits>>=
TEXT mode32bit(SB), $0
        /* At this point, the GDT setup is done. */

        MOVL    $PADDR(CPU0PDB), DI             /* clear 4 pages for the tables etc. */
        XORL    AX, AX
        MOVL    $(4*BY2PG), CX
        SHRL    $2, CX

        CLD
        REP;    STOSL

        MOVL    $PADDR(CPU0PDB), AX
        ADDL    $PDO(KZERO), AX                 /* page directory offset for KZERO */
        MOVL    $PADDR(CPU0PTE), (AX)           /* PTE's for KZERO */
        MOVL    $(PTEWRITE|PTEVALID), BX        /* page permissions */
        ORL     BX, (AX)

        ADDL    $4, AX
        MOVL    $PADDR(CPU0PTE1), (AX)          /* PTE's for KZERO+4MB */
        MOVL    $(PTEWRITE|PTEVALID), BX        /* page permissions */
        ORL     BX, (AX)

        MOVL    $PADDR(CPU0PTE), AX             /* first page of page table */
        MOVL    $1024, CX                       /* 1024 pages in 4MB */
_setpte:
        MOVL    BX, (AX)
        ADDL    $(1<<PGSHIFT), BX
        ADDL    $4, AX
        LOOP    _setpte

        MOVL    $PADDR(CPU0PTE1), AX            /* second page of page table */
        MOVL    $1024, CX                       /* 1024 pages in 4MB */
_setpte1:
        MOVL    BX, (AX)
        ADDL    $(1<<PGSHIFT), BX
        ADDL    $4, AX
        LOOP    _setpte1

        MOVL    $PADDR(CPU0PTE), AX
        ADDL    $PTO(CPUADDR), AX              /* page table entry offset for CPUADDR */
        MOVL    $PADDR(CPU0CPU), (AX)          /* PTE for Cpu */
        MOVL    $(PTEWRITE|PTEVALID), BX        /* page permissions */
        ORL     BX, (AX)

/*
 * Now ready to use the new map. Make sure the processor options are what is wanted.
 * It is necessary on some processors to immediately follow mode switching with a JMP instruction
 * to clear the prefetch queues.
 */
        MOVL    $PADDR(CPU0PDB), CX             /* load address of page directory */
        MOVL    (PDO(KZERO))(CX), DX            /* double-map KZERO at 0 */
        MOVL    DX, (PDO(0))(CX)
        MOVL    CX, CR3
        DELAY                                   /* JMP .+2 */

        MOVL    CR0, DX
        ORL     $0x80010000, DX                 /* PG|WP */
        ANDL    $~0x6000000A, DX                /* ~(CD|NW|TS|MP) */

        MOVL    $_startpg(SB), AX               /* this is a virtual address */
        MOVL    DX, CR0                         /* turn on paging */
        JMP*    AX                              /* jump to the virtual nirvana */
@
%$

\subsection{BSS and stack initialization}

% rename, setup_bss_stack_KADDR
% the x86 archi does not have multi register, so have to use same
% pointer to differently mapped physical page
<<function _startpg>>=
/*
 * Basic machine environment set, can clear BSS and create a stack.
 * The stack starts at the top of the page containing the Cpu structure.
 * The x86 architecture forces the use of the same virtual address for
 * each processor's Cpu structure, so the global Cpu pointer 'cpu' can
 * be initialised here.
 */
TEXT _startpg(SB), $0
        MOVL    $0, (PDO(0))(CX)                /* undo double-map of KZERO at 0 */
        MOVL    CX, CR3                         /* load and flush the mmu */

_clearbss:
        MOVL    $edata(SB), DI
        XORL    AX, AX
        MOVL    $end(SB), CX
        SUBL    DI, CX                          /* end-edata bytes */
        SHRL    $2, CX                          /* end-edata doublewords */

        CLD
        REP;    STOSL                           /* clear BSS */

        MOVL    $CPUADDR, SP
        MOVL    SP, cpu(SB)                /* initialise global Cpu pointer */
        MOVL    $0, 0(SP)                       /* initialise cpu->cpuno */


        ADDL    $(CPUSIZE-4), SP               /* initialise stack */

<<end of _startpg>>
@


\subsection{Jumping to C [[main()]]}

% or do another function and in previous code to a JMP _last_before_main_KADDR?
<<end of _startpg>>=
/*
 * Need to do one final thing to ensure a clean machine environment,
 * clear the EFLAGS register, which can only be done once there is a stack.
 */
        MOVL    $0, AX
        PUSHL   AX
        POPFL

        CALL    main(SB)
@
%$

\section{Kernel initialization}

<<function main>>=
//@Scheck: not dead, entry point :) jumped from assembly at _startpg() end
void
main(void)
{
    <<[[main()]] initial assgnments for backward dependencies>>
    cgapost(0);

    cpu0init(); // cpu0 initialization (calls cpuinit())

    options(); // setup values for getconf() from bootloader config
    // example of manual config:
    // TODO confname(``console'') = 1?

    ioinit(); // does some getconf("ioexclude") so must be after options()

    screeninit(); // screenputs = cgascreenputs
    quotefmtinstall(); // libc printf initialization
    i8250console(); // setup optional serial console if getconf("console") == 1
    print("\nPlan 9\n");

    // the init0 means this is really early on (e.g. malloc is not available)
    trapinit0();
    mmuinit0();

    kbdinit(); // kbd is then fully enabled below via kdbenable()
    i8253init(); // clock controller

    cpuidentify(); // setup cpu, to know which advanced features we can enable
    cpuidprint();

    meminit(); // setup conf.mem memory banks
    confinit(); // setup conf
    archinit(); // setup arch
    xinit(); // setup xalloc memory allocator
    if(i8237alloc != nil)
            i8237alloc(); // setup dma

    trapinit();
    mmuinit();

    fpsavealloc();
    if(arch->intrinit)      /* launches other processors on an mp */
        arch->intrinit();

    timersinit();
    mathinit();

    kbdenable(); // setup kdbq
    //TODO: bad name, setup lineq = queue for keyboard for reading /dev/cons
    printinit();  // setup lineq

    if(arch->clockenable)
        arch->clockenable();

    procinit();
    initimage();

    if(delaylink) {
       bootlinks();
       pcimatch(0, 0, 0);
    } else
       links();

    // initialize all devices
    chandevreset();
    cgapost(0xcd); // 0xcd, for chandev :)

    pageinit();
    swapinit();

    // let's craft our first process (that will then exec("boot/boot"))
    userinit();
    <<[[main()]] before schedinit()>>
    cgapost(0x99); // done!
    schedinit();
}
@

\subsection{[[cpu]] initialization}

<<function cpu0init>>=
void
cpu0init(void)
{
        conf.ncpu = 1;
        // note that cpu points to CPUADDR, which then is mapped to CPU0CPU
        // via the page table on the first processor
        CPUS(0) = (Cpu*)CPU0CPU;
        cpu->pdb = (ulong*)CPU0PDB;
        cpu->gdt = (Segdesc*)CPU0GDT;

        cpuinit();

        active.cpus = 1;
        active.exiting = false;
}
@

% inline in previous func? no? because used in squidboy!
<<function cpuinit>>=
void
cpuinit(void)
{
    int cpuno;
    ulong *pdb;
    Segdesc *gdt;

    cpuno = cpu->cpuno;
    pdb = cpu->pdb;
    gdt = cpu->gdt;
    memset(cpu, 0, sizeof(Cpu));
    cpu->cpuno = cpuno;
    cpu->pdb = pdb;
    cpu->gdt = gdt;

    cpu->perf.period = 1;
    /*
     * For polled uart output at boot, need
     * a default delay constant. 100000 should
     * be enough for a while. Cpuidentify will
     * calculate the real value later.
     */
    cpu->loopconst = 100000;
}
@


\subsection{CPU detection}

<<[[Cpu]] [[Arch]] cpuid fields>>=
char  cpuidid[16];
char* cpuidtype;
int cpuidax;
int cpuiddx;
@

% put code guesscpu? guesshz? but quite long and ugly ...
% or maybe can simplify?

<<function cpuidprint>>=
void
cpuidprint(void)
{
    int i;
    char buf[128];

    i = snprint(buf, sizeof buf, "cpu%d: %s%dMHz ", cpu->cpuno,
        cpu->cpuno < 10? " ": "", cpu->cpumhz);
    if(cpu->cpuidid[0])
        i += sprint(buf+i, "%12.12s ", cpu->cpuidid);
    seprint(buf+i, buf + sizeof buf - 1,
        "%s (cpuid: AX 0x%4.4uX DX 0x%4.4uX)\n",
        cpu->cpuidtype, cpu->cpuidax, cpu->cpuiddx);
    print(buf);
}
@

\subsection{[[arch]] initialization}

<<function archinit>>=
void
archinit(void)
{
    PCArch **p;

    arch = nil;
    for(p = knownarch; *p; p++){
        if((*p)->ident && (*p)->ident() == 0){
            arch = *p;
            break;
        }
    }
    if(arch == nil)
        arch = &archgeneric;
    else{
        if(arch->id == 0)
            arch->id = archgeneric.id;
        if(arch->reset == 0)
            arch->reset = archgeneric.reset;
        if(arch->serialpower == 0)
            arch->serialpower = archgeneric.serialpower;
        if(arch->modempower == 0)
            arch->modempower = archgeneric.modempower;
        if(arch->intrinit == 0)
            arch->intrinit = archgeneric.intrinit;
        if(arch->intrenable == 0)
            arch->intrenable = archgeneric.intrenable;
    }

    /*
     *  Decide whether to use copy-on-reference (386 and mp).
     *  We get another chance to set it in mpinit() for a
     *  multiprocessor.
     */
    if(X86FAMILY(cpu->cpuidax) == 3)
        conf.copymode = true;

    if(X86FAMILY(cpu->cpuidax) >= 4)
        cmpswap = cmpswap486;

    if(X86FAMILY(cpu->cpuidax) >= 5)
        coherence = mb586;

    if(cpu->cpuiddx & Sse2)
        coherence = mfence;

    addarchfile("cputype", 0444, cputyperead, nil);
    addarchfile("archctl", 0664, archctlread, archctlwrite);
}
@

\subsection{Memory detection}

<<struct Map>>=
struct Map {
    ulong   size;
    ulong   addr;
};
@


<<struct RMap>>=
struct RMap {
    char*   name;
    Map*    map;
    Map*    mapend;

    Lock;
};
@

<<enum memkind>>=
enum memkind {
    MemUPA,        /* unbacked physical address */
    MemRAM,        /* physical memory */
    MemUMB,        /* upper memory block (<16MB) */
    MemReserved,

    NMemType, // must be last
};
@

<<function meminit>>=
void
meminit(void)
{
    int i;
    Map *mp;
    Confmem *cm;
    ulong pa, *pte;
    ulong maxmem, lost;
    char *p;

    if(p = getconf("*maxmem"))
        maxmem = strtoul(p, 0, 0);
    else
        maxmem = 0;

    /*
     * Set special attributes for memory between 640KB and 1MB:
     *   VGA memory is writethrough;
     *   BIOS ROM's/UMB's are uncached;
     * then scan for useful memory.
     */
    for(pa = 0xA0000; pa < 0xC0000; pa += BY2PG){
        pte = mmuwalk(cpu->pdb, (ulong)KADDR(pa), 2, 0);
        *pte |= PTEWT;
    }
    for(pa = 0xC0000; pa < 0x100000; pa += BY2PG){
        pte = mmuwalk(cpu->pdb, (ulong)KADDR(pa), 2, 0);
        *pte |= PTEUNCACHED;
    }
    mmuflushtlb(PADDR(cpu->pdb));

    umbscan();
    lowraminit();
    if(e820scan() < 0)
        ramscan(maxmem);

    /*
     * Set the conf entries describing banks of allocatable memory.
     */
    for(i=0; i<nelem(mapram) && i<nelem(conf.mem); i++){
        mp = &rmapram.map[i];
        cm = &conf.mem[i];
        cm->base = mp->addr;
        cm->npage = mp->size/BY2PG;
    }
    
    lost = 0;
    for(; i<nelem(mapram); i++)
        lost += rmapram.map[i].size;
    if(lost)
        print("meminit - lost %lud bytes\n", lost);

    if(MEMDEBUG)
        memdebug();
}
@



<<function mapfree>>=
void
mapfree(RMap* rmap, ulong addr, ulong size)
{
    Map *mp;
    ulong t;

    if(size <= 0)
        return;

    lock(rmap);
    for(mp = rmap->map; mp->addr <= addr && mp->size; mp++)
        ;

    if(mp > rmap->map && (mp-1)->addr+(mp-1)->size == addr){
        (mp-1)->size += size;
        if(addr+size == mp->addr){
            (mp-1)->size += mp->size;
            while(mp->size){
                mp++;
                (mp-1)->addr = mp->addr;
                (mp-1)->size = mp->size;
            }
        }
    }
    else{
        if(addr+size == mp->addr && mp->size){
            mp->addr -= size;
            mp->size += size;
        }
        else do{
            if(mp >= rmap->mapend){
                print("mapfree: %s: losing 0x%luX, %ld\n",
                    rmap->name, addr, size);
                break;
            }
            t = mp->addr;
            mp->addr = addr;
            addr = t;
            t = mp->size;
            mp->size = size;
            mp++;
        }while(size = t);
    }
    unlock(rmap);
}
@


<<function mapalloc>>=
ulong
mapalloc(RMap* rmap, ulong addr, int size, int align)
{
    Map *mp;
    ulong maddr, oaddr;

    lock(rmap);
    for(mp = rmap->map; mp->size; mp++){
        maddr = mp->addr;

        if(addr){
            /*
             * A specific address range has been given:
             *   if the current map entry is greater then
             *   the address is not in the map;
             *   if the current map entry does not overlap
             *   the beginning of the requested range then
             *   continue on to the next map entry;
             *   if the current map entry does not entirely
             *   contain the requested range then the range
             *   is not in the map.
             */
            if(maddr > addr)
                break;
            if(mp->size < addr - maddr) /* maddr+mp->size < addr, but no overflow */
                continue;
            if(addr - maddr > mp->size - size)  /* addr+size > maddr+mp->size, but no overflow */
                break;
            maddr = addr;
        }

        if(align > 0)
            maddr = ((maddr+align-1)/align)*align;
        if(mp->addr+mp->size-maddr < size)
            continue;

        oaddr = mp->addr;
        mp->addr = maddr+size;
        mp->size -= maddr-oaddr+size;
        if(mp->size == 0){
            do{
                mp++;
                (mp-1)->addr = mp->addr;
            }while((mp-1)->size = mp->size);
        }

        unlock(rmap);
        if(oaddr != maddr)
            mapfree(rmap, oaddr, maddr-oaddr);

        return maddr;
    }
    unlock(rmap);

    return nilptr;
}
@


<<function rampage>>=
/*
 * Allocate from the ram map directly to make page tables.
 * Called by mmuwalk during e820scan.
 */
void*
rampage(void)
{
    ulong m;
    
    m = mapalloc(&rmapram, 0, BY2PG, BY2PG);
    if(m == 0)
        return nil;
    return KADDR(m);
}
@


<<function umbexclude>>=
static void
umbexclude(void)
{
    int size;
    ulong addr;
    char *op, *p, *rptr;

    if((p = getconf("umbexclude")) == nil)
        return;

    while(p && *p != '\0' && *p != '\n'){
        op = p;
        addr = strtoul(p, &rptr, 0);
        if(rptr == nil || rptr == p || *rptr != '-'){
            print("umbexclude: invalid argument <%s>\n", op);
            break;
        }
        p = rptr+1;

        size = strtoul(p, &rptr, 0) - addr + 1;
        if(size <= 0){
            print("umbexclude: bad range <%s>\n", op);
            break;
        }
        if(rptr != nil && *rptr == ',')
            *rptr++ = '\0';
        p = rptr;

        mapalloc(&rmapumb, addr, size, 0);
    }
}
@


<<function umbscan>>=
static void
umbscan(void)
{
    uchar o[2], *p;

    /*
     * Scan the Upper Memory Blocks (0xA0000->0xF0000) for pieces
     * which aren't used; they can be used later for devices which
     * want to allocate some virtual address space.
     * Check for two things:
     * 1) device BIOS ROM. This should start with a two-byte header
     *    of 0x55 0xAA, followed by a byte giving the size of the ROM
     *    in 512-byte chunks. These ROM's must start on a 2KB boundary.
     * 2) device memory. This is read-write.
     * There are some assumptions: there's VGA memory at 0xA0000 and
     * the VGA BIOS ROM is at 0xC0000. Also, if there's no ROM signature
     * at 0xE0000 then the whole 64KB up to 0xF0000 is theoretically up
     * for grabs; check anyway.
     */
    p = KADDR(0xD0000);
    while(p < (uchar*)KADDR(0xE0000)){
        /*
         * Check for the ROM signature, skip if valid.
         */
        if(p[0] == 0x55 && p[1] == 0xAA){
            p += p[2]*512;
            continue;
        }

        /*
         * Is it writeable? If yes, then stick it in
         * the UMB device memory map. A floating bus will
         * return 0xff, so add that to the map of the
         * UMB space available for allocation.
         * If it is neither of those, ignore it.
         */
        o[0] = p[0];
        p[0] = 0xCC;
        o[1] = p[2*KB-1];
        p[2*KB-1] = 0xCC;
        if(p[0] == 0xCC && p[2*KB-1] == 0xCC){
            p[0] = o[0];
            p[2*KB-1] = o[1];
            mapfree(&rmapumbrw, PADDR(p), 2*KB);
        }
        else if(p[0] == 0xFF && p[1] == 0xFF)
            mapfree(&rmapumb, PADDR(p), 2*KB);
        p += 2*KB;
    }

    p = KADDR(0xE0000);
    if(p[0] != 0x55 || p[1] != 0xAA){
        p[0] = 0xCC;
        p[64*KB-1] = 0xCC;
        if(p[0] != 0xCC && p[64*KB-1] != 0xCC)
            mapfree(&rmapumb, PADDR(p), 64*KB);
    }

    umbexclude();
}
@


<<function sigscan>>=
static void*
sigscan(uchar* addr, int len, char* signature)
{
    int sl;
    uchar *e, *p;

    e = addr+len;
    sl = strlen(signature);
    for(p = addr; p+sl < e; p += 16)
        if(memcmp(p, signature, sl) == 0)
            return p;
    return nil;
}
@

<<function sigsearch>>=
void*
sigsearch(char* signature)
{
    uintptr p;
    uchar *bda;
    void *r;

    /*
     * Search for the data structure:
     * 1) within the first KiB of the Extended BIOS Data Area (EBDA), or
     * 2) within the last KiB of system base memory if the EBDA segment
     *    is undefined, or
     * 3) within the BIOS ROM address space between 0xf0000 and 0xfffff
     *    (but will actually check 0xe0000 to 0xfffff).
     */
    bda = BIOSSEG(0x40);
    if(memcmp(KADDR(0xfffd9), "EISA", 4) == 0){
        if((p = (bda[0x0f]<<8)|bda[0x0e]) != 0){
            if((r = sigscan(BIOSSEG(p), 1024, signature)) != nil)
                return r;
        }
    }

    if((p = ((bda[0x14]<<8)|bda[0x13])*1024) != 0){
        if((r = sigscan(KADDR(p-1024), 1024, signature)) != nil)
            return r;
    }
    /* hack for virtualbox: look in KiB below 0xa0000 */
    if((r = sigscan(KADDR(0xa0000-1024), 1024, signature)) != nil)
        return r;

    return sigscan(BIOSSEG(0xe000), 0x20000, signature);
}
@

<<function lowraminit>>=
static void
lowraminit(void)
{
    ulong n, pa, x;
    uchar *bda;

    /*
     * Initialise the memory bank information for conventional memory
     * (i.e. less than 640KB). The base is the first location after the
     * bootstrap processor MMU information and the limit is obtained from
     * the BIOS data area.
     */
    x = PADDR(CPU0END);
    bda = (uchar*)KADDR(0x400);
    n = ((bda[0x14]<<8)|bda[0x13])*KB-x;
    mapfree(&rmapram, x, n);
    memset(KADDR(x), 0, n);         /* keep us honest */

    x = PADDR(PGROUND((ulong)end));
    pa = MemMin;
    if(x > pa)
        panic("kernel too big");
    mapfree(&rmapram, x, pa-x);
    memset(KADDR(x), 0, pa-x);      /* keep us honest */
}
@

<<function mmuflushtlb>>=
#define mmuflushtlb(pdb) putcr3(pdb)
@

<<function ramscan>>=
static void
ramscan(ulong maxmem)
{
    ulong *k0, kzero, map, maxkpa, maxpa, pa, *pte, *table, *va, vbase, x;
    int nvalid[NMemType];

    /*
     * The bootstrap code has has created a prototype page
     * table which maps the first MemMin of physical memory to KZERO.
     * The page directory is at cpu->pdb and the first page of
     * free memory is after the per-processor MMU information.
     */
    pa = MemMin;

    /*
     * Check if the extended memory size can be obtained from the CMOS.
     * If it's 0 then it's either not known or >= 64MB. Always check
     * at least 24MB in case there's a memory gap (up to 8MB) below 16MB;
     * in this case the memory from the gap is remapped to the top of
     * memory.
     * The value in CMOS is supposed to be the number of KB above 1MB.
     */
    if(maxmem == 0){
        x = (nvramread(0x18)<<8)|nvramread(0x17);
        if(x == 0 || x >= (63*KB))
            maxpa = MemMax;
        else
            maxpa = MB+x*KB;
        if(maxpa < 24*MB)
            maxpa = 24*MB;
    }else
        maxpa = maxmem;
    maxkpa = (u32int)-KZERO;    /* 2^32 - KZERO */

    /*
     * March up memory from MemMin to maxpa 1MB at a time,
     * mapping the first page and checking the page can
     * be written and read correctly. The page tables are created here
     * on the fly, allocating from low memory as necessary.
     */
    k0 = (ulong*)KADDR(0);
    kzero = *k0;
    map = 0;
    x = 0x12345678;
    memset(nvalid, 0, sizeof(nvalid));
    
    /*
     * Can't map memory to KADDR(pa) when we're walking because
     * can only use KADDR for relatively low addresses.
     * Instead, map each 4MB we scan to the virtual address range
     * MemMin->MemMin+4MB while we are scanning.
     */
    vbase = MemMin;
    while(pa < maxpa){
        /*
         * Map the page. Use mapalloc(&rmapram, ...) to make
         * the page table if necessary, it will be returned to the
         * pool later if it isn't needed.  Map in a fixed range (the second 4M)
         * because high physical addresses cannot be passed to KADDR.
         */
        va = (void*)(vbase + pa%(4*MB));
        table = &cpu->pdb[PDX(va)];
        if(pa%(4*MB) == 0){
            if(map == 0 && (map = mapalloc(&rmapram, 0, BY2PG, BY2PG)) == 0)
                break;
            memset(KADDR(map), 0, BY2PG);
            *table = map|PTEWRITE|PTEVALID;
            memset(nvalid, 0, sizeof(nvalid));
        }
        table = KADDR(PPN(*table));
        pte = &table[PTX(va)];

        *pte = pa|PTEWRITE|PTEUNCACHED|PTEVALID;
        mmuflushtlb(PADDR(cpu->pdb));
        /*
         * Write a pattern to the page and write a different
         * pattern to a possible mirror at KZERO. If the data
         * reads back correctly the chunk is some type of RAM (possibly
         * a linearly-mapped VGA framebuffer, for instance...) and
         * can be cleared and added to the memory pool. If not, the
         * chunk is marked uncached and added to the UMB pool if <16MB
         * or is marked invalid and added to the UPA pool.
         */
        *va = x;
        *k0 = ~x;
        if(*va == x){
            nvalid[MemRAM] += MB/BY2PG;
            mapfree(&rmapram, pa, MB);

            do{
                *pte++ = pa|PTEWRITE|PTEVALID;
                pa += BY2PG;
            }while(pa % MB);
            mmuflushtlb(PADDR(cpu->pdb));
            /* memset(va, 0, MB); so damn slow to memset all of memory */
        }
        else if(pa < 16*MB){
            nvalid[MemUMB] += MB/BY2PG;
            mapfree(&rmapumb, pa, MB);

            do{
                *pte++ = pa|PTEWRITE|PTEUNCACHED|PTEVALID;
                pa += BY2PG;
            }while(pa % MB);
        }
        else{
            nvalid[MemUPA] += MB/BY2PG;
            mapfree(&rmapupa, pa, MB);

            *pte = 0;
            pa += MB;
        }
        /*
         * Done with this 4MB chunk, review the options:
         * 1) not physical memory and >=16MB - invalidate the PDB entry;
         * 2) physical memory - use the 4MB page extension if possible;
         * 3) not physical memory and <16MB - use the 4MB page extension
         *    if possible;
         * 4) mixed or no 4MB page extension - commit the already
         *    initialised space for the page table.
         */
        if(pa%(4*MB) == 0 && pa >= 32*MB && nvalid[MemUPA] == (4*MB)/BY2PG){
            /*
             * If we encounter a 4MB chunk of missing memory
             * at a sufficiently high offset, call it the end of
             * memory.  Otherwise we run the risk of thinking
             * that video memory is real RAM.
             */
            break;
        }
        if(pa <= maxkpa && pa%(4*MB) == 0){
            table = &cpu->pdb[PDX(KADDR(pa - 4*MB))];
            if(nvalid[MemUPA] == (4*MB)/BY2PG)
                *table = 0;
            else if(nvalid[MemRAM] == (4*MB)/BY2PG && (cpu->cpuiddx & 0x08))
                *table = (pa - 4*MB)|PTESIZE|PTEWRITE|PTEVALID;
            else if(nvalid[MemUMB] == (4*MB)/BY2PG && (cpu->cpuiddx & 0x08))
                *table = (pa - 4*MB)|PTESIZE|PTEWRITE|PTEUNCACHED|PTEVALID;
            else{
                *table = map|PTEWRITE|PTEVALID;
                map = 0;
            }
        }
        mmuflushtlb(PADDR(cpu->pdb));
        x += 0x3141526;
    }
    /*
     * If we didn't reach the end of the 4MB chunk, that part won't
     * be mapped.  Commit the already initialised space for the page table.
     */
    if(pa % (4*MB) && pa <= maxkpa){
        cpu->pdb[PDX(KADDR(pa))] = map|PTEWRITE|PTEVALID;
        map = 0;
    }
    if(map)
        mapfree(&rmapram, map, BY2PG);

    cpu->pdb[PDX(vbase)] = 0;
    mmuflushtlb(PADDR(cpu->pdb));

    mapfree(&rmapupa, pa, (u32int)-pa);
    *k0 = kzero;
}
@

<<function emapcmp>>=
static int
emapcmp(const void *va, const void *vb)
{
    Emap *a, *b;
    
    a = (Emap*)va;
    b = (Emap*)vb;
    if(a->base < b->base)
        return -1;
    if(a->base > b->base)
        return 1;
    if(a->len < b->len)
        return -1;
    if(a->len > b->len)
        return 1;
    return a->type - b->type;
}
@


<<function map>>=
static void
map(ulong base, ulong len, int type)
{
    ulong e, n;
    ulong *table, flags, maxkpa;
    
    /*
     * Split any call crossing MemMin to make below simpler.
     */
    if(base < MemMin && len > MemMin-base){
        n = MemMin - base;
        map(base, n, type);
        map(MemMin, len-n, type);
    }
    
    /*
     * Let lowraminit and umbscan hash out the low MemMin.
     */
    if(base < MemMin)
        return;

    /*
     * Any non-memory below 16*MB is used as upper mem blocks.
     */
    if(type == MemUPA && base < 16*MB && base+len > 16*MB){
        map(base, 16*MB-base, MemUMB);
        map(16*MB, len-(16*MB-base), MemUPA);
        return;
    }
    
    /*
     * Memory below CPU0END is reserved for the kernel
     * and already mapped.
     */
    if(base < PADDR(CPU0END)){
        n = PADDR(CPU0END) - base;
        if(len <= n)
            return;
        map(PADDR(CPU0END), len-n, type);
        return;
    }
    
    /*
     * Memory between KTZERO and end is the kernel itself
     * and is already mapped.
     */
    if(base < PADDR(KTZERO) && base+len > PADDR(KTZERO)){
        map(base, PADDR(KTZERO)-base, type);
        return;
    }
    if(PADDR(KTZERO) < base && base < PADDR(PGROUND((ulong)end))){
        n = PADDR(PGROUND((ulong)end));
        if(len <= n)
            return;
        map(PADDR(PGROUND((ulong)end)), len-n, type);
        return;
    }
    
    /*
     * Now we have a simple case.
     */
    // print("map %.8lux %.8lux %d\n", base, base+len, type);
    switch(type){
    case MemRAM:
        mapfree(&rmapram, base, len);
        flags = PTEWRITE|PTEVALID;
        break;
    case MemUMB:
        mapfree(&rmapumb, base, len);
        flags = PTEWRITE|PTEUNCACHED|PTEVALID;
        break;
    case MemUPA:
        mapfree(&rmapupa, base, len);
        flags = 0;
        break;
    default:
    case MemReserved:
        flags = 0;
        break;
    }
    
    /*
     * bottom MemMin is already mapped - just twiddle flags.
     * (not currently used - see above)
     */
    if(base < MemMin){
        table = KADDR(PPN(cpu->pdb[PDX(base)]));
        e = base+len;
        base = PPN(base);
        for(; base<e; base+=BY2PG)
            table[PTX(base)] |= flags;
        return;
    }
    
    /*
     * Only map from KZERO to 2^32.
     */
    if(flags){
        maxkpa = -KZERO;
        if(base >= maxkpa)
            return;
        if(len > maxkpa-base)
            len = maxkpa - base;
        pdbmap(cpu->pdb, base|flags, base+KZERO, len);
    }
}
@

<<function e820scan>>=
static int
e820scan(void)
{
    int i;
    Ureg u;
    ulong cont, base, len;
    uvlong last;
    Emap *e;

    if(getconf("*norealmode") || getconf("*noe820scan"))
        return -1;

    cont = 0;
    for(i=0; i<nelem(emap); i++){
        memset(&u, 0, sizeof u);
        u.ax = 0xE820;
        u.bx = cont;
        u.cx = 20;
        u.dx = SMAP;
        u.es = (PADDR(RMBUF)>>4)&0xF000;
        u.di = PADDR(RMBUF)&0xFFFF;
        u.trap = 0x15;
        realmode(&u);
        cont = u.bx;
        if((u.flags&Carry) || u.ax != SMAP || u.cx != 20)
            break;
        e = &emap[nemap++];
        *e = *(Emap*)RMBUF;
        if(u.bx == 0)
            break;
    }
    if(nemap == 0)
        return -1;
    
    qsort(emap, nemap, sizeof emap[0], emapcmp);

    if(getconf("*noe820print") == nil){
        for(i=0; i<nemap; i++){
            e = &emap[i];
            print("E820: %.8llux %.8llux ", e->base, e->base+e->len);
            if(e->type < nelem(etypes))
                print("%s\n", etypes[e->type]);
            else
                print("type=%lud\n", e->type);
        }
    }

    last = 0;
    for(i=0; i<nemap; i++){ 
        e = &emap[i];
        /*
         * pull out the info but only about the low 32 bits...
         */
        if(e->base >= (1LL<<32))
            break;
        base = e->base;
        if(base+e->len > (1LL<<32))
            len = -base;
        else
            len = e->len;
        /*
         * If the map skips addresses, mark them available.
         */
        if(last < e->base)
            map(last, e->base-last, MemUPA);
        last = base+len;
        if(e->type == Ememory)
            map(base, len, MemRAM);
        else
            map(base, len, MemReserved);
    }
    if(last < (1LL<<32))
        map(last, (u32int)-last, MemUPA);
    return 0;
}
@



<<function umbmalloc>>=
/*
 * Allocate memory from the upper memory blocks.
 */
kern_addr
umbmalloc(ulong addr, int size, int align)
{
    ulong a;

    if(a = mapalloc(&rmapumb, addr, size, align))
        return (ulong)KADDR(a);

    return nilptr;
}
@


<<function umbfree>>=
void
umbfree(ulong addr, int size)
{
    mapfree(&rmapumb, PADDR(addr), size);
}
@


<<function upalloc>>=
/*
 * Give out otherwise-unused physical address space
 * for use in configuring devices.  Note that unlike upamalloc
 * before it, upaalloc does not map the physical address
 * into virtual memory.  Call vmap to do that.
 */
ulong
upaalloc(int size, int align)
{
    ulong a;

    a = mapalloc(&rmapupa, 0, size, align);
    if(a == 0){
        print("out of physical address space allocating %d\n", size);
        mapprint(&rmapupa);
    }
    return a;
}
@


<<function upareserve>>=
void
upareserve(ulong pa, int size)
{
    ulong a;
    
    a = mapalloc(&rmapupa, pa, size, 0);
    if(a != pa){
        /*
         * This can happen when we're using the E820
         * map, which might have already reserved some
         * of the regions claimed by the pci devices.
         */
    //  print("upareserve: cannot reserve pa=%#.8lux size=%d\n", pa, size);
        if(a != 0)
            mapfree(&rmapupa, a, size);
    }
}
@

\subsection{[[conf]] initialization}

% already set conf.ncpu (but to 1), and conf.mem normally

<<[[Conf]] other fields>>=
ulong npage;    /* total physical pages of memory */

// kpages = npage - upages
ulong upages;   /* user page pool */ 
ulong nimage;   /* number of page cache image headers */
ulong ialloc;   /* max interrupt time allocation in bytes */
@

<<function confinit>>=
// precondition: meminit() have initialized Conf.mem
void
confinit(void)
{
    char *p;
    int i, userpcnt;
    ulong kpages;

    if(p = getconf("*kernelpercent"))
        userpcnt = 100 - strtol(p, 0, 0);
    else
        userpcnt = 0;

    conf.npage = 0;
    for(i=0; i<nelem(conf.mem); i++)
        conf.npage += conf.mem[i].npage;

    conf.nproc = 100 + ((conf.npage*BY2PG)/MB)*5;
    if(cpuserver)
        conf.nproc *= 3;
    if(conf.nproc > 2000)
        conf.nproc = 2000;
    conf.nimage = 200;
    conf.nswap = conf.nproc*80;
    conf.nswppo = 4096;

    if(cpuserver) {
        if(userpcnt < 10)
            userpcnt = 70;
        kpages = conf.npage - (conf.npage*userpcnt)/100;

        /*
         * Hack for the big boys. Only good while physmem < 4GB.
         * Give the kernel fixed max + enough to allocate the
         * page pool.
         * This is an overestimate as conf.upages < conf.npages.
         * The patch of nimage is a band-aid, scanning the whole
         * page list in imagereclaim just takes too long.
         */
        if(kpages > (128*MB + conf.npage*sizeof(Page))/BY2PG){
            kpages = (128*MB + conf.npage*sizeof(Page))/BY2PG;
            conf.nimage = 2000;
            kpages += (conf.nproc*KSTACK)/BY2PG;
        }
    } else {
        if(userpcnt < 10) {
            if(conf.npage*BY2PG < 16*MB)
                userpcnt = 40;
            else
                userpcnt = 80;
        }
        kpages = conf.npage - (conf.npage*userpcnt)/100;

        /*
         * Make sure terminals with low memory get at least
         * 4MB on the first Image chunk allocation.
         */
        if(conf.npage*BY2PG < 16*MB)
            imagmem->minarena = 4*1024*1024;
    }

    /*
     * can't go past the end of virtual memory
     * (ulong)-KZERO is 2^32 - KZERO
     */
    if(kpages > ((ulong)-KZERO)/BY2PG)
        kpages = ((ulong)-KZERO)/BY2PG;

    conf.upages = conf.npage - kpages;
    conf.ialloc = (kpages/2)*BY2PG;

    /*
     * Guess how much is taken by the large permanent
     * datastructures. Mntcache and Mntrpc are not accounted for
     * (probably ~300KB).
     */
    kpages *= BY2PG;
    kpages -= conf.upages*sizeof(Page)
            + conf.nproc*sizeof(Proc)
            + conf.nimage*sizeof(KImage)
            + conf.nswap
            + conf.nswppo*sizeof(Page);
    mainmem->maxsize = kpages;
    if(!cpuserver){
        /*
         * give terminals lots of image memory, too; the dynamic
         * allocation will balance the load properly, hopefully.
         * be careful with 32-bit overflow.
         */
        imagmem->maxsize = kpages;
    }
}
@

\subsection{[[idt]] initialization}

<<function trapinit0>>=
/*
 * Minimal trap setup.  Just enough so that we can panic
 * on traps (bugs) during kernel initialization.
 * Called very early - malloc is not yet available.
 */
void
trapinit0(void)
{
    int d1, v;
    ulong vaddr;
    Segdesc *idt;

    idt = (Segdesc*)IDTADDR;
    vaddr = (ulong)vectortable;
    for(v = 0; v < 256; v++){
        d1 = (vaddr & 0xFFFF0000)|SEGP;
        switch(v){

        case VectorBPT:
            d1 |= SEGPL(3)|SEGIG;
            break;

        case VectorSYSCALL:
            d1 |= SEGPL(3)|SEGIG;
            break;

        default:
            d1 |= SEGPL(0)|SEGIG;
            break;
        }
        idt[v].d0 = (vaddr & 0xFFFF)|(KESEL<<16);
        idt[v].d1 = d1;
        vaddr += 6;
    }
}
@ 
% >>

<<function trapinit>>=
void
trapinit(void)
{
    /*
     * Special traps.
     * Syscall() is called directly without going through trap().
     */
    trapenable(VectorBPT, debugbpt, 0, "debugpt");
    trapenable(VectorPF, fault386, 0, "fault386");
    trapenable(Vector2F, doublefault, 0, "doublefault");
    trapenable(Vector15, unexpected, 0, "unexpected");
    nmienable();

    addarchfile("irqalloc", 0444, irqallocread, nil);
    trapinited = true;
}
@ 

<<global trapinited>>=
static bool trapinited;
@

\subsection{Virtual memory initialisation}

<<function mmuinit0>>=
void
mmuinit0(void)
{
    // cpu->gdt should point to CPU0GDT, see cpu0init
    memmove(cpu->gdt, gdt, sizeof gdt); 
}
@

% need xinit, cos mmuwalk possible call xpanalloc
% todo simplify the code?
<<function mmuinit>>=
void
mmuinit(void)
{
    ulong x, *p;
    ushort ptr[3];

    didmmuinit = true;

    if(0) print("vpt=%#.8ux vpd=%#p kmap=%#.8ux\n",
        VPT, vpd, KMAP);

    memglobal();
    cpu->pdb[PDX(VPT)] = PADDR(cpu->pdb)|PTEWRITE|PTEVALID;
    
    cpu->tss = malloc(sizeof(Tss));
    if(cpu->tss == nil)
        panic("mmuinit: no memory");
    memset(cpu->tss, 0, sizeof(Tss));
    cpu->tss->iomap = 0xDFFF<<16;

    /*
     * We used to keep the GDT in the Cpu structure, but it
     * turns out that that slows down access to the rest of the
     * page.  Since the Cpu structure is accessed quite often,
     * it pays off anywhere from a factor of 1.25 to 2 on real
     * hardware to separate them (the AMDs are more sensitive
     * than Intels in this regard).  Under VMware it pays off
     * a factor of about 10 to 100.
     */

    // we already did that in mmuinit0, but mmuinit is also called by
    // the other processors which don't call mmuinit0 and which have
    // a different cpu->gdt pointer.
    memmove(cpu->gdt, gdt, sizeof gdt); 
    x = (ulong)cpu->tss;
    cpu->gdt[TSSSEG].d0 = (x<<16)|sizeof(Tss);
    cpu->gdt[TSSSEG].d1 = (x&0xFF000000)|((x>>16)&0xFF)|SEGTSS|SEGPL(0)|SEGP;

    ptr[0] = sizeof(gdt)-1;
    x = (ulong)cpu->gdt;
    ptr[1] = x & 0xFFFF;
    ptr[2] = (x>>16) & 0xFFFF;
    lgdt(ptr);

    ptr[0] = sizeof(Segdesc)*256-1;
    x = IDTADDR;
    ptr[1] = x & 0xFFFF;
    ptr[2] = (x>>16) & 0xFFFF;
    lidt(ptr);

    /* make kernel text unwritable */
    for(x = KTZERO; x < (ulong)etext; x += BY2PG){
        p = mmuwalk(cpu->pdb, x, 2, 0);
        if(p == nil)
            panic("mmuinit");
        *p &= ~PTEWRITE;
    }

    taskswitch(PADDR(cpu->pdb),  (ulong)cpu + BY2PG);
    ltr(TSSSEL);
}
@

<<global didmmuinit>>=
static bool didmmuinit;
@


<<[[Cpu]] [[Arch]] other fields>>=
int havepge;
@

<<function memglobal>>=
/* 
 * On processors that support it, we set the PTEGLOBAL bit in
 * page table and page directory entries that map kernel memory.
 * Doing this tells the processor not to bother flushing them
 * from the TLB when doing the TLB flush associated with a 
 * context switch (write to CR3).  Since kernel memory mappings
 * are never removed, this is safe.  (If we ever remove kernel memory
 * mappings, we can do a full flush by turning off the PGE bit in CR4,
 * writing to CR3, and then turning the PGE bit back on.) 
 *
 * See also mmukmap below.
 * 
 * Processor support for the PTEGLOBAL bit is enabled in devarch.c.
 */
static void
memglobal(void)
{
    int i, j;
    ulong *pde, *pte;

    /* only need to do this once, on bootstrap processor */
    if(cpu->cpuno != 0)
        return;

    if(!cpu->havepge)
        return;

    pde = cpu->pdb;
    for(i=PDX(KZERO); i<1024; i++){
        if(pde[i] & PTEVALID){
            pde[i] |= PTEGLOBAL;
            if(!(pde[i] & PTESIZE)){
                pte = KADDR(pde[i]&~(BY2PG-1));
                for(j=0; j<1024; j++)
                    if(pte[j] & PTEVALID)
                        pte[j] |= PTEGLOBAL;
            }
        }
    }           
}
@

\subsection{Memory initialisation}

<<function xinit>>=
void
xinit(void)
{
    int i, n, upages, kpages;
    ulong maxpages;
    Confmem *m;
    Pallocmem *pm;
    Hole *h, *eh;

    eh = &xlists.hole[Nhole-1];
    for(h = xlists.hole; h < eh; h++)
        h->link = h+1;

    xlists.flist = xlists.hole;

    upages = conf.upages;
    kpages = conf.npage - upages;
    pm = palloc.mem;
    for(i=0; i<nelem(conf.mem); i++){
        m = &conf.mem[i];
        n = m->npage;
        if(n > kpages)
            n = kpages;
        /* don't try to use non-KADDR-able memory for kernel */
        maxpages = cankaddr(m->base)/BY2PG;
        if(n > maxpages)
            n = maxpages;

        /* first give to kernel */
        if(n > 0){
            m->kbase = (ulong)KADDR(m->base);
            m->klimit = (ulong)KADDR(m->base+n*BY2PG);
            xhole(m->base, n*BY2PG);
            kpages -= n;
        }
        /* if anything left over, give to user */
        if(n < m->npage){
            if(pm >= palloc.mem+nelem(palloc.mem)){
                print("xinit: losing %lud pages\n", m->npage-n);
                continue;
            }
            pm->base = m->base+n*BY2PG;
            pm->npage = m->npage - n;
            pm++;
        }
    }
}
@

<<function procinit>>=
void
procinit(void)
{
    Proc *p;
    int i;

    procalloc.free = xalloc(conf.nproc*sizeof(Proc));
    if(procalloc.free == nil){
        xsummary();
        panic("cannot allocate %lud procs (%ludMB)\n", 
                      conf.nproc, conf.nproc*sizeof(Proc)/(1024*1024));
    }
    procalloc.arena = procalloc.free;

    p = procalloc.free;
    for(i=0; i<conf.nproc-1; i++,p++)
        p->qnext = p+1;
    p->qnext = nil;
}
@ 

<<function initimage>>=
void
initimage(void)
{
    KImage *i, *ie;

    imagealloc.free = xalloc(conf.nimage*sizeof(KImage));
    if (imagealloc.free == nil)
        panic("initimage: no memory");
    ie = &imagealloc.free[conf.nimage-1];
    for(i = imagealloc.free; i < ie; i++)
        i->next = i+1;
    i->next = 0;
    imagealloc.freechan = malloc(NFREECHAN * sizeof(Chan*));
    imagealloc.szfreechan = NFREECHAN;
}
@
% was called initseg, not sure why


<<function pageinit>>=
void
pageinit(void)
{
    int color, i, j;
    Page *p;
    Pallocmem *pm;
    ulong m, np, k, vkb, pkb;

    np = 0;
    for(i=0; i<nelem(palloc.mem); i++){
        pm = &palloc.mem[i];
        np += pm->npage;
    }
    palloc.pages = xalloc(np*sizeof(Page));
    if(palloc.pages == 0)
        panic("pageinit");

    color = 0;
    palloc.head = palloc.pages;
    p = palloc.head;
    for(i=0; i<nelem(palloc.mem); i++){
        pm = &palloc.mem[i];
        for(j=0; j<pm->npage; j++){
            p->prev = p-1;
            p->next = p+1;
            p->pa = pm->base+j*BY2PG;
            p->color = color;
            palloc.freecount++;
            color = (color+1)%NCOLOR;
            p++;
        }
    }
    palloc.tail = p - 1;
    palloc.head->prev = 0;
    palloc.tail->next = 0;

    palloc.user = p - palloc.pages; // TODO? should be np too no?
    pkb = palloc.user*BY2PG/1024;
    vkb = pkb + (conf.nswap*BY2PG)/1024;

    /* Paging numbers */
    swapalloc.highwater = (palloc.user*5)/100;
    swapalloc.headroom = swapalloc.highwater + (swapalloc.highwater/4);

    m = 0;
    for(i=0; i<nelem(conf.mem); i++)
        if(conf.mem[i].npage)
            m += conf.mem[i].npage*BY2PG;
    k = PGROUND(end - (char*)KTZERO);
    print("%ldM memory: ", (m+k+1024*1024-1)/(1024*1024));
    print("%ldM kernel data, ", (m+k-pkb*1024+1024*1024-1)/(1024*1024));
    print("%ldM user, ", pkb/1024);
    print("%ldM swap\n", vkb/1024);
}
@


<<function swapinit>>=
void
swapinit(void)
{
    swapalloc.swmap = xalloc(conf.nswap);
    swapalloc.top = &swapalloc.swmap[conf.nswap];
    swapalloc.alloc = swapalloc.swmap;
    swapalloc.last = swapalloc.swmap;
    swapalloc.free = conf.nswap;
    iolist = xalloc(conf.nswppo*sizeof(Page*));
    if(swapalloc.swmap == 0 || iolist == 0)
        panic("swapinit: not enough memory");

    swapimage.notext = 1;
}
@


\subsection{Device initialisation}

<<function chandevreset>>=
void
chandevreset(void)
{
    int i;

    todinit();  /* avoid later reentry causing infinite recursion */
    //debugstart = getconf("*debugstart") != nil;
    for(i=0; devtab[i] != nil; i++) {
        devtab[i]->reset();
    }
}
@

\section{The first process}

<<function userinit>>=
void
userinit(void)
{
    void *v;
    Proc *p;
    Segment *s;
    Page *pg;

    p = newproc();
    p->pgrp = newpgrp();
    p->egrp = smalloc(sizeof(Egrp)); //todo: newegrp()
    p->egrp->ref = 1;
    p->fgrp = dupfgrp(nil);
    p->rgrp = newrgrp();
    p->procmode = 0640;

    kstrdup(&eve, "");
    kstrdup(&p->text, "*init*");
    kstrdup(&p->user, eve);

    p->fpstate = FPinit;
    fpoff();

    /*
     * Kernel Stack
     *
     * N.B. make sure there's enough space for syscall to check
     *      for valid args and 
     *      4 bytes for gotolabel's return PC
     */
    p->sched.pc = (ulong)init0;
    p->sched.sp = (ulong)p->kstack+KSTACK-(sizeof(Sargs)+BY2WD);

    /*
     * User Stack
     *
     * N.B. cannot call newpage() with clear=1, because pc kmap
     * requires up != nil.  use tmpmap instead.
     */
    s = newseg(SG_STACK, USTKTOP-USTKSIZE, USTKSIZE/BY2PG);
    p->seg[SSEG] = s;
    pg = newpage(0, 0, USTKTOP-BY2PG);
    v = tmpmap(pg);
    memset(v, 0, BY2PG);
    segpage(s, pg);

    bootargs(v);
    tmpunmap(v);

    /*
     * Text
     */
    s = newseg(SG_TEXT, UTZERO, 1);
    s->flushme++;
    p->seg[TSEG] = s;
    pg = newpage(0, 0, UTZERO);
    memset(pg->cachectl, PG_TXTFLUSH, sizeof(pg->cachectl));
    segpage(s, pg);
    v = tmpmap(pg);
    memset(v, 0, BY2PG);
    memmove(v, initcode, sizeof initcode);
    tmpunmap(v);

    ready(p);
}
@

<<function chandevinit>>=
void
chandevinit(void)
{
    int i;
    for(i=0; devtab[i] != nil; i++) {
        devtab[i]->init();
    }
}
@

<<function init0>>=
// set by userinit to sched.pc
void
init0(void)
{
        int i;
        char buf[2*KNAMELEN];
        
        up->nerrlab = 0;

        spllo();

        /*
         * These are o.k. because rootinit is null.
         * Then early kproc's will have a root and dot.
         */
        up->slash = namec("#/", Atodir, 0, 0);
        pathclose(up->slash->path);
        up->slash->path = newpath("/");
        up->dot = cclone(up->slash);

        chandevinit();

        if(!waserror()){
                snprint(buf, sizeof(buf), "%s %s", arch->id, conffile);
                ksetenv("terminal", buf, 0);
                ksetenv("cputype", "386", 0);
                if(cpuserver)
                        ksetenv("service", "cpu", 0);
                else
                        ksetenv("service", "terminal", 0);
                for(i = 0; i < nconf; i++){
                        if(confname[i][0] != '*')
                                ksetenv(confname[i], confval[i], 0);
                        ksetenv(confname[i], confval[i], 1);
                }
                poperror();
        }
        kproc("alarm", alarmkproc, 0);
        cgapost(0x9);
        touser(sp);
}
@

<<function touser>>=
/*
 *  Used to get to the first process:
 *      set up an interrupt return frame and IRET to user level.
 */
TEXT touser(SB), $0
        PUSHL   $(UDSEL)                        /* old ss */
        MOVL    sp+0(FP), AX                    /* old sp */
        PUSHL   AX
        MOVL    $0x200, AX                      /* interrupt enable flag */
        PUSHL   AX                              /* old flags */
        PUSHL   $(UESEL)                        /* old cs */
        PUSHL   $(UTZERO+32)                    /* old pc */
        MOVL    $(UDSEL), AX
        MOVW    AX, DS
        MOVW    AX, ES
        MOVW    AX, GS
        MOVW    AX, FS
        IRETL
@ 


\section{Booting the user}
% see section on Userspace system programs
% when arrive here, we got the first process executing! and
% a working kernel!

\chapter{Files}
\minitoc

<<systab file syscalls>>=
    [OPEN]      sysopen,
    [CLOSE]     sysclose,
    [PREAD]     syspread,
    [PWRITE]    syspwrite,
    [SEEK]      sysseek,
@ 

% note that files are used for many things, including devices!!
% plan9 has actually lots of file servers
%pike: interface is not everything is a file, but everything is
% a file server interface!

\section{Overview}

\section{[[Chan]]nels}

<<[[Chan]] other fields>>=
ushort  flag;
@

<<enum channelflag>>=
/*
 * channel flags
 */
enum 
{
  COPEN = 0x0001,   /* for i/o */
  CMSG  = 0x0002,   /* the message channel for a mount */
/*rsc CCREATE = 0x0004,   /* permits creation if c->mnt */
  CCEXEC  = 0x0008,   /* close on exec */
  CFREE = 0x0010,   /* not in use */
  CRCLOSE = 0x0020,   /* remove on close */
  CCACHE  = 0x0080,   /* client cache */
};
@


<<struct Chanalloc>>=
struct Chanalloc
{
    int fid; // could be a Counter, but already have a Lock anyway
    //list<ref<Chan>> ???
    Chan    *free;
    //list<ref<Chan>> ???
    Chan    *list;
    // extra
    Lock;
};
@


<<global chanalloc>>=
struct Chanalloc chanalloc;
@

<<[[Chan]] extra fields>>=
Chan* next;     /* allocation */
Chan* link;
@ 


<<constructor newchan>>=
Chan*
newchan(void)
{
    Chan *c;

    lock(&chanalloc);
    c = chanalloc.free;
    if(c != 0)
        chanalloc.free = c->next;
    unlock(&chanalloc);

    if(c == nil){
        c = smalloc(sizeof(Chan));
        lock(&chanalloc);
        c->fid = ++chanalloc.fid;
        c->link = chanalloc.list;
        chanalloc.list = c;
        unlock(&chanalloc);
    }

    /* if you get an error before associating with a dev,
       close calls rootclose, a nop */
    c->type = 0;
    c->flag = 0;
    c->ref = 1;
    c->dev = 0;
    c->offset = 0;
    c->devoffset = 0;
    c->iounit = 0;
    c->umh = nil;
    c->uri = 0;
    c->dri = 0;
    c->aux = nil;
    c->mchan = nil;
    c->mcp = nil;
    c->mux = nil;
    memset(&c->mqid, 0, sizeof(c->mqid));
    c->path = 0;
    c->ismtpt = false;
    
    return c;
}
@

<<destructor chanfree>>=
void
chanfree(Chan *c)
{
    c->flag = CFREE;

    if(c->dirrock != nil){
        free(c->dirrock);
        c->dirrock = nil;
        c->nrock = 0;
        c->mrock = 0;
    }
    if(c->umh != nil){
        putmhead(c->umh);
        c->umh = nil;
    }
    if(c->umc != nil){
        cclose(c->umc);
        c->umc = nil;
    }
    if(c->mux != nil){
        muxclose(c->mux);
        c->mux = nil;
    }
    if(c->mchan != nil){
        cclose(c->mchan);
        c->mchan = nil;
    }

    pathclose(c->path);
    c->path = nil;

    lock(&chanalloc);
    c->next = chanalloc.free;
    chanalloc.free = c;
    unlock(&chanalloc);
}
@


<<function cclose>>=
void
chan_cclose(Chan *c)
{
    if(c->flag&CFREE)
        panic("cclose %#p", getcallerpc(&c));

    DBG("cclose %p name=%s ref=%ld\n", c, c->path->s, c->ref);
    if(decref(c))
        return;

    if(!waserror()){
        devtab[c->type]->close(c);
        poperror();
    }
    chanfree(c);
}
@


<<function cclone>>=
Chan*
cclone(Chan *c)
{
    Chan *nc;
    Walkqid *wq;

    wq = devtab[c->type]->walk(c, nil, nil, 0);
    if(wq == nil)
        error("clone failed");
    nc = wq->clone;
    free(wq);
    nc->path = c->path;
    if(c->path)
        incref(c->path);
    return nc;
}
@

<<function cunique>>=
/*
 * Make sure we have the only copy of c.  (Copy on write.)
 */
Chan*
cunique(Chan *c)
{
    Chan *nc;

    if(c->ref != 1){
        nc = cclone(c);
        cclose(c);
        c = nc;
    }

    return c;
}
@



\section{[[Block]]}

<<enum blockflag>>=
/* flag values */
enum
{
  BINTR = (1<<0),
  BFREE = (1<<1),
  Bipck = (1<<2),   /* ip checksum */
  Budpck  = (1<<3),   /* udp checksum */
  Btcpck  = (1<<4),   /* tcp checksum */
  Bpktck  = (1<<5),   /* packet checksum */
};
@

<<struct Block>>=
struct Block
{
  long  ref;
  Block*  next;
  Block*  list;
  uchar*  rp;     /* first unconsumed byte */
  uchar*  wp;     /* first empty byte */
  uchar*  lim;      /* 1 past the end of the buffer */
  uchar*  base;     /* start of the buffer */
  void  (*free)(Block*);
  ushort  flag;
  ushort  checksum;   /* IP checksum of complete packet (minus media header) */
};
@

<<function BLEN>>=
#define BLEN(s) ((s)->wp - (s)->rp)
@


<<function BALLOC>>=
#define BALLOC(s) ((s)->lim - (s)->base)
@


<<function _allocb>>=
static Block*
_allocb(int size)
{
    Block *b;
    ulong addr;

    if((b = mallocz(sizeof(Block)+size+Hdrspc, 0)) == nil)
        return nil;

    b->next = nil;
    b->list = nil;
    b->free = 0;
    b->flag = 0;
    b->ref = 0;
    _xinc(&b->ref);

    /* align start of data portion by rounding up */
    addr = (ulong)b;
    addr = ROUND(addr + sizeof(Block), BLOCKALIGN);
    b->base = (uchar*)addr;

    /* align end of data portion by rounding down */
    b->lim = ((uchar*)b) + msize(b);
    addr = (ulong)(b->lim);
    addr = addr & ~(BLOCKALIGN-1);
    b->lim = (uchar*)addr;

    /* leave sluff at beginning for added headers */
    b->rp = b->lim - ROUND(size, BLOCKALIGN);
    if(b->rp < b->base)
        panic("_allocb");
    b->wp = b->rp;

    return b;
}
@

<<function allocb>>=
Block*
allocb(int size)
{
    Block *b;

    /*
     * Check in a process and wait until successful.
     * Can still error out of here, though.
     */
    if(up == nil)
        panic("allocb without up: %#p", getcallerpc(&size));
    if((b = _allocb(size)) == nil){
        splhi();
        xsummary();
        mallocsummary();
        delay(500);
        panic("allocb: no memory for %d bytes; caller %#p", size,
            getcallerpc(&size));
    }
    setmalloctag(b, getcallerpc(&size));

    return b;
}
@




<<struct Ialloc>>=
struct Ialloc
{
    Lock;
    ulong   bytes;
};
@


<<global ialloc>>=
struct Ialloc ialloc;
@

<<function iallocb>>=
Block*
iallocb(int size)
{
    Block *b;
    static int m1, m2, mp;

    if(ialloc.bytes > conf.ialloc){
        if((m1++%10000)==0){
            if(mp++ > 1000){
                active.exiting = true;
                exit(0);
            }
            iprint("iallocb: limited %lud/%lud\n",
                ialloc.bytes, conf.ialloc);
        }
        return nil;
    }

    if((b = _allocb(size)) == nil){
        if((m2++%10000)==0){
            if(mp++ > 1000){
                active.exiting = true;
                exit(0);
            }
            iprint("iallocb: no memory %lud/%lud\n",
                ialloc.bytes, conf.ialloc);
        }
        return nil;
    }
    setmalloctag(b, getcallerpc(&size));
    b->flag = BINTR;

    ilock(&ialloc);
    ialloc.bytes += b->lim - b->base;
    iunlock(&ialloc);

    return b;
}
@


<<function freeb>>=
void
freeb(Block *b)
{
    void *dead = (void*)Bdead;
    long ref;

    if(b == nil || (ref = _xdec(&b->ref)) > 0)
        return;

    if(ref < 0){
        dumpstack();
        panic("freeb: ref %ld; caller pc %#p", ref, getcallerpc(&b));
    }

    /*
     * drivers which perform non cache coherent DMA manage their own buffer
     * pool of uncached buffers and provide their own free routine.
     */
    if(b->free) {
        b->free(b);
        return;
    }
    if(b->flag & BINTR) {
        ilock(&ialloc);
        ialloc.bytes -= b->lim - b->base;
        iunlock(&ialloc);
    }

    /* poison the block in case someone is still holding onto it */
    b->next = dead;
    b->rp = dead;
    b->wp = dead;
    b->lim = dead;
    b->base = dead;

    free(b);
}
@


<<function checkb>>=
void
checkb(Block *b, char *msg)
{
    void *dead = (void*)Bdead;

    if(b == dead)
        panic("checkb b %s %#p", msg, b);
    if(b->base == dead || b->lim == dead || b->next == dead
      || b->rp == dead || b->wp == dead){
        print("checkb: base %#p lim %#p next %#p\n",
            b->base, b->lim, b->next);
        print("checkb: rp %#p wp %#p\n", b->rp, b->wp);
        panic("checkb dead: %s", msg);
    }

    if(b->base > b->lim)
        panic("checkb 0 %s %#p %#p", msg, b->base, b->lim);
    if(b->rp < b->base)
        panic("checkb 1 %s %#p %#p", msg, b->base, b->rp);
    if(b->wp < b->base)
        panic("checkb 2 %s %#p %#p", msg, b->base, b->wp);
    if(b->rp > b->lim)
        panic("checkb 3 %s %#p %#p", msg, b->rp, b->lim);
    if(b->wp > b->lim)
        panic("checkb 4 %s %#p %#p", msg, b->wp, b->lim);
}
@





<<function freeblist>>=
/*
 *  free a list of blocks
 */
void
freeblist(Block *b)
{
    Block *next;

    for(; b != 0; b = next){
        next = b->next;
        if(b->ref == 1)
            b->next = nil;
        freeb(b);
    }
}
@


<<function padblock>>=
/*
 *  pad a block to the front (or the back if size is negative)
 */
Block*
padblock(Block *bp, int size)
{
    int n;
    Block *nbp;

    QDEBUG checkb(bp, "padblock 1");
    if(size >= 0){
        if(bp->rp - bp->base >= size){
            bp->rp -= size;
            return bp;
        }

        if(bp->next)
            panic("padblock %#p", getcallerpc(&bp));
        n = BLEN(bp);
        padblockcnt++;
        nbp = allocb(size+n);
        nbp->rp += size;
        nbp->wp = nbp->rp;
        memmove(nbp->wp, bp->rp, n);
        nbp->wp += n;
        freeb(bp);
        nbp->rp -= size;
    } else {
        size = -size;

        if(bp->next)
            panic("padblock %#p", getcallerpc(&bp));

        if(bp->lim - bp->wp >= size)
            return bp;

        n = BLEN(bp);
        padblockcnt++;
        nbp = allocb(size+n);
        memmove(nbp->wp, bp->rp, n);
        nbp->wp += n;
        freeb(bp);
    }
    QDEBUG checkb(nbp, "padblock 1");
    return nbp;
}
@


<<function blocklen>>=
/*
 *  return count of bytes in a string of blocks
 */
int
blocklen(Block *bp)
{
    int len;

    len = 0;
    while(bp) {
        len += BLEN(bp);
        bp = bp->next;
    }
    return len;
}
@


<<function blockalloclen>>=
/*
 * return count of space in blocks
 */
int
blockalloclen(Block *bp)
{
    int len;

    len = 0;
    while(bp) {
        len += BALLOC(bp);
        bp = bp->next;
    }
    return len;
}
@


<<function concatblock>>=
/*
 *  copy the  string of blocks into
 *  a single block and free the string
 */
Block*
concatblock(Block *bp)
{
    int len;
    Block *nb, *f;

    if(bp->next == 0)
        return bp;

    nb = allocb(blocklen(bp));
    for(f = bp; f; f = f->next) {
        len = BLEN(f);
        memmove(nb->wp, f->rp, len);
        nb->wp += len;
    }
    concatblockcnt += BLEN(nb);
    freeblist(bp);
    QDEBUG checkb(nb, "concatblock 1");
    return nb;
}
@


<<function pullupblock>>=
/*
 *  make sure the first block has at least n bytes
 */
Block*
pullupblock(Block *bp, int n)
{
    int i;
    Block *nbp;

    /*
     *  this should almost always be true, it's
     *  just to avoid every caller checking.
     */
    if(BLEN(bp) >= n)
        return bp;

    /*
     *  if not enough room in the first block,
     *  add another to the front of the list.
     */
    if(bp->lim - bp->rp < n){
        nbp = allocb(n);
        nbp->next = bp;
        bp = nbp;
    }

    /*
     *  copy bytes from the trailing blocks into the first
     */
    n -= BLEN(bp);
    while(nbp = bp->next){
        i = BLEN(nbp);
        if(i > n) {
            memmove(bp->wp, nbp->rp, n);
            pullupblockcnt++;
            bp->wp += n;
            nbp->rp += n;
            QDEBUG checkb(bp, "pullupblock 1");
            return bp;
        } else {
            /* shouldn't happen but why crash if it does */
            if(i < 0){
                print("pullup negative length packet, called from %#p\n",
                    getcallerpc(&bp));
                i = 0;
            }
            memmove(bp->wp, nbp->rp, i);
            pullupblockcnt++;
            bp->wp += i;
            bp->next = nbp->next;
            nbp->next = 0;
            freeb(nbp);
            n -= i;
            if(n == 0){
                QDEBUG checkb(bp, "pullupblock 2");
                return bp;
            }
        }
    }
    freeb(bp);
    return nil;
}
@


<<function packblock>>=
/*
 *  if the allocated space is way out of line with the used
 *  space, reallocate to a smaller block
 */
Block*
packblock(Block *bp)
{
    Block **l, *nbp;
    int n;

    for(l = &bp; *l; l = &(*l)->next){
        nbp = *l;
        n = BLEN(nbp);
        if((n<<2) < BALLOC(nbp)){
            *l = allocb(n);
            memmove((*l)->wp, nbp->rp, n);
            (*l)->wp += n;
            (*l)->next = nbp->next;
            freeb(nbp);
        }
    }

    return bp;
}
@


<<function trimblock>>=
/*
 *  trim to len bytes starting at offset
 */
Block *
trimblock(Block *bp, int offset, int len)
{
    ulong l;
    Block *nb, *startb;

    QDEBUG checkb(bp, "trimblock 1");
    if(blocklen(bp) < offset+len) {
        freeblist(bp);
        return nil;
    }

    while((l = BLEN(bp)) < offset) {
        offset -= l;
        nb = bp->next;
        bp->next = nil;
        freeb(bp);
        bp = nb;
    }

    startb = bp;
    bp->rp += offset;

    while((l = BLEN(bp)) < len) {
        len -= l;
        bp = bp->next;
    }

    bp->wp -= (BLEN(bp) - len);

    if(bp->next) {
        freeblist(bp->next);
        bp->next = nil;
    }

    return startb;
}
@


<<function copyblock>>=
/*
 *  copy 'count' bytes into a new block
 */
Block*
copyblock(Block *bp, int count)
{
    int l;
    Block *nbp;

    QDEBUG checkb(bp, "copyblock 0");
    nbp = allocb(count);
    for(; count > 0 && bp != 0; bp = bp->next){
        l = BLEN(bp);
        if(l > count)
            l = count;
        memmove(nbp->wp, bp->rp, l);
        nbp->wp += l;
        count -= l;
    }
    if(count > 0){
        memset(nbp->wp, 0, count);
        nbp->wp += count;
    }
    copyblockcnt++;
    QDEBUG checkb(nbp, "copyblock 1");

    return nbp;
}
@


<<function adjustblock>>=
Block*
adjustblock(Block* bp, int len)
{
    int n;
    Block *nbp;

    if(len < 0){
        freeb(bp);
        return nil;
    }

    if(bp->rp+len > bp->lim){
        nbp = copyblock(bp, len);
        freeblist(bp);
        QDEBUG checkb(nbp, "adjustblock 1");

        return nbp;
    }

    n = BLEN(bp);
    if(len > n)
        memset(bp->wp, 0, len-n);
    bp->wp = bp->rp+len;
    QDEBUG checkb(bp, "adjustblock 2");

    return bp;
}
@


<<function pullblock>>=
/*
 *  throw away up to count bytes from a
 *  list of blocks.  Return count of bytes
 *  thrown away.
 */
int
pullblock(Block **bph, int count)
{
    Block *bp;
    int n, bytes;

    bytes = 0;
    if(bph == nil)
        return 0;

    while(*bph != nil && count != 0) {
        bp = *bph;
        n = BLEN(bp);
        if(count < n)
            n = count;
        bytes += n;
        count -= n;
        bp->rp += n;
        QDEBUG checkb(bp, "pullblock ");
        if(BLEN(bp) == 0) {
            *bph = bp->next;
            bp->next = nil;
            freeb(bp);
        }
    }
    return bytes;
}
@

<<function bl2mem>>=
/*
 *  copy the contents of a string of blocks into
 *  memory.  emptied blocks are freed.  return
 *  pointer to first unconsumed block.
 */
Block*
bl2mem(uchar *p, Block *b, int n)
{
    int i;
    Block *next;

    for(; b != nil; b = next){
        i = BLEN(b);
        if(i > n){
            memmove(p, b->rp, n);
            b->rp += n;
            return b;
        }
        memmove(p, b->rp, i);
        n -= i;
        p += i;
        b->rp += i;
        next = b->next;
        freeb(b);
    }
    return nil;
}
@


\section{[[Clunkq]]}
%?????

<<struct Clunkq>>=
/*
 * Queue a chan to be closed by one of the clunk procs.
 */
struct Clunkq {
    Chan *head;
    Chan *tail;
    int nqueued;
    int nclosed;
    Lock l;
    QLock q;
    Rendez r;
};
@


<<global clunkq>>=
struct Clunkq clunkq;
@


<<function ccloseq>>=
void
ccloseq(Chan *c)
{
    if(c->flag&CFREE)
        panic("cclose %#p", getcallerpc(&c));

    DBG("ccloseq %p name=%s ref=%ld\n", c, c->path->s, c->ref);

    if(decref(c))
        return;

    lock(&clunkq.l);
    clunkq.nqueued++;
    c->next = nil;
    if(clunkq.head)
        clunkq.tail->next = c;
    else
        clunkq.head = c;
    clunkq.tail = c;
    unlock(&clunkq.l);

    if(!wakeup(&clunkq.r))
        kproc("closeproc", closeproc, nil); 
}
@


<<function clunkwork>>=
static int
clunkwork(void*)
{
    return clunkq.head != nil;
}
@


<<function closeproc>>=
void
closeproc(void*)
{
    Chan *c;

    for(;;){
        qlock(&clunkq.q);
        if(clunkq.head == nil){
            if(!waserror()){
                tsleep(&clunkq.r, clunkwork, nil, 5000);
                poperror();
            }
            if(clunkq.head == nil){
                qunlock(&clunkq.q);
                pexit("no work", true);
            }
        }
        lock(&clunkq.l);
        c = clunkq.head;
        clunkq.head = c->next;
        clunkq.nclosed++;
        unlock(&clunkq.l);
        qunlock(&clunkq.q);
        if(!waserror()){
            devtab[c->type]->close(c);
            poperror();
        }
        chanfree(c);
    }
}
@

\section{[[Queue]]}

<<enum queuestate>>=
/* queue state bits,  Qmsg, Qcoalesce, and Qkick can be set in qopen */
enum
{
  /* Queue.state */
  Qstarve   = (1<<0), /* consumer starved */
  Qmsg    = (1<<1), /* message stream */
  Qclosed   = (1<<2), /* queue has been closed/hungup */
  Qflow   = (1<<3), /* producer flow controlled */
  Qcoalesce = (1<<4), /* coalesce packets on read */
  Qkick   = (1<<5), /* always call the kick routine after qwrite */
};
@

<<struct Queue>>=
struct Queue
{
  Lock;

  Block*  bfirst;   /* buffer */
  Block*  blast;

  int len;    /* bytes allocated to queue */
  int dlen;   /* data bytes in queue */
  int limit;    /* max bytes in queue */
  int inilim;   /* initial limit */
  int state;
  int noblock;  /* true if writes return immediately when q full */
  int eof;    /* number of eofs read by user */

  void  (*kick)(void*); /* restart output */
  void  (*bypass)(void*, Block*); /* bypass queue altogether */
  void* arg;    /* argument to kick */

  QLock rlock;    /* mutex for reading processes */
  Rendez  rr;   /* process waiting to read */
  QLock wlock;    /* mutex for writing processes */
  Rendez  wr;   /* process waiting to write */

  char  err[ERRMAX];
};
@

<<function pullupqueue>>=
/*
 *  make sure the first block has at least n bytes
 */
Block*
pullupqueue(Queue *q, int n)
{
    Block *b;

    if(BLEN(q->bfirst) >= n)
        return q->bfirst;
    q->bfirst = pullupblock(q->bfirst, n);
    for(b = q->bfirst; b != nil && b->next != nil; b = b->next)
        ;
    q->blast = b;
    return q->bfirst;
}
@


<<function qwrite>>=
/*
 *  write to a queue.  only Maxatomic bytes at a time is atomic.
 */
int
qwrite(Queue *q, void *vp, int len)
{
    int n, sofar;
    Block *b;
    uchar *p = vp;

    QDEBUG if(!islo())
        print("qwrite hi %#p\n", getcallerpc(&q));

    sofar = 0;
    do {
        n = len-sofar;
        if(n > Maxatomic)
            n = Maxatomic;

        b = allocb(n);
        setmalloctag(b, (up->text[0]<<24)|(up->text[1]<<16)|(up->text[2]<<8)|up->text[3]);
        if(waserror()){
            freeb(b);
            nexterror();
        }
        memmove(b->wp, p+sofar, n);
        poperror();
        b->wp += n;

        qbwrite(q, b);

        sofar += n;
    } while(sofar < len && (q->state & Qmsg) == 0);

    return len;
}
@



<<function qget>>=
/*
 *  get next block from a queue, return null if nothing there
 */
Block*
qget(Queue *q)
{
    int dowakeup;
    Block *b;

    /* sync with qwrite */
    ilock(q);

    b = q->bfirst;
    if(b == nil){
        q->state |= Qstarve;
        iunlock(q);
        return nil;
    }
    q->bfirst = b->next;
    b->next = 0;
    q->len -= BALLOC(b);
    q->dlen -= BLEN(b);
    QDEBUG checkb(b, "qget");

    /* if writer flow controlled, restart */
    if((q->state & Qflow) && q->len < q->limit/2){
        q->state &= ~Qflow;
        dowakeup = 1;
    } else
        dowakeup = 0;

    iunlock(q);

    if(dowakeup)
        wakeup(&q->wr);

    return b;
}
@


<<function qdiscard>>=
/*
 *  throw away the next 'len' bytes in the queue
 */
int
qdiscard(Queue *q, int len)
{
    Block *b;
    int dowakeup, n, sofar;

    ilock(q);
    for(sofar = 0; sofar < len; sofar += n){
        b = q->bfirst;
        if(b == nil)
            break;
        QDEBUG checkb(b, "qdiscard");
        n = BLEN(b);
        if(n <= len - sofar){
            q->bfirst = b->next;
            b->next = 0;
            q->len -= BALLOC(b);
            q->dlen -= BLEN(b);
            freeb(b);
        } else {
            n = len - sofar;
            b->rp += n;
            q->dlen -= n;
        }
    }

    /*
     *  if writer flow controlled, restart
     *
     *  This used to be
     *  q->len < q->limit/2
     *  but it slows down tcp too much for certain write sizes.
     *  I really don't understand it completely.  It may be
     *  due to the queue draining so fast that the transmission
     *  stalls waiting for the app to produce more data.  - presotto
     */
    if((q->state & Qflow) && q->len < q->limit){
        q->state &= ~Qflow;
        dowakeup = 1;
    } else
        dowakeup = 0;

    iunlock(q);

    if(dowakeup)
        wakeup(&q->wr);

    return sofar;
}
@


<<function qconsume>>=
/*
 *  Interrupt level copy out of a queue, return # bytes copied.
 */
int
qconsume(Queue *q, void *vp, int len)
{
    Block *b;
    int n, dowakeup;
    uchar *p = vp;
    Block *tofree = nil;

    /* sync with qwrite */
    ilock(q);

    for(;;) {
        b = q->bfirst;
        if(b == 0){
            q->state |= Qstarve;
            iunlock(q);
            return -1;
        }
        QDEBUG checkb(b, "qconsume 1");

        n = BLEN(b);
        if(n > 0)
            break;
        q->bfirst = b->next;
        q->len -= BALLOC(b);

        /* remember to free this */
        b->next = tofree;
        tofree = b;
    };

    if(n < len)
        len = n;
    memmove(p, b->rp, len);
    consumecnt += n;
    b->rp += len;
    q->dlen -= len;

    /* discard the block if we're done with it */
    if((q->state & Qmsg) || len == n){
        q->bfirst = b->next;
        b->next = 0;
        q->len -= BALLOC(b);
        q->dlen -= BLEN(b);

        /* remember to free this */
        b->next = tofree;
        tofree = b;
    }

    /* if writer flow controlled, restart */
    if((q->state & Qflow) && q->len < q->limit/2){
        q->state &= ~Qflow;
        dowakeup = 1;
    } else
        dowakeup = 0;

    iunlock(q);

    if(dowakeup)
        wakeup(&q->wr);

    if(tofree != nil)
        freeblist(tofree);

    return len;
}
@


<<function qpass>>=
int
qpass(Queue *q, Block *b)
{
    int dlen, len, dowakeup;

    /* sync with qread */
    dowakeup = 0;
    ilock(q);
    if(q->len >= q->limit){
        freeblist(b);
        iunlock(q);
        return -1;
    }
    if(q->state & Qclosed){
        len = BALLOC(b);
        freeblist(b);
        iunlock(q);
        return len;
    }

    /* add buffer to queue */
    if(q->bfirst)
        q->blast->next = b;
    else
        q->bfirst = b;
    len = BALLOC(b);
    dlen = BLEN(b);
    QDEBUG checkb(b, "qpass");
    while(b->next){
        b = b->next;
        QDEBUG checkb(b, "qpass");
        len += BALLOC(b);
        dlen += BLEN(b);
    }
    q->blast = b;
    q->len += len;
    q->dlen += dlen;

    if(q->len >= q->limit/2)
        q->state |= Qflow;

    if(q->state & Qstarve){
        q->state &= ~Qstarve;
        dowakeup = 1;
    }
    iunlock(q);

    if(dowakeup)
        wakeup(&q->rr);

    return len;
}
@


<<function qpassnolim>>=
int
qpassnolim(Queue *q, Block *b)
{
    int dlen, len, dowakeup;

    /* sync with qread */
    dowakeup = 0;
    ilock(q);

    if(q->state & Qclosed){
        freeblist(b);
        iunlock(q);
        return BALLOC(b);
    }

    /* add buffer to queue */
    if(q->bfirst)
        q->blast->next = b;
    else
        q->bfirst = b;
    len = BALLOC(b);
    dlen = BLEN(b);
    QDEBUG checkb(b, "qpass");
    while(b->next){
        b = b->next;
        QDEBUG checkb(b, "qpass");
        len += BALLOC(b);
        dlen += BLEN(b);
    }
    q->blast = b;
    q->len += len;
    q->dlen += dlen;

    if(q->len >= q->limit/2)
        q->state |= Qflow;

    if(q->state & Qstarve){
        q->state &= ~Qstarve;
        dowakeup = 1;
    }
    iunlock(q);

    if(dowakeup)
        wakeup(&q->rr);

    return len;
}
@


<<function qproduce>>=
int
qproduce(Queue *q, void *vp, int len)
{
    Block *b;
    int dowakeup;
    uchar *p = vp;

    /* sync with qread */
    dowakeup = 0;
    ilock(q);

    /* no waiting receivers, room in buffer? */
    if(q->len >= q->limit){
        q->state |= Qflow;
        iunlock(q);
        return -1;
    }

    /* save in buffer */
    b = iallocb(len);
    if(b == 0){
        iunlock(q);
        return 0;
    }
    memmove(b->wp, p, len);
    producecnt += len;
    b->wp += len;
    if(q->bfirst)
        q->blast->next = b;
    else
        q->bfirst = b;
    q->blast = b;
    /* b->next = 0; done by iallocb() */
    q->len += BALLOC(b);
    q->dlen += BLEN(b);
    QDEBUG checkb(b, "qproduce");

    if(q->state & Qstarve){
        q->state &= ~Qstarve;
        dowakeup = 1;
    }

    if(q->len >= q->limit)
        q->state |= Qflow;
    iunlock(q);

    if(dowakeup)
        wakeup(&q->rr);

    return len;
}
@


<<function qcopy>>=
/*
 *  copy from offset in the queue
 */
Block*
qcopy(Queue *q, int len, ulong offset)
{
    int sofar;
    int n;
    Block *b, *nb;
    uchar *p;

    nb = allocb(len);

    ilock(q);

    /* go to offset */
    b = q->bfirst;
    for(sofar = 0; ; sofar += n){
        if(b == nil){
            iunlock(q);
            return nb;
        }
        n = BLEN(b);
        if(sofar + n > offset){
            p = b->rp + offset - sofar;
            n -= offset - sofar;
            break;
        }
        QDEBUG checkb(b, "qcopy");
        b = b->next;
    }

    /* copy bytes from there */
    for(sofar = 0; sofar < len;){
        if(n > len - sofar)
            n = len - sofar;
        memmove(nb->wp, p, n);
        qcopycnt += n;
        sofar += n;
        nb->wp += n;
        b = b->next;
        if(b == nil)
            break;
        n = BLEN(b);
        p = b->rp;
    }
    iunlock(q);

    return nb;
}
@


<<function qopen>>=
/*
 *  called by non-interrupt code
 */
Queue*
qopen(int limit, int msg, void (*kick)(void*), void *arg)
{
    Queue *q;

    q = malloc(sizeof(Queue));
    if(q == nil)
        return nil;

    q->limit = q->inilim = limit;
    q->kick = kick;
    q->arg = arg;
    q->state = msg;
    
    q->state |= Qstarve;
    q->eof = 0;
    q->noblock = 0;

    return q;
}
@


<<function qbypass>>=
/* open a queue to be bypassed */
Queue*
qbypass(void (*bypass)(void*, Block*), void *arg)
{
    Queue *q;

    q = malloc(sizeof(Queue));
    if(q == nil)
        return nil;

    q->limit = 0;
    q->arg = arg;
    q->bypass = bypass;
    q->state = 0;

    return q;
}
@


<<function notempty>>=
static int
notempty(void *a)
{
    Queue *q = a;

    return (q->state & Qclosed) || q->bfirst != 0;
}
@


<<function qwait>>=
/*
 *  wait for the queue to be non-empty or closed.
 *  called with q ilocked.
 */
static int
qwait(Queue *q)
{
    /* wait for data */
    for(;;){
        if(q->bfirst != nil)
            break;

        if(q->state & Qclosed){
            if(++q->eof > 3)
                return -1;
            if(*q->err && strcmp(q->err, Ehungup) != 0)
                return -1;
            return 0;
        }

        q->state |= Qstarve;    /* flag requesting producer to wake me */
        iunlock(q);
        sleep(&q->rr, notempty, q);
        ilock(q);
    }
    return 1;
}
@


<<function qaddlist>>=
/*
 * add a block list to a queue
 */
void
qaddlist(Queue *q, Block *b)
{
    /* queue the block */
    if(q->bfirst)
        q->blast->next = b;
    else
        q->bfirst = b;
    q->len += blockalloclen(b);
    q->dlen += blocklen(b);
    while(b->next)
        b = b->next;
    q->blast = b;
}
@


<<function qremove>>=
/*
 *  called with q ilocked
 */
Block*
qremove(Queue *q)
{
    Block *b;

    b = q->bfirst;
    if(b == nil)
        return nil;
    q->bfirst = b->next;
    b->next = nil;
    q->dlen -= BLEN(b);
    q->len -= BALLOC(b);
    QDEBUG checkb(b, "qremove");
    return b;
}
@


<<function qputback>>=
/*
 *  put a block back to the front of the queue
 *  called with q ilocked
 */
void
qputback(Queue *q, Block *b)
{
    b->next = q->bfirst;
    if(q->bfirst == nil)
        q->blast = b;
    q->bfirst = b;
    q->len += BALLOC(b);
    q->dlen += BLEN(b);
}
@


<<function qwakeup_iunlock>>=
/*
 *  flow control, get producer going again
 *  called with q ilocked
 */
static void
qwakeup_iunlock(Queue *q)
{
    int dowakeup = 0;

    /* if writer flow controlled, restart */
    if((q->state & Qflow) && q->len < q->limit/2){
        q->state &= ~Qflow;
        dowakeup = 1;
    }

    iunlock(q);

    /* wakeup flow controlled writers */
    if(dowakeup){
        if(q->kick)
            q->kick(q->arg);
        wakeup(&q->wr);
    }
}
@


<<function qbread>>=
/*
 *  get next block from a queue (up to a limit)
 */
Block*
qbread(Queue *q, int len)
{
    Block *b, *nb;
    int n;

    qlock(&q->rlock);
    if(waserror()){
        qunlock(&q->rlock);
        nexterror();
    }

    ilock(q);
    switch(qwait(q)){
    case 0:
        /* queue closed */
        iunlock(q);
        qunlock(&q->rlock);
        poperror();
        return nil;
    case -1:
        /* multiple reads on a closed queue */
        iunlock(q);
        error(q->err);
    }

    /* if we get here, there's at least one block in the queue */
    b = qremove(q);
    n = BLEN(b);

    /* split block if it's too big and this is not a message queue */
    nb = b;
    if(n > len){
        if((q->state&Qmsg) == 0){
            n -= len;
            b = allocb(n);
            memmove(b->wp, nb->rp+len, n);
            b->wp += n;
            qputback(q, b);
        }
        nb->wp = nb->rp + len;
    }

    /* restart producer */
    qwakeup_iunlock(q);

    poperror();
    qunlock(&q->rlock);
    return nb;
}
@


<<function qread>>=
/*
 *  read a queue.  if no data is queued, post a Block
 *  and wait on its Rendez.
 */
long
qread(Queue *q, void *vp, int len)
{
    Block *b, *first, **l;
    int m, n;

    qlock(&q->rlock);
    if(waserror()){
        qunlock(&q->rlock);
        nexterror();
    }

    ilock(q);
again:
    switch(qwait(q)){
    case 0:
        /* queue closed */
        iunlock(q);
        qunlock(&q->rlock);
        poperror();
        return 0;
    case -1:
        /* multiple reads on a closed queue */
        iunlock(q);
        error(q->err);
    }

    /* if we get here, there's at least one block in the queue */
    if(q->state & Qcoalesce){
        /* when coalescing, 0 length blocks just go away */
        b = q->bfirst;
        if(BLEN(b) <= 0){
            freeb(qremove(q));
            goto again;
        }

        /*  grab the first block plus as many
         *  following blocks as will completely
         *  fit in the read.
         */
        n = 0;
        l = &first;
        m = BLEN(b);
        for(;;) {
            *l = qremove(q);
            l = &b->next;
            n += m;

            b = q->bfirst;
            if(b == nil)
                break;
            m = BLEN(b);
            if(n+m > len)
                break;
        }
    } else {
        first = qremove(q);
        n = BLEN(first);
    }

    /* copy to user space outside of the ilock */
    iunlock(q);
    b = bl2mem(vp, first, len);
    ilock(q);

    /* take care of any left over partial block */
    if(b != nil){
        n -= BLEN(b);
        if(q->state & Qmsg)
            freeb(b);
        else
            qputback(q, b);
    }

    /* restart producer */
    qwakeup_iunlock(q);

    poperror();
    qunlock(&q->rlock);
    return n;
}
@


<<function qnotfull>>=
static int
qnotfull(void *a)
{
    Queue *q = a;

    return q->len < q->limit || (q->state & Qclosed);
}
@


<<function qbwrite>>=
/*
 *  add a block to a queue obeying flow control
 */
long
qbwrite(Queue *q, Block *b)
{
    int n, dowakeup;
    Proc *p;

    n = BLEN(b);

    if(q->bypass){
        (*q->bypass)(q->arg, b);
        return n;
    }

    dowakeup = 0;
    qlock(&q->wlock);
    if(waserror()){
        if(b != nil)
            freeb(b);
        qunlock(&q->wlock);
        nexterror();
    }

    ilock(q);

    /* give up if the queue is closed */
    if(q->state & Qclosed){
        iunlock(q);
        error(q->err);
    }

    /* if nonblocking, don't queue over the limit */
    if(q->len >= q->limit){
        if(q->noblock){
            iunlock(q);
            freeb(b);
            noblockcnt += n;
            qunlock(&q->wlock);
            poperror();
            return n;
        }
    }

    /* queue the block */
    if(q->bfirst)
        q->blast->next = b;
    else
        q->bfirst = b;
    q->blast = b;
    b->next = 0;
    q->len += BALLOC(b);
    q->dlen += n;
    QDEBUG checkb(b, "qbwrite");
    b = nil;

    /* make sure other end gets awakened */
    if(q->state & Qstarve){
        q->state &= ~Qstarve;
        dowakeup = 1;
    }
    iunlock(q);

    /*  get output going again */
    if(q->kick && (dowakeup || (q->state&Qkick)))
        q->kick(q->arg);

    /* wakeup anyone consuming at the other end */
    if(dowakeup){
        p = wakeup(&q->rr);

        /* if we just wokeup a higher priority process, let it run */
        if(p != nil && p->priority > up->priority)
            sched();
    }

    /*
     *  flow control, wait for queue to get below the limit
     *  before allowing the process to continue and queue
     *  more.  We do this here so that postnote can only
     *  interrupt us after the data has been queued.  This
     *  means that things like 9p flushes and ssl messages
     *  will not be disrupted by software interrupts.
     *
     *  Note - this is moderately dangerous since a process
     *  that keeps getting interrupted and rewriting will
     *  queue infinite crud.
     */
    for(;;){
        if(q->noblock || qnotfull(q))
            break;

        ilock(q);
        q->state |= Qflow;
        iunlock(q);
        sleep(&q->wr, qnotfull, q);
    }
    USED(b);

    qunlock(&q->wlock);
    poperror();
    return n;
}
@


<<function qiwrite>>=
/*
 *  used by print() to write to a queue.  Since we may be splhi or not in
 *  a process, don't qlock.
 *
 *  this routine merges adjacent blocks if block n+1 will fit into
 *  the free space of block n.
 */
int
qiwrite(Queue *q, void *vp, int len)
{
    int n, sofar, dowakeup;
    Block *b;
    uchar *p = vp;

    dowakeup = 0;

    sofar = 0;
    do {
        n = len-sofar;
        if(n > Maxatomic)
            n = Maxatomic;

        b = iallocb(n);
        if(b == nil)
            break;
        memmove(b->wp, p+sofar, n);
        b->wp += n;

        ilock(q);

        /* we use an artificially high limit for kernel prints since anything
         * over the limit gets dropped
         */
        if(q->dlen >= 16*1024){
            iunlock(q);
            freeb(b);
            break;
        }

        QDEBUG checkb(b, "qiwrite");
        if(q->bfirst)
            q->blast->next = b;
        else
            q->bfirst = b;
        q->blast = b;
        q->len += BALLOC(b);
        q->dlen += n;

        if(q->state & Qstarve){
            q->state &= ~Qstarve;
            dowakeup = 1;
        }

        iunlock(q);

        if(dowakeup){
            if(q->kick)
                q->kick(q->arg);
            wakeup(&q->rr);
        }

        sofar += n;
    } while(sofar < len && (q->state & Qmsg) == 0);

    return sofar;
}
@


<<function qfree>>=
/*
 *  be extremely careful when calling this,
 *  as there is no reference accounting
 */
void
qfree(Queue *q)
{
    qclose(q);
    free(q);
}
@


<<function qclose>>=
/*
 *  Mark a queue as closed.  No further IO is permitted.
 *  All blocks are released.
 */
void
qclose(Queue *q)
{
    Block *bfirst;

    if(q == nil)
        return;

    /* mark it */
    ilock(q);
    q->state |= Qclosed;
    q->state &= ~(Qflow|Qstarve);
    strcpy(q->err, Ehungup);
    bfirst = q->bfirst;
    q->bfirst = 0;
    q->len = 0;
    q->dlen = 0;
    q->noblock = 0;
    iunlock(q);

    /* free queued blocks */
    freeblist(bfirst);

    /* wake up readers/writers */
    wakeup(&q->rr);
    wakeup(&q->wr);
}
@


<<function qhangup>>=
/*
 *  Mark a queue as closed.  Wakeup any readers.  Don't remove queued
 *  blocks.
 */
void
qhangup(Queue *q, char *msg)
{
    /* mark it */
    ilock(q);
    q->state |= Qclosed;
    if(msg == 0 || *msg == 0)
        strcpy(q->err, Ehungup);
    else
        strncpy(q->err, msg, ERRMAX-1);
    iunlock(q);

    /* wake up readers/writers */
    wakeup(&q->rr);
    wakeup(&q->wr);
}
@


<<function qiclosed>>=
/*
 *  return non-zero if the q is hungup
 */
int
qisclosed(Queue *q)
{
    return q->state & Qclosed;
}
@


<<function qreopen>>=
/*
 *  mark a queue as no longer hung up
 */
void
qreopen(Queue *q)
{
    ilock(q);
    q->state &= ~Qclosed;
    q->state |= Qstarve;
    q->eof = 0;
    q->limit = q->inilim;
    iunlock(q);
}
@


<<function qlen>>=
/*
 *  return bytes queued
 */
int
qlen(Queue *q)
{
    return q->dlen;
}
@


<<function qwindow>>=
/*
 * return space remaining before flow control
 */
int
qwindow(Queue *q)
{
    int l;

    l = q->limit - q->len;
    if(l < 0)
        l = 0;
    return l;
}
@


<<function qcanread>>=
/*
 *  return true if we can read without blocking
 */
int
qcanread(Queue *q)
{
    return q->bfirst!=0;
}
@


<<function qsetlimit>>=
/*
 *  change queue limit
 */
void
qsetlimit(Queue *q, int limit)
{
    q->limit = limit;
}
@


<<function qnoblock>>=
/*
 *  set blocking/nonblocking
 */
void
qnoblock(Queue *q, bool onoff)
{
    q->noblock = onoff;
}
@


<<function qflush>>=
/*
 *  flush the output queue
 */
void
qflush(Queue *q)
{
    Block *bfirst;

    /* mark it */
    ilock(q);
    bfirst = q->bfirst;
    q->bfirst = 0;
    q->len = 0;
    q->dlen = 0;
    iunlock(q);

    /* free queued blocks */
    freeblist(bfirst);

    /* wake up readers/writers */
    wakeup(&q->wr);
}
@


<<function qfull>>=
int
qfull(Queue *q)
{
    return q->state & Qflow;
}
@



\section{Devices table [[devtab]]}

<<function devno>>=
int
devno(int c, int user)
{
    int i;

    for(i = 0; devtab[i] != nil; i++) {
        if(devtab[i]->dc == c)
            return i;
    }
    if(user == 0)
        panic("devno %C %#ux", c, c);

    return -1;
}
@



\section{File descriptors}

<<struct Fgrp>>=
struct Fgrp
{
    // array<ref_counted<Chan>, smalloc'ed?
    Chan  **fd;
    // nelem(fd) ?
    int nfd;      /* number allocated */
    int maxfd;      /* highest fd in use */
  
    int exceed;     /* debugging */
  
    // extra
    Ref;
};
@ 

<<[[Proc]] files fields>>=
// ref_counted<fgrp>
Fgrp  *fgrp;    /* File descriptor group */
@

<<function dupfgrp>>=
Fgrp*
dupfgrp(Fgrp *f)
{
    Fgrp *new;
    Chan *c;
    int i;

    new = smalloc(sizeof(Fgrp));
    if(f == nil){
        new->fd = smalloc(DELTAFD*sizeof(Chan*));
        new->nfd = DELTAFD;
        new->ref = 1;
        return new;
    }

    lock(f);
    /* Make new fd list shorter if possible, preserving quantization */
    new->nfd = f->maxfd+1;
    i = new->nfd%DELTAFD;
    if(i != 0)
        new->nfd += DELTAFD - i;
    new->fd = malloc(new->nfd*sizeof(Chan*));
    if(new->fd == nil){
        unlock(f);
        free(new);
        error("no memory for fgrp");
    }
    new->ref = 1;

    new->maxfd = f->maxfd;
    for(i = 0; i <= f->maxfd; i++) {
        if(c = f->fd[i]){
            incref(c);
            new->fd[i] = c;
        }
    }
    unlock(f);

    return new;
}
@ 


<<function closefgrp>>=
void
closefgrp(Fgrp *f)
{
    int i;
    Chan *c;

    if(f == 0)
        return;

    if(decref(f) != 0)
        return;

    /*
     * If we get into trouble, forceclosefgrp
     * will bail us out.
     */
    up->closingfgrp = f;
    for(i = 0; i <= f->maxfd; i++)
        if(c = f->fd[i]){
            f->fd[i] = nil;
            cclose(c);
        }
    up->closingfgrp = nil;

    free(f->fd);
    free(f);
}
@ 


<<[[Proc]] files fields>>=
Fgrp  *closingfgrp; /* used during teardown */
@

<<function forceclosefgrp>>=
/*
 * Called from sleep because up is in the middle
 * of closefgrp and just got a kill ctl message.
 * This usually means that up has wedged because
 * of some kind of deadly embrace with mntclose
 * trying to talk to itself.  To break free, hand the
 * unclosed channels to the close queue.  Once they
 * are finished, the blocked cclose that we've 
 * interrupted will finish by itself.
 */
void
forceclosefgrp(void)
{
    int i;
    Chan *c;
    Fgrp *f;

    if(up->procctl != Proc_exitme || up->closingfgrp == nil){
        print("bad forceclosefgrp call");
        return;
    }

    f = up->closingfgrp;
    for(i = 0; i <= f->maxfd; i++)
        if(c = f->fd[i]){
            f->fd[i] = nil;
            ccloseq(c);
        }
}
@ 



<<function fdtochan>>=
Chan*
fdtochan(int fd, int mode, int chkmnt, int iref)
{
    Chan *c;
    Fgrp *f;

    c = 0;
    f = up->fgrp;

    lock(f);
    if(fd<0 || f->nfd<=fd || (c = f->fd[fd])==0) {
        unlock(f);
        error(Ebadfd);
    }
    if(iref)
        incref(c);
    unlock(f);

    if(chkmnt && (c->flag&CMSG)) {
        if(iref)
            cclose(c);
        error(Ebadusefd);
    }

    if(mode<0 || c->mode==ORDWR)
        return c;

    if((mode&OTRUNC) && c->mode==OREAD) {
        if(iref)
            cclose(c);
        error(Ebadusefd);
    }

    if((mode&~OTRUNC) != c->mode) {
        if(iref)
            cclose(c);
        error(Ebadusefd);
    }

    return c;
}
@


<<function unlockfgrp>>=
static void
unlockfgrp(Fgrp *f)
{
    int ex;

    ex = f->exceed;
    f->exceed = 0;
    unlock(f);
    if(ex)
        pprint("warning: process exceeds %d file descriptors\n", ex);
}
@


<<function growfd>>=
int
growfd(Fgrp *f, int fd) /* fd is always >= 0 */
{
    Chan **newfd, **oldfd;

    if(fd < f->nfd)
        return 0;
    if(fd >= f->nfd+DELTAFD)
        return -1;  /* out of range */
    /*
     * Unbounded allocation is unwise
     */
    if(f->nfd >= 5000){
    Exhausted:
        print("no free file descriptors\n");
        return -1;
    }
    newfd = malloc((f->nfd+DELTAFD)*sizeof(Chan*));
    if(newfd == 0)
        goto Exhausted;
    oldfd = f->fd;
    memmove(newfd, oldfd, f->nfd*sizeof(Chan*));
    f->fd = newfd;
    free(oldfd);
    f->nfd += DELTAFD;
    if(fd > f->maxfd){
        if(fd/100 > f->maxfd/100)
            f->exceed = (fd/100)*100;
        f->maxfd = fd;
    }
    return 1;
}
@


<<function findfreefd>>=
/*
 *  this assumes that the fgrp is locked
 */
int
findfreefd(Fgrp *f, int start)
{
    int fd;

    for(fd=start; fd<f->nfd; fd++)
        if(f->fd[fd] == 0)
            break;
    if(fd >= f->nfd && growfd(f, fd) < 0)
        return -1;
    return fd;
}
@


<<function newfd>>=
int
newfd(Chan *c)
{
    int fd;
    Fgrp *f;

    f = up->fgrp;
    lock(f);
    fd = findfreefd(f, 0);
    if(fd < 0){
        unlockfgrp(f);
        return -1;
    }
    if(fd > f->maxfd)
        f->maxfd = fd;
    f->fd[fd] = c;
    unlockfgrp(f);
    return fd;
}
@


<<function newfd2>>=
int
newfd2(int fd[2], Chan *c[2])
{
    Fgrp *f;

    f = up->fgrp;
    lock(f);
    fd[0] = findfreefd(f, 0);
    if(fd[0] < 0){
        unlockfgrp(f);
        return -1;
    }
    fd[1] = findfreefd(f, fd[0]+1);
    if(fd[1] < 0){
        unlockfgrp(f);
        return -1;
    }
    if(fd[1] > f->maxfd)
        f->maxfd = fd[1];
    f->fd[fd[0]] = c[0];
    f->fd[fd[1]] = c[1];
    unlockfgrp(f);

    return 0;
}
@


\section {[[sysopen()]], [[sysclose()]]}


<<syscall open>>=
// int open(char *file, int omode);
long
sysopen(ulong *arg)
{
    int fd;
    Chan *c;

    openmode(arg[1]);   /* error check only */
    validaddr(arg[0], 1, 0);
    c = namec((char*)arg[0], Aopen, arg[1], 0);
    if(waserror()){
        cclose(c);
        nexterror();
    }
    fd = newfd(c);
    if(fd < 0)
        error(Enofd);
    poperror();
    return fd;
}
@



<<syscall close>>=
// int close(int fd);
long
sysclose(ulong *arg)
{
    fdtochan(arg[0], -1, 0, 0);
    fdclose(arg[0], 0);
    return 0;
}
@

<<function fdclose>>=
void
fdclose(int fd, int flag)
{
    int i;
    Chan *c;
    Fgrp *f = up->fgrp;

    lock(f);
    c = f->fd[fd];
    if(c == 0){
        /* can happen for users with shared fd tables */
        unlock(f);
        return;
    }
    if(flag){
        if(c==0 || !(c->flag&flag)){
            unlock(f);
            return;
        }
    }
    f->fd[fd] = 0;
    if(fd == f->maxfd)
        for(i=fd; --i>=0 && f->fd[i]==0; )
            f->maxfd = i;

    unlock(f);
    cclose(c);
}
@

\section {[[syspread()]], [[syspwrite()]]}

<<[[Chan]] other fields>>=
vlong devoffset;    /* in underlying device; see read */
@

<<function read>>=
static long
read(ulong *arg, vlong *offp)
{
    long n, nn, nnn;
    uchar *p;
    Chan *c;
    vlong off;

    n = arg[2];
    validaddr(arg[1], n, 1);
    p = (void*)arg[1];
    c = fdtochan(arg[0], OREAD, 1, 1);

    if(waserror()){
        cclose(c);
        nexterror();
    }

    /*
     * The offset is passed through on directories, normally.
     * Sysseek complains, but pread is used by servers like exportfs,
     * that shouldn't need to worry about this issue.
     *
     * Notice that c->devoffset is the offset that c's dev is seeing.
     * The number of bytes read on this fd (c->offset) may be different
     * due to rewritings in rockfix.
     */
    if(offp == nil) /* use and maintain channel's offset */
        off = c->offset;
    else
        off = *offp;
    if(off < 0)
        error(Enegoff);

    if(off == 0){   /* rewind to the beginning of the directory */
        if(offp == nil){
            c->offset = 0;
            c->devoffset = 0;
        }
        mountrewind(c);
        unionrewind(c);
    }

    if(c->qid.type & QTDIR){
        if(mountrockread(c, p, n, &nn)){
            /* do nothing: mountrockread filled buffer */
        }else if(c->umh)
            nn = unionread(c, p, n);
        else{
            if(off != c->offset)
                error(Edirseek);
            nn = devtab[c->type]->read(c, p, n, c->devoffset);
        }
        nnn = mountfix(c, p, nn, n);
    }else
        nnn = nn = devtab[c->type]->read(c, p, n, off);

    lock(c);
    c->devoffset += nn;
    c->offset += nnn;
    unlock(c);

    poperror();
    cclose(c);

    return nnn;
}
@


<<syscall pread>>=
// long pread(int fd, void *buf, long nbytes, vlong offset);
long
syspread(ulong *arg)
{
    vlong v;
    va_list list;

    /* use varargs to guarantee alignment of vlong */
    va_start(list, arg[2]);
    v = va_arg(list, vlong);
    va_end(list);

    if(v == ~0ULL)
        return read(arg, nil);

    return read(arg, &v);
}
@


<<function write>>=
static long
write(ulong *arg, vlong *offp)
{
    Chan *c;
    long m, n;
    vlong off;

    validaddr(arg[1], arg[2], 0);
    n = 0;
    c = fdtochan(arg[0], OWRITE, 1, 1);
    if(waserror()) {
        if(offp == nil){
            lock(c);
            c->offset -= n;
            unlock(c);
        }
        cclose(c);
        nexterror();
    }

    if(c->qid.type & QTDIR)
        error(Eisdir);

    n = arg[2];

    if(offp == nil){    /* use and maintain channel's offset */
        lock(c);
        off = c->offset;
        c->offset += n;
        unlock(c);
    }else
        off = *offp;

    if(off < 0)
        error(Enegoff);

    m = devtab[c->type]->write(c, (void*)arg[1], n, off);

    if(offp == nil && m < n){
        lock(c);
        c->offset -= n - m;
        unlock(c);
    }

    poperror();
    cclose(c);

    return m;
}
@


<<syscall pwrite>>=
// long pwrite(int fd, void *buf, long nbytes, vlong offset);
long
syspwrite(ulong *arg)
{
    vlong v;
    va_list list;

    /* use varargs to guarantee alignment of vlong */
    va_start(list, arg[2]);
    v = va_arg(list, vlong);
    va_end(list);

    if(v == ~0ULL)
        return write(arg, nil);

    return write(arg, &v);
}
@

\section {[[sysstat()]]}

<<function validstat>>=
void
validstat(uchar *s, int n)
{
    int m;
    char buf[64];

    if(statcheck(s, n) < 0)
        error(Ebadstat);
    /* verify that name entry is acceptable */
    s += STATFIXLEN - 4*BIT16SZ;    /* location of first string */
    /*
     * s now points at count for first string.
     * if it's too long, let the server decide; this is
     * only for his protection anyway. otherwise
     * we'd have to allocate and waserror.
     */
    m = GBIT16(s);
    s += BIT16SZ;
    if(m+1 > sizeof buf)
        return;
    memmove(buf, s, m);
    buf[m] = '\0';
    /* name could be '/' */
    if(strcmp(buf, "/") != 0)
        validname(buf, 0);
}
@


<<function wstat>>=
static long
wstat(Chan *c, uchar *d, int nd)
{
    long l;
    int namelen;

    if(waserror()){
        cclose(c);
        nexterror();
    }
    if(c->ismtpt){
        /*
         * Renaming mount points is disallowed to avoid surprises
         * (which should be renamed? the mount point or the mounted Chan?).
         */
        dirname(d, &namelen);
        if(namelen)
            nameerror(chanpath(c), Eismtpt);
    }
    l = devtab[c->type]->wstat(c, d, nd);
    poperror();
    cclose(c);
    return l;
}
@


<<syscall wstat>>=
// int wstat(char *name, uchar *edir, int nedir);
long
syswstat(ulong *arg)
{
    Chan *c;
    uint l;

    l = arg[2];
    validaddr(arg[1], l, 0);
    validstat((uchar*)arg[1], l);
    validaddr(arg[0], 1, 0);
    c = namec((char*)arg[0], Aaccess, 0, 0);
    return wstat(c, (uchar*)arg[1], l);
}
@


<<syscall fwstat>>=
// int fwstat(int fd, uchar *edir, int nedir);
long
sysfwstat(ulong *arg)
{
    Chan *c;
    uint l;

    l = arg[2];
    validaddr(arg[1], l, 0);
    validstat((uchar*)arg[1], l);
    c = fdtochan(arg[0], -1, 1, 1);
    return wstat(c, (uchar*)arg[1], l);
}
@

<<syscall fstat>>=
// int fstat(int fd, uchar *edir, int nedir);
long
sysfstat(ulong *arg)
{
    Chan *c;
    uint l;

    l = arg[2];
    validaddr(arg[1], l, 1);
    c = fdtochan(arg[0], -1, 0, 1);
    if(waserror()) {
        cclose(c);
        nexterror();
    }
    l = devtab[c->type]->stat(c, (uchar*)arg[1], l);
    poperror();
    cclose(c);
    return l;
}
@


<<syscall stat>>=
// int stat(char *name, uchar *edir, int nedir);
long
sysstat(ulong *arg)
{
    char *name;
    Chan *c;
    uint l;

    l = arg[2];
    validaddr(arg[1], l, 1);
    validaddr(arg[0], 1, 0);
    c = namec((char*)arg[0], Aaccess, 0, 0);
    if(waserror()){
        cclose(c);
        nexterror();
    }
    l = devtab[c->type]->stat(c, (uchar*)arg[1], l);
    name = pathlast(c->path);
    if(name)
        l = dirsetname(name, strlen(name), (uchar*)arg[1], l, arg[2]);

    poperror();
    cclose(c);
    return l;
}
@


\section{[[sysseek()]]}

<<syscall seek>>=
// vlong seek(int fd, vlong n, int type);
long
sysseek(ulong *arg)
{
    validaddr(arg[0], BY2V, 1);
    sseek(arg);
    return 0;
}
@


<<function sseek>>=
static void
sseek(ulong *arg)
{
    Chan *c;
    uchar buf[sizeof(Dir)+100];
    Dir dir;
    int n;
    vlong off;
    union {
        vlong v;
        ulong u[2];
    } o;

    c = fdtochan(arg[1], -1, 1, 1);
    if(waserror()){
        cclose(c);
        nexterror();
    }
    if(devtab[c->type]->dc == '|')
        error(Eisstream);

    off = 0;
    o.u[0] = arg[2];
    o.u[1] = arg[3];
    switch(arg[4]){
    case 0:
        off = o.v;
        if((c->qid.type & QTDIR) && off != 0)
            error(Eisdir);
        if(off < 0)
            error(Enegoff);
        c->offset = off;
        break;

    case 1:
        if(c->qid.type & QTDIR)
            error(Eisdir);
        lock(c);    /* lock for read/write update */
        off = o.v + c->offset;
        if(off < 0){
            unlock(c);
            error(Enegoff);
        }
        c->offset = off;
        unlock(c);
        break;

    case 2:
        if(c->qid.type & QTDIR)
            error(Eisdir);
        n = devtab[c->type]->stat(c, buf, sizeof buf);
        if(convM2D(buf, n, &dir, nil) == 0)
            error("internal error: stat error in seek");
        off = dir.length + o.v;
        if(off < 0)
            error(Enegoff);
        c->offset = off;
        break;

    default:
        error(Ebadarg);
    }
    *(vlong*)arg[0] = off;
    c->uri = 0;
    c->dri = 0;
    cclose(c);
    poperror();
}
@



\chapter{Directories}

<<systab directory syscalls>>=
    [CREATE]    syscreate,
    [REMOVE]    sysremove,

    [CHDIR]     syschdir,
    [FD2PATH]   sysfd2path, // pwd?

    [STAT]      sysstat,
    [FSTAT]     sysfstat,
    [WSTAT]     syswstat,
    [FWSTAT]    sysfwstat,
@

\section{Overview}

<<function isdir>>=
void
isdir(Chan *c)
{
    if(c->qid.type & QTDIR)
        return;
    error(Enotdir);
}
@

% could put slash and dot Proc fields here

\section{[[Path]]}

% remember that field of Chan
%    Path* path;

<<struct Path>>=
struct Path
{
  char  *s;
  Chan  **mtpt;     /* mtpt history */
  int len;      /* strlen(s) */
  int alen;     /* allocated length of s */
  int mlen;     /* number of path elements */
  int malen;      /* allocated length of mtpt */

  // extra
  Ref;
};
@

% could delete, just used for statistics but never made accessible anywhere
<<global npath>>=
Ref npath;
@

<<constant PATHSLOP>>=
    PATHSLOP    = 20,
@

<<constant PATHMSLOP>>=
    PATHMSLOP   = 20,
@


<<constructor newpath>>=
Path*
newpath(char *s)
{
    int i;
    Path *p;

    p = smalloc(sizeof(Path));
    i = strlen(s);
    p->len = i;
    p->alen = i+PATHSLOP;
    p->s = smalloc(p->alen);
    memmove(p->s, s, i+1);
    p->ref = 1;
    incref(&npath);

    /*
     * Cannot use newpath for arbitrary names because the mtpt 
     * array will not be populated correctly.  The names #/ and / are
     * allowed, but other names with / in them draw warnings.
     */
    if(strchr(s, '/') && strcmp(s, "#/") != 0 && strcmp(s, "/") != 0)
        print("newpath: %s from %#p\n", s, getcallerpc(&s));

    p->mlen = 1;
    p->malen = PATHMSLOP;
    p->mtpt = smalloc(p->malen*sizeof p->mtpt[0]);
    return p;
}
@


<<function copypath>>=
//@Scheck: not dead, used below
static Path*
copypath(Path *p)
{
    int i;
    Path *pp;
    
    pp = smalloc(sizeof(Path));
    pp->ref = 1;
    incref(&npath);
    DBG("copypath %s %p => %p\n", p->s, p, pp);
    
    pp->len = p->len;
    pp->alen = p->alen;
    pp->s = smalloc(p->alen);
    memmove(pp->s, p->s, p->len+1);
    
    pp->mlen = p->mlen;
    pp->malen = p->malen;
    pp->mtpt = smalloc(p->malen*sizeof pp->mtpt[0]);
    for(i=0; i<pp->mlen; i++){
        pp->mtpt[i] = p->mtpt[i];
        if(pp->mtpt[i])
            incref(pp->mtpt[i]);
    }

    return pp;
}
@


<<destructor pathclose>>=
void
pathclose(Path *p)
{
    int i;
    
    if(p == nil)
        return;

    DBG("pathclose %p %s ref=%ld =>", p, p->s, p->ref);
    for(i=0; i<p->mlen; i++)
        DBG(" %p", p->mtpt[i]);
    DBG("\n");

    if(decref(p))
        return;
    decref(&npath);
    free(p->s);
    for(i=0; i<p->mlen; i++)
        if(p->mtpt[i])
            cclose(p->mtpt[i]);
    free(p->mtpt);
    free(p);
}
@


<<function fixdotdotname>>=
/*
 * In place, rewrite name to compress multiple /, eliminate ., and process ..
 * (Really only called to remove a trailing .. that has been added.
 * Otherwise would need to update n->mtpt as well.)
 */
static void
fixdotdotname(Path *p)
{
    char *r;

    if(p->s[0] == '#'){
        r = strchr(p->s, '/');
        if(r == nil)
            return;
        cleanname(r);

        /*
         * The correct name is #i rather than #i/,
         * but the correct name of #/ is #/.
         */
        if(strcmp(r, "/")==0 && p->s[1] != '/')
            *r = '\0';
    }else
        cleanname(p->s);
    p->len = strlen(p->s);
}
@


<<function uniquepath>>=
static Path*
uniquepath(Path *p)
{
    Path *new;
    
    if(p->ref > 1){
        /* copy on write */
        new = copypath(p);
        pathclose(p);
        p = new;
    }
    return p;
}
@


<<function addelem>>=
static Path*
addelem(Path *p, char *s, Chan *from)
{
    char *t;
    int a, i;
    Chan *c, **tt;

    if(s[0]=='.' && s[1]=='\0')
        return p;

    p = uniquepath(p);

    i = strlen(s);
    if(p->len+1+i+1 > p->alen){
        a = p->len+1+i+1 + PATHSLOP;
        t = smalloc(a);
        memmove(t, p->s, p->len+1);
        free(p->s);
        p->s = t;
        p->alen = a;
    }
    /* don't insert extra slash if one is present */
    if(p->len>0 && p->s[p->len-1]!='/' && s[0]!='/')
        p->s[p->len++] = '/';
    memmove(p->s+p->len, s, i+1);
    p->len += i;
    if(isdotdot(s)){
        fixdotdotname(p);
        DBG("addelem %s .. => rm %p\n", p->s, p->mtpt[p->mlen-1]);
        if(p->mlen>1 && (c = p->mtpt[--p->mlen])){
            p->mtpt[p->mlen] = nil;
            cclose(c);
        }
    }else{
        if(p->mlen >= p->malen){
            p->malen = p->mlen+1+PATHMSLOP;
            tt = smalloc(p->malen*sizeof tt[0]);
            memmove(tt, p->mtpt, p->mlen*sizeof tt[0]);
            free(p->mtpt);
            p->mtpt = tt;
        }
        DBG("addelem %s %s => add %p\n", p->s, s, from);
        p->mtpt[p->mlen++] = from;
        if(from)
            incref(from);
    }
    return p;
}
@

<<function pathlast>>=
static char*
pathlast(Path *p)
{
    char *s;

    if(p == nil)
        return nil;
    if(p->len == 0)
        return nil;
    s = strrchr(p->s, '/');
    if(s)
        return s+1;
    return p->s;
}
@


<<function chanpath>>=
char*
chanpath(Chan *c)
{
    if(c == nil)
        return "<nil chan>";
    if(c->path == nil)
        return "<nil path>";
    if(c->path->s == nil)
        return "<nil path.s>";
    return c->path->s;
}
@





<<function skipslash>>=
/*
 * name is valid. skip leading / and ./ as much as possible
 */
char*
skipslash(char *name)
{
    while(name[0]=='/' || (name[0]=='.' && (name[1]==0 || name[1]=='/')))
        name++;
    return name;
}
@

<<function emptystr>>=
bool
emptystr(char *s)
{
    if(s == nil)
        return true;
    if(s[0] == '\0')
        return true;
    return false;
}
@


<<global isfrog>>=
char isfrog[256]={
    /*NUL*/ 1, 1, 1, 1, 1, 1, 1, 1,
    /*BKS*/ 1, 1, 1, 1, 1, 1, 1, 1,
    /*DLE*/ 1, 1, 1, 1, 1, 1, 1, 1,
    /*CAN*/ 1, 1, 1, 1, 1, 1, 1, 1,
    ['/']   1,
    [0x7f]  1,
};
@

<<macro SEP>>=
#define SEP(c) ((c) == 0 || (c) == '/')
@


<<function isdotdot>>=
int
isdotdot(char *p)
{
    return p[0]=='.' && p[1]=='.' && p[2]=='\0';
}
@

\section{[[Dir]]}

<<struct Dir>>=
struct Dir {
  /* system-modified data */
  ushort  type; /* server type */
  uint  dev;  /* server subtype */

  /* file data */
  Qid qid;  /* unique id from server */
  // bitset<enum<dirmode>>
  ulong mode; /* permissions */
  ulong atime;  /* last read time */
  ulong mtime;  /* last write time */
  vlong length; /* file length: see <u.h> */
  char  *name;  /* last element of path */
  char  *uid; /* owner name */
  char  *gid; /* group name */
  char  *muid;  /* last modifier name */
};
@ 

<<enum dirmode>>=
/* bits in Dir.mode */
enum dirmode {
  DMDIR = 0x80000000,  /* mode bit for directories */
  DMAPPEND = 0x40000000,  /* mode bit for append only files */
  DMEXCL = 0x20000000,  /* mode bit for exclusive use files */
  DMMOUNT = 0x10000000,  /* mode bit for mounted channel */

  DMREAD = 0x4,   /* mode bit for read permission */
  DMWRITE = 0x2,   /* mode bit for write permission */
  DMEXEC = 0x1,   /* mode bit for execute permission */
};
@ 




<<struct Dirtab>>=
struct Dirtab
{
  char  name[KNAMELEN];
  Qid qid;
  vlong length;
  long  perm;
};
@

<<struct Walkqid>>=
struct Walkqid
{
  Chan  *clone;
  int nqid;
  Qid qid[1];
};
@


<<struct Elemlist>>=
struct Elemlist
{
    char    *aname; /* original name */
    char    *name;  /* copy of name, so '/' can be overwritten */
    int nelems;
    char    **elems;
    int *off;
    int mustbedir;
    int nerror;
    int prefix;
};
@

<<function growparse>>=
static void
growparse(Elemlist *e)
{
    char **new;
    int *inew;
    enum { Delta = 8 };

    if(e->nelems % Delta == 0){
        new = smalloc((e->nelems+Delta) * sizeof(char*));
        memmove(new, e->elems, e->nelems*sizeof(char*));
        free(e->elems);
        e->elems = new;
        inew = smalloc((e->nelems+Delta+1) * sizeof(int));
        memmove(inew, e->off, (e->nelems+1)*sizeof(int));
        free(e->off);
        e->off = inew;
    }
}
@


<<function parsename>>=
/*
 * The name is known to be valid.
 * Copy the name so slashes can be overwritten.
 * An empty string will set nelem=0.
 * A path ending in / or /. or /.//./ etc. will have
 * e.mustbedir = 1, so that we correctly
 * reject, e.g., "/adm/users/." when /adm/users is a file
 * rather than a directory.
 */
static void
parsename(char *aname, Elemlist *e)
{
    char *name, *slash;

    kstrdup(&e->name, aname);
    name = e->name;
    e->nelems = 0;
    e->elems = nil;
    e->off = smalloc(sizeof(int));
    e->off[0] = skipslash(name) - name;
    for(;;){
        name = skipslash(name);
        if(*name == '\0'){
            e->off[e->nelems] = name+strlen(name) - e->name;
            e->mustbedir = 1;
            break;
        }
        growparse(e);
        e->elems[e->nelems++] = name;
        slash = utfrune(name, '/');
        if(slash == nil){
            e->off[e->nelems] = name+strlen(name) - e->name;
            e->mustbedir = 0;
            break;
        }
        e->off[e->nelems] = slash - e->name;
        *slash++ = '\0';
        name = slash;
    }
    
    if(0 && chandebug){
        int i;
        
        print("parsename %s:", e->name);
        for(i=0; i<=e->nelems; i++)
            print(" %d", e->off[i]);
        print("\n");
    }
}
@



<<function dirfixed>>=
static int
dirfixed(uchar *p, uchar *e, Dir *d)
{
    int len;

    len = GBIT16(p)+BIT16SZ;
    if(p + len > e)
        return -1;

    p += BIT16SZ;   /* ignore size */
    d->type = devno(GBIT16(p), 1);
    p += BIT16SZ;
    d->dev = GBIT32(p);
    p += BIT32SZ;
    d->qid.type = GBIT8(p);
    p += BIT8SZ;
    d->qid.vers = GBIT32(p);
    p += BIT32SZ;
    d->qid.path = GBIT64(p);
    p += BIT64SZ;
    d->mode = GBIT32(p);
    p += BIT32SZ;
    d->atime = GBIT32(p);
    p += BIT32SZ;
    d->mtime = GBIT32(p);
    p += BIT32SZ;
    d->length = GBIT64(p);

    return len;
}
@


<<function dirname>>=
static char*
dirname(uchar *p, int *n)
{
    p += BIT16SZ+BIT16SZ+BIT32SZ+BIT8SZ+BIT32SZ+BIT64SZ
        + BIT32SZ+BIT32SZ+BIT32SZ+BIT64SZ;
    *n = GBIT16(p);
    return (char*)p+BIT16SZ;
}
@


<<function dirsetname>>=
static long
dirsetname(char *name, int len, uchar *p, long n, long maxn)
{
    char *oname;
    int olen;
    long nn;

    if(n == BIT16SZ)
        return BIT16SZ;

    oname = dirname(p, &olen);

    nn = n+len-olen;
    PBIT16(p, nn-BIT16SZ);
    if(nn > maxn)
        return BIT16SZ;

    if(len != olen)
        memmove(oname+len, oname+olen, p+n-(uchar*)(oname+olen));
    PBIT16((uchar*)(oname-2), len);
    memmove(oname, name, len);
    return nn;
}
@


<<function createdir>>=
/*
 * c is a mounted non-creatable directory.  find a creatable one.
 */
Chan*
createdir(Chan *c, Mhead *m)
{
    Chan *nc;
    Mount *f;

    rlock(&m->lock);
    if(waserror()){
        runlock(&m->lock);
        nexterror();
    }
    for(f = m->mount; f; f = f->next){
        if(f->mflag&MCREATE){
            nc = cclone(f->to);
            runlock(&m->lock);
            poperror();
            cclose(c);
            return nc;
        }
    }
    error(Enocreate);
    panic("createdir: should not reach this point");
}
@


\section{Union directories}


<<[[Chan]] other fields>>=
Mhead*  umh;      /* mount point that derived Chan; used in unionread */
Chan* umc;      /* channel in union; held for union read */
QLock umqlock;    /* serialize unionreads */
int uri;      /* union read index */
@

<<function unionread>>=
long
unionread(Chan *c, void *va, long n)
{
    int i;
    long nr;
    Mhead *m;
    Mount *mount;

    qlock(&c->umqlock);
    m = c->umh;
    rlock(&m->lock);
    mount = m->mount;
    /* bring mount in sync with c->uri and c->umc */
    for(i = 0; mount != nil && i < c->uri; i++)
        mount = mount->next;

    nr = 0;
    while(mount != nil){
        /* Error causes component of union to be skipped */
        if(mount->to && !waserror()){
            if(c->umc == nil){
                c->umc = cclone(mount->to);
                c->umc = devtab[c->umc->type]->open(c->umc, OREAD);
            }
    
            nr = devtab[c->umc->type]->read(c->umc, va, n, c->umc->offset);
            c->umc->offset += nr;
            poperror();
        }
        if(nr > 0)
            break;

        /* Advance to next element */
        c->uri++;
        if(c->umc){
            cclose(c->umc);
            c->umc = nil;
        }
        mount = mount->next;
    }
    runlock(&m->lock);
    qunlock(&c->umqlock);
    return nr;
}
@


<<function unionrewind>>=
static void
unionrewind(Chan *c)
{
    qlock(&c->umqlock);
    c->uri = 0;
    if(c->umc){
        cclose(c->umc);
        c->umc = nil;
    }
    qunlock(&c->umqlock);
}
@


\section{[[namec()]]}
% first part

<<enum accessnamec>>=
/*
 * Access types in namec
 */
enum
{
  Aaccess,      /* as in stat, wstat */
  Abind,        /* for left-hand-side of bind */
  Atodir,       /* as in chdir */
  Aopen,        /* for i/o */
  Amount,       /* to be mounted or mounted upon */
  Acreate,      /* is to be created */
  Aremove,      /* will be removed by caller */
};
@


% another big function ...
<<function namec>>=
/*
 * Turn a name into a channel.
 * &name[0] is known to be a valid address.  It may be a kernel address.
 *
 * Opening with amode Aopen, Acreate, Aremove, or Aaccess guarantees
 * that the result will be the only reference to that particular fid.
 * This is necessary since we might pass the result to
 * devtab[]->remove().
 *
 * Opening Atodir or Amount does not guarantee this.
 *
 * Under certain circumstances, opening Aaccess will cause
 * an unnecessary clone in order to get a cunique Chan so it
 * can attach the correct name.  Sysstat and sys_stat need the
 * correct name so they can rewrite the stat info.
 */
Chan*
namec(char *aname, int amode, int omode, ulong perm)
{
    int len, n, t, nomount;
    Chan *c, *cnew;
    Path *path;
    Elemlist e;
    Rune r;
    Mhead *m;
    char *createerr, tmperrbuf[ERRMAX];
    char *name;

    if(aname[0] == '\0')
        error("empty file name");
    aname = validnamedup(aname, 1);
    if(waserror()){
        free(aname);
        nexterror();
    }
    DBG("namec %s %d %d\n", aname, amode, omode);
    name = aname;

    /*
     * Find the starting off point (the current slash, the root of
     * a device tree, or the current dot) as well as the name to
     * evaluate starting there.
     */
    nomount = 0;
    switch(name[0]){
    case '/':
        c = up->slash;
        incref(c);
        break;
    
    case '#':
        nomount = 1;
        up->genbuf[0] = '\0';
        n = 0;
        while(*name != '\0' && (*name != '/' || n < 2)){
            if(n >= sizeof(up->genbuf)-1)
                error(Efilename);
            up->genbuf[n++] = *name++;
        }
        up->genbuf[n] = '\0';
        /*
         *  noattach is sandboxing.
         *
         *  the OK exceptions are:
         *  |  it only gives access to pipes you create
         *  d  this process's file descriptors
         *  e  this process's environment
         *  the iffy exceptions are:
         *  c  time and pid, but also cons and consctl
         *  p  control of your own processes (and unfortunately
         *     any others left unprotected)
         */
        n = chartorune(&r, up->genbuf+1)+1;
        /* actually / is caught by parsing earlier */
        if(utfrune("M", r))
            error(Enoattach);
        if(up->pgrp->noattach && utfrune("|decp", r)==nil)
            error(Enoattach);
        t = devno(r, 1);
        if(t == -1)
            error(Ebadsharp);

        c = devtab[t]->attach(up->genbuf+n);
        break;

    default:
        c = up->dot;
        incref(c);
        break;
    }

    e.aname = aname;
    e.prefix = name - aname;
    e.name = nil;
    e.elems = nil;
    e.off = nil;
    e.nelems = 0;
    e.nerror = 0;
    if(waserror()){
        cclose(c);
        free(e.name);
        free(e.elems);
        /*
         * Prepare nice error, showing first e.nerror elements of name.
         */
        if(e.nerror == 0)
            nexterror();
        strcpy(tmperrbuf, up->errstr);
        if(e.off[e.nerror]==0)
            print("nerror=%d but off=%d\n",
                e.nerror, e.off[e.nerror]);
        if(0 && chandebug)
            print("showing %d+%d/%d (of %d) of %s (%d %d)\n", e.prefix, e.off[e.nerror], e.nerror, e.nelems, aname, e.off[0], e.off[1]);
        len = e.prefix+e.off[e.nerror];
        free(e.off);
        namelenerror(aname, len, tmperrbuf);
    }

    /*
     * Build a list of elements in the name.
     */
    parsename(name, &e);

    /*
     * On create, ....
     */
    if(amode == Acreate){
        /* perm must have DMDIR if last element is / or /. */
        if(e.mustbedir && !(perm&DMDIR)){
            e.nerror = e.nelems;
            error("create without DMDIR");
        }

        /* don't try to walk the last path element just yet. */
        if(e.nelems == 0)
            error(Eexist);
        e.nelems--;
    }

    if(walk(&c, e.elems, e.nelems, nomount, &e.nerror) < 0){
        if(e.nerror < 0 || e.nerror > e.nelems){
            print("namec %s walk error nerror=%d\n", aname, e.nerror);
            e.nerror = 0;
        }
        nexterror();
    }

    if(e.mustbedir && !(c->qid.type&QTDIR))
        error("not a directory");

    if(amode == Aopen && (omode&3) == OEXEC && (c->qid.type&QTDIR))
        error("cannot exec directory");

    switch(amode){
    case Abind:
        /* no need to maintain path - cannot dotdot an Abind */
        m = nil;
        if(!nomount)
            domount(&c, &m, nil);
        if(c->umh != nil)
            putmhead(c->umh);
        c->umh = m;
        break;

    case Aaccess:
    case Aremove:
    case Aopen:
    Open:
        /* save&update the name; domount might change c */
        path = c->path;
        incref(path);
        m = nil;
        if(!nomount)
            domount(&c, &m, &path);

        /* our own copy to open or remove */
        c = cunique(c);

        /* now it's our copy anyway, we can put the name back */
        pathclose(c->path);
        c->path = path;

        /* record whether c is on a mount point */
        c->ismtpt = (m!=nil);

        switch(amode){
        case Aaccess:
        case Aremove:
            putmhead(m);
            break;

        case Aopen:
        case Acreate:
if(c->umh != nil){
    print("cunique umh Open\n");
    putmhead(c->umh);
    c->umh = nil;
}
            /* only save the mount head if it's a multiple element union */
            if(m && m->mount && m->mount->next)
                c->umh = m;
            else
                putmhead(m);

            /* save registers else error() in open has wrong value of c saved */
            //old: saveregisters();

            if(omode == OEXEC)
                c->flag &= ~CCACHE;

            c = devtab[c->type]->open(c, omode&~OCEXEC);

            if(omode & OCEXEC)
                c->flag |= CCEXEC;
            if(omode & ORCLOSE)
                c->flag |= CRCLOSE;
            break;
        }
        break;

    case Atodir:
        /*
         * Directories (e.g. for cd) are left before the mount point,
         * so one may mount on / or . and see the effect.
         */
        if(!(c->qid.type & QTDIR))
            error(Enotdir);
        break;

    case Amount:
        /*
         * When mounting on an already mounted upon directory,
         * one wants subsequent mounts to be attached to the
         * original directory, not the replacement.  Don't domount.
         */
        break;

    case Acreate:
        /*
         * We've already walked all but the last element.
         * If the last exists, try to open it OTRUNC.
         * If omode&OEXCL is set, just give up.
         */
        e.nelems++;
        e.nerror++;
        if(walk(&c, e.elems+e.nelems-1, 1, nomount, nil) == 0){
            if(omode&OEXCL)
                error(Eexist);
            omode |= OTRUNC;
            goto Open;
        }

        /*
         * The semantics of the create(2) system call are that if the
         * file exists and can be written, it is to be opened with truncation.
         * On the other hand, the create(5) message fails if the file exists.
         * If we get two create(2) calls happening simultaneously, 
         * they might both get here and send create(5) messages, but only 
         * one of the messages will succeed.  To provide the expected create(2)
         * semantics, the call with the failed message needs to try the above
         * walk again, opening for truncation.  This correctly solves the 
         * create/create race, in the sense that any observable outcome can
         * be explained as one happening before the other.
         * The create/create race is quite common.  For example, it happens
         * when two rc subshells simultaneously update the same
         * environment variable.
         *
         * The implementation still admits a create/create/remove race:
         * (A) walk to file, fails
         * (B) walk to file, fails
         * (A) create file, succeeds, returns 
         * (B) create file, fails
         * (A) remove file, succeeds, returns
         * (B) walk to file, return failure.
         *
         * This is hardly as common as the create/create race, and is really
         * not too much worse than what might happen if (B) got a hold of a
         * file descriptor and then the file was removed -- either way (B) can't do
         * anything with the result of the create call.  So we don't care about this race.
         *
         * Applications that care about more fine-grained decision of the races
         * can use the OEXCL flag to get at the underlying create(5) semantics;
         * by default we provide the common case.
         *
         * We need to stay behind the mount point in case we
         * need to do the first walk again (should the create fail).
         *
         * We also need to cross the mount point and find the directory
         * in the union in which we should be creating.
         *
         * The channel staying behind is c, the one moving forward is cnew.
         */
        m = nil;
        cnew = nil; /* is this assignment necessary? */
        if(!waserror()){    /* try create */
            if(!nomount && findmount(&cnew, &m, c->type, c->dev, c->qid))
                cnew = createdir(cnew, m);
            else{
                cnew = c;
                incref(cnew);
            }

            /*
             * We need our own copy of the Chan because we're
             * about to send a create, which will move it.  Once we have
             * our own copy, we can fix the name, which might be wrong
             * if findmount gave us a new Chan.
             */
            cnew = cunique(cnew);
            pathclose(cnew->path);
            cnew->path = c->path;
            incref(cnew->path);

            devtab[cnew->type]->create(cnew, e.elems[e.nelems-1], omode&~(OEXCL|OCEXEC), perm);
            poperror();
            if(omode & OCEXEC)
                cnew->flag |= CCEXEC;
            if(omode & ORCLOSE)
                cnew->flag |= CRCLOSE;
            if(m)
                putmhead(m);
            cclose(c);
            c = cnew;
            c->path = addelem(c->path, e.elems[e.nelems-1], nil);
            break;
        }

        /* create failed */
        cclose(cnew);
        if(m)
            putmhead(m);
        if(omode & OEXCL)
            nexterror();
        /* save error */
        createerr = up->errstr;
        up->errstr = tmperrbuf;
        /* note: we depend that walk does not error */
        if(walk(&c, e.elems+e.nelems-1, 1, nomount, nil) < 0){
            up->errstr = createerr;
            error(createerr);   /* report true error */
        }
        up->errstr = createerr;
        omode |= OTRUNC;
        goto Open;

    default:
        panic("unknown namec access %d\n", amode);
    }

    /* place final element in genbuf for e.g. exec */
    if(e.nelems > 0)
        kstrcpy(up->genbuf, e.elems[e.nelems-1], sizeof up->genbuf);
    else
        kstrcpy(up->genbuf, ".", sizeof up->genbuf);
    free(e.name);
    free(e.elems);
    free(e.off);
    poperror(); /* e c */
    free(aname);
    poperror(); /* aname */

    return c;
}
@


<<[[Proc]] other fields>>=
char  genbuf[128];  /* buffer used e.g. for last name element from namec */
@

<<function namelenerror>>=
void
namelenerror(char *aname, int len, char *err)
{
    char *ename, *name, *next;
    int i, errlen;

    /*
     * If the name is short enough, just use the whole thing.
     */
    errlen = strlen(err);
    if(len < ERRMAX/3 || len+errlen < 2*ERRMAX/3)
        snprint(up->genbuf, sizeof up->genbuf, "%.*s", 
            utfnlen(aname, len), aname);
    else{
        /*
         * Print a suffix of the name, but try to get a little info.
         */
        ename = aname+len;
        next = ename;
        do{
            name = next;
            next = memrchr(aname, '/', name-aname);
            if(next == nil)
                next = aname;
            len = ename-next;
        }while(len < ERRMAX/3 || len + errlen < 2*ERRMAX/3);

        /*
         * If the name is ridiculously long, chop it.
         */
        if(name == ename){
            name = ename-ERRMAX/4;
            if(name <= aname)
                panic("bad math in namelenerror");
            /* walk out of current UTF sequence */
            for(i=0; (*name&0xC0)==0x80 && i<UTFmax; i++)
                name++;
        }
        snprint(up->genbuf, sizeof up->genbuf, "...%.*s",
            utfnlen(name, ename-name), name);
    }               
    snprint(up->errstr, ERRMAX, "%#q %s", up->genbuf, err);
    nexterror();
}
@


<<function nameerror>>=
void
nameerror(char *name, char *err)
{
    namelenerror(name, strlen(name), err);
}
@




<<function validname0>>=
/*
 * Check that the name
 *  a) is in valid memory.
 *  b) is shorter than 2^16 bytes, so it can fit in a 9P string field.
 *  c) contains no frogs.
 * The first byte is known to be addressible by the requester, so the
 * routine works for kernel and user memory both.
 * The parameter slashok flags whether a slash character is an error
 * or a valid character.
 *
 * The parameter dup flags whether the string should be copied
 * out of user space before being scanned the second time.
 * (Otherwise a malicious thread could remove the NUL, causing us
 * to access unchecked addresses.) 
 */
static char*
validname0(char *aname, int slashok, int dup, ulong pc)
{
    char *ename, *name, *s;
    int c, n;
    Rune r;

    name = aname;
    if((ulong)name < KZERO){
        if(!dup)
            print("warning: validname called from %#p with user pointer", pc);
        ename = vmemchr(name, 0, (1<<16));
    }else
        ename = memchr(name, 0, (1<<16));

    if(ename==nil || ename-name>=(1<<16))
        error("name too long");

    s = nil;
    if(dup){
        n = ename-name;
        s = smalloc(n+1);
        memmove(s, name, n);
        s[n] = 0;
        aname = s;
        name = s;
        setmalloctag(s, pc);
    }
    
    while(*name){
        /* all characters above '~' are ok */
        c = *(uchar*)name;
        if(c >= Runeself)
            name += chartorune(&r, name);
        else{
            if(isfrog[c])
                if(!slashok || c!='/'){
                    snprint(up->genbuf, sizeof(up->genbuf), "%s: %q", Ebadchar, aname);
                    free(s);
                    error(up->genbuf);
            }
            name++;
        }
    }
    return s;
}
@
% >> >> >>

<<function validname>>=
void
validname(char *aname, int slashok)
{
    validname0(aname, slashok, 0, getcallerpc(&aname));
}
@


<<function validnamedup>>=
char*
validnamedup(char *aname, int slashok)
{
    return validname0(aname, slashok, 1, getcallerpc(&aname));
}
@



\section{[[syscreate()]], [[sysremove()]]}

<<function openmode>>=
int
openmode(ulong o)
{
    o &= ~(OTRUNC|OCEXEC|ORCLOSE);
    if(o > OEXEC)
        error(Ebadarg);
    if(o == OEXEC)
        return OREAD;
    return o;
}
@

<<syscall create>>=
// int create(char *file, int omode, ulong perm);
long
syscreate(ulong *arg)
{
    int fd;
    Chan *c;

    openmode(arg[1]&~OEXCL);    /* error check only; OEXCL okay here */
    validaddr(arg[0], 1, 0);
    c = namec((char*)arg[0], Acreate, arg[1], arg[2]);
    if(waserror()) {
        cclose(c);
        nexterror();
    }
    fd = newfd(c);
    if(fd < 0)
        error(Enofd);
    poperror();
    return fd;
}
@


<<syscall remove>>=
// int remove(char *file);
long
sysremove(ulong *arg)
{
    Chan *c;

    validaddr(arg[0], 1, 0);
    c = namec((char*)arg[0], Aremove, 0, 0);
    /*
     * Removing mount points is disallowed to avoid surprises
     * (which should be removed: the mount point or the mounted Chan?).
     */
    if(c->ismtpt){
        cclose(c);
        error(Eismtpt);
    }
    if(waserror()){
        c->type = 0;    /* see below */
        cclose(c);
        nexterror();
    }
    devtab[c->type]->remove(c);
    /*
     * Remove clunks the fid, but we need to recover the Chan
     * so fake it up.  rootclose() is known to be a nop.
     */
    c->type = 0;
    poperror();
    cclose(c);
    return 0;
}
@
\section {[[syschdir()]]}


<<syscall chdir>>=
// int chdir(char *dirname);
long
syschdir(ulong *arg)
{
    Chan *c;

    validaddr(arg[0], 1, 0);

    c = namec((char*)arg[0], Atodir, 0, 0);
    cclose(up->dot);
    up->dot = c;
    return 0;
}
@


\section {[[sysfd2path()]] (a.k.a [[pwd()]])}

<<syscall fd2path>>=
// int fd2path(int fd, char *buf, int nbuf);
long
sysfd2path(ulong *arg)
{
    Chan *c;

    validaddr(arg[1], arg[2], 1);

    c = fdtochan(arg[0], -1, 0, 1);
    snprint((char*)arg[1], arg[2], "%s", chanpath(c));
    cclose(c);
    return 0;
}
@




\chapter{Namespace}
\minitoc

% see names.ps
% see lexnames.ps

<<systab namespace syscalls>>=
    [BIND]      sysbind,
    [MOUNT]     sysmount,
    [UNMOUNT]   sysunmount,
@ 

\section{Overview}

\section{[[Mnt]] and [[Mount]]}

<<struct Mnt>>=
struct Mnt
{
  Lock;
  /* references are counted using c->ref; channels on this mount point incref(c->mchan) == Mnt.c */
  Chan  *c;   /* Channel to file service */
  Proc  *rip;   /* Reader in progress */
  Mntrpc  *queue;   /* Queue of pending requests on this channel */
  ulong id;   /* Multiplexer id for channel check */
  Mnt *list;    /* Free list */
  int flags;    /* cache */
  int msize;    /* data + IOHDRSZ */
  char  *version; /* 9P version */
  Queue *q;   /* input queue */
};
@

<<struct Mntalloc>>=
/*
 * References are managed as follows:
 * The channel to the server - a network connection or pipe - has one
 * reference for every Chan open on the server.  The server channel has
 * c->mux set to the Mnt used for muxing control to that server.  Mnts
 * have no reference count; they go away when c goes away.
 * Each channel derived from the mount point has mchan set to c,
 * and increfs/decrefs mchan to manage references on the server
 * connection.
 */
struct Mntalloc
{
    Mnt*    list;       /* Mount devices in use */
    Mnt*    mntfree;    /* Free list */
    Mntrpc* rpcfree;
    int nrpcfree;
    int nrpcused;
    ulong   id;
    ulong   tagmask[NMASK];

    // extra
    Lock;

};
@

<<global mntalloc>>=
struct Mntalloc mntalloc;
@

<<constants tags>>=
enum
{
    TAGSHIFT = 5,           /* ulong has to be 32 bits */
    TAGMASK = (1<<TAGSHIFT)-1,
    NMASK = (64*1024)>>TAGSHIFT,
};
@

<<function freetag>>=
void
freetag(int t)
{
    mntalloc.tagmask[t>>TAGSHIFT] &= ~(1<<(t&TAGMASK));
}
@

<<function mntfree>>=
void
mntfree(Mntrpc *r)
{
    if(r->b != nil)
        freeblist(r->b);
    lock(&mntalloc);
    if(mntalloc.nrpcfree >= 10){
        free(r->rpc);
        freetag(r->request.tag);
        free(r);
    }
    else{
        r->list = mntalloc.rpcfree;
        mntalloc.rpcfree = r;
        mntalloc.nrpcfree++;
    }
    mntalloc.nrpcused--;
    unlock(&mntalloc);
}
@

<<function mntpntfree>>=
void
mntpntfree(Mnt *m)
{
    Mnt *f, **l;
    Queue *q;

    lock(&mntalloc);
    l = &mntalloc.list;
    for(f = *l; f; f = f->list) {
        if(f == m) {
            *l = m->list;
            break;
        }
        l = &f->list;
    }
    m->list = mntalloc.mntfree;
    mntalloc.mntfree = m;
    q = m->q;
    unlock(&mntalloc);

    qfree(q);
}
@


<<function muxclose>>=
void
muxclose(Mnt *m)
{
    Mntrpc *q, *r;

    for(q = m->queue; q; q = r) {
        r = q->list;
        mntfree(q);
    }
    m->id = 0;
    free(m->version);
    m->version = nil;
    mntpntfree(m);
}
@




<<struct Mount>>=
struct Mount
{
  ulong mountid;
  Mount*  next;
  Mhead*  head;
  Mount*  copy;
  Mount*  order;
  Chan* to;     /* channel replacing channel */
  int mflag;
  char  *spec;
};
@


<<struct Mhead>>=
struct Mhead
{
  Ref;
  RWlock  lock;
  Chan* from;     /* channel mounted upon */
  Mount*  mount;      /* what's mounted upon it */
  Mhead*  hash;     /* Hash chain */
};
@

<<constructor newmount>>=
Mount*
newmount(Mhead *mh, Chan *to, int flag, char *spec)
{
    Mount *m;

    m = smalloc(sizeof(Mount));
    m->to = to;
    m->head = mh;
    incref(to);
    m->mountid = incref(&mountid);
    m->mflag = flag;
    if(spec != 0)
        kstrdup(&m->spec, spec);

    return m;
}
@ 


<<destructor mountfree>>=
void
mountfree(Mount *m)
{
    Mount *f;

    while(m) {
        f = m->next;
        cclose(m->to);
        m->mountid = 0;
        free(m->spec);
        free(m);
        m = f;
    }
}
@ 

<<constructor newmhead>>=
Mhead*
newmhead(Chan *from)
{
    Mhead *mh;

    mh = smalloc(sizeof(Mhead));
    mh->ref = 1;
    mh->from = from;
    incref(from);
    return mh;
}
@

<<destructor putmhead>>=
/*
 * This is necessary because there are many
 * pointers to the top of a given mount list:
 *
 *  - the mhead in the namespace hash table
 *  - the mhead in chans returned from findmount:
 *    used in namec and then by unionread.
 *  - the mhead in chans returned from createdir:
 *    used in the open/create race protect, which is gone.
 *
 * The RWlock in the Mhead protects the mount list it contains.
 * The mount list is deleted when we cunmount.
 * The RWlock ensures that nothing is using the mount list at that time.
 *
 * It is okay to replace c->mh with whatever you want as 
 * long as you are sure you have a unique reference to it.
 *
 * This comment might belong somewhere else.
 */
void
putmhead(Mhead *m)
{
    if(m && decref(m) == 0){
        m->mount = (Mount*)0xCafeBeef;
        free(m);
    }
}
@


<<function findmount>>=
/* also used by sysfile.c:/^mountfix */
int
findmount(Chan **cp, Mhead **mp, int type, int dev, Qid qid)
{
    Pgrp *pg;
    Mhead *m;

    pg = up->pgrp;
    rlock(&pg->ns);
    for(m = MOUNTH(pg, qid); m; m = m->hash){
        rlock(&m->lock);
        if(m->from == nil){
            print("m %p m->from 0\n", m);
            runlock(&m->lock);
            continue;
        }
        if(eqchantdqid(m->from, type, dev, qid, 1)){
            runlock(&pg->ns);
            if(mp != nil){
                incref(m);
                if(*mp != nil)
                    putmhead(*mp);
                *mp = m;
            }
            if(*cp != nil)
                cclose(*cp);
            incref(m->mount->to);
            *cp = m->mount->to;
            runlock(&m->lock);
            return 1;
        }
        runlock(&m->lock);
    }

    runlock(&pg->ns);
    return 0;
}
@


<<function domount>>=
/*
 * Calls findmount but also updates path.
 */
static int
domount(Chan **cp, Mhead **mp, Path **path)
{
    Chan **lc;
    Path *p;

    if(findmount(cp, mp, (*cp)->type, (*cp)->dev, (*cp)->qid) == 0)
        return 0;

    if(path){
        p = *path;
        p = uniquepath(p);
        if(p->mlen <= 0)
            print("domount: path %s has mlen==%d\n", p->s, p->mlen);
        else{
            lc = &p->mtpt[p->mlen-1];
DBG("domount %p %s => add %p (was %p)\n", p, p->s, (*mp)->from, p->mtpt[p->mlen-1]);
            incref((*mp)->from);
            if(*lc)
                cclose(*lc);
            *lc = (*mp)->from;
        }
        *path = p;
    }
    return 1;
}
@


<<function undomount>>=
/*
 * If c is the right-hand-side of a mount point, returns the left hand side.
 * Changes name to reflect the fact that we've uncrossed the mountpoint,
 * so name had better be ours to change!
 */
static Chan*
undomount(Chan *c, Path *path)
{
    Chan *nc;

    if(path->ref != 1 || path->mlen == 0)
        print("undomount: path %s ref %ld mlen %d caller %#p\n",
            path->s, path->ref, path->mlen, getcallerpc(&c));

    if(path->mlen>0 && (nc=path->mtpt[path->mlen-1]) != nil){
DBG("undomount %p %s => remove %p\n", path, path->s, nc);
        cclose(c);
        path->mtpt[path->mlen-1] = nil;
        c = nc;
    }
    return c;
}
@


<<function ewalk>>=
/*
 * Call dev walk but catch errors.
 */
static Walkqid*
ewalk(Chan *c, Chan *nc, char **name, int nname)
{
    Walkqid *wq;

    if(waserror())
        return nil;
    wq = devtab[c->type]->walk(c, nc, name, nname);
    poperror();
    return wq;
}
@


<<global Edoesnotexist>>=
static char Edoesnotexist[] = "does not exist";
@


<<function walk>>=
/*
 * Either walks all the way or not at all.  No partial results in *cp.
 * *nerror is the number of names to display in an error message.
 */

int
walk(Chan **cp, char **names, int nnames, int nomount, int *nerror)
{
    int dev, didmount, dotdot, i, n, nhave, ntry, type;
    Chan *c, *nc, *mtpt;
    Path *path;
    Mhead *mh, *nmh;
    Mount *f;
    Walkqid *wq;

    c = *cp;
    incref(c);
    path = c->path;
    incref(path);
    mh = nil;

    /*
     * While we haven't gotten all the way down the path:
     *    1. step through a mount point, if any
     *    2. send a walk request for initial dotdot or initial prefix without dotdot
     *    3. move to the first mountpoint along the way.
     *    4. repeat.
     *
     * Each time through the loop:
     *
     *  If didmount==0, c is on the undomount side of the mount point.
     *  If didmount==1, c is on the domount side of the mount point.
     *  Either way, c's full path is path.
     */
    didmount = 0;
    for(nhave=0; nhave<nnames; nhave+=n){
        if((c->qid.type&QTDIR)==0){
            if(nerror)
                *nerror = nhave;
            pathclose(path);
            cclose(c);
            strcpy(up->errstr, Enotdir);
            if(mh != nil)
                putmhead(mh);
            return -1;
        }
        ntry = nnames - nhave;
        if(ntry > MAXWELEM)
            ntry = MAXWELEM;
        dotdot = 0;
        for(i=0; i<ntry; i++){
            if(isdotdot(names[nhave+i])){
                if(i==0){
                    dotdot = 1;
                    ntry = 1;
                }else
                    ntry = i;
                break;
            }
        }

        if(!dotdot && !nomount && !didmount)
            domount(&c, &mh, &path);
        
        type = c->type;
        dev = c->dev;

        if((wq = ewalk(c, nil, names+nhave, ntry)) == nil){
            /* try a union mount, if any */
            if(mh && !nomount){
                /*
                 * mh->mount->to == c, so start at mh->mount->next
                 */
                rlock(&mh->lock);
                f = mh->mount;
                for(f = (f? f->next: f); f; f = f->next)
                    if((wq = ewalk(f->to, nil, names+nhave, ntry)) != nil)
                        break;
                runlock(&mh->lock);
                if(f != nil){
                    type = f->to->type;
                    dev = f->to->dev;
                }
            }
            if(wq == nil){
                cclose(c);
                pathclose(path);
                if(nerror)
                    *nerror = nhave+1;
                if(mh != nil)
                    putmhead(mh);
                return -1;
            }
        }

        didmount = 0;
        if(dotdot){
            assert(wq->nqid == 1);
            assert(wq->clone != nil);

            path = addelem(path, "..", nil);
            nc = undomount(wq->clone, path);
            nmh = nil;
            n = 1;
        }else{
            nc = nil;
            nmh = nil;
            if(!nomount){
                for(i=0; i<wq->nqid && i<ntry-1; i++){
                    if(findmount(&nc, &nmh, type, dev, wq->qid[i])){
                        didmount = 1;
                        break;
                    }
                }
            }
            if(nc == nil){  /* no mount points along path */
                if(wq->clone == nil){
                    cclose(c);
                    pathclose(path);
                    if(wq->nqid==0 || (wq->qid[wq->nqid-1].type&QTDIR)){
                        if(nerror)
                            *nerror = nhave+wq->nqid+1;
                        strcpy(up->errstr, Edoesnotexist);
                    }else{
                        if(nerror)
                            *nerror = nhave+wq->nqid;
                        strcpy(up->errstr, Enotdir);
                    }
                    free(wq);
                    if(mh != nil)
                        putmhead(mh);
                    return -1;
                }
                n = wq->nqid;
                nc = wq->clone;
            }else{      /* stopped early, at a mount point */
                didmount = 1;
                if(wq->clone != nil){
                    cclose(wq->clone);
                    wq->clone = nil;
                }
                n = i+1;
            }
            for(i=0; i<n; i++){
                mtpt = nil;
                if(i==n-1 && nmh)
                    mtpt = nmh->from;
                path = addelem(path, names[nhave+i], mtpt);
            }
        }
        cclose(c);
        c = nc;
        putmhead(mh);
        mh = nmh;
        free(wq);
    }

    putmhead(mh);

    c = cunique(c);

    if(c->umh != nil){  //BUG
        print("walk umh\n");
        putmhead(c->umh);
        c->umh = nil;
    }

    pathclose(c->path);
    c->path = path;

    cclose(*cp);
    *cp = c;
    if(nerror)
        *nerror = nhave;
    return 0;
}
@

\section{[[Pgrp]]}

<<function MOUNTH>>=
enum
{
    MNTLOG  = 5,
    MNTHASH = 1<<MNTLOG,  /* Hash to walk mount table */
};
#define MOUNTH(p,qid) ((p)->mnthash[(qid).path&((1<<MNTLOG)-1)])
@ 

<<struct Pgrp>>=
// Namespace process group
struct Pgrp
{
    // hash<qid.path, list<ref<Mhead> (next = Mhead.next)>
    Mhead *mnthash[MNTHASH];
    ulong pgrpid;
    bool noattach;
  
    // extra
    Ref;        /* also used as a lock when mounting */
    QLock debug;      /* single access via devproc.c */
    RWlock  ns;     /* Namespace n read/one write lock */
};
@ 

<<[[Proc]] files fields>>=
// ref_counted<pgrp>
Pgrp  *pgrp;    /* Process group for namespace */
@

<<global pgrpid>>=
static Counter pgrpid;
@ 


<<constructor newpgrp>>=
Pgrp*
newpgrp(void)
{
    Pgrp *p;

    p = smalloc(sizeof(Pgrp));
    p->ref = 1;
    p->pgrpid = incref(&pgrpid);
    return p;
}
@ 

<<destructor closepgrp>>=
void
closepgrp(Pgrp *p)
{
    Mhead **h, **e, *f, *next;

    if(decref(p) != 0)
        return;

    qlock(&p->debug);
    wlock(&p->ns);
    p->pgrpid = -1;

    e = &p->mnthash[MNTHASH];
    for(h = p->mnthash; h < e; h++) {
        for(f = *h; f; f = next) {
            wlock(&f->lock);
            cclose(f->from);
            mountfree(f->mount);
            f->mount = nil;
            next = f->hash;
            wunlock(&f->lock);
            putmhead(f);
        }
    }
    wunlock(&p->ns);
    qunlock(&p->debug);
    free(p);
}
@ 

<<function pgrpinsert>>=
void
pgrpinsert(Mount **order, Mount *m)
{
    Mount *f;

    m->order = 0;
    if(*order == 0) {
        *order = m;
        return;
    }
    for(f = *order; f; f = f->order) {
        if(m->mountid < f->mountid) {
            m->order = f;
            *order = m;
            return;
        }
        order = &f->order;
    }
    *order = m;
}
@ 


<<function pgrpcpy>>=
/*
 * pgrpcpy MUST preserve the mountid allocation order of the parent group
 */
void
pgrpcpy(Pgrp *to, Pgrp *from)
{
    int i;
    Mount *n, *m, **link, *order;
    Mhead *f, **tom, **l, *mh;

    wlock(&from->ns);
    order = 0;
    tom = to->mnthash;
    for(i = 0; i < MNTHASH; i++) {
        l = tom++;
        for(f = from->mnthash[i]; f; f = f->hash) {
            rlock(&f->lock);
            mh = newmhead(f->from);
            *l = mh;
            l = &mh->hash;
            link = &mh->mount;
            for(m = f->mount; m; m = m->next) {
                n = newmount(mh, m->to, m->mflag, m->spec);
                m->copy = n;
                pgrpinsert(&order, m);
                *link = n;
                link = &n->next;
            }
            runlock(&f->lock);
        }
    }
    /*
     * Allocate mount ids in the same sequence as the parent group
     */
    lock(&mountid);
    for(m = order; m; m = m->order)
        m->copy->mountid = mountid.ref++;
    unlock(&mountid);
    wunlock(&from->ns);
}
@ 

\section{miscmount}

<<[[Chan]] other fields>>=
uchar*  dirrock;    /* directory entry rock for translations */
int nrock;
int mrock;
QLock rockqlock;
@

<<function mountrock>>=
/*
 * Mountfix might have caused the fixed results of the directory read
 * to overflow the buffer.  Catch the overflow in c->dirrock.
 */
static void
mountrock(Chan *c, uchar *p, uchar **pe)
{
    uchar *e, *r;
    int len, n;

    e = *pe;

    /* find last directory entry */
    for(;;){
        len = BIT16SZ+GBIT16(p);
        if(p+len >= e)
            break;
        p += len;
    }

    /* save it away */
    qlock(&c->rockqlock);
    if(c->nrock+len > c->mrock){
        n = ROUND(c->nrock+len, 1024);
        r = smalloc(n);
        memmove(r, c->dirrock, c->nrock);
        free(c->dirrock);
        c->dirrock = r;
        c->mrock = n;
    }
    memmove(c->dirrock+c->nrock, p, len);
    c->nrock += len;
    qunlock(&c->rockqlock);

    /* drop it */
    *pe = p;
}
@


<<function mountrockread>>=
/*
 * Satisfy a directory read with the results saved in c->dirrock.
 */
static bool
mountrockread(Chan *c, uchar *op, long n, long *nn)
{
    long dirlen;
    uchar *rp, *erp, *ep, *p;

    /* common case */
    if(c->nrock == 0)
        return false;

    /* copy out what we can */
    qlock(&c->rockqlock);
    rp = c->dirrock;
    erp = rp+c->nrock;
    p = op;
    ep = p+n;
    while(rp+BIT16SZ <= erp){
        dirlen = BIT16SZ+GBIT16(rp);
        if(p+dirlen > ep)
            break;
        memmove(p, rp, dirlen);
        p += dirlen;
        rp += dirlen;
    }

    if(p == op){
        qunlock(&c->rockqlock);
        return false;
    }

    /* shift the rest */
    if(rp != erp)
        memmove(c->dirrock, rp, erp-rp);
    c->nrock = erp - rp;

    *nn = p - op;
    qunlock(&c->rockqlock);
    return true;
}
@


<<function mountrewind>>=
static void
mountrewind(Chan *c)
{
    c->nrock = 0;
}
@


<<function mountfix>>=
/*
 * Rewrite the results of a directory read to reflect current 
 * name space bindings and mounts.  Specifically, replace
 * directory entries for bind and mount points with the results
 * of statting what is mounted there.  Except leave the old names.
 */
static long
mountfix(Chan *c, uchar *op, long n, long maxn)
{
    char *name;
    int nbuf, nname;
    Chan *nc;
    Mhead *mh;
    Mount *m;
    uchar *p;
    int dirlen, rest;
    long l;
    uchar *buf, *e;
    Dir d;

    p = op;
    buf = nil;
    nbuf = 0;
    for(e=&p[n]; p+BIT16SZ<e; p+=dirlen){
        dirlen = dirfixed(p, e, &d);
        if(dirlen < 0)
            break;
        nc = nil;
        mh = nil;
        if(findmount(&nc, &mh, d.type, d.dev, d.qid)){
            /*
             * If it's a union directory and the original is
             * in the union, don't rewrite anything.
             */
            for(m=mh->mount; m; m=m->next)
                if(eqchantdqid(m->to, d.type, d.dev, d.qid, 1))
                    goto Norewrite;

            name = dirname(p, &nname);
            /*
             * Do the stat but fix the name.  If it fails, leave old entry.
             * BUG: If it fails because there isn't room for the entry,
             * what can we do?  Nothing, really.  Might as well skip it.
             */
            if(buf == nil){
                buf = smalloc(4096);
                nbuf = 4096;
            }
            if(waserror())
                goto Norewrite;
            l = devtab[nc->type]->stat(nc, buf, nbuf);
            l = dirsetname(name, nname, buf, l, nbuf);
            if(l == BIT16SZ)
                error("dirsetname");
            poperror();

            /*
             * Shift data in buffer to accomodate new entry,
             * possibly overflowing into rock.
             */
            rest = e - (p+dirlen);
            if(l > dirlen){
                while(p+l+rest > op+maxn){
                    mountrock(c, p, &e);
                    if(e == p){
                        dirlen = 0;
                        goto Norewrite;
                    }
                    rest = e - (p+dirlen);
                }
            }
            if(l != dirlen){
                memmove(p+l, p+dirlen, rest);
                dirlen = l;
                e = p+dirlen+rest;
            }

            /*
             * Rewrite directory entry.
             */
            memmove(p, buf, l);

            Norewrite:
            cclose(nc);
            putmhead(mh);
        }
    }
    if(buf)
        free(buf);

    if(p != e)
        error("oops in rockfix");

    return e-op;
}
@


\section{[[bindmount()]]}

<<function bindmount>>=
long
bindmount(int ismount, int fd, int afd, char* arg0, char* arg1, ulong flag, char* spec)
{
    int ret;
    Chan *c0, *c1, *ac, *bc;
    struct{
        Chan    *chan;
        Chan    *authchan;
        char    *spec;
        int flags;
    }bogus;

    if((flag&~MMASK) || (flag&MORDER)==(MBEFORE|MAFTER))
        error(Ebadarg);

    if(ismount){
        validaddr((ulong)spec, 1, 0);
        spec = validnamedup(spec, 1);
        if(waserror()){
            free(spec);
            nexterror();
        }

        if(up->pgrp->noattach)
            error(Enoattach);

        ac = nil;
        bc = fdtochan(fd, ORDWR, 0, 1);
        if(waserror()) {
            if(ac)
                cclose(ac);
            cclose(bc);
            nexterror();
        }

        if(afd >= 0)
            ac = fdtochan(afd, ORDWR, 0, 1);

        bogus.flags = flag & MCACHE;
        bogus.chan = bc;
        bogus.authchan = ac;
        bogus.spec = spec;
        ret = devno('M', 0);
        c0 = devtab[ret]->attach((char*)&bogus);
        poperror(); /* ac bc */
        if(ac)
            cclose(ac);
        cclose(bc);
    }else{
        spec = 0;
        validaddr((ulong)arg0, 1, 0);
        c0 = namec(arg0, Abind, 0, 0);
    }

    if(waserror()){
        cclose(c0);
        nexterror();
    }

    validaddr((ulong)arg1, 1, 0);
    c1 = namec(arg1, Amount, 0, 0);
    if(waserror()){
        cclose(c1);
        nexterror();
    }

    ret = cmount(&c0, c1, flag, spec);

    poperror();
    cclose(c1);
    poperror();
    cclose(c0);
    if(ismount){
        fdclose(fd, 0);
        poperror();
        free(spec);
    }
    return ret;
}
@

<<function cmount>>=
int
cmount(Chan **newp, Chan *old, int flag, char *spec)
{
    int order, flg;
    Chan *new;
    Mhead *m, **l, *mh;
    Mount *nm, *f, *um, **h;
    Pgrp *pg;

    if(QTDIR & (old->qid.type^(*newp)->qid.type))
        error(Emount);

    if(old->umh)
        print("cmount: unexpected umh, caller %#p\n", getcallerpc(&newp));

    order = flag&MORDER;

    if((old->qid.type&QTDIR)==0 && order != MREPL)
        error(Emount);

    new = *newp;
    mh = new->umh;

    /*
     * Not allowed to bind when the old directory is itself a union. 
     * (Maybe it should be allowed, but I don't see what the semantics
     * would be.)
     *
     * We need to check mh->mount->next to tell unions apart from
     * simple mount points, so that things like
     *  mount -c fd /root
     *  bind -c /root /
     * work.  
     * 
     * The check of mount->mflag allows things like
     *  mount fd /root
     *  bind -c /root /
     * 
     * This is far more complicated than it should be, but I don't
     * see an easier way at the moment.
     */
    if((flag&MCREATE) && mh && mh->mount
    && (mh->mount->next || !(mh->mount->mflag&MCREATE)))
        error(Emount);

    pg = up->pgrp;
    wlock(&pg->ns);

    l = &MOUNTH(pg, old->qid);
    for(m = *l; m; m = m->hash){
        if(eqchan(m->from, old, 1))
            break;
        l = &m->hash;
    }

    if(m == nil){
        /*
         *  nothing mounted here yet.  create a mount
         *  head and add to the hash table.
         */
        m = newmhead(old);
        *l = m;

        /*
         *  if this is a union mount, add the old
         *  node to the mount chain.
         */
        if(order != MREPL)
            m->mount = newmount(m, old, 0, 0);
    }
    wlock(&m->lock);
    if(waserror()){
        wunlock(&m->lock);
        nexterror();
    }
    wunlock(&pg->ns);

    nm = newmount(m, new, flag, spec);
    if(mh != nil && mh->mount != nil){
        /*
         *  copy a union when binding it onto a directory
         */
        flg = order;
        if(order == MREPL)
            flg = MAFTER;
        h = &nm->next;
        um = mh->mount;
        for(um = um->next; um; um = um->next){
            f = newmount(m, um->to, flg, um->spec);
            *h = f;
            h = &f->next;
        }
    }

    if(m->mount && order == MREPL){
        mountfree(m->mount);
        m->mount = 0;
    }

    if(flag & MCREATE)
        nm->mflag |= MCREATE;

    if(m->mount && order == MAFTER){
        for(f = m->mount; f->next; f = f->next)
            ;
        f->next = nm;
    }else{
        for(f = nm; f->next; f = f->next)
            ;
        f->next = m->mount;
        m->mount = nm;
    }

    wunlock(&m->lock);
    poperror();
    return nm->mountid;
}
@


\section{[[sysbind()]]}

<<syscall bind>>=
// int bind(char *name, char *old, int flag);
long
sysbind(ulong *arg)
{
    return bindmount(0, -1, -1, (char*)arg[0], (char*)arg[1], arg[2], nil);
}
@



\section{[[sysmount()]]}

<<syscall mount>>=
// int mount(int fd, int afd, char *old, int flag, char *aname);
long
sysmount(ulong *arg)
{
    return bindmount(1, arg[0], arg[1], nil, (char*)arg[2], arg[3], (char*)arg[4]);
}
@

\section{[[sysumount()]]}

<<[[Chan]] other fields>>=
Chan* mchan;      /* channel to mounted server */
@

<<syscall unmount>>=
// int unmount(char *name, char *old);
long
sysunmount(ulong *arg)
{
    Chan *cmount, *cmounted;

    cmounted = 0;

    validaddr(arg[1], 1, 0);
    cmount = namec((char *)arg[1], Amount, 0, 0);
    if(waserror()) {
        cclose(cmount);
        if(cmounted)
            cclose(cmounted);
        nexterror();
    }

    if(arg[0]) {
        /*
         * This has to be namec(..., Aopen, ...) because
         * if arg[0] is something like /srv/cs or /fd/0,
         * opening it is the only way to get at the real
         * Chan underneath.
         */
        validaddr(arg[0], 1, 0);
        cmounted = namec((char*)arg[0], Aopen, OREAD, 0);
    }
    cunmount(cmount, cmounted);
    poperror();
    cclose(cmount);
    if(cmounted)
        cclose(cmounted);
    return 0;
}
@



<<function cunmount>>=
void
cunmount(Chan *mnt, Chan *mounted)
{
    Pgrp *pg;
    Mhead *m, **l;
    Mount *f, **p;

    if(mnt->umh)    /* should not happen */
        print("cunmount newp extra umh %p has %p\n", mnt, mnt->umh);

    /*
     * It _can_ happen that mounted->umh is non-nil, 
     * because mounted is the result of namec(Aopen)
     * (see sysfile.c:/^sysunmount).
     * If we open a union directory, it will have a umh.
     * Although surprising, this is okay, since the
     * cclose will take care of freeing the umh.
     */

    pg = up->pgrp;
    wlock(&pg->ns);

    l = &MOUNTH(pg, mnt->qid);
    for(m = *l; m; m = m->hash){
        if(eqchan(m->from, mnt, 1))
            break;
        l = &m->hash;
    }

    if(m == 0){
        wunlock(&pg->ns);
        error(Eunmount);
    }

    wlock(&m->lock);
    if(mounted == 0){
        *l = m->hash;
        wunlock(&pg->ns);
        mountfree(m->mount);
        m->mount = nil;
        cclose(m->from);
        wunlock(&m->lock);
        putmhead(m);
        return;
    }

    p = &m->mount;
    for(f = *p; f; f = f->next){
        /* BUG: Needs to be 2 pass */
        if(eqchan(f->to, mounted, 1) ||
          (f->to->mchan && eqchan(f->to->mchan, mounted, 1))){
            *p = f->next;
            f->next = 0;
            mountfree(f);
            if(m->mount == nil){
                *l = m->hash;
                cclose(m->from);
                wunlock(&m->lock);
                wunlock(&pg->ns);
                putmhead(m);
                return;
            }
            wunlock(&m->lock);
            wunlock(&pg->ns);
            return;
        }
        p = &f->next;
    }
    wunlock(&m->lock);
    wunlock(&pg->ns);
    error(Eunion);
}
@

\chapter{Devices}
\minitoc

% see docs/man/3/ for references on all "devices/fileservers"

% often "one-level directory containing a single file" 

% reorganize, have a Root device, then Keyboad, Screen, Console ?
% and mv devproc, devenv, elsewhere

% could we Keyboard/Screen before? instead of after all those
% File/Dir/Namespace thing/

\section{The keyboard}

<<enum specialkey>>=
enum {
    Spec=       0xF800,     /* Unicode private space */
    PF=     Spec|0x20,  /* num pad function key */
    View=       Spec|0x00,  /* view (shift window up) */
    KF=     0xF000,     /* function key (begin Unicode private space) */
    Shift=      Spec|0x60,
    Break=      Spec|0x61,
    Ctrl=       Spec|0x62,
    Latin=      Spec|0x63,
    Caps=       Spec|0x64,
    Num=        Spec|0x65,
    Middle=     Spec|0x66,
    Altgr=      Spec|0x67,
    Kmouse=     Spec|0x100,
    No=     0x00,       /* peter */

    Home=       KF|13,
    Up=     KF|14,
    Pgup=       KF|15,
    Print=      KF|16,
    Left=       KF|17,
    Right=      KF|18,
    End=        KF|24,
    Down=       View,
    Pgdown=     KF|19,
    Ins=        KF|20,
    Del=        0x7F,
    Scroll=     KF|21,

    Nscan=  128,
};
@


<<global kbtab>>=
/*
 * The codes at 0x79 and 0x7b are produced by the PFU Happy Hacking keyboard.
 * A 'standard' keyboard doesn't produce anything above 0x58.
 */
Rune kbtab[Nscan] = 
{
[0x00]  No, 0x1b,   '1',    '2',    '3',    '4',    '5',    '6',
[0x08]  '7',    '8',    '9',    '0',    '-',    '=',    '\b',   '\t',
[0x10]  'q',    'w',    'e',    'r',    't',    'y',    'u',    'i',
[0x18]  'o',    'p',    '[',    ']',    '\n',   Ctrl,   'a',    's',
[0x20]  'd',    'f',    'g',    'h',    'j',    'k',    'l',    ';',
[0x28]  '\'',   '`',    Shift,  '\\',   'z',    'x',    'c',    'v',
[0x30]  'b',    'n',    'm',    ',',    '.',    '/',    Shift,  '*',
[0x38]  Latin,  ' ',    Ctrl,   KF|1,   KF|2,   KF|3,   KF|4,   KF|5,
[0x40]  KF|6,   KF|7,   KF|8,   KF|9,   KF|10,  Num,    Scroll, '7',
[0x48]  '8',    '9',    '-',    '4',    '5',    '6',    '+',    '1',
[0x50]  '2',    '3',    '0',    '.',    No, No, No, KF|11,
[0x58]  KF|12,  No, No, No, No, No, No, No,
[0x60]  No, No, No, No, No, No, No, No,
[0x68]  No, No, No, No, No, No, No, No,
[0x70]  No, No, No, No, No, No, No, No,
[0x78]  No, View,   No, Up, No, No, No, No,
};
@


<<global kbtabshift>>=
Rune kbtabshift[Nscan] =
{
[0x00]  No, 0x1b,   '!',    '@',    '#',    '$',    '%',    '^',
[0x08]  '&',    '*',    '(',    ')',    '_',    '+',    '\b',   '\t',
[0x10]  'Q',    'W',    'E',    'R',    'T',    'Y',    'U',    'I',
[0x18]  'O',    'P',    '{',    '}',    '\n',   Ctrl,   'A',    'S',
[0x20]  'D',    'F',    'G',    'H',    'J',    'K',    'L',    ':',
[0x28]  '"',    '~',    Shift,  '|',    'Z',    'X',    'C',    'V',
[0x30]  'B',    'N',    'M',    '<',    '>',    '?',    Shift,  '*',
[0x38]  Latin,  ' ',    Ctrl,   KF|1,   KF|2,   KF|3,   KF|4,   KF|5,
[0x40]  KF|6,   KF|7,   KF|8,   KF|9,   KF|10,  Num,    Scroll, '7',
[0x48]  '8',    '9',    '-',    '4',    '5',    '6',    '+',    '1',
[0x50]  '2',    '3',    '0',    '.',    No, No, No, KF|11,
[0x58]  KF|12,  No, No, No, No, No, No, No,
[0x60]  No, No, No, No, No, No, No, No,
[0x68]  No, No, No, No, No, No, No, No,
[0x70]  No, No, No, No, No, No, No, No,
[0x78]  No, Up, No, Up, No, No, No, No,
};
@


<<global kbtabesc1>>=
Rune kbtabesc1[Nscan] =
{
[0x00]  No, No, No, No, No, No, No, No,
[0x08]  No, No, No, No, No, No, No, No,
[0x10]  No, No, No, No, No, No, No, No,
[0x18]  No, No, No, No, '\n',   Ctrl,   No, No,
[0x20]  No, No, No, No, No, No, No, No,
[0x28]  No, No, Shift,  No, No, No, No, No,
[0x30]  No, No, No, No, No, '/',    No, Print,
[0x38]  Altgr,  No, No, No, No, No, No, No,
[0x40]  No, No, No, No, No, No, Break,  Home,
[0x48]  Up, Pgup,   No, Left,   No, Right,  No, End,
[0x50]  Down,   Pgdown, Ins,    Del,    No, No, No, No,
[0x58]  No, No, No, No, No, No, No, No,
[0x60]  No, No, No, No, No, No, No, No,
[0x68]  No, No, No, No, No, No, No, No,
[0x70]  No, No, No, No, No, No, No, No,
[0x78]  No, Up, No, No, No, No, No, No,
};
@


<<global kbtabaltgr>>=
Rune kbtabaltgr[Nscan] =
{
[0x00]  No, No, No, No, No, No, No, No,
[0x08]  No, No, No, No, No, No, No, No,
[0x10]  No, No, No, No, No, No, No, No,
[0x18]  No, No, No, No, '\n',   Ctrl,   No, No,
[0x20]  No, No, No, No, No, No, No, No,
[0x28]  No, No, Shift,  No, No, No, No, No,
[0x30]  No, No, No, No, No, '/',    No, Print,
[0x38]  Altgr,  No, No, No, No, No, No, No,
[0x40]  No, No, No, No, No, No, Break,  Home,
[0x48]  Up, Pgup,   No, Left,   No, Right,  No, End,
[0x50]  Down,   Pgdown, Ins,    Del,    No, No, No, No,
[0x58]  No, No, No, No, No, No, No, No,
[0x60]  No, No, No, No, No, No, No, No,
[0x68]  No, No, No, No, No, No, No, No,
[0x70]  No, No, No, No, No, No, No, No,
[0x78]  No, Up, No, No, No, No, No, No,
};
@


<<global kbtabctrl decl>>=
extern Rune kbtabctrl[];
@
%$


<<struct Kbscan>>=
struct Kbscan {
    bool esc1;
    bool alt;
    bool altgr;
    bool caps;
    bool ctl;
    bool num;
    bool shift;

    int esc2;

    bool collecting;
    int nk;
    Rune    kc[5];
    int buttons;
};
@


<<global kbscans>>=
Kbscan kbscans[Nscans]; /* kernel and external scan code state */
@


<<global nokbd>>=
static bool nokbd = true;           /* flag: no PS/2 keyboard */
@

<<global ccc>>=
static uchar ccc;
@



<<function kbdinit>>=
void
kbdinit(void)
{
    int c, try;

    /* wait for a quiescent controller */
    try = 500;
    while(try-- > 0 && (c = inb(Status)) & (Outbusy | Inready)) {
        if(c & Inready)
            inb(Data);
        delay(1);
    }
    if (try <= 0) {
        print(initfailed);
        return;
    }

    /* get current controller command byte */
    outb(Cmd, 0x20);
    if(inready() < 0){
        print("i8042: kbdinit can't read ccc\n");
        ccc = 0;
    } else
        ccc = inb(Data);

    /* enable kbd xfers and interrupts */
    ccc &= ~Ckbddis;
    ccc |= Csf | Ckbdint | Cscs1;
    if(outready() < 0) {
        print(initfailed);
        return;
    }

    nokbd = false;

    /* disable mouse */
    if (outbyte(Cmd, 0x60) < 0 || outbyte(Data, ccc) < 0)
        print("i8042: kbdinit mouse disable failed\n");

    /* see http://www.computer-engineering.org/ps2keyboard for codes */
    if(getconf("*typematic") != nil)
        /* set typematic rate/delay (0 -> delay=250ms & rate=30cps) */
        if(outbyte(Data, 0xf3) < 0 || outbyte(Data, 0) < 0)
            print("i8042: kbdinit set typematic rate failed\n");
}
@


<<function kbdenable>>=
void
kbdenable(void)
{
    kbdq = qopen(4*1024, 0, 0, 0);
    if(kbdq == nil)
        panic("kbdinit");
    qnoblock(kbdq, 1);

    ioalloc(Data, 1, 0, "kbd");
    ioalloc(Cmd, 1, 0, "kbd");

    intrenable(IrqKBD, i8042intr, 0, BUSUNKNOWN, "kbd");

    kbscans[Int].num = 0;
    setleds(&kbscans[Int]);
}
@

<<global i8042lock>>=
static Lock i8042lock;
@


<<interrupt callback i8042intr>>=
/*
 *  keyboard interrupt
 */
static void
i8042intr(Ureg*, void*)
{
    int s, c;

    /*
     *  get status
     */
    ilock(&i8042lock);
    s = inb(Status);
    if(!(s&Inready)){
        iunlock(&i8042lock);
        return;
    }

    /*
     *  get the character
     */
    c = inb(Data);
    iunlock(&i8042lock);

    /*
     *  if it's the aux port...
     */
    if(s & Minready){
        if(auxputc != nil)
            auxputc(c, kbscans[Int].shift);
        return;
    }

    kbdputsc(c, Int);
}
@




<<function kbdputsc>>=
/*
 * Scan code processing
 */
void
kbdputsc(int c, bool external)
{
    int i, keyup;
    Kbscan *kbscan;

    if(external)
        kbscan = &kbscans[Ext];
    else
        kbscan = &kbscans[Int];

    if(kdebug)
        print("sc %x ms %d\n", c, mouseshifted);
    /*
     *  e0's is the first of a 2 character sequence, e1 the first
     *  of a 3 character sequence (on the safari)
     */
    if(c == 0xe0){
        kbscan->esc1 = 1;
        return;
    } else if(c == 0xe1){
        kbscan->esc2 = 2;
        return;
    }

    keyup = c & 0x80;
    c &= 0x7f;
    if(c > sizeof kbtab){
        c |= keyup;
        if(c != 0xFF)   /* these come fairly often: CAPSLOCK U Y */
            print("unknown key %ux\n", c);
        return;
    }

    if(kbscan->esc1){
        c = kbtabesc1[c];
        kbscan->esc1 = 0;
    } else if(kbscan->esc2){
        kbscan->esc2--;
        return;
    } else if(kbscan->shift)
        c = kbtabshift[c];
    else if(kbscan->altgr)
        c = kbtabaltgr[c];
    else if(kbscan->ctl)
        c = kbtabctrl[c];
    else
        c = kbtab[c];

    if(kbscan->caps && c<='z' && c>='a')
        c += 'A' - 'a';

    /*
     *  keyup only important for shifts
     */
    if(keyup){
        switch(c){
        case Latin:
            kbscan->alt = 0;
            break;
        case Shift:
            kbscan->shift = 0;
            mouseshifted = 0;
            if(kdebug)
                print("shiftclr\n");
            break;
        case Ctrl:
            kbscan->ctl = 0;
            break;
        case Altgr:
            kbscan->altgr = 0;
            break;
        case Kmouse|1:
        case Kmouse|2:
        case Kmouse|3:
        case Kmouse|4:
        case Kmouse|5:
            kbscan->buttons &= ~(1<<(c-Kmouse-1));
            if(kbdmouse)
                kbdmouse(kbscan->buttons);
            break;
        }
        return;
    }

    /*
     *  normal character
     */
    if(!(c & (Spec|KF))){
        if(kbscan->ctl)
            if(kbscan->alt && c == Del)
                exit(0);
        if(!kbscan->collecting){
            kbdputc(kbdq, c);
            return;
        }
        kbscan->kc[kbscan->nk++] = c;
        c = latin1(kbscan->kc, kbscan->nk);
        if(c < -1)  /* need more keystrokes */
            return;
        if(c != -1) /* valid sequence */
            kbdputc(kbdq, c);
        else    /* dump characters */
            for(i=0; i<kbscan->nk; i++)
                kbdputc(kbdq, kbscan->kc[i]);
        kbscan->nk = 0;
        kbscan->collecting = 0;
        return;
    } else {
        switch(c){
        case Caps:
            kbscan->caps ^= 1;
            return;
        case Num:
            kbscan->num ^= 1;
            if(!external)
                setleds(kbscan);
            return;
        case Shift:
            kbscan->shift = 1;
            if(kdebug)
                print("shift\n");
            mouseshifted = 1;
            return;
        case Latin:
            kbscan->alt = 1;
            /*
             * VMware and Qemu use Ctl-Alt as the key combination
             * to make the VM give up keyboard and mouse focus.
             * This has the unfortunate side effect that when you
             * come back into focus, Plan 9 thinks you want to type
             * a compose sequence (you just typed alt). 
             *
             * As a clumsy hack around this, we look for ctl-alt
             * and don't treat it as the start of a compose sequence.
             */
            if(!kbscan->ctl){
                kbscan->collecting = 1;
                kbscan->nk = 0;
            }
            return;
        case Ctrl:
            kbscan->ctl = 1;
            return;
        case Altgr:
            kbscan->altgr = 1;
            return;
        case Kmouse|1:
        case Kmouse|2:
        case Kmouse|3:
        case Kmouse|4:
        case Kmouse|5:
            kbscan->buttons |= 1<<(c-Kmouse-1);
            if(kbdmouse)
                kbdmouse(kbscan->buttons);
            return;
        case KF|11:
            print("kbd debug on, F12 turns it off\n");
            kdebug = 1;
            break;
        case KF|12:
            kdebug = 0;
            break;
        }
    }
    kbdputc(kbdq, c);
}
@

%TODO: return bool instead? those outread < 0 seems bad no?
<<function outbyte>>=
static int
outbyte(int port, int c)
{
    outb(port, c);
    if(outready() < 0) {
        print(initfailed);
        return -1;
    }
    return 0;
}
@

<<function outready>>=
/*
 *  wait for output no longer busy
 */
static int
outready(void)
{
    int tries;

    for(tries = 0; (inb(Status) & Outbusy); tries++){
        if(tries > 500)
            return -1;
        delay(2);
    }
    return 0;
}
@


<<function inready>>=
/*
 *  wait for input
 */
static int
inready(void)
{
    int tries;

    for(tries = 0; !(inb(Status) & Inready); tries++){
        if(tries > 500)
            return -1;
        delay(2);
    }
    return 0;
}
@


<<function i8042auxcmd>>=
int
i8042auxcmd(int cmd)
{
    unsigned int c;
    int tries;
    static int badkbd;

    if(badkbd)
        return -1;
    c = 0;
    tries = 0;

    ilock(&i8042lock);
    do{
        if(tries++ > 2)
            break;
        if(outready() < 0)
            break;
        outb(Cmd, 0xD4);
        if(outready() < 0)
            break;
        outb(Data, cmd);
        if(outready() < 0)
            break;
        if(inready() < 0)
            break;
        c = inb(Data);
    } while(c == 0xFE || c == 0);
    iunlock(&i8042lock);

    if(c != 0xFA){
        print("i8042: %2.2ux returned to the %2.2ux command\n", c, cmd);
        badkbd = 1; /* don't keep trying; there might not be one */
        return -1;
    }
    return 0;
}
@

<<function i8042auxenable>>=
void
i8042auxenable(void (*putc)(int, int))
{
    char *err = "i8042: aux init failed\n";

    /* enable kbd/aux xfers and interrupts */
    ccc &= ~Cauxdis;
    ccc |= Cauxint;

    ilock(&i8042lock);
    if(outready() < 0)
        print(err);
    outb(Cmd, 0x60);            /* write control register */
    if(outready() < 0)
        print(err);
    outb(Data, ccc);
    if(outready() < 0)
        print(err);
    outb(Cmd, 0xA8);            /* auxiliary device enable */
    if(outready() < 0){
        iunlock(&i8042lock);
        return;
    }
    auxputc = putc;
    intrenable(IrqAUX, i8042intr, 0, BUSUNKNOWN, "kbdaux");
    iunlock(&i8042lock);
}
@


% to change keyboard: kbdputmap, kbdgetmap and probably /dev/kbmap

\section{The screen}
% just cga.c here, see Window.tex.nw for the advanced vga kernel support

<<cga.c enum color>>=
enum color {
    Black,
    Blue,
    Green,
    Cyan,
    Red,
    Magenta,
    Brown,
    Grey,

    Bright = 0x08,
    Blinking = 0x80,

    Yellow = Bright|Brown,
    White = Bright|Grey,
};
@

<<cga.c enum misc>>=
enum {
    Width       = 80*2,
    Height      = 25,

    Attr        = (Black<<4)|Grey,  /* high nibble background
                         * low foreground
                         */

    Poststrlen  = 0,
    Postcodelen = 2,
    Postlen     = Poststrlen+Postcodelen,
};
@

<<constant CGASCREENBASE>>=
#define CGASCREENBASE   ((uchar*)KADDR(0xB8000))
@


<<global cgapos>>=
static int cgapos;
@


<<global cgascreenlock>>=
static Lock cgascreenlock;
@

<<function screeninit>>=
void
screeninit(void)
{

    cgapos = cgaregr(0x0E)<<8;
    cgapos |= cgaregr(0x0F);
    cgapos *= 2;

    screenputs = cgascreenputs;
}
@


<<function cgaregr>>=
static uchar
cgaregr(int index)
{
    outb(0x3D4, index);
    return inb(0x3D4+1) & 0xFF;
}
@


<<function cgaregw>>=
static void
cgaregw(int index, int data)
{
    outb(0x3D4, index);
    outb(0x3D4+1, data);
}
@


<<function movecursor>>=
static void
movecursor(void)
{
    cgaregw(0x0E, (cgapos/2>>8) & 0xFF);
    cgaregw(0x0F, cgapos/2 & 0xFF);
    CGASCREENBASE[cgapos+1] = Attr;
}
@


<<function cgascreenputc>>=
static void
cgascreenputc(int c)
{
    int i;
    uchar *p;

    if(c == '\n'){
        cgapos = cgapos/Width;
        cgapos = (cgapos+1)*Width;
    }
    else if(c == '\t'){
        i = 8 - ((cgapos/2)&7);
        while(i-->0)
            cgascreenputc(' ');
    }
    else if(c == '\b'){
        if(cgapos >= 2)
            cgapos -= 2;
        cgascreenputc(' ');
        cgapos -= 2;
    }
    else{
        CGASCREENBASE[cgapos++] = c;
        CGASCREENBASE[cgapos++] = Attr;
    }
    if(cgapos >= Width*Height){
        memmove(CGASCREENBASE, &CGASCREENBASE[Width], Width*(Height-1));
        p = &CGASCREENBASE[Width*(Height-1)];
        for(i=0; i<Width/2; i++){
            *p++ = ' ';
            *p++ = Attr;
        }
        cgapos = Width*(Height-1);
    }
    movecursor();
}
@


<<function cgascreenputs>>=
static void
cgascreenputs(char* s, int n)
{
    if(!islo()){
        /*
         * Don't deadlock trying to
         * print in an interrupt.
         */
        if(!canlock(&cgascreenlock))
            return;
    }
    else
        lock(&cgascreenlock);

    while(n-- > 0)
        cgascreenputc(*s++);

    unlock(&cgascreenlock);
}
@

\section{The console device [[/dev/cons]]}

\subsection{Overview}

<<devcons.c enum Qxxx>>=
enum{
    Qdir,

    Qcons,

    Qbintime,
    Qconsctl,
    Qcputime,
    Qdrivers,
    Qkmesg,
    Qkprint,
    Qhostdomain,
    Qhostowner,
    Qnull,
    Qosversion,
    Qpgrpid,
    Qpid,
    Qppid,
    Qrandom,
    Qreboot,
    Qswap,
    Qsysname,
    Qsysstat,
    Qtime,
    Quser,
    Qzero,
    Qconfig,
};
@ 


<<global consdir>>=
static Dirtab consdir[]={
    ".",    {Qdir, 0, QTDIR},   0,      DMDIR|0555,
    "cons",     {Qcons},    0,      0660,
    "bintime",  {Qbintime}, 24,     0664,
    "consctl",  {Qconsctl}, 0,      0220,
    "cputime",  {Qcputime}, 6*NUMSIZE,  0444,
    "drivers",  {Qdrivers}, 0,      0444,
    "hostdomain",   {Qhostdomain},  DOMLEN,     0664,
    "hostowner",    {Qhostowner},   0,      0664,
    "kmesg",    {Qkmesg},   0,      0440,
    "kprint",   {Qkprint, 0, QTEXCL},   0,  DMEXCL|0440,
    "null",     {Qnull},    0,      0666,
    "osversion",    {Qosversion},   0,      0444,
    "pgrpid",   {Qpgrpid},  NUMSIZE,    0444,
    "pid",      {Qpid},     NUMSIZE,    0444,
    "ppid",     {Qppid},    NUMSIZE,    0444,
    "random",   {Qrandom},  0,      0444,
    "reboot",   {Qreboot},  0,      0660,
    "swap",     {Qswap},    0,      0664,
    "sysname",  {Qsysname}, 0,      0664,
    "sysstat",  {Qsysstat}, 0,      0666,
    "time",     {Qtime},    NUMSIZE+3*VLNUMSIZE,    0664,
    "user",     {Quser},    0,      0666,
    "zero",     {Qzero},    0,      0444,
    "config",   {Qconfig},  0,      0444,
};
@ 


\subsection{Input}
%buffered input

<<struct ConsKbd>>=
struct ConsKbd
{
    bool raw;        /* true if we shouldn't process input */

    char    line[1024]; /* current input line */
    int x;      /* index into line */

    int count;
    int ctlpoff;

    /* a place to save up characters at interrupt time before dumping them in the queue */
    Lock    lockputc;
    char    istage[1024];

    // extra
    QLock;
    Ref ctl;        /* number of opens to the control file */

    //???
    char    *iw;
    char    *ir;
    char    *ie;
};
@ 

<<global kbd>>=
static struct ConsKbd kbd = 
{
    .iw = kbd.istage,
    .ir = kbd.istage,
    .ie = kbd.istage + sizeof(kbd.istage),
};
@ 

<<global kbdq>>=
Queue*  kbdq;           /* unprocessed console input */
@ 


<<global lineq>>=
Queue*  lineq;          /* processed console input */
@ 

<<function printinit>>=
void
printinit(void)
{
    lineq = qopen(2*1024, 0, nil, nil);
    if(lineq == nil)
        panic("printinit");
    qnoblock(lineq, 1);
}
@ 

% return void?
<<function kbdputc>>=
/*
 *  Put character, possibly a rune, into read queue at interrupt time.
 *  Called at interrupt time to process a character.
 */
int
kbdputc(Queue*, int ch)
{
    int i, n;
    char buf[3];
    Rune r;
    char *next;

    if(kbd.ir == nil)
        return 0;       /* in case we're not inited yet */
    
    ilock(&kbd.lockputc);       /* just a mutex */
    r = ch;
    n = runetochar(buf, &r);
    for(i = 0; i < n; i++){
        next = kbd.iw+1;
        if(next >= kbd.ie)
            next = kbd.istage;
        if(next == kbd.ir)
            break;
        *kbd.iw = buf[i];
        kbd.iw = next;
    }
    iunlock(&kbd.lockputc);
    return 0;
}
@ 

<<clock callback kbdputcclock>>=
/*
 *  we save up input characters till clock time to reduce
 *  per character interrupt overhead.
 */
static void
kbdputcclock(void)
{
    char *iw;

    /* this amortizes cost of qproduce */
    if(kbd.iw != kbd.ir){
        iw = kbd.iw;
        if(iw < kbd.ir){
            echo(kbd.ir, kbd.ie-kbd.ir);
            kbd.ir = kbd.istage;
        }
        if(kbd.ir != iw){
            echo(kbd.ir, iw-kbd.ir);
            kbd.ir = iw;
        }
    }
}
@ 

% see echo() below!


<<[[consread()]] Qcons case>>=
    case Qcons:
        qlock(&kbd);
        if(waserror()) {
            qunlock(&kbd);
            nexterror();
        }
        while(!qcanread(lineq)){
            if(qread(kbdq, &ch, 1) == 0)
                continue;
            send = 0;
            if(ch == 0){
                /* flush output on rawoff -> rawon */
                if(kbd.x > 0)
                    send = !qcanread(kbdq);
            }else if(kbd.raw){
                kbd.line[kbd.x++] = ch;
                send = !qcanread(kbdq);
            }else{
                switch(ch){
                case '\b':
                    if(kbd.x > 0)
                        kbd.x--;
                    break;
                case 0x15:  /* ^U */
                    kbd.x = 0;
                    break;
                case '\n':
                case 0x04:  /* ^D */
                    send = 1;
                default:
                    if(ch != 0x04)
                        kbd.line[kbd.x++] = ch;
                    break;
                }
            }
            if(send || kbd.x == sizeof kbd.line){
                qwrite(lineq, kbd.line, kbd.x);
                kbd.x = 0;
            }
        }
        n = qread(lineq, buf, n);
        qunlock(&kbd);
        poperror();
        return n;
@


\subsection{Output}
% what happens when do ls > file, how we do not call screenputs?
% because in this case /dev/cons is not binded to the console!??
% but then how can still read from it? because fd0 is binded to it,
% but fd1 no!??? but then why  echo 'foo' > dev/cons from
% rio does the right thing? how does not call cgascreenputs?
% because screenputs has been redirected in rio! via vga controller?

\subsubsection{[[/dev/cons]]}

<<[[conswrite()]] Qcons case>>=
    case Qcons:
        /*
         * Can't page fault in putstrn, so copy the data locally.
         */
        l = n;
        while(l > 0){
            bp = l;
            if(bp > sizeof buf)
                bp = sizeof buf;
            memmove(buf, a, bp);
            putstrn0(buf, bp, 1);
            a += bp;
            l -= bp;
        }
        break;
@

<<function putstrn0>>=
/*
 *   Print a string on the console.  Convert \n to \r\n for serial
 *   line consoles.  Locking of the queues is left up to the screen
 *   or uart code.  Multi-line messages to serial consoles may get
 *   interspersed with other messages.
 */
static void
putstrn0(char *str, int n, bool usewrite)
{
    int m;
    char *t;

    if(!islo())
        usewrite = false;

    /*
     *  how many different output devices do we need?
     */
    kmesgputs(str, n);

    /*
     *  if someone is reading /dev/kprint,
     *  put the message there.
     *  if not and there's an attached bit mapped display,
     *  put the message there.
     *
     *  if there's a serial line being used as a console,
     *  put the message there.
     */
    if(kprintoq != nil && !qisclosed(kprintoq)){
        if(usewrite)
            qwrite(kprintoq, str, n);
        else
            qiwrite(kprintoq, str, n);
    }else if(screenputs != nil)
        screenputs(str, n);

    if(serialoq == nil){
        uartputs(str, n);
        return;
    }

    while(n > 0) {
        t = memchr(str, '\n', n);
        if(t && !kbd.raw) {
            m = t-str;
            if(usewrite){
                qwrite(serialoq, str, m);
                qwrite(serialoq, "\r\n", 2);
            } else {
                qiwrite(serialoq, str, m);
                qiwrite(serialoq, "\r\n", 2);
            }
            n -= m+1;
            str = t+1;
        } else {
            if(usewrite)
                qwrite(serialoq, str, n);
            else
                qiwrite(serialoq, str, n);
            break;
        }
    }
}
@ 

<<hook screenputs>>=
void    (*screenputs)(char*, int) = nil;
@ 


<<function echo>>=
static void
echo(char *buf, int n)
{
    static int ctrlt, pid;
    int x;
    char *e, *p;
    void* tmp;

    if(n == 0)
        return;

    e = buf+n;
    for(p = buf; p < e; p++){
        switch(*p){
        case 0x10:  /* ^P */
            if(cpuserver && !kbd.ctlpoff){
                active.exiting = true;
                return;
            }
            break;
        case 0x14:  /* ^T */
            ctrlt++;
            if(ctrlt > 2)
                ctrlt = 2;
            continue;
        }
        if(ctrlt != 2)
            continue;

        <<[[echo()]] C-t C-t special keys handler>>
    }

    qproduce(kbdq, buf, n);
    if(kbd.raw)
        return;
    kmesgputs(buf, n);
    if(screenputs != nil)
        echoscreen(buf, n);
    if(serialoq)
        echoserialoq(buf, n);
}
@ 

<<function echoscreen>>=
static void
echoscreen(char *buf, int n)
{
    char *e, *p;
    char ebuf[128];
    int x;

    p = ebuf;
    e = ebuf + sizeof(ebuf) - 4;
    while(n-- > 0){
        if(p >= e){
            screenputs(ebuf, p - ebuf);
            p = ebuf;
        }
        x = *buf++;
        if(x == 0x15){
            *p++ = '^';
            *p++ = 'U';
            *p++ = '\n';
        } else
            *p++ = x;
    }
    if(p != ebuf)
        screenputs(ebuf, p - ebuf);
}
@ 


\subsubsection{[[print()]]}

<<constant PRINTSIZE>>=
PRINTSIZE = 256,
@

<<function print>>=
bool noprint; // to debug?

int
devcons_print(char *fmt, ...)
{
    int n;
    va_list arg;
    char buf[PRINTSIZE];

    if(noprint)
        return -1;

    va_start(arg, fmt);
    n = vseprint(buf, buf+sizeof(buf), fmt, arg) - buf;
    va_end(arg);
    putstrn(buf, n);

    return n;
}
@ 

<<function putstrn>>=
void
putstrn(char *str, int n)
{
    putstrn0(str, n, 0);
}
@ 


\subsubsection{[[iprint()]]}

<<global iprintscreenputs>>=
int iprintscreenputs = 1;
@ 

<<function iprint>>=
int
devcons_iprint(char *fmt, ...)
{
    int n, s, locked;
    va_list arg;
    char buf[PRINTSIZE];

    s = splhi();
    va_start(arg, fmt);
    n = vseprint(buf, buf+sizeof(buf), fmt, arg) - buf;
    va_end(arg);
    locked = iprintcanlock(&iprintlock);
    if(screenputs != nil && iprintscreenputs)
        screenputs(buf, n);
    uartputs(buf, n);
    if(locked)
        unlock(&iprintlock);
    splx(s);

    return n;
}
@ 

<<global iprintlock>>=
/*
 * Want to interlock iprints to avoid interlaced output on 
 * multiprocessor, but don't want to deadlock if one processor
 * dies during print and another has something important to say.
 * Make a good faith effort.
 */
static Lock iprintlock;
@


<<function iprintcanlock>>=
static bool
iprintcanlock(Lock *l)
{
    int i;
    
    for(i=0; i<1000; i++){
        if(canlock(l))
            return true;
        if(l->m == CPUS(cpu->cpuno))
            return false;
        microdelay(100);
    }
    return false;
}
@


\subsubsection{[[pprint()]]}

% todo: see balestero note,
% in distributed context we want to print process error at the right place
% not just on kernel console
<<function pprint>>=
int
devcons_pprint(char *fmt, ...)
{
    int n;
    Chan *c;
    va_list arg;
    char buf[2*PRINTSIZE];

    if(up == nil || up->fgrp == nil)
        return 0;

    c = up->fgrp->fd[2];
    if(c==0 || (c->mode!=OWRITE && c->mode!=ORDWR))
        return 0;
    n = snprint(buf, sizeof buf, "%s %lud: ", up->text, up->pid);
    va_start(arg, fmt);
    n = vseprint(buf+n, buf+sizeof(buf), fmt, arg) - buf;
    va_end(arg);

    if(waserror())
        return 0;
    devtab[c->type]->write(c, buf, n, c->offset);
    poperror();

    lock(c);
    c->offset += n;
    unlock(c);

    return n;
}
@ 

\subsection{[[/dev/cons]]}

<<method consinit>>=
static void
consinit(void)
{
    todinit();
    randominit();
    /*
     * at 115200 baud, the 1024 char buffer takes 56 ms to process,
     * processing it every 22 ms should be fine
     */
    addclock0link(kbdputcclock, 22);
}
@ 


<<method consopen>>=
static Chan*
consopen(Chan *c, int omode)
{
    c->aux = nil;
    c = devopen(c, omode, consdir, nelem(consdir), devgen);
    switch((ulong)c->qid.path){
    case Qconsctl:
        incref(&kbd.ctl);
        break;

    case Qkprint:
        if(tas(&kprintinuse) != 0){
            c->flag &= ~COPEN;
            error(Einuse);
        }
        if(kprintoq == nil){
            kprintoq = qopen(8*1024, Qcoalesce, 0, 0);
            if(kprintoq == nil){
                c->flag &= ~COPEN;
                error(Enomem);
            }
            qnoblock(kprintoq, 1);
        }else
            qreopen(kprintoq);
        c->iounit = qiomaxatomic;
        break;
    }
    return c;
}
@ 


<<method consclose>>=
static void
consclose(Chan *c)
{
    switch((ulong)c->qid.path){
    /* last close of control file turns off raw */
    case Qconsctl:
        if(c->flag&COPEN){
            if(decref(&kbd.ctl) == 0)
                kbd.raw = false;
        }
        break;

    /* close of kprint allows other opens */
    case Qkprint:
        if(c->flag & COPEN){
            kprintinuse = 0;
            qhangup(kprintoq, nil);
        }
        break;
    }
}
@ 

<<method consread>>=
static long
consread(Chan *c, void *buf, long n, vlong off)
{
    ulong l;
    Cpu *mp;
    char *b, *bp, ch;
    char tmp[256];      /* must be >= 18*NUMSIZE (Qswap) */
    int i, k, id, send;
    vlong offset = off;
    extern char configfile[];

    if(n <= 0)
        return n;

    switch((ulong)c->qid.path){
    case Qdir:
        return devdirread(c, buf, n, consdir, nelem(consdir), devgen);

    <<[[consread()]] Qcons case>>

    case Qcputime:
        k = offset;
        if(k >= 6*NUMSIZE)
            return 0;
        if(k+n > 6*NUMSIZE)
            n = 6*NUMSIZE - k;
        /* easiest to format in a separate buffer and copy out */
        for(i=0; i<6 && NUMSIZE*i<k+n; i++){
            l = up->time[i];
            if(i == TReal)
                l = CPUS(0)->ticks - l;
            l = TK2MS(l);
            readnum(0, tmp+NUMSIZE*i, NUMSIZE, l, NUMSIZE);
        }
        memmove(buf, tmp+k, n);
        return n;

    case Qkmesg:
        /*
         * This is unlocked to avoid tying up a process
         * that's writing to the buffer.  kmesg.n never 
         * gets smaller, so worst case the reader will
         * see a slurred buffer.
         */
        if(off >= kmesg.n)
            n = 0;
        else{
            if(off+n > kmesg.n)
                n = kmesg.n - off;
            memmove(buf, kmesg.buf+off, n);
        }
        return n;
        
    case Qkprint:
        return qread(kprintoq, buf, n);

    case Qpgrpid:
        return readnum((ulong)offset, buf, n, up->pgrp->pgrpid, NUMSIZE);

    case Qpid:
        return readnum((ulong)offset, buf, n, up->pid, NUMSIZE);

    case Qppid:
        return readnum((ulong)offset, buf, n, up->parentpid, NUMSIZE);

    case Qtime:
        return readtime((ulong)offset, buf, n);

    case Qbintime:
        return readbintime(buf, n);

    case Qhostowner:
        return readstr((ulong)offset, buf, n, eve);

    case Qhostdomain:
        return readstr((ulong)offset, buf, n, hostdomain);

    case Quser:
        return readstr((ulong)offset, buf, n, up->user);

    case Qnull:
        return 0;

    case Qconfig:
        return readstr((ulong)offset, buf, n, configfile);

    case Qsysstat:
        b = smalloc(conf.ncpu*(NUMSIZE*11+1) + 1); /* +1 for NUL */
        bp = b;
        for(id = 0; id < MAXCPUS; id++) {
            if(active.cpus & (1<<id)) {
                mp = CPUS(id);
                readnum(0, bp, NUMSIZE, id, NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE, mp->cs, NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE, mp->intr, NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE, mp->syscall, NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE, mp->pfault, NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE, mp->tlbfault, NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE, mp->tlbpurge, NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE, mp->load, NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE,
                    (mp->perf.avg_inidle*100)/mp->perf.period,
                    NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE,
                    (mp->perf.avg_inintr*100)/mp->perf.period,
                    NUMSIZE);
                bp += NUMSIZE;
                *bp++ = '\n';
            }
        }
        if(waserror()){
            free(b);
            nexterror();
        }
        n = readstr((ulong)offset, buf, n, b);
        free(b);
        poperror();
        return n;

    case Qswap:
        snprint(tmp, sizeof tmp,
            "%lud memory\n"
            "%d pagesize\n"
            "%lud kernel\n"
            "%lud/%lud user\n"
            "%lud/%lud swap\n"
            "%lud/%lud kernel malloc\n"
            "%lud/%lud kernel draw\n",
            conf.npage*BY2PG,
            BY2PG,
            conf.npage-conf.upages,
            palloc.user-palloc.freecount, palloc.user,
            conf.nswap-swapalloc.free, conf.nswap,
            mainmem->cursize, mainmem->maxsize,
            imagmem->cursize, imagmem->maxsize);

        return readstr((ulong)offset, buf, n, tmp);

    case Qsysname:
        if(sysname == nil)
            return 0;
        return readstr((ulong)offset, buf, n, sysname);

    case Qrandom:
        return randomread(buf, n);

    case Qdrivers:
        b = malloc(READSTR);
        if(b == nil)
            error(Enomem);
        k = 0;
        for(i = 0; devtab[i] != nil; i++)
            k += snprint(b+k, READSTR-k, "#%C %s\n",
                devtab[i]->dc, devtab[i]->name);
        if(waserror()){
            free(b);
            nexterror();
        }
        n = readstr((ulong)offset, buf, n, b);
        free(b);
        poperror();
        return n;

    case Qzero:
        memset(buf, 0, n);
        return n;

    case Qosversion:
        snprint(tmp, sizeof tmp, "2000");
        n = readstr((ulong)offset, buf, n, tmp);
        return n;

    default:
        print("consread %#llux\n", c->qid.path);
        error(Egreg);
    }
    panic("consread: should not reach this point");
}
@

<<method conswrite>>=
static long
conswrite(Chan *c, void *va, long n, vlong off)
{
    char buf[256], ch;
    long l, bp;
    char *a;
    Cpu *mp;
    int id, fd;
    Chan *swc;
    ulong offset;
    Cmdbuf *cb;
    Cmdtab *ct;

    a = va;
    offset = off;

    switch((ulong)c->qid.path){

    <<[[conswrite()]] Qcons case>>

    case Qconsctl:
        if(n >= sizeof(buf))
            n = sizeof(buf)-1;
        strncpy(buf, a, n);
        buf[n] = 0;
        for(a = buf; a;){
            if(strncmp(a, "rawon", 5) == 0){
                kbd.raw = 1;
                /* clumsy hack - wake up reader */
                ch = 0;
                qwrite(kbdq, &ch, 1);           
            } else if(strncmp(a, "rawoff", 6) == 0){
                kbd.raw = 0;
            } else if(strncmp(a, "ctlpon", 6) == 0){
                kbd.ctlpoff = 0;
            } else if(strncmp(a, "ctlpoff", 7) == 0){
                kbd.ctlpoff = 1;
            }
            if(a = strchr(a, ' '))
                a++;
        }
        break;

    case Qtime:
        if(!iseve())
            error(Eperm);
        return writetime(a, n);

    case Qbintime:
        if(!iseve())
            error(Eperm);
        return writebintime(a, n);

    case Qhostowner:
        return hostownerwrite(a, n);

    case Qhostdomain:
        return hostdomainwrite(a, n);

    case Quser:
        return userwrite(a, n);

    case Qnull:
        break;

    case Qconfig:
        error(Eperm);
        break;

    case Qreboot:
        if(!iseve())
            error(Eperm);
        cb = parsecmd(a, n);

        if(waserror()) {
            free(cb);
            nexterror();
        }
        ct = lookupcmd(cb, rebootmsg, nelem(rebootmsg));
        switch(ct->index) {
        case CMhalt:
            reboot(nil, 0, 0);
            break;
        case CMreboot:
            rebootcmd(cb->nf-1, cb->f+1);
            break;
        case CMpanic:
            *(ulong*)0=0;
            panic("/dev/reboot");
        }
        poperror();
        free(cb);
        break;

    case Qsysstat:
        for(id = 0; id < 32; id++) {
            if(active.cpus & (1<<id)) {
                mp = CPUS(id);
                mp->cs = 0;
                mp->intr = 0;
                mp->syscall = 0;
                mp->pfault = 0;
                mp->tlbfault = 0;
                mp->tlbpurge = 0;
            }
        }
        break;

    case Qswap:
        if(n >= sizeof buf)
            error(Egreg);
        memmove(buf, va, n);    /* so we can NUL-terminate */
        buf[n] = 0;
        /* start a pager if not already started */
        if(strncmp(buf, "start", 5) == 0){
            kickpager();
            break;
        }
        if(!iseve())
            error(Eperm);
        if(buf[0]<'0' || '9'<buf[0])
            error(Ebadarg);
        fd = strtoul(buf, 0, 0);
        swc = fdtochan(fd, -1, 1, 1);
        setswapchan(swc);
        break;

    case Qsysname:
        if(offset != 0)
            error(Ebadarg);
        if(n <= 0 || n >= sizeof buf)
            error(Ebadarg);
        strncpy(buf, a, n);
        buf[n] = 0;
        if(buf[n-1] == '\n')
            buf[n-1] = 0;
        kstrdup(&sysname, buf);
        break;

    default:
        print("conswrite: %#llux\n", c->qid.path);
        error(Egreg);
    }
    return n;
}
@ 

<<global consdevtab>>=
Dev consdevtab = {
    .dc       =    'c',
    .name     =    "cons",
               
    .reset    =    devreset,
    .init     =    consinit,
    .shutdown =    devshutdown,
    .attach   =    consattach,
    .walk     =    conswalk,
    .stat     =    consstat,
    .open     =    consopen,
    .create   =    devcreate,
    .close    =    consclose,
    .read     =    consread,
    .bread    =    devbread,
    .write    =    conswrite,
    .bwrite   =    devbwrite,
    .remove   =    devremove,
    .wstat    =    devwstat,
};
@ 

\subsection{Other}

<<global sysname>>=
char    *sysname;
@ 

\section{Special devices}
%optional, advanced concepts

% see also devpipe.c and devdup.c, devmnt.c, devsrv.c

\chapter{Filesystems}

\section{Helpers}

<<function devdir>>=
void
devdir(Chan *c, Qid qid, char *n, vlong length, char *user, long perm, Dir *db)
{
    db->name = n;
    if(c->flag&CMSG)
        qid.type |= QTMOUNT;
    db->qid = qid;
    db->type = devtab[c->type]->dc;
    db->dev = c->dev;
    db->mode = perm;
    db->mode |= qid.type << 24;
    db->atime = seconds();
    db->mtime = kerndate;
    db->length = length;
    db->uid = user;
    db->gid = eve;
    db->muid = user;
}
@

<<function devgen>>=
/*
 * (here, Devgen is the prototype; devgen is the function in dev.c.)
 * 
 * a Devgen is expected to return the directory entry for ".."
 * if you pass it s==DEVDOTDOT (-1).  otherwise...
 * 
 * there are two contradictory rules.
 * 
 * (i) if c is a directory, a Devgen is expected to list its children
 * as you iterate s.
 * 
 * (ii) whether or not c is a directory, a Devgen is expected to list
 * its siblings as you iterate s.
 * 
 * devgen always returns the list of children in the root
 * directory.  thus it follows (i) when c is the root and (ii) otherwise.
 * many other Devgens follow (i) when c is a directory and (ii) otherwise.
 * 
 * devwalk assumes (i).  it knows that devgen breaks (i)
 * for children that are themselves directories, and explicitly catches them.
 * 
 * devstat assumes (ii).  if the Devgen in question follows (i)
 * for this particular c, devstat will not find the necessary info.
 * with our particular Devgen functions, this happens only for
 * directories, so devstat makes something up, assuming
 * c->name, c->qid, eve, DMDIR|0555.
 * 
 * devdirread assumes (i).  the callers have to make sure
 * that the Devgen satisfies (i) for the chan being read.
 */
/*
 * the zeroth element of the table MUST be the directory itself for ..
*/
int
devgen(Chan *c, char *name, Dirtab *tab, int ntab, int i, Dir *dp)
{
    if(tab == 0)
        return -1;
    if(i == DEVDOTDOT){
        /* nothing */
    }else if(name){
        for(i=1; i<ntab; i++)
            if(strcmp(tab[i].name, name) == 0)
                break;
        if(i==ntab)
            return -1;
        tab += i;
    }else{
        /* skip over the first element, that for . itself */
        i++;
        if(i >= ntab)
            return -1;
        tab += i;
    }
    devdir(c, tab->qid, tab->name, tab->length, eve, tab->perm, dp);
    return 1;
}
@


<<function devattach>>=
Chan*
devattach(int tc, char *spec)
{
    int n;
    Chan *c;
    char *buf;

    c = newchan();
    mkqid(&c->qid, 0, 0, QTDIR);
    c->type = devno(tc, 0);
    if(spec == nil)
        spec = "";
    n = 1+UTFmax+strlen(spec)+1;
    buf = smalloc(n);
    snprint(buf, n, "#%C%s", tc, spec);
    c->path = newpath(buf);
    free(buf);
    return c;
}
@


<<function devclone>>=
Chan*
devclone(Chan *c)
{
    Chan *nc;

    if(c->flag & COPEN)
        panic("clone of open file type %C\n", devtab[c->type]->dc);

    nc = newchan();

    nc->type = c->type;
    nc->dev = c->dev;
    nc->mode = c->mode;
    nc->qid = c->qid;
    nc->offset = c->offset;
    nc->umh = nil;
    nc->aux = c->aux;
    nc->mqid = c->mqid;
    nc->mcp = c->mcp;
    return nc;
}
@


<<function devwalk>>=
Walkqid*
devwalk(Chan *c, Chan *nc, char **name, int nname, Dirtab *tab, int ntab, Devgen *gen)
{
    int i, j, alloc;
    Walkqid *wq;
    char *n;
    Dir dir;

    if(nname > 0)
        isdir(c);

    alloc = 0;
    wq = smalloc(sizeof(Walkqid)+(nname-1)*sizeof(Qid));
    if(waserror()){
        if(alloc && wq->clone!=nil)
            cclose(wq->clone);
        free(wq);
        return nil;
    }
    if(nc == nil){
        nc = devclone(c);
        nc->type = 0;   /* device doesn't know about this channel yet */
        alloc = 1;
    }
    wq->clone = nc;

    for(j=0; j<nname; j++){
        if(!(nc->qid.type&QTDIR)){
            if(j==0)
                error(Enotdir);
            goto Done;
        }
        n = name[j];
        if(strcmp(n, ".") == 0){
    Accept:
            wq->qid[wq->nqid++] = nc->qid;
            continue;
        }
        if(strcmp(n, "..") == 0){
            if((*gen)(nc, nil, tab, ntab, DEVDOTDOT, &dir) != 1){
                print("devgen walk .. in dev%s %llux broken\n",
                    devtab[nc->type]->name, nc->qid.path);
                error("broken devgen");
            }
            nc->qid = dir.qid;
            goto Accept;
        }
        /*
         * Ugly problem: If we're using devgen, make sure we're
         * walking the directory itself, represented by the first
         * entry in the table, and not trying to step into a sub-
         * directory of the table, e.g. /net/net. Devgen itself
         * should take care of the problem, but it doesn't have
         * the necessary information (that we're doing a walk).
         */
        if(gen==devgen && nc->qid.path!=tab[0].qid.path)
            goto Notfound;
        for(i=0;; i++) {
            switch((*gen)(nc, n, tab, ntab, i, &dir)){
            case -1:
            Notfound:
                if(j == 0)
                    error(Enonexist);
                kstrcpy(up->errstr, Enonexist, ERRMAX);
                goto Done;
            case 0:
                continue;
            case 1:
                if(strcmp(n, dir.name) == 0){
                    nc->qid = dir.qid;
                    goto Accept;
                }
                continue;
            }
        }
    }
    /*
     * We processed at least one name, so will return some data.
     * If we didn't process all nname entries succesfully, we drop
     * the cloned channel and return just the Qids of the walks.
     */
Done:
    poperror();
    if(wq->nqid < nname){
        if(alloc)
            cclose(wq->clone);
        wq->clone = nil;
    }else if(wq->clone){
        /* attach cloned channel to same device */
        wq->clone->type = c->type;
    }
    return wq;
}
@


<<function devstat>>=
int
devstat(Chan *c, uchar *db, int n, Dirtab *tab, int ntab, Devgen *gen)
{
    int i;
    Dir dir;
    char *p, *elem;

    for(i=0;; i++){
        switch((*gen)(c, nil, tab, ntab, i, &dir)){
        case -1:
            if(c->qid.type & QTDIR){
                if(c->path == nil)
                    elem = "???";
                else if(strcmp(c->path->s, "/") == 0)
                    elem = "/";
                else
                    for(elem=p=c->path->s; *p; p++)
                        if(*p == '/')
                            elem = p+1;
                devdir(c, c->qid, elem, 0, eve, DMDIR|0555, &dir);
                n = convD2M(&dir, db, n);
                if(n == 0)
                    error(Ebadarg);
                return n;
            }

            error(Enonexist);
        case 0:
            break;
        case 1:
            if(c->qid.path == dir.qid.path) {
                if(c->flag&CMSG)
                    dir.mode |= DMMOUNT;
                n = convD2M(&dir, db, n);
                if(n == 0)
                    error(Ebadarg);
                return n;
            }
            break;
        }
    }
}
@

% could not be a local var of devdirread?
<<[[Chan]] other fields>>=
int dri;      /* devdirread index */
@

<<function devdirread>>=
long
devdirread(Chan *c, char *d, long n, Dirtab *tab, int ntab, Devgen *gen)
{
    long m, dsz;
    Dir dir;

    for(m=0; m<n; c->dri++) {
        switch((*gen)(c, nil, tab, ntab, c->dri, &dir)){
        case -1:
            return m;

        case 0:
            break;

        case 1:
            dsz = convD2M(&dir, (uchar*)d, n-m);
            if(dsz <= BIT16SZ){ /* <= not < because this isn't stat; read is stuck */
                if(m == 0)
                    error(Eshort);
                return m;
            }
            m += dsz;
            d += dsz;
            break;
        }
    }

    return m;
}
@

<<function devpermcheck>>=
/*
 * error(Eperm) if open permission not granted for up->user.
 */
void
devpermcheck(char *fileuid, ulong perm, int omode)
{
    ulong t;
    static int access[] = { 0400, 0200, 0600, 0100 };

    if(strcmp(up->user, fileuid) == 0)
        perm <<= 0;
    else
    if(strcmp(up->user, eve) == 0)
        perm <<= 3;
    else
        perm <<= 6;

    t = access[omode&3];
    if((t&perm) != t)
        error(Eperm);
}
@

<<function devopen>>=
Chan*
devopen(Chan *c, int omode, Dirtab *tab, int ntab, Devgen *gen)
{
    int i;
    Dir dir;

    for(i=0;; i++) {
        switch((*gen)(c, nil, tab, ntab, i, &dir)){
        case -1:
            goto Return;
        case 0:
            break;
        case 1:
            if(c->qid.path == dir.qid.path) {
                devpermcheck(dir.uid, dir.mode, omode);
                goto Return;
            }
            break;
        }
    }
Return:
    c->offset = 0;
    if((c->qid.type&QTDIR) && omode!=OREAD)
        error(Eperm);
    c->mode = openmode(omode);
    c->flag |= COPEN;
    return c;
}
@


<<function devbread>>=
Block*
devbread(Chan *c, long n, ulong offset)
{
    Block *bp;

    bp = allocb(n);
    if(bp == 0)
        error(Enomem);
    if(waserror()) {
        freeb(bp);
        nexterror();
    }
    bp->wp += devtab[c->type]->read(c, bp->wp, n, offset);
    poperror();
    return bp;
}
@


<<function devbrwrite>>=
long
devbwrite(Chan *c, Block *bp, ulong offset)
{
    long n;

    if(waserror()) {
        freeb(bp);
        nexterror();
    }
    n = devtab[c->type]->write(c, bp->rp, BLEN(bp), offset);
    poperror();
    freeb(bp);

    return n;
}
@

\section{The root filesystem}
% root device, root filesystem

% just with that we can already have a working environment
% with a memory fs! where all binaries are processed via data2txt

% also see the trick with data2txt to get an initial rootfs
% that is not too bad, that allows for instance to have dossrv
% so can boostrap the whole thing

%#/

<<global rootdevtab>>=
Dev rootdevtab = {
    .dc       = '/',
    .name     = "root",
  
    .reset    = rootreset,
    .init     = devinit,
    .shutdown = devshutdown,
    .attach   = rootattach,
    .walk     = rootwalk,
    .stat     = rootstat,
    .open     = rootopen,
    .create   = devcreate,
    .close    = rootclose,
    .read     = rootread,
    .bread    = devbread,
    .write    = rootwrite,
    .bwrite   = devbwrite,
    .remove   = devremove,
    .wstat    = devwstat,
};
@

<<devroot enum Qxxx>>=
enum
{
    Qdir = 0,
    Qboot = 0x1000,

    Nrootfiles = 32,
    Nbootfiles = 32,
};
@


<<struct Dirlist>>=
struct Dirlist
{
    uint base; // for unique qids
    Dirtab *dir;
    uchar **data;
    int ndir; // number of dir used
    int mdir; // max dir entries
};
@


<<globals rootdir, rootdata, rootlist>>=
static Dirtab rootdir[Nrootfiles] = {
  {
    .name = "#/",
    .qid = {Qdir, 0, QTDIR},
    .length = 0,
    .perm = DMDIR|0555,
  },
  {    
    .name = "boot", 
    .qid = {Qboot, 0, QTDIR},
    .length = 0,
    .perm = DMDIR|0555,
  }
};
static uchar *rootdata[Nrootfiles];
static Dirlist rootlist = 
{
  .base = 0,
  .dir = rootdir,
  .data = rootdata,
  .ndir = 2,
  .mdir = Nrootfiles
};
@


<<globals bootdir, bootdata, bootlist>>=
static Dirtab bootdir[Nbootfiles] = {
  {
    .name = "boot",
    .qid = {Qboot, 0, QTDIR},
    .length = 0,
    .perm = DMDIR|0555,
  }
};

static uchar *bootdata[Nbootfiles];
static Dirlist bootlist =
{
    .base = Qboot,
    .dir = bootdir,
    .data = bootdata,
    .ndir = 1,
    .mdir = Nbootfiles
};
@


<<function addlist>>=
/*
 *  add a file to the list
 */
static void
addlist(Dirlist *l, char *name, uchar *contents, ulong len, int perm)
{
    Dirtab *d;

    if(l->ndir >= l->mdir)
        panic("too many root files");
    l->data[l->ndir] = contents;
    d = &l->dir[l->ndir];
    strcpy(d->name, name);
    d->length = len;
    d->perm = perm;
    d->qid.type = 0;
    d->qid.vers = 0;
    d->qid.path = ++l->ndir + l->base;
    if(perm & DMDIR)
        d->qid.type |= QTDIR;
}
@


<<function addbootfile>>=
/*
 *  add a boot file
 */
void
addbootfile(char *name, uchar *contents, ulong len)
{
    addlist(&bootlist, name, contents, len, 0555);
}
@


<<function addrootdir>>=
/*
 *  add a root directory
 */
static void
addrootdir(char *name)
{
    addlist(&rootlist, name, nil, 0, DMDIR|0555);
}
@


<<method rootreset>>=
static void
rootreset(void)
{
    addrootdir("bin");
    addrootdir("dev");
    addrootdir("env");
    addrootdir("fd");
    addrootdir("mnt");
    addrootdir("net");
    addrootdir("net.alt");
    addrootdir("proc");
    addrootdir("root");
    addrootdir("srv");
}
@


<<function rootgen>>=
static int
rootgen(Chan *c, char *name, Dirtab*, int, int s, Dir *dp)
{
    int t;
    Dirtab *d;
    Dirlist *l;

    switch((int)c->qid.path){
    case Qdir:
        if(s == DEVDOTDOT){
            devdir(c, (Qid){Qdir, 0, QTDIR}, "#/", 0, eve, 0555, dp);
            return 1;
        }
        return devgen(c, name, rootlist.dir, rootlist.ndir, s, dp);
    case Qboot:
        if(s == DEVDOTDOT){
            devdir(c, (Qid){Qdir, 0, QTDIR}, "#/", 0, eve, 0555, dp);
            return 1;
        }
        return devgen(c, name, bootlist.dir, bootlist.ndir, s, dp);
    default:
        if(s == DEVDOTDOT){
            if((int)c->qid.path < Qboot)
                devdir(c, (Qid){Qdir, 0, QTDIR}, "#/", 0, eve, 0555, dp);
            else
                devdir(c, (Qid){Qboot, 0, QTDIR}, "#/", 0, eve, 0555, dp);
            return 1;
        }
        if(s != 0)
            return -1;
        if((int)c->qid.path < Qboot){
            t = c->qid.path-1;
            l = &rootlist;
        }else{
            t = c->qid.path - Qboot - 1;
            l = &bootlist;
        }
        if(t >= l->ndir)
            return -1;
        d = &l->dir[t];
        devdir(c, d->qid, d->name, d->length, eve, d->perm, dp);
        return 1;
    }
}
@

%if(t < 0){
%print("rootgen %llud %d %d\n", c->qid.path, s, t);
%panic("whoops");
%}

<<method rootread>>=
static long
rootread(Chan *c, void *buf, long n, vlong off)
{
    ulong t;
    Dirtab *d;
    Dirlist *l;
    uchar *data;
    ulong offset = off;

    t = c->qid.path;
    switch(t){
    case Qdir:
    case Qboot:
        return devdirread(c, buf, n, nil, 0, rootgen);
    }

    if(t<Qboot)
        l = &rootlist;
    else{
        t -= Qboot;
        l = &bootlist;
    }

    t--;
    if(t >= l->ndir)
        error(Egreg);

    d = &l->dir[t];
    data = l->data[t];
    if(offset >= d->length)
        return 0;
    if(offset+n > d->length)
        n = d->length - offset;
#ifdef asdf
print("[%d] kaddr %.8ulx base %.8ulx offset %ld (%.8ulx), n %d %.8ulx %.8ulx %.8ulx\n", 
        t, buf, data, offset, offset, n,
        ((ulong*)(data+offset))[0],
        ((ulong*)(data+offset))[1],
        ((ulong*)(data+offset))[2]);
#endif asdf
    memmove(buf, data+offset, n);
    return n;
}
@

\section{Kenfs}
% would be good to have a simplefs ...

\chapter{Fileservers}
\minitoc
% put after Devices? after all Device and file servers
% are similar, they also implement the Dev interface
% it's just that they provide a Dev on top of another Dev

\section{Overview}

% intro to architecture? vs micro kernel?
% ref to FUSE?
% explain RPC? 9p

\section{[[MntRpc]]}

<<struct Mntrpc>>=
struct Mntrpc
{
  Chan* c;    /* Channel for whom we are working */
  Mntrpc* list;   /* Free/pending list */
  Fcall request;  /* Outgoing file system protocol message */
  Fcall   reply;    /* Incoming reply */
  Mnt*  m;    /* Mount device during rpc */
  Rendez  r;    /* Place to hang out */
  uchar*  rpc;    /* I/O Data buffer */
  uint  rpclen;   /* len of buffer */
  Block *b;   /* reply blocks */
  char  done;   /* Rpc completed */
  uvlong  stime;    /* start time for mnt statistics */
  ulong reqlen;   /* request length for mnt statistics */
  ulong replen;   /* reply length for mnt statistics */
  Mntrpc* flushed;  /* message this one flushes */
};
@


\section{[[devmnt.c]]}

\section{[[devsrv.c]]}


\section{[[devfs.c]]}

\section{Ramfs}

\section{Dossrv}


\chapter{Time}
\minitoc

<<systab time syscalls>>=
    [SLEEP]     syssleep,
    [ALARM]     sysalarm,
@

<<[[Cpu]] [[Arch]] other fields>>=
// for perfticks, tsc = time stamp counter
bool havetsc;
@

\section{Overview}

% different capabilities? timer, clock, rtc, ??

<<[[PCArch]] time methods fields>>=
void  (*clockenable)(void);
uvlong  (*fastclock)(uvlong*);
void  (*timerset)(uvlong);
@

<<[[archgeneric]] time methods>>=
.clockenable=   i8253enable,
.fastclock= i8253read,
.timerset=  i8253timerset,
@

<<global fasthz>>=
vlong   fasthz;
@ 


\section{Time units}

<<type Txxx>>=
typedef vlong   Tval; // ticks
typedef vlong   Tnano; // nanoseconds
typedef vlong   Tmicro; // microseconds
typedef int     Tms; // milliseconds
typedef vlong   Tsec; // seconds
@

<<function tk2ms>>=
/*
 *  This tk2ms avoids overflows that the macro version is prone to.
 *  It is a LOT slower so shouldn't be used if you're just converting
 *  a delta.
 */
ulong
tk2ms(ulong ticks)
{
    uvlong t, hz;

    t = ticks;
    hz = HZ;
    t *= 1000L;
    t = t/hz;
    ticks = t;
    return ticks;
}
@ 


<<function ms2tk>>=
ulong
ms2tk(ulong ms)
{
    /* avoid overflows at the cost of precision */
    if(ms >= 1000000000/HZ)
        return (ms/1000)*HZ;
    return (ms*HZ+500)/1000;
}
@ 


<<function us>>=
ulong
s(void)
{
    return fastticks2us((*arch->fastclock)(nil));
}
@


<<function fastticks>>=
/*
 *  return value and speed of timer set in arch->clockenable
 */
uvlong
devarch_fastticks(uvlong *hz)
{
    return (*arch->fastclock)(hz);
}
@


<<function cycles and default implementation>>=
static void
simplecycles(uvlong*x)
{
    *x = cpu->ticks;
}

void    (*cycles)(uvlong*) = simplecycles;
@ 


\section{Timers}

% capacity of machine is very low, just timer next point
%  but have many processes, many timer needs, so need map
%  all of that on very limited hardware power



\subsection{[[timerset()]]}

<<function timerset>>=
// used to be static, but now shared between arch.c and devarch.c
int doi8253set = 1;
/*
 *  set next timer interrupt
 */
void
timerset(Tval x)
{
    if(doi8253set)
        (*arch->timerset)(x);
}
@

<<function i8253timerset>>=
void
i8253timerset(uvlong next)
{
    long period;
    ulong want;
    ulong now;

    period = MaxPeriod;
    if(next != 0){
        want = next>>Tickshift;
        now = i8253.ticks;  /* assuming whomever called us just did fastticks() */

        period = want - now;
        if(period < MinPeriod)
            period = MinPeriod;
        else if(period > MaxPeriod)
            period = MaxPeriod;
    }

    /* hysteresis */
    if(i8253.period != period){
        ilock(&i8253);
        /* load new value */
        outb(Tmode, Load0|Square);
        outb(T0cntr, period);       /* low byte */
        outb(T0cntr, period >> 8);      /* high byte */

        /* remember period */
        i8253.period = period;
        i8253.periodset++;
        iunlock(&i8253);
    }
}
@

\subsection{[[Timer]] and [[Timers]]}

<<struct Timer>>=
struct Timer
{
    /* Public interface */
    // enum<timermode>
    int tmode;    /* See above */
    Tnano tns;    /* meaning defined by mode */ //nanosecond
    void  (*tf)(Ureg*, Timer*);
    void  *ta;
  
    /* Internal */
    Lock;
    Tval  tticks;   /* tns converted to ticks */
    Tval  twhen;    /* ns represented in fastticks */

    <<[[Timer extra fields>>
    };
@ 

<<enum timermode>>=
/*
 * fasttick timer interrupts
 */
enum timermode 
{
    Trelative,  /* timer programmed in ns from now */
    Tperiodic,  /* periodic timer, period in ns */
};
@ 

<<struct Timers>>=
struct Timers
{
    // list<Timer> (next = Timer.tnext)
    Timer *head;
    // extra
    Lock;
};
@ 

<<[[Timer extra fields>>=
// list<Timer> of Timers.head
Timer *tnext;
// ref<list<Timer>> Timers.head
Timers  *tt;    /* Timers queue this timer runs on */
@


<<function tadd>>=
static Tval
tadd(Timers *tt, Timer *nt)
{
    Timer *t, **last;

    /* Called with tt locked */
    assert(nt->tt == nil);
    switch(nt->tmode){
    case Trelative:
        if(nt->tns <= 0)
            nt->tns = 1;
        nt->twhen = fastticks(nil) + ns2fastticks(nt->tns);
        break;
    case Tperiodic:
        assert(nt->tns >= 100000);  /* At least 100 s period */
        if(nt->twhen == 0){
            /* look for another timer at same frequency for combining */
            for(t = tt->head; t; t = t->tnext){
                if(t->tmode == Tperiodic && t->tns == nt->tns)
                    break;
            }
            if (t)
                nt->twhen = t->twhen;
            else
                nt->twhen = fastticks(nil);
        }
        nt->twhen += ns2fastticks(nt->tns);
        break;
    default:
        panic("timer: impossible");
        break;
    }

    for(last = &tt->head; t = *last; last = &t->tnext){
        if(t->twhen > nt->twhen)
            break;
    }
    nt->tnext = *last;
    *last = nt;
    nt->tt = tt;
    if(last == &tt->head)
        return nt->twhen;
    return 0;
}
@ 


<<function tdel>>=
static Tval
tdel(Timer *dt)
{
    Timer *t, **last;
    Timers *tt;

    tt = dt->tt;
    if (tt == nil)
        return 0; // possible? panic("impossible") would be better no?
    for(last = &tt->head; t = *last; last = &t->tnext){
        if(t == dt){
            assert(dt->tt);
            dt->tt = nil;
            *last = t->tnext;
            break;
        }
    }
    if(last == &tt->head && tt->head)
        return tt->head->twhen;
    return 0;
}
@ 

\subsection{[[timers]]}
<<global timers>>=
static Timers timers[MAXCPUS];
@ 

<<function timeradd>>=
/* add or modify a timer */
void
timeradd(Timer *nt)
{
    Timers *tt;
    Tval when;

    /* Must lock Timer struct before Timers struct */
    ilock(nt);

    if(tt = nt->tt){
        ilock(tt);
        tdel(nt);
        iunlock(tt);
    }

    tt = &timers[cpu->cpuno];
    ilock(tt);
    when = tadd(tt, nt);
    if(when)
        timerset(when);
    iunlock(tt);
    iunlock(nt);
}
@ 

<<function timerdel>>=
void
timerdel(Timer *dt)
{
    Timers *tt;
    Tval when;

    ilock(dt);
    if(tt = dt->tt){
        ilock(tt);
        when = tdel(dt);
        if(when && tt == &timers[cpu->cpuno])
            timerset(tt->head->twhen);
        iunlock(tt);
    }
    iunlock(dt);
}
@ 


\subsection{Initialisation}

<<function timersinit>>=
void
timersinit(void)
{
    Timer *t;

    timersinited = true;
    todinit();

    t = malloc(sizeof(Timer));
    if(t == nil)
        error(Enomem);
    t->tmode = Tperiodic;
    t->tt = nil;
    t->tns = 1000000000/HZ;
    /*
     * T->tf == nil means the HZ clock for this processor.
     */
    t->tf = nil;
    timeradd(t);
}
@ 

\subsection{[[timerintr()]]}

<<interrupt callback timerintr>>=
// called via i8253clock
void
timerintr(Ureg *u, Tval)
{
    Timer *t;
    Timers *tt;
    uvlong when, now;
    int count, callhzclock;

    intrcount[cpu->cpuno]++;
    callhzclock = 0;
    tt = &timers[cpu->cpuno];
    now = fastticks(nil);
    if(now == 0)
        panic("timerintr: zero fastticks()");
    ilock(tt);
    count = Maxtimerloops;
    while((t = tt->head) != nil){
        /*
         * No need to ilock t here: any manipulation of t
         * requires tdel(t) and this must be done with a
         * lock to tt held.  We have tt, so the tdel will
         * wait until we're done
         */
        when = t->twhen;
        if(when > now){
            timerset(when);
            iunlock(tt);
            if(callhzclock)
                hzclock(u);
            return;
        }
        tt->head = t->tnext;
        assert(t->tt == tt);
        t->tt = nil;
        fcallcount[cpu->cpuno]++;
        iunlock(tt);
        if(t->tf)
            (*t->tf)(u, t);
        else
            callhzclock++;
        ilock(tt);
        if(t->tmode == Tperiodic)
            tadd(tt, t);
        if (--count <= 0) {
            count = Maxtimerloops;
            iprint("timerintr: probably stuck in while loop; "
                "scrutinise clock.c or use faster cycle "
                "counter\n");
        }
    }
    iunlock(tt);
}
@ 

\subsection{Clock callbacks}

<<function addclock0link>>=
Timer*
addclock0link(void (*f)(void), Tms ms)
{
    Timer *nt;
    Tval when;

    if(!timersinited)
        panic("addclock0link: timersinit not called yet");

    /* Synchronize to hztimer if ms is 0 */
    nt = malloc(sizeof(Timer));
    if(nt == nil)
        error(Enomem);
    if(ms == 0)
        ms = 1000/HZ;

    nt->tns = (Tnano)ms*1000000LL;
    nt->tmode = Tperiodic;
    nt->tt = nil;
    nt->tf = (void (*)(Ureg*, Timer*))f;

    // those clock callbacks are all done on the bootstrap processor
    //dupe: timeradd() but with forced processor number
    ilock(&timers[0]);
    when = tadd(&timers[0], nt);
    if(when)
        timerset(when);
    iunlock(&timers[0]);
    return nt;
}
@ 

\section{[[syssleep()]]}

<<[[Proc]] synchronization fields>>=
Rendez  sleepr;    /* place for syssleep/debug/tsleep */
@ 

<<syscall sleep>>=
// int sleep(long millisecs);
long
syssleep(ulong *arg)
{
    int n;
    n = arg[0];
    if(n <= 0) {
        <<[[syssleep()]] optional [[edfyield()]] for real-time scheduling>>
        yield();
        return 0;
    }
    if(n < TK2MS(1))
        n = TK2MS(1);
    tsleep(&up->sleepr, returnfalse, 0, n);
    return 0;
}
@ 

% time field?
<<[[Proc]] other fields>>=
Timer;      /* For tsleep and real-time */
Rendez  *trend;
int (*tfn)(void*);
@

<<function tsleep>>=
void
proc_tsleep(Rendez *r, int (*fn)(void*), void *arg, ulong ms)
{
    if (up->tt){
        print("tsleep: timer active: mode %d, tf %#p\n", up->tmode, up->tf);
        timerdel(up);
    }
    up->tns = MS2NS(ms);
    up->tf = twakeup;
    up->tmode = Trelative;
    up->ta = up;
    up->trend = r;
    up->tfn = fn;
    timeradd(up);

    if(waserror()){
        timerdel(up);
        nexterror();
    }
    sleep(r, tfn, arg);
    if(up->tt)
        timerdel(up);
    up->twhen = 0;
    poperror();
}
@ 


\section{[[sysalarm()]]}
%related? tsleep, tsemacquire

<<struct Alarms>>=
struct Alarms
{
    // list<ref<Proc> (next = Proc.palarm)
    Proc  *head;
    // extra
    QLock;
};
@ 

<<[[Proc]] extra fields>>=
// Alarms.head chain?
Proc  *palarm;  /* Next alarm time */
@

<<global alarms>>=
static Alarms   alarms;
@ 

<<syscall alarm>>=
// long alarm(unsigned long millisecs);
long
sysalarm(ulong *arg)
{
    return procalarm(arg[0]);
}
@ 

% have a [[Proc]] time field?
<<[[Proc]] other fields>>=
ulong alarm;    /* Time of call */
@

<<function procalarm>>=
ulong
procalarm(ulong time)
{
    Proc **l, *f;
    ulong when, old;

    if(up->alarm)
        old = tk2ms(up->alarm - CPUS(0)->ticks);
    else
        old = 0;
    if(time == 0) {
        up->alarm = 0;
        return old;
    }
    when = ms2tk(time)+CPUS(0)->ticks;
    if(when == 0)       /* ticks have wrapped to 0? */
        when = 1;   /* distinguish a wrapped alarm from no alarm */

    qlock(&alarms);
    l = &alarms.head;
    for(f = *l; f; f = f->palarm) {
        if(up == f){
            *l = f->palarm;
            break;
        }
        l = &f->palarm;
    }

    up->palarm = 0;
    if(alarms.head) {
        l = &alarms.head;
        for(f = *l; f; f = f->palarm) {
            if((long)(f->alarm - when) >= 0) {
                up->palarm = f;
                *l = up;
                goto done;
            }
            l = &f->palarm;
        }
        *l = up;
    }
    else
        alarms.head = up;
done:
    up->alarm = when;
    qunlock(&alarms);

    return old;
}
@ 





<<global alarmr>>=
static Rendez alarmr;
@ 

<<kernel process alarmkproc>>=
// Kernel Process for alarm managment
void
alarmkproc(void*)
{
    Proc *rp;
    ulong now;

    for(;;){
        now = CPUS(0)->ticks;
        qlock(&alarms);
        /*
         * the odd test of now vs. rp->alarm is to cope with
         * now wrapping around.
         */
        while((rp = alarms.head) && (long)(now - rp->alarm) >= 0){
            if(rp->alarm != 0L){
                if(canqlock(&rp->debug)){
                    if(!waserror()){
                        postnote(rp, 0, "alarm", NUser);
                        poperror();
                    }
                    qunlock(&rp->debug);
                    rp->alarm = 0L;
                }else
                    break;
            }
            alarms.head = rp->palarm;
        }
        qunlock(&alarms);

        sleep(&alarmr, returnfalse, 0);
    }
}
@ 


<<function checkalarms>>=
/*
 *  called every clock tick
 */
void
checkalarms(void)
{
    Proc *p;
    ulong now;

    p = alarms.head;
    now = CPUS(0)->ticks;

    if(p && (long)(now - p->alarm) >= 0)
        wakeup(&alarmr);
}
@ 

\section{Real time clock}


\section{Time of day}

<<struct TOD>>=
struct TOD {
    int init;       /* true if initialized */
    ulong   cnt;
    Lock;
    uvlong  multiplier; /* ns = off + (multiplier*ticks)>>31 */
    uvlong  divider;    /* ticks = (divider*(ns-off))>>31 */
    uvlong  umultiplier;    /* s = (multiplier*ticks)>>31 */
    uvlong  udivider;   /* ticks = (divider*s)>>31 */
    vlong   hz;     /* frequency of fast clock */
    vlong   last;       /* last reading of fast clock */
    vlong   off;        /* offset from epoch to last */
    vlong   lasttime;   /* last return value from todget */
    vlong   delta;  /* add 'delta' each slow clock tick from sstart to send */
    ulong   sstart;     /* ... */
    ulong   send;       /* ... */
};
@ 


<<global tod>>=
struct TOD tod;
@ 


<<devcons.c Exxx errors>>=
char *Ebadtimectl = "bad time control";
@

<<function readtime>>=
/*
 *  like the old #c/time but with added info.  Return
 *
 *  secs    nanosecs    fastticks   fasthz
 */
static int
readtime(ulong off, char *buf, int n)
{
    vlong   nsec, ticks;
    long sec;
    char str[7*NUMSIZE];

    nsec = todget(&ticks);
    if(fasthz == 0LL)
        fastticks((uvlong*)&fasthz);
    sec = nsec/1000000000ULL;
    snprint(str, sizeof(str), "%*lud %*llud %*llud %*llud ",
        NUMSIZE-1, sec,
        VLNUMSIZE-1, nsec,
        VLNUMSIZE-1, ticks,
        VLNUMSIZE-1, fasthz);
    return readstr(off, buf, n, str);
}
@


<<function writetime>>=
/*
 *  set the time in seconds
 */
static int
writetime(char *buf, int n)
{
    char b[13];
    long i;
    vlong now;

    if(n >= sizeof(b))
        error(Ebadtimectl);
    strncpy(b, buf, n);
    b[n] = 0;
    i = strtol(b, 0, 0);
    if(i <= 0)
        error(Ebadtimectl);
    now = i*1000000000LL;
    todset(now, 0, 0);
    return n;
}
@


<<function readbintime>>=
/*
 *  read binary time info.  all numbers are little endian.
 *  ticks and nsec are syncronized.
 */
static int
readbintime(char *buf, int n)
{
    int i;
    vlong nsec, ticks;
    uchar *b = (uchar*)buf;

    i = 0;
    if(fasthz == 0LL)
        fastticks((uvlong*)&fasthz);
    nsec = todget(&ticks);
    if(n >= 3*sizeof(uvlong)){
        vlong2le(b+2*sizeof(uvlong), fasthz);
        i += sizeof(uvlong);
    }
    if(n >= 2*sizeof(uvlong)){
        vlong2le(b+sizeof(uvlong), ticks);
        i += sizeof(uvlong);
    }
    if(n >= 8){
        vlong2le(b, nsec);
        i += sizeof(vlong);
    }
    return i;
}
@


<<function writebintime>>=
/*
 *  set any of the following
 *  - time in nsec
 *  - nsec trim applied over some seconds
 *  - clock frequency
 */
static int
writebintime(char *buf, int n)
{
    uchar *p;
    vlong delta;
    long period;

    n--;
    p = (uchar*)buf + 1;
    switch(*buf){
    case 'n':
        if(n < sizeof(vlong))
            error(Ebadtimectl);
        le2vlong(&delta, p);
        todset(delta, 0, 0);
        break;
    case 'd':
        if(n < sizeof(vlong)+sizeof(long))
            error(Ebadtimectl);
        p = le2vlong(&delta, p);
        le2long(&period, p);
        todset(-1, delta, period);
        break;
    case 'f':
        if(n < sizeof(uvlong))
            error(Ebadtimectl);
        le2vlong(&fasthz, p);
        if(fasthz <= 0)
            error(Ebadtimectl);
        todsetfreq(fasthz);
        break;
    }
    return n;
}
@

\section{[[/dev/rtc]]}

<<struct Rtc>>=
struct Rtc
{
    int sec;
    int min;
    int hour;
    int mday;
    int mon;
    int year;
};
@


<<global rtcdevtab>>=
Dev rtcdevtab = {
    .dc       =    'r',
    .name     =    "rtc",
               
    .reset    =    devreset,
    .init     =    rtcinit,
    .shutdown =    devshutdown,
    .attach   =    rtcattach,
    .walk     =    rtcwalk,
    .stat     =    rtcstat,
    .open     =    rtcopen,
    .create   =    devcreate,
    .close    =    rtcclose,
    .read     =    rtcread,
    .bread    =    devbread,
    .write    =    rtcwrite,
    .bwrite   =    devbwrite,
    .remove   =    devremove,
    .wstat    =    devwstat,
};
@

<<constants SEC2XXX>>=
#define SEC2MIN 60L
#define SEC2HOUR (60L*SEC2MIN)
#define SEC2DAY (24L*SEC2HOUR)
@

<<globals dmsize ldmsize>>=
/*
 *  days per month plus days/year
 */
static  int dmsize[] =
{
    365, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31
};
static  int ldmsize[] =
{
    366, 31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31
};
@

<<function yrsize>>=
/*
 *  return the days/month for the given year
 */
static int*
yrsize(int y)
{
    if((y%4) == 0 && ((y%100) != 0 || (y%400) == 0))
        return ldmsize;
    else
        return dmsize;
}
@

<<function rtc2sec>>=
/*
 *  compute seconds since Jan 1 1970
 */
static ulong
rtc2sec(Rtc *rtc)
{
    ulong secs;
    int i;
    int *d2m;

    secs = 0;

    /*
     *  seconds per year
     */
    for(i = 1970; i < rtc->year; i++){
        d2m = yrsize(i);
        secs += d2m[0] * SEC2DAY;
    }

    /*
     *  seconds per month
     */
    d2m = yrsize(rtc->year);
    for(i = 1; i < rtc->mon; i++)
        secs += d2m[i] * SEC2DAY;

    secs += (rtc->mday-1) * SEC2DAY;
    secs += rtc->hour * SEC2HOUR;
    secs += rtc->min * SEC2MIN;
    secs += rtc->sec;

    return secs;
}
@

<<function sec2rtc>>=
/*
 *  compute rtc from seconds since Jan 1 1970
 */
static void
sec2rtc(ulong secs, Rtc *rtc)
{
    int d;
    long hms, day;
    int *d2m;

    /*
     * break initial number into days
     */
    hms = secs % SEC2DAY;
    day = secs / SEC2DAY;
    if(hms < 0) {
        hms += SEC2DAY;
        day -= 1;
    }

    /*
     * generate hours:minutes:seconds
     */
    rtc->sec = hms % 60;
    d = hms / 60;
    rtc->min = d % 60;
    d /= 60;
    rtc->hour = d;

    /*
     * year number
     */
    if(day >= 0)
        for(d = 1970; day >= *yrsize(d); d++)
            day -= *yrsize(d);
    else
        for (d = 1970; day < 0; d--)
            day += *yrsize(d-1);
    rtc->year = d;

    /*
     * generate month
     */
    d2m = yrsize(rtc->year);
    for(d = 1; day >= d2m[d]; d++)
        day -= d2m[d];
    rtc->mday = day + 1;
    rtc->mon = d;

    return;
}
@


\chapter{IPC}
\minitoc

% of course can use fs to communicate between process :)
% also when fork child inherit fd and can share stuff there
% also child can communicate to parent fix exit code (if parent calls wait())

<<systab ipc syscalls>>=
    [NOTIFY]    sysnotify,
    [NOTED]     sysnoted,

    [PIPE]      syspipe,

    [SEGATTACH] syssegattach,
    [SEGDETACH] syssegdetach,
    [SEGFREE]   syssegfree,
    [SEGFLUSH]  syssegflush,
    [SEGBRK]    syssegbrk,
@ 

<<systab concurrency syscalls>>=
    [RENDEZVOUS]    sysrendezvous,

    [SEMACQUIRE]    syssemacquire,
    [SEMRELEASE]    syssemrelease,
    [TSEMACQUIRE]   systsemacquire,
@ 

\section{Notes (signals)}

<<enum notekind>>=
enum notekind
{
    NUser,        /* note provided externally */
    NExit,        /* deliver note quietly */
    NDebug,       /* print debug message */
};
@ 


<<struct Note>>=
// a kind of unix signal
struct Note
{
    char  msg[ERRMAX];
    // enum<notekind>
    int flag;     /* whether system posted it */
};
@ 


<<[[Proc]] notes fields>>=
Note  note[NNOTE];
short nnote;

int (*notify)(void*, char*);
short notified; /* sysnoted is due */

ulong noteid;   /* Equivalent of note group */

bool notepending;  /* note issued but not acted on */

Note  lastnote;

void  *ureg;    /* User registers for notes */
@ 

<<syscall notify>>=
// int notify(void (*f)(void*, char*));
long
sysnotify(ulong *arg)
{
    if(arg[0] != 0)
        validaddr(arg[0], sizeof(ulong), 0);
    up->notify = (int(*)(void*, char*))(arg[0]);
    return 0;
}
@ 

<<syscall noted>>=
// int noted(int v);
long
sysnoted(ulong *arg)
{
    if(arg[0]!=NRSTR && !up->notified)
        error(Egreg);
    return 0;
}
@ 

<<function postnote>>=
/*
 *  if waking a sleeping process, this routine must hold both
 *  p->rlock and r->lock.  However, it can't know them in
 *  the same order as wakeup causing a possible lock ordering
 *  deadlock.  We break the deadlock by giving up the p->rlock
 *  lock if we can't get the r->lock and retrying.
 */
int
proc_postnote(Proc *p, int dolock, char *n, int flag)
{
    int s, ret;
    Rendez *r;
    Proc *d, **l;

    if(dolock)
        qlock(&p->debug);

    if(flag != NUser && (p->notify == 0 || p->notified))
        p->nnote = 0;

    ret = 0;
    if(p->nnote < NNOTE) {
        strcpy(p->note[p->nnote].msg, n);
        p->note[p->nnote++].flag = flag;
        ret = 1;
    }
    p->notepending = true;
    if(dolock)
        qunlock(&p->debug);

    /* this loop is to avoid lock ordering problems. */
    for(;;){
        s = splhi();
        lock(&p->rlock);
        r = p->r;

        /* waiting for a wakeup? */
        if(r == nil)
            break;  /* no */

        /* try for the second lock */
        if(canlock(r)){
            if(p->state != Wakeme || r->p != p)
                panic("postnote: state %d %d %d", r->p != p, p->r != r, p->state);
            p->r = nil;
            r->p = nil;
            ready(p);
            unlock(r);
            break;
        }

        /* give other process time to get out of critical section and try again */
        unlock(&p->rlock);
        splx(s);
        sched();
    }
    unlock(&p->rlock);
    splx(s);

    if(p->state != Rendezvous)
        return ret;

    /* Try and pull out of a rendezvous */
    lock(p->rgrp);
    if(p->state == Rendezvous) {
        p->rendval = ~0;
        l = &REND(p->rgrp, p->rendtag);
        for(d = *l; d; d = d->rendhash) {
            if(d == p) {
                *l = p->rendhash;
                break;
            }
            l = &d->rendhash;
        }
        ready(p);
    }
    unlock(p->rgrp);
    return ret;
}
@ 

<<function notify>>=
/*
 *  Call user, if necessary, with note.
 *  Pass user the Ureg struct and the note on his stack.
 */
int
notify(Ureg* ureg)
{
    int l;
    ulong s, sp;
    Note *n;

    if(up->procctl)
        procctl(up); // a bit ugly to group procctl handling and note handling
    if(up->nnote == 0)
        return 0;

    if(up->fpstate == FPactive){
        fpsave(&up->fpsave);
        up->fpstate = FPinactive;
    }
    up->fpstate |= FPillegal;

    s = spllo();
    qlock(&up->debug);
    up->notepending = false;
    n = &up->note[0];
    if(strncmp(n->msg, "sys:", 4) == 0){
        l = strlen(n->msg);
        if(l > ERRMAX-15)   /* " pc=0x12345678\0" */
            l = ERRMAX-15;
        seprint(n->msg+l, &n->msg[sizeof n->msg], " pc=0x%.8lux",
            ureg->pc);
    }

    if(n->flag!=NUser && (up->notified || up->notify==0)){
        if(n->flag == NDebug)
            pprint("suicide: %s\n", n->msg);
        qunlock(&up->debug);
        pexit(n->msg, n->flag!=NDebug);
    }

    if(up->notified){
        qunlock(&up->debug);
        splhi();
        return 0;
    }

    if(!up->notify){
        qunlock(&up->debug);
        pexit(n->msg, n->flag!=NDebug);
    }
    sp = ureg->usp;
    sp -= 256;  /* debugging: preserve context causing problem */
    sp -= sizeof(Ureg);
if(0) print("%s %lud: notify %.8lux %.8lux %.8lux %s\n",
    up->text, up->pid, ureg->pc, ureg->usp, sp, n->msg);

    if(!okaddr((ulong)up->notify, 1, 0)
    || !okaddr(sp-ERRMAX-4*BY2WD, sizeof(Ureg)+ERRMAX+4*BY2WD, 1)){
        qunlock(&up->debug);
        pprint("suicide: bad address in notify\n");
        pexit("Suicide", false);
    }

    memmove((Ureg*)sp, ureg, sizeof(Ureg));
    *(Ureg**)(sp-BY2WD) = up->ureg; /* word under Ureg is old up->ureg */
    up->ureg = (void*)sp;
    sp -= BY2WD+ERRMAX;
    memmove((char*)sp, up->note[0].msg, ERRMAX);
    sp -= 3*BY2WD;
    *(ulong*)(sp+2*BY2WD) = sp+3*BY2WD;     /* arg 2 is string */
    *(ulong*)(sp+1*BY2WD) = (ulong)up->ureg;    /* arg 1 is ureg* */
    *(ulong*)(sp+0*BY2WD) = 0;          /* arg 0 is pc */
    ureg->usp = sp;
    ureg->pc = (ulong)up->notify;
    up->notified = 1;
    up->nnote--;
    memmove(&up->lastnote, &up->note[0], sizeof(Note));
    memmove(&up->note[0], &up->note[1], up->nnote*sizeof(Note));

    qunlock(&up->debug);
    splx(s);
    return 1;
}
@ 


<<function noted>>=
/*
 *   Return user to state before notify()
 */
void
noted(Ureg* ureg, ulong arg0)
{
    Ureg *nureg;
    ulong oureg, sp;

    qlock(&up->debug);
    if(arg0!=NRSTR && !up->notified) {
        qunlock(&up->debug);
        pprint("call to noted() when not notified\n");
        pexit("Suicide", false);
    }
    up->notified = 0;

    nureg = up->ureg;   /* pointer to user returned Ureg struct */

    up->fpstate &= ~FPillegal;

    /* sanity clause */
    oureg = (ulong)nureg;
    if(!okaddr((ulong)oureg-BY2WD, BY2WD+sizeof(Ureg), 0)){
        qunlock(&up->debug);
        pprint("bad ureg in noted or call to noted when not notified\n");
        pexit("Suicide", false);
    }

    /*
     * Check the segment selectors are all valid, otherwise
     * a fault will be taken on attempting to return to the
     * user process.
     * Take care with the comparisons as different processor
     * generations push segment descriptors in different ways.
     */
    if((nureg->cs & 0xFFFF) != UESEL || (nureg->ss & 0xFFFF) != UDSEL
      || (nureg->ds & 0xFFFF) != UDSEL || (nureg->es & 0xFFFF) != UDSEL
      || (nureg->fs & 0xFFFF) != UDSEL || (nureg->gs & 0xFFFF) != UDSEL){
        qunlock(&up->debug);
        pprint("bad segment selector in noted\n");
        pexit("Suicide", false);
    }

    /* don't let user change system flags */
    nureg->flags = (ureg->flags & ~0xCD5) | (nureg->flags & 0xCD5);

    memmove(ureg, nureg, sizeof(Ureg));

    switch(arg0){
    case NCONT:
    case NRSTR:
if(0) print("%s %lud: noted %.8lux %.8lux\n",
    up->text, up->pid, nureg->pc, nureg->usp);
        if(!okaddr(nureg->pc, 1, 0) || !okaddr(nureg->usp, BY2WD, 0)){
            qunlock(&up->debug);
            pprint("suicide: trap in noted\n");
            pexit("Suicide", false);
        }
        up->ureg = (Ureg*)(*(ulong*)(oureg-BY2WD));
        qunlock(&up->debug);
        break;

    case NSAVE:
        if(!okaddr(nureg->pc, BY2WD, 0)
        || !okaddr(nureg->usp, BY2WD, 0)){
            qunlock(&up->debug);
            pprint("suicide: trap in noted\n");
            pexit("Suicide", false);
        }
        qunlock(&up->debug);
        sp = oureg-4*BY2WD-ERRMAX;
        splhi();
        ureg->sp = sp;
        ((ulong*)sp)[1] = oureg;    /* arg 1 0(FP) is ureg* */
        ((ulong*)sp)[0] = 0;        /* arg 0 is pc */
        break;

    default:
        pprint("unknown noted arg 0x%lux\n", arg0);
        up->lastnote.flag = NDebug;
        /* fall through */

    case NDFLT:
        if(up->lastnote.flag == NDebug){
            qunlock(&up->debug);
            pprint("suicide: %s\n", up->lastnote.msg);
        } else
            qunlock(&up->debug);
        pexit(up->lastnote.msg, up->lastnote.flag!=NDebug);
    }
}
@ 


\section{Pipes}

\subsection{[[syspipe()]]}

<<syscall pipe>>=
// int pipe(int fd[2]);
long
syspipe(ulong *arg)
{
    int fd[2];
    Chan *c[2];
    Dev *d;
    static char *datastr[] = {"data", "data1"};

    validaddr(arg[0], 2*BY2WD, 1);
    evenaddr(arg[0]);
    d = devtab[devno('|', 0)];
    c[0] = namec("#|", Atodir, 0, 0);
    c[1] = nil;
    fd[0] = -1;
    fd[1] = -1;

    if(waserror()){
        cclose(c[0]);
        if(c[1])
            cclose(c[1]);
        nexterror();
    }
    c[1] = cclone(c[0]);
    if(walk(&c[0], datastr+0, 1, 1, nil) < 0)
        error(Egreg);
    if(walk(&c[1], datastr+1, 1, 1, nil) < 0)
        error(Egreg);
    c[0] = d->open(c[0], ORDWR);
    c[1] = d->open(c[1], ORDWR);
    if(newfd2(fd, c) < 0)
        error(Enofd);
    poperror();

    ((long*)arg[0])[0] = fd[0];
    ((long*)arg[0])[1] = fd[1];
    return 0;
}
@

\subsection{[[/dev/pipe]]}
% have pipe syscall and device, both useful? the syscall
% anyway calls the device, and named pipe
% can be done only via the device

<<struct Pipe>>=
struct Pipe
{
    int ref;
    ulong   path;
    long    perm;
    Queue   *q[2];
    int qref[2];

    // extra
    QLock;
    Pipe    *next;
};
@


<<struct Pipealloc>>=
struct Pipealloc
{
    ulong   path;

    // extra
    Lock;
};
@


<<global pipealloc>>=
struct Pipealloc pipealloc;
@


<<devpipe.c enum Qxxx>>=
enum
{
    Qdir,
    Qdata0,
    Qdata1,
};
@


<<global pipedir>>=
Dirtab pipedir[] =
{
    ".",        {Qdir,0,QTDIR}, 0,      DMDIR|0500,
    "data",     {Qdata0},   0,      0600,
    "data1",    {Qdata1},   0,      0600,
};
@

<<[[Conf]] other fields>>=
ulong pipeqsize;  /* size in bytes of pipe queues */
@ 

<<method pipeinit>>=
static void
pipeinit(void)
{
    if(conf.pipeqsize == 0){
        if(conf.ncpu > 1)
            conf.pipeqsize = 256*1024;
        else
            conf.pipeqsize = 32*1024;
    }
}
@

%TODO: use chanpipe below instead of chan
<<[[Chan]] union other fields>>=
/*Pipe*/void* chanpipe; // for pipes
@

<<method pipeattach>>=
/*
 *  create a pipe, no streams are created until an open
 */
static Chan*
pipeattach(char *spec)
{
    Pipe *p;
    Chan *c;

    c = devattach('|', spec);
    p = malloc(sizeof(Pipe));
    if(p == 0)
        exhausted("memory");
    p->ref = 1;

    p->q[0] = qopen(conf.pipeqsize, 0, 0, 0);
    if(p->q[0] == 0){
        free(p);
        exhausted("memory");
    }
    p->q[1] = qopen(conf.pipeqsize, 0, 0, 0);
    if(p->q[1] == 0){
        free(p->q[0]);
        free(p);
        exhausted("memory");
    }

    lock(&pipealloc);
    p->path = ++pipealloc.path;
    unlock(&pipealloc);
    p->perm = pipedir[Qdata0].perm;

    mkqid(&c->qid, NETQID(2*p->path, Qdir), 0, QTDIR);
    c->aux = p;
    c->dev = 0;
    return c;
}
@


<<function pipegen>>=
static int
pipegen(Chan *c, char*, Dirtab *tab, int ntab, int i, Dir *dp)
{
    Qid q;
    int len;
    Pipe *p;

    if(i == DEVDOTDOT){
        devdir(c, c->qid, "#|", 0, eve, DMDIR|0555, dp);
        return 1;
    }
    i++;    /* skip . */
    if(tab==0 || i>=ntab)
        return -1;

    tab += i;
    p = c->aux;
    switch((ulong)tab->qid.path){
    case Qdata0:
        len = qlen(p->q[0]);
        break;
    case Qdata1:
        len = qlen(p->q[1]);
        break;
    default:
        len = tab->length;
        break;
    }
    mkqid(&q, NETQID(NETID(c->qid.path), tab->qid.path), 0, QTFILE);
    devdir(c, q, tab->name, len, eve, p->perm, dp);
    return 1;
}
@


<<method pipewalk>>=
static Walkqid*
pipewalk(Chan *c, Chan *nc, char **name, int nname)
{
    Walkqid *wq;
    Pipe *p;

    wq = devwalk(c, nc, name, nname, pipedir, NPIPEDIR, pipegen);
    if(wq != nil && wq->clone != nil && wq->clone != c){
        p = c->aux;
        qlock(p);
        p->ref++;
        if(c->flag & COPEN){
            print("channel open in pipewalk\n");
            switch(NETTYPE(c->qid.path)){
            case Qdata0:
                p->qref[0]++;
                break;
            case Qdata1:
                p->qref[1]++;
                break;
            }
        }
        qunlock(p);
    }
    return wq;
}
@


<<method pipestat>>=
static int
pipestat(Chan *c, uchar *db, int n)
{
    Pipe *p;
    Dir dir;

    p = c->aux;

    switch(NETTYPE(c->qid.path)){
    case Qdir:
        devdir(c, c->qid, ".", 0, eve, DMDIR|0555, &dir);
        break;
    case Qdata0:
        devdir(c, c->qid, "data", qlen(p->q[0]), eve, p->perm, &dir);
        break;
    case Qdata1:
        devdir(c, c->qid, "data1", qlen(p->q[1]), eve, p->perm, &dir);
        break;
    default:
        panic("pipestat");
    }
    n = convD2M(&dir, db, n);
    if(n < BIT16SZ)
        error(Eshortstat);
    return n;
}
@


<<method pipewstat>>=
static int
pipewstat(Chan* c, uchar* db, int n)
{
    int m;
    Dir *dir;
    Pipe *p;

    p = c->aux;
    if(strcmp(up->user, eve) != 0)
        error(Eperm);
    if(NETTYPE(c->qid.path) == Qdir)
        error(Eisdir);

    dir = smalloc(sizeof(Dir)+n);
    if(waserror()){
        free(dir);
        nexterror();
    }
    m = convM2D(db, n, &dir[0], (char*)&dir[1]);
    if(m == 0)
        error(Eshortstat);
    if(!emptystr(dir[0].uid))
        error("can't change owner");
    if(dir[0].mode != ~0UL)
        p->perm = dir[0].mode;
    poperror();
    free(dir);
    return m;
}
@


<<method pipeopen>>=
/*
 *  if the stream doesn't exist, create it
 */
static Chan*
pipeopen(Chan *c, int omode)
{
    Pipe *p;

    if(c->qid.type & QTDIR){
        if(omode != OREAD)
            error(Ebadarg);
        c->mode = omode;
        c->flag |= COPEN;
        c->offset = 0;
        return c;
    }

    p = c->aux;
    qlock(p);
    switch(NETTYPE(c->qid.path)){
    case Qdata0:
        p->qref[0]++;
        break;
    case Qdata1:
        p->qref[1]++;
        break;
    }
    qunlock(p);

    c->mode = openmode(omode);
    c->flag |= COPEN;
    c->offset = 0;
    c->iounit = qiomaxatomic;
    return c;
}
@


<<method pipeclose>>=
static void
pipeclose(Chan *c)
{
    Pipe *p;

    p = c->aux;
    qlock(p);

    if(c->flag & COPEN){
        /*
         *  closing either side hangs up the stream
         */
        switch(NETTYPE(c->qid.path)){
        case Qdata0:
            p->qref[0]--;
            if(p->qref[0] == 0){
                qhangup(p->q[1], 0);
                qclose(p->q[0]);
            }
            break;
        case Qdata1:
            p->qref[1]--;
            if(p->qref[1] == 0){
                qhangup(p->q[0], 0);
                qclose(p->q[1]);
            }
            break;
        }
    }


    /*
     *  if both sides are closed, they are reusable
     */
    if(p->qref[0] == 0 && p->qref[1] == 0){
        qreopen(p->q[0]);
        qreopen(p->q[1]);
    }

    /*
     *  free the structure on last close
     */
    p->ref--;
    if(p->ref == 0){
        qunlock(p);
        free(p->q[0]);
        free(p->q[1]);
        free(p);
    } else
        qunlock(p);
}
@


<<method piperead>>=
static long
piperead(Chan *c, void *va, long n, vlong)
{
    Pipe *p;

    p = c->aux;

    switch(NETTYPE(c->qid.path)){
    case Qdir:
        return devdirread(c, va, n, pipedir, NPIPEDIR, pipegen);
    case Qdata0:
        return qread(p->q[0], va, n);
    case Qdata1:
        return qread(p->q[1], va, n);
    default:
        panic("piperead");
    }
    panic("piperead: should not reach this point");
}
@


<<method pipebread>>=
static Block*
pipebread(Chan *c, long n, ulong offset)
{
    Pipe *p;

    p = c->aux;

    switch(NETTYPE(c->qid.path)){
    case Qdata0:
        return qbread(p->q[0], n);
    case Qdata1:
        return qbread(p->q[1], n);
    }

    return devbread(c, n, offset);
}
@


<<method pipewrite>>=
/*
 *  a write to a closed pipe causes a note to be sent to
 *  the process.
 */
static long
pipewrite(Chan *c, void *va, long n, vlong)
{
    Pipe *p;

    if(!islo())
        print("pipewrite hi %#p\n", getcallerpc(&c));
    if(waserror()) {
        /* avoid notes when pipe is a mounted queue */
        if((c->flag & CMSG) == 0)
            postnote(up, 1, "sys: write on closed pipe", NUser);
        nexterror();
    }

    p = c->aux;

    switch(NETTYPE(c->qid.path)){
    case Qdata0:
        n = qwrite(p->q[1], va, n);
        break;

    case Qdata1:
        n = qwrite(p->q[0], va, n);
        break;

    default:
        panic("pipewrite");
    }

    poperror();
    return n;
}
@


<<method pipebwrite>>=
static long
pipebwrite(Chan *c, Block *bp, ulong)
{
    long n;
    Pipe *p;

    if(waserror()) {
        /* avoid notes when pipe is a mounted queue */
        if((c->flag & CMSG) == 0)
            postnote(up, 1, "sys: write on closed pipe", NUser);
        nexterror();
    }

    p = c->aux;
    switch(NETTYPE(c->qid.path)){
    case Qdata0:
        n = qbwrite(p->q[1], bp);
        break;

    case Qdata1:
        n = qbwrite(p->q[0], bp);
        break;

    default:
        n = 0;
        panic("pipebwrite");
    }

    poperror();
    return n;
}
@


<<global pipedevtab>>=
Dev pipedevtab = {
    .dc       =    '|',
    .name     =    "pipe",
               
    .reset    =    devreset,
    .init     =    pipeinit,
    .shutdown =    devshutdown,
    .attach   =    pipeattach,
    .walk     =    pipewalk,
    .stat     =    pipestat,
    .open     =    pipeopen,
    .create   =    devcreate,
    .close    =    pipeclose,
    .read     =    piperead,
    .bread    =    pipebread,
    .write    =    pipewrite,
    .bwrite   =    pipebwrite,
    .remove   =    devremove,
    .wstat    =    pipewstat,
};
@


\section{Shared segment and semaphore}

% shared segment? and so semaphore? libc_thread?

\subsection{Segment}

<<syscall segbrk>>=
// void* segbrk(void *saddr, void *addr);
long
syssegbrk(ulong *arg)
{
    int i;
    ulong addr;
    Segment *s;

    addr = arg[0];
    for(i = 0; i < NSEG; i++) {
        s = up->seg[i];
        if(s == 0 || addr < s->base || addr >= s->top)
            continue;
        switch(s->type&SG_TYPE) {
        case SG_TEXT:
        case SG_DATA:
        case SG_STACK:
            error(Ebadarg);
        default:
            return ibrk(arg[1], i);
        }
    }

    error(Ebadarg);
    panic("syssegbrk: should not reach this point");
}
@ 

<<syscall segattach>>=
// void* segattach(int attr, char *class, void *va, ulong len);
long
syssegattach(ulong *arg)
{
    return segattach(up, arg[0], (char*)arg[1], arg[2], arg[3]);
}
@ 

<<syscall segdetach>>=
// int segdetach(void *addr);
long
syssegdetach(ulong *arg)
{
    int i;
    ulong addr;
    Segment *s;

    qlock(&up->seglock);
    if(waserror()){
        qunlock(&up->seglock);
        nexterror();
    }

    s = 0;
    addr = arg[0];
    for(i = 0; i < NSEG; i++)
        if(s = up->seg[i]) {
            qlock(&s->lk);
            if((addr >= s->base && addr < s->top) ||
               (s->top == s->base && addr == s->base))
                goto found;
            qunlock(&s->lk);
        }

    error(Ebadarg);

found:
    /*
     * Check we are not detaching the initial stack segment.
     */
    if(s == up->seg[SSEG]){
        qunlock(&s->lk);
        error(Ebadarg);
    }
    up->seg[i] = 0;
    qunlock(&s->lk);
    putseg(s);
    qunlock(&up->seglock);
    poperror();

    /* Ensure we flush any entries from the lost segment */
    flushmmu();
    return 0;
}
@ 


<<syscall segfree>>=
// int segfree(void *va, ulong len);
long
syssegfree(ulong *arg)
{
    Segment *s;
    ulong from, to;

    from = arg[0];
    s = seg(up, from, 1);
    if(s == nil)
        error(Ebadarg);
    to = (from + arg[1]) & ~(BY2PG-1);
    from = PGROUND(from);

    if(to > s->top) {
        qunlock(&s->lk);
        error(Ebadarg);
    }

    mfreeseg(s, from, (to - from) / BY2PG);
    qunlock(&s->lk);
    flushmmu();

    return 0;
}
@ 

\subsection{Semaphore}

% and show code of libcore/libc/port/lock.c! that uses that

<<struct Sema>>=
// user level semaphores, used to implement user-level lock, 
// see libc/port/lock.c
struct Sema
{
    long  *addr; // value stored in user space!
    bool waiting;
  
    //list<Sema> of Segment.sema
    Sema  *next;
    Sema  *prev;

    Rendez;
};
@ 

<<function cmpswap and default implementation>>=
/*
 * 386 has no compare-and-swap instruction.
 * Run it with interrupts turned off instead.
 */
// used to be static, but now shared between arch.c and devarch.c
int
cmpswap386(long *addr, long old, long new)
{
    int r, s;

    s = splhi();
    if(r = (*addr == old))
        *addr = new;
    splx(s);
    return r;
}

int (*cmpswap)(long*, long, long) = cmpswap386;
@


<<function semqueue>>=
/* Add semaphore p with addr a to list in seg. */
static void
semqueue(Segment *s, long *a, Sema *p)
{
    memset(p, 0, sizeof *p);
    p->addr = a;
    lock(&s->sema); /* uses s->sema.Rendez.Lock, but no one else is */
    p->next = &s->sema;
    p->prev = s->sema.prev;
    p->next->prev = p;
    p->prev->next = p;
    unlock(&s->sema);
}
@ 


<<function semdequeue>>=
/* Remove semaphore p from list in seg. */
static void
semdequeue(Segment *s, Sema *p)
{
    lock(&s->sema);
    p->next->prev = p->prev;
    p->prev->next = p->next;
    unlock(&s->sema);
}
@ 


<<function semwakeup>>=
/* Wake up n waiters with addr a on list in seg. */
static void
semwakeup(Segment *s, long *a, long n)
{
    Sema *p;
    
    lock(&s->sema);
    for(p=s->sema.next; p!=&s->sema && n>0; p=p->next){
        if(p->addr == a && p->waiting){
            p->waiting = false;
            coherence();
            wakeup(p);
            n--;
        }
    }
    unlock(&s->sema);
}
@ 


<<function semrelease>>=
/* Add delta to semaphore and wake up waiters as appropriate. */
static long
semrelease(Segment *s, long *addr, long delta)
{
    long value;

    do
        value = *addr;
    while(!cmpswap(addr, value, value+delta));
    semwakeup(s, addr, delta);
    return value+delta;
}
@ 


<<function canacquire>>=
/* Try to acquire semaphore using compare-and-swap */
static bool
canacquire(long *addr)
{
    long value;
    
    while((value=*addr) > 0)
        if(cmpswap(addr, value, value-1))
            return true;
    return false;
}       
@ 


<<function semawoke>>=
/* Should we wake up? */
static bool
semawoke(void *p)
{
    coherence();
    return !((Sema*)p)->waiting;
}
@ 


<<function semacquire>>=
/* Acquire semaphore (subtract 1). */
static bool
semacquire(Segment *s, long *addr, bool block)
{
    int acquired;
    Sema phore;

    if(canacquire(addr))
        return true;
    if(!block)
        return false;

    acquired = false;
    semqueue(s, addr, &phore);
    for(;;){
        phore.waiting = true;
        coherence();
        if(canacquire(addr)){
            acquired = true;
            break;
        }
        if(waserror())
            break;
        sleep(&phore, semawoke, &phore);
        poperror();
    }
    semdequeue(s, &phore);
    coherence();    /* not strictly necessary due to lock in semdequeue */
    if(!phore.waiting)
        semwakeup(s, addr, 1);
    if(!acquired)
        nexterror();
    return false;
}
@ 


<<function tsemacquire>>=
/* Acquire semaphore or time-out */
static bool
tsemacquire(Segment *s, long *addr, ulong ms)
{
    int acquired, timedout;
    ulong t, elms;
    Sema phore;

    if(canacquire(addr))
        return true;
    if(ms == 0)
        return false;
    acquired = timedout = false;
    semqueue(s, addr, &phore);
    for(;;){
        phore.waiting = true;
        coherence();
        if(canacquire(addr)){
            acquired = true;
            break;
        }
        if(waserror())
            break;
        t = cpu->ticks;
        tsleep(&phore, semawoke, &phore, ms);
        elms = TK2MS(cpu->ticks - t);
        poperror();
        if(elms >= ms){
            timedout = true;
            break;
        }
        ms -= elms;
    }
    semdequeue(s, &phore);
    coherence();    /* not strictly necessary due to lock in semdequeue */
    if(!phore.waiting)
        semwakeup(s, addr, 1);
    if(timedout)
        return false;
    if(!acquired)
        nexterror();
    return false;
}
@ 


<<syscall semacquire>>=
// int semacquire(long *addr, int block);
long
syssemacquire(ulong *arg)
{
    int block;
    long *addr;
    Segment *s;

    validaddr(arg[0], sizeof(long), 1);
    evenaddr(arg[0]);
    addr = (long*)arg[0];
    block = arg[1];
    
    if((s = seg(up, (ulong)addr, 0)) == nil)
        error(Ebadarg);
    if(*addr < 0)
        error(Ebadarg);
    return semacquire(s, addr, block);
}
@ 


<<syscall tsemacquire>>=
// int tsemacquire(long *addr, ulong ms);
long
systsemacquire(ulong *arg)
{
    long *addr;
    ulong ms;
    Segment *s;

    validaddr(arg[0], sizeof(long), 1);
    evenaddr(arg[0]);
    addr = (long*)arg[0];
    ms = arg[1];

    if((s = seg(up, (ulong)addr, 0)) == nil)
        error(Ebadarg);
    if(*addr < 0)
        error(Ebadarg);
    return tsemacquire(s, addr, ms);
}
@ 


<<syscall semrelease>>=
// long semrelease(long *addr, long count);
long
syssemrelease(ulong *arg)
{
    long *addr, delta;
    Segment *s;

    validaddr(arg[0], sizeof(long), 1);
    evenaddr(arg[0]);
    addr = (long*)arg[0];
    delta = arg[1];

    if((s = seg(up, (ulong)addr, 0)) == nil)
        error(Ebadarg);
    /* delta == 0 is a no-op, not a release */
    if(delta < 0 || *addr < 0)
        error(Ebadarg);
    return semrelease(s, addr, delta);
}
@ 


\section{[[sysrendezvous()]]}


<<function REND>>=
enum
{
    RENDLOG = 5,
    RENDHASH =  1<<RENDLOG, /* Hash to lookup rendezvous tags */
};
#define REND(p,s) ((p)->rendhash[(s)&((1<<RENDLOG)-1)])
@

% >>

<<struct Rgrp>>=
struct Rgrp
{
    // hash<??, list<ref<Proc>>>
    Proc  *rendhash[RENDHASH];  /* Rendezvous tag hash */
  
    // extra
    Ref;        /* the Ref's lock is also the Rgrp's lock */
};
@ 

% could be in other fields honestly, just like Egrp fields
<<[[Proc]] synchronization fields>>=
Rgrp  *rgrp;    /* Rendez group */

uintptr rendtag;  /* Tag for rendezvous */
uintptr rendval;  /* Value for rendezvous */
//??
Proc  *rendhash;  /* Hash list for tag values */
@


<<constructor newrgrp>>=
Rgrp*
newrgrp(void)
{
    Rgrp *r;

    r = smalloc(sizeof(Rgrp));
    r->ref = 1;
    return r;
}
@ 

<<destructor closergrp>>=
void
closergrp(Rgrp *r)
{
    if(decref(r) == 0)
        free(r);
}
@ 


<<enum procstate cases>>=
Rendezvous,
@

<<syscall rendezvous>>=
// void* rendezvous(void* tag, void* value);
long
sysrendezvous(ulong *arg)
{
    uintptr tag, val;
    Proc *p, **l;

    tag = arg[0];
    l = &REND(up->rgrp, tag);
    up->rendval = ~(uintptr)0;

    lock(up->rgrp);
    for(p = *l; p; p = p->rendhash) {
        if(p->rendtag == tag) {
            *l = p->rendhash;
            val = p->rendval;
            p->rendval = arg[1];

            while(p->cpu != 0)
                ;
            ready(p);
            unlock(up->rgrp);
            return val;
        }
        l = &p->rendhash;
    }

    /* Going to sleep here */
    up->rendtag = tag;
    up->rendval = arg[1];
    up->rendhash = *l;
    *l = up;
    up->state = Rendezvous;
    unlock(up->rgrp);

    sched();

    return up->rendval;
}
@ 



\section{Network}

\chapter{Userspace System Programs}
\minitoc

% can execute them because they are in rootfs, via addrootfile,
% see mkrootall in mkfile via data2txt

\section{[[/boot/boot]]}

<<boot.c>>=
#include <u.h>
#include <libc.h>
#include "../boot/boot.h"

/*
 * we should inherit the standard fds all referring to /dev/cons,
 * but we're being paranoid.
 */
static void
opencons(void)
{
  close(0);
  close(1);
  close(2);
  open("/dev/cons", OREAD);
  open("/dev/cons", OWRITE);
  open("/dev/cons", OWRITE);
}

/*
 * init will reinitialize its namespace.
 * #ec gets us plan9.ini settings (*var variables).
 */
static void
bindenvsrv(void)
{
  bind("#ec", "/env", MREPL);
  bind("#e", "/env", MBEFORE|MCREATE);
  bind("#s", "/srv/", MREPL|MCREATE);
}

static void
swapproc(void)
{
    int fd;

    fd = open("#c/swap", OWRITE);
    if(fd < 0){
        warning("opening #c/swap");
        return;
    }
    if(write(fd, "start", 5) <= 0)
        warning("starting swap kproc");
    close(fd);
}

static void
execinit(void)
{
  int fd;

  bind_safe("#p", "/proc", MREPL); //devproc
  // used by rc and many programs, e.g. via open("#d/0")
  bind_safe("#d", "/fd", MREPL); //devdup

  bind_safe("/root", "/", MAFTER|MCREATE);
  bind_safe("/386/bin", "/bin", MREPL);
  bind_safe("/rc/bin", "/bin", MAFTER);

  bind_safe("#v", "/dev", MAFTER); //devvga
  bind_safe("#m", "/dev", MAFTER); //devmouse
  bind_safe("#P", "/dev", MAFTER);

  run("/bin/mouse", "ps2", nil);
  //this just need a regular vga driver
  //run("/bin/vga", "-l", "640x480x8", nil);
  //this need special drivers, such as the clgd424x.c in the kernel
  run("/bin/vga", "-l", "1024x768x8", nil);
  bind_safe("#i", "/dev", MAFTER);

  // for rio
  run("/bin/ramfs", "-m", "/mnt", nil);
  run("/bin/mkdir", "/mnt/temp", nil); // see thread(2), used to create pipes
  run("/bin/mkdir", "/mnt/wsys", nil);
  fd = open_safe("#c/hostowner", OWRITE);
  print_safe(fd, "pad");
  close(fd);

  // network
  bind_safe("#I", "/net", MREPL);
  bind_safe("#l0", "/net", MAFTER);

  run("/bin/rc", nil);
}


// called from boot$CONF.c:main()
void
boot(int argc, char *argv[])
{
  USED(argc);
  USED(argv);

  fmtinstall('r', errfmt);

  //At this point we should have #/ and #c setup by the kernel init0

  opencons();
  bindenvsrv();

  print("booooooooting...\n");

  rfork(RFNAMEG);

  connectlocal();

  swapproc();
  execinit();

  exits("failed to exec init");
}
@
%$

<<function run>>=
void
run(char *file, ...)
{
  runv(&file);
}
@

<<function runv>>=
void
runv(char **argv)
{
  int i, pid;
  
  switch(pid = fork()){
  case -1:
    fatal("fork");
  case 0:
    exec(argv[0], argv);
    fatal(smprint("can't exec %s: %r", argv[0]));
  default:
    while ((i = waitpid()) != pid && i != -1)
      ;
    if(i == -1)
      fatal(smprint("wait failed running %s", argv[0]));
  }
}
@


<<local.c>>=
#include <u.h>
#include <libc.h>
#include "../boot/boot.h"

void
connectlocal(void)
{
  int fd;
  
  bind_safe("#S", "/dev", MAFTER);

  fd = open_safe("/dev/sdC0/ctl", ORDWR);
  //TODO: use fdisk -p /dev/sdC1/data > /dev/sdC1/ctl
  //for sdC0: #prep -p /dev/sdC1/plan9 > /dev/sdC1/ctl
  print_safe(fd, "part dos 1 1000063");
  close_safe(fd);

  run("/boot/dossrv", nil);
  run("/boot/mount", "-c", "/srv/dos", "/root", "/dev/sdC0/dos", nil);
  
  return;
}
@

\section{[[/root/init]]}
% user init, != kernel init

\section{The shell}






\chapter{Advanced Topics}

\section{SMP}

\section{Real-time scheduling}

\section{Floating point}

\section{Power managment}



\chapter{Special Fileservers}

\section{[[Cmdtab]]}

% kind of replacment for ioctl

<<struct Cmdtab>>=
struct Cmdtab
{
  int index;  /* used by client to switch on result */
  char  *cmd; /* command name */
  int narg; /* expected #args; 0 ==> variadic */
};
@

<<struct Cmdbuf>>=
struct Cmdbuf
{
  char  *buf;
  char  **f;
  int nf;
};
@

<<function parsecmd>>=
/*
 *  parse a command written to a device
 */
Cmdbuf*
parsecmd(char *p, int n)
{
    Cmdbuf *volatile cb;
    int nf;
    char *sp;

    nf = ncmdfield(p, n);

    /* allocate Cmdbuf plus string pointers plus copy of string including \0 */
    sp = smalloc(sizeof(*cb) + nf * sizeof(char*) + n + 1);
    cb = (Cmdbuf*)sp;
    cb->f = (char**)(&cb[1]);
    cb->buf = (char*)(&cb->f[nf]);

    if(up!=nil && waserror()){
        free(cb);
        nexterror();
    }
    memmove(cb->buf, p, n);
    if(up != nil)
        poperror();

    /* dump new line and null terminate */
    if(n > 0 && cb->buf[n-1] == '\n')
        n--;
    cb->buf[n] = '\0';

    cb->nf = tokenize(cb->buf, cb->f, nf-1);
    cb->f[cb->nf] = nil;

    return cb;
}
@


<<function cmderror>>=
/*
 * Reconstruct original message, for error diagnostic
 */
void
cmderror(Cmdbuf *cb, char *s)
{
    int i;
    char *p, *e;

    p = up->genbuf;
    e = p+ERRMAX-10;
    p = seprint(p, e, "%s \"", s);
    for(i=0; i<cb->nf; i++){
        if(i > 0)
            p = seprint(p, e, " ");
        p = seprint(p, e, "%q", cb->f[i]);
    }
    strcpy(p, "\"");
    error(up->genbuf);
}
@


<<function lookupcmd>>=
/*
 * Look up entry in table
 */
Cmdtab*
lookupcmd(Cmdbuf *cb, Cmdtab *ctab, int nctab)
{
    int i;
    Cmdtab *ct;

    if(cb->nf == 0)
        error("empty control message");

    for(ct = ctab, i=0; i<nctab; i++, ct++){
        if(strcmp(ct->cmd, "*") !=0)    /* wildcard always matches */
        if(strcmp(ct->cmd, cb->f[0]) != 0)
            continue;
        if(ct->narg != 0 && ct->narg != cb->nf)
            cmderror(cb, Ecmdargs);
        return ct;
    }

    cmderror(cb, "unknown control message");
    return nil;
}
@

<<ncmdfield>>=
/*
 * Generous estimate of number of fields, including terminal nil pointer
 */
static int
ncmdfield(char *p, int n)
{
    int white, nwhite;
    char *ep;
    int nf;

    if(p == nil)
        return 1;

    nf = 0;
    ep = p+n;
    white = 1;  /* first text will start field */
    while(p < ep){
        nwhite = (strchr(" \t\r\n", *p++ & 0xFF) != 0); /* UTF is irrelevant */
        if(white && !nwhite)    /* beginning of field */
            nf++;
        white = nwhite;
    }
    return nf+1;    /* +1 for nil */
}
@



\section{[[/env/]]}
%kind of an IPC?

\subsection{[[Egrp]]}

<<struct Evalue>>=
struct Evalue
{
  char  *name;
  char  *value;
  int len;
  Evalue  *link;
  Qid qid;
};
@


<<struct Egrp>>=
struct Egrp
{
  Ref;
  RWlock;
  Evalue  **ent;
  int nent;
  int ment;
  ulong path; /* qid.path of next Evalue to be allocated */
  ulong vers; /* of Egrp */
};
@

<<[[Proc]] other fields>>=
// ref_counted<egrp>
Egrp  *egrp;    /* Environment group */
@

<<function closeegrp>>=
void
closeegrp(Egrp *eg)
{
    int i;
    Evalue *e;

    if(decref(eg) == 0){
        for(i=0; i<eg->nent; i++){
            e = eg->ent[i];
            free(e->name);
            if(e->value)
                free(e->value);
            free(e);
        }
        free(eg->ent);
        free(eg);
    }
}
@

\subsection{[[/env/]]}

%#e

\section{[[/proc/]]}
%#p

<<[[Proc]] other fields>>=
ulong procmode; /* proc device default file mode */
@



<<[[Proc]] other fields>>=
bool privatemem; /* proc does not let anyone read mem */
@

<<[[procctlreq()]] CMprivate case>>=
    case CMprivate:
        p->privatemem = true;
        break;
@

% apparently can also be used by the debugger acid
%  chmod +w /proc/96/mem and then acid 96

<<devproc.c enum Qxxx>>=
enum
{
    Qdir,
    Qtrace,

    Qargs,
    Qctl,
    Qfd,
    Qfpregs,
    Qkregs,
    Qmem,
    Qnote,
    Qnoteid,
    Qnotepg,
    Qns,
    Qproc,
    Qregs,
    Qsegment,
    Qstatus,
    Qtext,
    Qwait,
    Qprofile,
    Qsyscall,
};
@


<<devproc enum CMxxx>>=
enum
{
    CMclose,
    CMclosefiles,
    CMhang,
    CMkill,
    CMnohang,
    CMnoswap,
    CMprivate,
    CMprofile,

    CMpri,
    CMfixedpri,
    CMwired,

    CMstart,
    CMstartstop,
    CMstartsyscall,
    CMstop,
    CMwaitstop,
    CMtrace,

    /* real time */
    CMperiod,
    CMdeadline,
    CMcost,
    CMsporadic,
    CMdeadlinenotes,
    CMadmit,
    CMextra,
    CMexpel,
    CMevent,
};
@

<<global procdir>>=
/*
 * Status, fd, and ns are left fully readable (0444) because of their use in debugging,
 * particularly on shared servers.
 * Arguably, ns and fd shouldn't be readable; if you'd prefer, change them to 0000
 */
Dirtab procdir[] =
{
    "args",     {Qargs},    0,          0660,
    "ctl",      {Qctl},     0,          0000,
    "fd",       {Qfd},      0,          0444,
    "fpregs",   {Qfpregs},  sizeof(ArchFPsave),     0000,
    "kregs",    {Qkregs},   sizeof(Ureg),       0400,
    "mem",      {Qmem},     0,          0000,
    "note",     {Qnote},    0,          0000,
    "noteid",   {Qnoteid},  0,          0664,
    "notepg",   {Qnotepg},  0,          0000,
    "ns",       {Qns},      0,          0444,
    "proc",     {Qproc},    0,          0400,
    "regs",     {Qregs},    sizeof(Ureg),       0000,
    "segment",  {Qsegment}, 0,          0444,
    "status",   {Qstatus},  STATSIZE,       0444,
    "text",     {Qtext},    0,          0000,
    "wait",     {Qwait},    0,          0400,
    "profile",  {Qprofile}, 0,          0400,
    "syscall",  {Qsyscall}, 0,          0400,   
};
@

<<global proccmd>>=
static
Cmdtab proccmd[] = {
    CMclose,        "close",        2,
    CMclosefiles,       "closefiles",       1,
    CMfixedpri,     "fixedpri",     2,
    CMhang,         "hang",         1,
    CMnohang,       "nohang",       1,
    CMnoswap,       "noswap",       1,
    CMkill,         "kill",         1,
    CMpri,          "pri",          2,
    CMprivate,      "private",      1,
    CMprofile,      "profile",      1,
    CMstart,        "start",        1,
    CMstartstop,        "startstop",        1,
    CMstartsyscall,     "startsyscall",     1,
    CMstop,         "stop",         1,
    CMwaitstop,     "waitstop",     1,
    CMwired,        "wired",        2,
    CMtrace,        "trace",        0,
    CMperiod,       "period",       2,
    CMdeadline,     "deadline",     2,
    CMcost,         "cost",         2,
    CMsporadic,     "sporadic",     1,
    CMdeadlinenotes,    "deadlinenotes",    1,
    CMadmit,        "admit",        1,
    CMextra,        "extra",        1,
    CMexpel,        "expel",        1,
    CMevent,        "event",        1,
};
@

<<devproc QXXX macros>>=
/*
 * Qids are, in path:
 *   5 bits of file type (qids above)
 *  26 bits of process slot number + 1
 *       in vers,
 *  32 bits of pid, for consistency checking
 * If notepg, c->pgrpid.path is pgrp slot, .vers is noteid.
 */
#define QSHIFT  5   /* location in qid of proc slot # */

#define QID(q)      ((((ulong)(q).path) & ((1<<QSHIFT)-1)) >> 0)
#define SLOT(q)     (((((ulong)(q).path) & ~(1UL<<31)) >> QSHIFT) - 1)
#define PID(q)      ((q).vers)
#define NOTEID(q)   ((q).vers)
@

<<[[Chan]] union other fields>>=
Qid pgrpid;   /* for #p/notepg */
@

<<method procinit>>=
static void
proc_init(void)
{
    if(conf.nproc >= (1<<(31-QSHIFT))-1)
        print("warning: too many procs for devproc\n");
    addclock0link((void (*)(void))profclock, 113);  /* Relative prime to HZ */
}
@
% >>
% was called procinit but conflict with procalloc procinit() function

<<global procdevtab>>=
Dev procdevtab = {
    .dc       =    'p',
    .name     =    "proc",
               
    .reset    =    devreset,
    .init     =    proc_init,
    .shutdown =    devshutdown,
    .attach   =    procattach,
    .walk     =    procwalk,
    .stat     =    procstat,
    .open     =    procopen,
    .create   =    devcreate,
    .close    =    procclose,
    .read     =    procread,
    .bread    =    devbread,
    .write    =    procwrite,
    .bwrite   =    devbwrite,
    .remove   =    devremove,
    .wstat    =    procwstat,
};
@

%TODO: use mid below instead of ->aux
<<[[Chan]] union other fields>>=
  ulong mid;    /* for ns in devproc */
@


<<method procread>>=
static long
procread(Chan *c, void *va, long n, vlong off)
{
    /* NSEG*32 was too small for worst cases */
    char *a, flag[10], *sps, *srv, statbuf[NSEG*64];
    int i, j, m, navail, ne, pid, rsize;
    long l;
    uchar *rptr;
    ulong offset;
    Confmem *cm;
    Mntwalk *mw;
    Proc *p;
    Segment *sg, *s;
    Ureg kur;
    Waitq *wq;
    
    a = va;
    offset = off;

    if(c->qid.type & QTDIR)
        return devdirread(c, a, n, 0, 0, procgen);

    <<[[procread()]] Qtrace if>>

    p = proctab(SLOT(c->qid));

    if(p->pid != PID(c->qid))
        error(Eprocdied);

    switch(QID(c->qid)){
    case Qargs:
        qlock(&p->debug);
        j = procargs(p, up->genbuf, sizeof up->genbuf);
        qunlock(&p->debug);
        if(offset >= j)
            return 0;
        if(offset+n > j)
            n = j-offset;
        memmove(a, &up->genbuf[offset], n);
        return n;

    <<[[procread()]] Qsyscall case>>

    case Qmem:
        if(offset < KZERO)
            return procctlmemio(p, offset, n, va, 1);

        if(!iseve())
            error(Eperm);

        /* validate kernel addresses */
        if(offset < (ulong)end) {
            if(offset+n > (ulong)end)
                n = (ulong)end - offset;
            memmove(a, (char*)offset, n);
            return n;
        }
        for(i=0; i<nelem(conf.mem); i++){
            cm = &conf.mem[i];
            /* klimit-1 because klimit might be zero! */
            if(cm->kbase <= offset && offset <= cm->klimit-1){
                if(offset+n >= cm->klimit-1)
                    n = cm->klimit - offset;
                memmove(a, (char*)offset, n);
                return n;
            }
        }
        error(Ebadarg);

    case Qprofile:
        s = p->seg[TSEG];
        if(s == 0 || s->profile == 0)
            error("profile is off");
        i = (s->top-s->base)>>LRESPROF;
        i *= sizeof(*s->profile);
        if(offset >= i)
            return 0;
        if(offset+n > i)
            n = i - offset;
        memmove(a, ((char*)s->profile)+offset, n);
        return n;

    case Qnote:
        qlock(&p->debug);
        if(waserror()){
            qunlock(&p->debug);
            nexterror();
        }
        if(p->pid != PID(c->qid))
            error(Eprocdied);
        if(n < 1)   /* must accept at least the '\0' */
            error(Etoosmall);
        if(p->nnote == 0)
            n = 0;
        else {
            m = strlen(p->note[0].msg) + 1;
            if(m > n)
                m = n;
            memmove(va, p->note[0].msg, m);
            ((char*)va)[m-1] = '\0';
            p->nnote--;
            memmove(p->note, p->note+1, p->nnote*sizeof(Note));
            n = m;
        }
        if(p->nnote == 0)
            p->notepending = false;
        poperror();
        qunlock(&p->debug);
        return n;

    case Qproc:
        if(offset >= sizeof(Proc))
            return 0;
        if(offset+n > sizeof(Proc))
            n = sizeof(Proc) - offset;
        memmove(a, ((char*)p)+offset, n);
        return n;

    case Qregs:
        rptr = (uchar*)p->dbgreg;
        rsize = sizeof(Ureg);
        goto regread;

    case Qkregs:
        memset(&kur, 0, sizeof(Ureg));
        setkernur(&kur, p);
        rptr = (uchar*)&kur;
        rsize = sizeof(Ureg);
        goto regread;

    case Qfpregs:
        rptr = (uchar*)&p->fpsave;
        rsize = sizeof(ArchFPsave);
    regread:
        if(rptr == 0)
            error(Enoreg);
        if(offset >= rsize)
            return 0;
        if(offset+n > rsize)
            n = rsize - offset;
        memmove(a, rptr+offset, n);
        return n;

    case Qstatus:
        if(offset >= STATSIZE)
            return 0;
        if(offset+n > STATSIZE)
            n = STATSIZE - offset;

        sps = p->psstate;
        if(sps == 0)
            sps = statename[p->state];
        memset(statbuf, ' ', sizeof statbuf);
        readstr(0, statbuf+0*KNAMELEN, KNAMELEN-1, p->text);
        readstr(0, statbuf+1*KNAMELEN, KNAMELEN-1, p->user);
        readstr(0, statbuf+2*KNAMELEN, 11, sps);
        j = 2*KNAMELEN + 12;

        for(i = 0; i < 6; i++) {
            l = p->time[i];
            if(i == TReal)
                l = CPUS(0)->ticks - l;
            l = TK2MS(l);
            readnum(0, statbuf+j+NUMSIZE*i, NUMSIZE, l, NUMSIZE);
        }
        /* ignore stack, which is mostly non-existent */
        l = 0;
        for(i=1; i<NSEG; i++){
            s = p->seg[i];
            if(s)
                l += s->top - s->base;
        }
        readnum(0, statbuf+j+NUMSIZE*6, NUMSIZE, l>>10, NUMSIZE);
        readnum(0, statbuf+j+NUMSIZE*7, NUMSIZE, p->basepri, NUMSIZE);
        readnum(0, statbuf+j+NUMSIZE*8, NUMSIZE, p->priority, NUMSIZE);
        memmove(a, statbuf+offset, n);
        return n;

    case Qsegment:
        j = 0;
        for(i = 0; i < NSEG; i++) {
            sg = p->seg[i];
            if(sg == 0)
                continue;
            j += snprint(statbuf+j, sizeof statbuf - j,
                "%-6s %c%c %.8lux %.8lux %4ld\n",
                sname[sg->type&SG_TYPE],
                sg->type&SG_RONLY ? 'R' : ' ',
                sg->profile ? 'P' : ' ',
                sg->base, sg->top, sg->ref);
        }
        if(offset >= j)
            return 0;
        if(offset+n > j)
            n = j-offset;
        if(n == 0 && offset == 0)
            exhausted("segments");
        memmove(a, &statbuf[offset], n);
        return n;

    case Qwait:
        if(!canqlock(&p->qwaitr))
            error(Einuse);

        if(waserror()) {
            qunlock(&p->qwaitr);
            nexterror();
        }

        lock(&p->exl);
        if(up == p && p->nchild == 0 && p->waitq == 0) {
            unlock(&p->exl);
            error(Enochild);
        }
        pid = p->pid;
        while(p->waitq == 0) {
            unlock(&p->exl);
            sleep(&p->waitr, haswaitq, p);
            if(p->pid != pid)
                error(Eprocdied);
            lock(&p->exl);
        }
        wq = p->waitq;
        p->waitq = wq->next;
        p->nwait--;
        unlock(&p->exl);

        qunlock(&p->qwaitr);
        poperror();
        n = snprint(a, n, "%d %lud %lud %lud %q",
            wq->w.pid,
            wq->w.time[TUser], wq->w.time[TSys], wq->w.time[TReal],
            wq->w.msg);
        free(wq);
        return n;

    case Qns:
        qlock(&p->debug);
        if(waserror()){
            qunlock(&p->debug);
            nexterror();
        }
        if(p->pgrp == nil || p->pid != PID(c->qid))
            error(Eprocdied);
        mw = c->aux;
        if(mw == nil)
            error(Enomem);
        if(mw->cddone){
            qunlock(&p->debug);
            poperror();
            return 0;
        }
        mntscan(mw, p);
        if(mw->mh == 0){
            mw->cddone = 1;
            i = snprint(a, n, "cd %s\n", p->dot->path->s);
            qunlock(&p->debug);
            poperror();
            return i;
        }
        int2flag(mw->cm->mflag, flag);
        if(strcmp(mw->cm->to->path->s, "#M") == 0){
            srv = srvname(mw->cm->to->mchan);
            i = snprint(a, n, "mount %s %s %s %s\n", flag,
                srv==nil? mw->cm->to->mchan->path->s : srv,
                mw->mh->from->path->s, mw->cm->spec? mw->cm->spec : "");
            free(srv);
        }else
            i = snprint(a, n, "bind %s %s %s\n", flag,
                mw->cm->to->path->s, mw->mh->from->path->s);
        qunlock(&p->debug);
        poperror();
        return i;

    case Qnoteid:
        return readnum(offset, va, n, p->noteid, NUMSIZE);
    case Qfd:
        return procfds(p, va, n, offset);
    }
    error(Egreg);
    panic("procread: should not reach this point");
}
@

<<method procwrite>>=
static long
procwrite(Chan *c, void *va, long n, vlong off)
{
    int id, m;
    Proc *p, *t, *et;
    char *a, *arg, buf[ERRMAX];
    ulong offset = off;

    a = va;
    if(c->qid.type & QTDIR)
        error(Eisdir);

    p = proctab(SLOT(c->qid));

    /* Use the remembered noteid in the channel rather
     * than the process pgrpid
     */
    if(QID(c->qid) == Qnotepg) {
        pgrpnote(NOTEID(c->pgrpid), va, n, NUser);
        return n;
    }

    qlock(&p->debug);
    if(waserror()){
        qunlock(&p->debug);
        nexterror();
    }
    if(p->pid != PID(c->qid))
        error(Eprocdied);

    switch(QID(c->qid)){
    case Qctl:
        procctlreq(p, va, n);
        break;


    case Qargs:
        if(n == 0)
            error(Eshort);
        if(n >= ERRMAX)
            error(Etoobig);
        arg = malloc(n+1);
        if(arg == nil)
            error(Enomem);
        memmove(arg, va, n);
        m = n;
        if(arg[m-1] != 0)
            arg[m++] = 0;
        free(p->args);
        p->nargs = m;
        p->args = arg;
        p->setargs = true;
        break;

    case Qmem:
        if(p->state != Stopped)
            error(Ebadctl);

        n = procctlmemio(p, offset, n, va, 0);
        break;

    case Qregs:
        if(offset >= sizeof(Ureg))
            n = 0;
        else if(offset+n > sizeof(Ureg))
            n = sizeof(Ureg) - offset;
        if(p->dbgreg == nil)
            error(Enoreg);
        setregisters(p->dbgreg, (char*)(p->dbgreg)+offset, va, n);
        break;

    case Qfpregs:
        if(offset >= sizeof(ArchFPsave))
            n = 0;
        else if(offset+n > sizeof(ArchFPsave))
            n = sizeof(ArchFPsave) - offset;
        memmove((uchar*)&p->fpsave+offset, va, n);
        break;


    case Qnote:
        if(p->kp)
            error(Eperm);
        if(n >= ERRMAX-1)
            error(Etoobig);
        memmove(buf, va, n);
        buf[n] = 0;
        if(!postnote(p, 0, buf, NUser))
            error("note not posted");
        break;
    case Qnoteid:
        id = atoi(a);
        if(id == p->pid) {
            p->noteid = id;
            break;
        }
        t = proctab(0);
        for(et = t+conf.nproc; t < et; t++) {
            if(t->state == Dead)
                continue;
            if(id == t->noteid) {
                if(strcmp(p->user, t->user) != 0)
                    error(Eperm);
                p->noteid = id;
                break;
            }
        }
        if(p->noteid != id)
            error(Ebadarg);
        break;
    default:
        pprint("unknown qid in procwrite\n");
        error(Egreg);
    }
    poperror();
    qunlock(&p->debug);
    return n;
}
@

<<method procopen>>=
static Chan*
procopen(Chan *c, int omode)
{
    Proc *p;
    Pgrp *pg;
    Chan *tc;
    int pid;

    if(c->qid.type & QTDIR)
        return devopen(c, omode, 0, 0, procgen);

    <<[[procopen()]] Qtrace if>>
        
    p = proctab(SLOT(c->qid));
    qlock(&p->debug);
    if(waserror()){
        qunlock(&p->debug);
        nexterror();
    }
    pid = PID(c->qid);
    if(p->pid != pid)
        error(Eprocdied);

    omode = openmode(omode);

    switch(QID(c->qid)){
    case Qtext:
        if(omode != OREAD)
            error(Eperm);
        tc = proctext(c, p);
        tc->offset = 0;
        qunlock(&p->debug);
        poperror();
        cclose(c);
        return tc;

    case Qproc:
    case Qkregs:
    case Qsegment:
    case Qprofile:
    case Qfd:
        if(omode != OREAD)
            error(Eperm);
        break;

    case Qnote:
        if(p->privatemem)
            error(Eperm);
        break;

    case Qmem:
    case Qctl:
        if(p->privatemem)
            error(Eperm);
        nonone(p);
        break;

    case Qargs:
    case Qnoteid:
    case Qstatus:
    case Qwait:
    case Qregs:
    case Qfpregs:
    case Qsyscall:  
        nonone(p);
        break;

    case Qns:
        if(omode != OREAD)
            error(Eperm);
        c->aux = malloc(sizeof(Mntwalk));
        break;

    case Qnotepg:
        nonone(p);
        pg = p->pgrp;
        if(pg == nil)
            error(Eprocdied);
        if(omode!=OWRITE || pg->pgrpid == 1)
            error(Eperm);
        c->pgrpid.path = pg->pgrpid+1;
        c->pgrpid.vers = p->noteid;
        break;

    default:
        pprint("procopen %#lux\n", QID(c->qid));
        error(Egreg);
    }

    /* Affix pid to qid */
    if(p->state != Dead)
        c->qid.vers = p->pid;

    /* make sure the process slot didn't get reallocated while we were playing */
    coherence();
    if(p->pid != pid)
        error(Eprocdied);

    tc = devopen(c, omode, 0, 0, procgen);
    qunlock(&p->debug);
    poperror();

    return tc;
}
@


<<method procwstat>>=
static int
procwstat(Chan *c, uchar *db, int n)
{
    Proc *p;
    Dir *d;

    if(c->qid.type&QTDIR)
        error(Eperm);

    if(QID(c->qid) == Qtrace)
        return devwstat(c, db, n);
        
    p = proctab(SLOT(c->qid));
    nonone(p);
    d = nil;
    if(waserror()){
        free(d);
        qunlock(&p->debug);
        nexterror();
    }
    qlock(&p->debug);

    if(p->pid != PID(c->qid))
        error(Eprocdied);

    if(strcmp(up->user, p->user) != 0 && strcmp(up->user, eve) != 0)
        error(Eperm);

    d = smalloc(sizeof(Dir)+n);
    n = convM2D(db, n, &d[0], (char*)&d[1]);
    if(n == 0)
        error(Eshortstat);
    if(!emptystr(d->uid) && strcmp(d->uid, p->user) != 0){
        if(strcmp(up->user, eve) != 0)
            error(Eperm);
        else
            kstrdup(&p->user, d->uid);
    }
    /* p->procmode determines default mode for files in /proc */
    if(d->mode != ~0UL)
        p->procmode = d->mode&0777;

    poperror();
    free(d);
    qunlock(&p->debug);
    return n;
}
@


<<function procoffset>>=
static long
procoffset(long offset, char *va, int *np)
{
    if(offset > 0) {
        offset -= *np;
        if(offset < 0) {
            memmove(va, va+*np+offset, -offset);
            *np = -offset;
        }
        else
            *np = 0;
    }
    return offset;
}
@


<<function procqidwidth>>=
static int
procqidwidth(Chan *c)
{
    char buf[32];

    return snprint(buf, sizeof buf, "%lud", c->qid.vers);
}
@

<<function procfdprint>>=
int
procfdprint(Chan *c, int fd, int w, char *s, int ns)
{
    int n;

    if(w == 0)
        w = procqidwidth(c);
    n = snprint(s, ns, "%3d %.2s %C %4ld (%.16llux %*lud %.2ux) %5ld %8lld %s\n",
        fd,
        &"r w rw"[(c->mode&3)<<1],
        devtab[c->type]->dc, c->dev,
        c->qid.path, w, c->qid.vers, c->qid.type,
        c->iounit, c->offset, c->path->s);
    return n;
}
@

<<function procgen>>=
static int
procgen(Chan *c, char *name, Dirtab *tab, int, int s, Dir *dp)
{
    Qid qid;
    Proc *p;
    char *ename;
    Segment *q;
    ulong pid, path, perm, len;

    if(s == DEVDOTDOT){
        mkqid(&qid, Qdir, 0, QTDIR);
        devdir(c, qid, "#p", 0, eve, 0555, dp);
        return 1;
    }

    if(c->qid.path == Qdir){
        if(s == 0){
            strcpy(up->genbuf, "trace");
            mkqid(&qid, Qtrace, -1, QTFILE);
            devdir(c, qid, up->genbuf, 0, eve, 0444, dp);
            return 1;
        }

        if(name != nil){
            /* ignore s and use name to find pid */
            pid = strtol(name, &ename, 10);
            if(pid==0 || ename[0]!='\0')
                return -1;
            s = procindex(pid);
            if(s < 0)
                return -1;
        }
        else if(--s >= conf.nproc)
            return -1;

        p = proctab(s);
        pid = p->pid;
        if(pid == 0)
            return 0;
        snprint(up->genbuf, sizeof up->genbuf, "%lud", pid);
        /*
         * String comparison is done in devwalk so name must match its formatted pid
        */
        if(name != nil && strcmp(name, up->genbuf) != 0)
            return -1;
        mkqid(&qid, (s+1)<<QSHIFT, pid, QTDIR);
        devdir(c, qid, up->genbuf, 0, p->user, DMDIR|0555, dp);
        return 1;
    }
    if(c->qid.path == Qtrace){
        strcpy(up->genbuf, "trace");
        mkqid(&qid, Qtrace, -1, QTFILE);
        devdir(c, qid, up->genbuf, 0, eve, 0444, dp);
        return 1;
    }
    if(s >= nelem(procdir))
        return -1;
    if(tab)
        panic("procgen");

    tab = &procdir[s];
    path = c->qid.path&~(((1<<QSHIFT)-1));  /* slot component */

    /* p->procmode determines default mode for files in /proc */
    p = proctab(SLOT(c->qid));
    perm = tab->perm;
    if(perm == 0)
        perm = p->procmode;
    else    /* just copy read bits */
        perm |= p->procmode & 0444;

    len = tab->length;
    switch(QID(c->qid)) {
    case Qwait:
        len = p->nwait; /* incorrect size, but >0 means there's something to read */
        break;
    case Qprofile:
        q = p->seg[TSEG];
        if(q && q->profile) {
            len = (q->top-q->base)>>LRESPROF;
            len *= sizeof(*q->profile);
        }
        break;
    }

    mkqid(&qid, path|tab->qid.path, c->qid.vers, QTFILE);
    devdir(c, qid, tab->name, len, p->user, perm, dp);
    return 1;
}
@



<<function nonone>>=
/*
 *  none can't read or write state on other
 *  processes.  This is to contain access of
 *  servers running as none should they be
 *  subverted by, for example, a stack attack.
 */
static void
nonone(Proc *p)
{
    if(p == up)
        return;
    if(strcmp(up->user, "none") != 0)
        return;
    if(iseve())
        return;
    error(Eperm);
}
@


<<function procfds>>=
static int
procfds(Proc *p, char *va, int count, long offset)
{
    Fgrp *f;
    Chan *c;
    char buf[256];
    int n, i, w, ww;
    char *a;

    /* print to buf to avoid holding fgrp lock while writing to user space */
    if(count > sizeof buf)
        count = sizeof buf;
    a = buf;

    qlock(&p->debug);
    f = p->fgrp;
    if(f == nil){
        qunlock(&p->debug);
        return 0;
    }
    lock(f);
    if(waserror()){
        unlock(f);
        qunlock(&p->debug);
        nexterror();
    }

    n = readstr(0, a, count, p->dot->path->s);
    n += snprint(a+n, count-n, "\n");
    offset = procoffset(offset, a, &n);
    /* compute width of qid.path */
    w = 0;
    for(i = 0; i <= f->maxfd; i++) {
        c = f->fd[i];
        if(c == nil)
            continue;
        ww = procqidwidth(c);
        if(ww > w)
            w = ww;
    }
    for(i = 0; i <= f->maxfd; i++) {
        c = f->fd[i];
        if(c == nil)
            continue;
        n += procfdprint(c, i, w, a+n, count-n);
        offset = procoffset(offset, a, &n);
    }
    unlock(f);
    qunlock(&p->debug);
    poperror();

    /* copy result to user space, now that locks are released */
    memmove(va, buf, n);

    return n;
}
@


<<method procclose>>=
static void
procclose(Chan * c)
{
    <<[[procclose()]] Qtrace if>>

    if(QID(c->qid) == Qns && c->aux != 0)
        free(c->aux);
}
@


<<function int2flag>>=
static void
int2flag(int flag, char *s)
{
    if(flag == 0){
        *s = '\0';
        return;
    }
    *s++ = '-';
    if(flag & MAFTER)
        *s++ = 'a';
    if(flag & MBEFORE)
        *s++ = 'b';
    if(flag & MCREATE)
        *s++ = 'c';
    if(flag & MCACHE)
        *s++ = 'C';
    *s = '\0';
}
@

<<[[Proc]] debugger fields>>=
bool setargs;
@ 



<<function procargs>>=
static int
procargs(Proc *p, char *buf, int nbuf)
{
    int j, k, m;
    char *a;
    int n;

    a = p->args;
    if(p->setargs){
        snprint(buf, nbuf, "%s [%s]", p->text, p->args);
        return strlen(buf);
    }
    n = p->nargs;
    for(j = 0; j < nbuf - 1; j += m){
        if(n <= 0)
            break;
        if(j != 0)
            buf[j++] = ' ';
        m = snprint(buf+j, nbuf-j, "%q",  a);
        k = strlen(a) + 1;
        a += k;
        n -= k;
    }
    return j;
}
@


<<function mntscan>>=
void
mntscan(Mntwalk *mw, Proc *p)
{
    Pgrp *pg;
    Mount *t;
    Mhead *f;
    int nxt, i;
    ulong last, bestmid;

    pg = p->pgrp;
    rlock(&pg->ns);

    nxt = 0;
    bestmid = ~0;

    last = 0;
    if(mw->mh)
        last = mw->cm->mountid;

    for(i = 0; i < MNTHASH; i++) {
        for(f = pg->mnthash[i]; f; f = f->hash) {
            for(t = f->mount; t; t = t->next) {
                if(mw->mh == 0 ||
                  (t->mountid > last && t->mountid < bestmid)) {
                    mw->cm = t;
                    mw->mh = f;
                    bestmid = mw->cm->mountid;
                    nxt = 1;
                }
            }
        }
    }
    if(nxt == 0)
        mw->mh = 0;

    runlock(&pg->ns);
}
@






<<function proctext>>=
Chan*
proctext(Chan *c, Proc *p)
{
    Chan *tc;
    KImage *i;
    Segment *s;

    s = p->seg[TSEG];
    if(s == 0)
        error(Enonexist);
    if(p->state==Dead)
        error(Eprocdied);

    lock(s);
    i = s->image;
    if(i == 0) {
        unlock(s);
        error(Eprocdied);
    }
    unlock(s);

    lock(i);
    if(waserror()) {
        unlock(i);
        nexterror();
    }

    tc = i->c;
    if(tc == 0)
        error(Eprocdied);

    if(incref(tc) == 1 || (tc->flag&COPEN) == 0 || tc->mode!=OREAD) {
        cclose(tc);
        error(Eprocdied);
    }

    if(p->pid != PID(c->qid)){
        cclose(tc);
        error(Eprocdied);
    }

    unlock(i);
    poperror();

    return tc;
}
@


<<function procctlcloseone>>=
static void
procctlcloseone(Proc *p, Fgrp *f, int fd)
{
    Chan *c;

    c = f->fd[fd];
    if(c == nil)
        return;
    f->fd[fd] = nil;
    unlock(f);
    qunlock(&p->debug);
    cclose(c);
    qlock(&p->debug);
    lock(f);
}
@


<<function procctlclosefiles>>=
void
procctlclosefiles(Proc *p, int all, int fd)
{
    int i;
    Fgrp *f;

    f = p->fgrp;
    if(f == nil)
        error(Eprocdied);

    lock(f);
    f->ref++;
    if(all)
        for(i = 0; i < f->maxfd; i++)
            procctlcloseone(p, f, i);
    else
        procctlcloseone(p, f, fd);
    unlock(f);
    closefgrp(f);
}
@


<<function parsetime>>=
static char *
parsetime(vlong *rt, char *s)
{
    uvlong ticks;
    ulong l;
    char *e, *p;
    static int p10[] = {100000000, 10000000, 1000000, 100000, 10000, 1000, 100, 10, 1};

    if (s == nil)
        return("missing value");
    ticks=strtoul(s, &e, 10);
    if (*e == '.'){
        p = e+1;
        l = strtoul(p, &e, 10);
        if(e-p > nelem(p10))
            return "too many digits after decimal point";
        if(e-p == 0)
            return "ill-formed number";
        l *= p10[e-p-1];
    }else
        l = 0;
    if (*e == '\0' || strcmp(e, "s") == 0){
        ticks = 1000000000 * ticks + l;
    }else if (strcmp(e, "ms") == 0){
        ticks = 1000000 * ticks + l/1000;
    }else if (strcmp(e, "s") == 0 || strcmp(e, "us") == 0){
        ticks = 1000 * ticks + l/1000000;
    }else if (strcmp(e, "ns") != 0)
        return "unrecognized unit";
    *rt = ticks;
    return nil;
}
@


<<function procctlreq>>=
// assumes p->debug is held
void
procctlreq(Proc *p, char *va, int n)
{
    Segment *s;
    int npc, pri;
    Cmdbuf *cb;
    Cmdtab *ct;
    vlong time;
    char *e;
    void (*pt)(Proc*, int, vlong);

    if(p->kp)   /* no ctl requests to kprocs */
        error(Eperm);

    cb = parsecmd(va, n);
    if(waserror()){
        free(cb);
        nexterror();
    }

    ct = lookupcmd(cb, proccmd, nelem(proccmd));

    switch(ct->index){
    case CMclose:
        procctlclosefiles(p, 0, atoi(cb->f[1]));
        break;
    case CMclosefiles:
        procctlclosefiles(p, 1, 0);
        break;

    <<[[procctlreq()]] CMhang case>>
    <<[[procctlreq()]] CMnohang case>>

    case CMkill:
        switch(p->state) {
        case Broken:
            unbreak(p);
            break;
        case Stopped:
            p->procctl = Proc_exitme;
            postnote(p, 0, "sys: killed", NExit);
            ready(p);
            break;
        default:
            p->procctl = Proc_exitme;
            postnote(p, 0, "sys: killed", NExit);
        }
        break;
    case CMnoswap:
        p->noswap = true;
        break;

    case CMpri:
        pri = atoi(cb->f[1]);
        if(pri > PriNormal && !iseve())
            error(Eperm);
        procpriority(p, pri, false);
        break;
    case CMfixedpri:
        pri = atoi(cb->f[1]);
        if(pri > PriNormal && !iseve())
            error(Eperm);
        procpriority(p, pri, true);
        break;

    <<[[procctlreq()]] CMprivate case>>
    case CMprofile:
        s = p->seg[TSEG];
        if(s == 0 || (s->type&SG_TYPE) != SG_TEXT)
            error(Ebadctl);
        if(s->profile != 0)
            free(s->profile);
        npc = (s->top-s->base)>>LRESPROF;
        s->profile = malloc(npc*sizeof(*s->profile));
        if(s->profile == 0)
            error(Enomem);
        break;
    case CMstart:
        if(p->state != Stopped)
            error(Ebadctl);
        ready(p);
        break;
    case CMstartstop:
        if(p->state != Stopped)
            error(Ebadctl);
        p->procctl = Proc_traceme;
        ready(p);
        procstopwait(p, Proc_traceme);
        break;
    <<[[procctlreq()]] CMstartsyscall case>>
    case CMstop:
        procstopwait(p, Proc_stopme);
        break;
    case CMwaitstop:
        procstopwait(p, Proc_nothing);
        break;
    case CMwired:
        procwired(p, atoi(cb->f[1]));
        break;

    <<[[procctlreq()]] CMtrace case>>
    <<[[procctlreq()]] CMevent case>>

    <<[[procctlreq()]] optional real-time commands>>

    }

    poperror();
    free(cb);
}
@



<<function procctlmemio>>=
int
procctlmemio(Proc *p, ulong offset, int n, void *va, int read)
{
    KMap *k;
    Pte *pte;
    Page *pg;
    Segment *s;
    ulong soff, l;
    char *a = va, *b;

    for(;;) {
        s = seg(p, offset, 1);
        if(s == 0)
            error(Ebadarg);

        if(offset+n >= s->top)
            n = s->top-offset;

        if(!read && (s->type&SG_TYPE) == SG_TEXT)
            s = txt2data(p, s);

        s->steal++;
        soff = offset-s->base;
        if(waserror()) {
            s->steal--;
            nexterror();
        }
        if(fixfault(s, offset, read, /*putmmu*/false) == 0)
            break;
        poperror();
        s->steal--;
    }
    poperror();
    pte = s->map[soff/PTEMAPMEM];
    if(pte == 0)
        panic("procctlmemio");
    pg = pte->pages[(soff&(PTEMAPMEM-1))/BY2PG];
    if(pagedout(pg))
        panic("procctlmemio1");

    l = BY2PG - (offset&(BY2PG-1));
    if(n > l)
        n = l;

    k = kmap(pg);
    if(waserror()) {
        s->steal--;
        kunmap(k);
        nexterror();
    }
    b = (char*)VA(k);
    b += offset&(BY2PG-1);
    if(read == 1)
        memmove(a, b, n);   /* This can fault */
    else
        memmove(b, a, n);
    kunmap(k);
    poperror();

    /* Ensure the process sees text page changes */
    if(s->flushme)
        memset(pg->cachectl, PG_TXTFLUSH, sizeof(pg->cachectl));

    s->steal--;

    if(read == 0)
        p->newtlb = false;

    return n;
}
@


<<function txt2data>>=
Segment*
txt2data(Proc *p, Segment *s)
{
    int i;
    Segment *ps;

    ps = newseg(SG_DATA, s->base, s->size);
    ps->image = s->image;
    incref(ps->image);
    ps->fstart = s->fstart;
    ps->flen = s->flen;
    ps->flushme = 1;

    qlock(&p->seglock);
    for(i = 0; i < NSEG; i++)
        if(p->seg[i] == s)
            break;
    if(i == NSEG)
        panic("segment gone");

    qunlock(&s->lk);
    putseg(s);
    qlock(&ps->lk);
    p->seg[i] = ps;
    qunlock(&p->seglock);

    return ps;
}
@


<<clock callback profclock>>=
static void
profclock(Ureg *ur, Timer *)
{
    Tos *tos;

    if(up == 0 || up->state != Running)
        return;

    /* user profiling clock */
    if(userureg(ur)){
        tos = (Tos*)(USTKTOP-sizeof(Tos));
        tos->clock += TK2MS(1);
        segclock(ur->pc);
    }
}
@ 


\section{[[/fd/]]}

\subsection{[[sysdup()]]}

<<systab special file syscalls>>=
    [DUP]       sysdup,
@ 

<<syscall dup>>=
// int dup(int oldfd, int newfd);
long
sysdup(ulong *arg)
{
    int fd;
    Chan *c, *oc;
    Fgrp *f = up->fgrp;

    /*
     * Close after dup'ing, so date > #d/1 works
     */
    c = fdtochan(arg[0], -1, 0, 1);
    fd = arg[1];
    if(fd != -1){
        lock(f);
        if(fd<0 || growfd(f, fd)<0) {
            unlockfgrp(f);
            cclose(c);
            error(Ebadfd);
        }
        if(fd > f->maxfd)
            f->maxfd = fd;

        oc = f->fd[fd];
        f->fd[fd] = c;
        unlockfgrp(f);
        if(oc)
            cclose(oc);
    }else{
        if(waserror()) {
            cclose(c);
            nexterror();
        }
        fd = newfd(c);
        if(fd < 0)
            error(Enofd);
        poperror();
    }

    return fd;
}
@

\subsection{[[/fd/]]}

\section{[[/dev/reboot]]}

<<function exit>>=
void
main_exit(bool ispanic)
{
        shutdown(ispanic);
        arch->reset();
}
@

<<[[Active]] other fields>>=
bool ispanic;    /* shutdown in response to a panic */
@

<<function shutdown>>=
static void
shutdown(bool ispanic)
{
    int ms, once;

    lock(&active);
    if(ispanic)
        active.ispanic = ispanic;
    else if(cpu->cpuno == 0 && (active.cpus & (1<<cpu->cpuno)) == 0)
        active.ispanic = false;
    once = active.cpus & (1<<cpu->cpuno);
    /*
     * setting exiting will make hzclock() on each processor call exit(0),
     * which calls shutdown(0) and arch->reset(), which on mp systems is
     * mpshutdown, which idles non-bootstrap cpus and returns on bootstrap
     * processors (to permit a reboot).  clearing our bit in cpus avoids
     * calling exit(0) from hzclock() on this processor.
     */
    active.cpus &= ~(1<<cpu->cpuno);
    active.exiting = true;
    unlock(&active);

    if(once)
        iprint("cpu%d: exiting\n", cpu->cpuno);

    /* wait for any other processors to shutdown */
    spllo();
    for(ms = 5*1000; ms > 0; ms -= TK2MS(2)){
        delay(TK2MS(2));
        if(active.cpus == 0 && consactive() == 0)
            break;
    }

    if(active.ispanic){
        if(!cpuserver)
            for(;;)
               halt();
        if(getconf("*debug"))
            delay(5*60*1000);
        else
            delay(10000);
    }else
        delay(1000);
}
@
% >>


<<function idle>>=
/*
 * Park a processor. Should never fall through a return from main to here,
 * should only be called by application processors when shutting down.
 */
TEXT idle(SB), $0
_idle:
        STI
        HLT
        JMP     _idle
@
%$

<<function archreset>>=
static void
archreset(void)
{
    i8042reset();

    /*
     * Often the BIOS hangs during restart if a conventional 8042
     * warm-boot sequence is tried. The following is Intel specific and
     * seems to perform a cold-boot, but at least it comes back.
     * And sometimes there is no keyboard...
     *
     * The reset register (0xcf9) is usually in one of the bridge
     * chips. The actual location and sequence could be extracted from
     * ACPI but why bother, this is the end of the line anyway.
     */
    print("Takes a licking and keeps on ticking...\n");
    *(ushort*)KADDR(0x472) = 0x1234;    /* BIOS warm-boot flag */
    outb(0xcf9, 0x02);
    outb(0xcf9, 0x06);

    for(;;)
        idle();
}
@

<<[[Active]] other fields>>=
bool rebooting;    /* just idle cpus > 0 */
@


<<function reboot>>=
void
reboot(void *entry, void *code, ulong size)
{
    void (*f)(ulong, ulong, ulong);
    ulong *pdb;

    writeconf();

    /*
     * the boot processor is cpu0.  execute this function on it
     * so that the new kernel has the same cpu0.  this only matters
     * because the hardware has a notion of which processor was the
     * boot processor and we look at it at start up.
     */
    if (cpu->cpuno != 0) {
        procwired(up, 0);
        sched();
    }

    if(conf.ncpu > 1) {
        /*
         * the other cpus could be holding locks that will never get
         * released (e.g., in the print path) if we put them into
         * reset now, so force them to shutdown gracefully first.
         */
        lock(&active);
        active.rebooting = true;
        unlock(&active);
        shutdown(0);
        if(arch->resetothers)
            arch->resetothers();
        delay(20);
    }

    /*
     * should be the only processor running now
     */
    active.cpus = 0;
    if (cpu->cpuno != 0)
        print("on cpu%d (not 0)!\n", cpu->cpuno);

    print("shutting down...\n");
    delay(200);

    splhi();

    /* turn off buffered serial console */
    serialoq = nil;

    /* shutdown devices */
    chandevshutdown();
    arch->introff();

    /*
     * Modify the processor page table to directly map the low 4MB of memory
     * This allows the reboot code to turn off the page mapping
     */
    pdb = cpu->pdb;
    pdb[PDX(0)] = pdb[PDX(KZERO)];
    mmuflushtlb(PADDR(pdb));

    /* setup reboot trampoline function */
    f = (void*)REBOOTADDR;
    memmove(f, rebootcode, sizeof(rebootcode));

    print("rebooting...\n");

    /* off we go - never to return */
    coherence();
    (*f)(PADDR(entry), PADDR(code), size);
}
@


<<function chandevshutdown>>=
void
chandevshutdown(void)
{
    int i;
    
    /* shutdown in reverse order */
    for(i=0; devtab[i] != nil; i++)
        ;
    for(i--; i >= 0; i--)
        devtab[i]->shutdown();
}
@


<<function i8042reset>>=
/*
 *  ask 8042 to reset the machine
 */
void
i8042reset(void)
{
    int i, x;

    if(nokbd)
        return;

    *((ushort*)KADDR(0x472)) = 0x1234;  /* BIOS warm-boot flag */

    /*
     *  newer reset the machine command
     */
    outready();
    outb(Cmd, 0xFE);
    outready();

    /*
     *  Pulse it by hand (old somewhat reliable)
     */
    x = 0xDF;
    for(i = 0; i < 5; i++){
        x ^= 1;
        outready();
        outb(Cmd, 0xD1);
        outready();
        outb(Data, x);  /* toggle reset */
        delay(100);
    }
}
@

<<devcons.c enum Cmd>>=
enum
{
    CMhalt,
    CMreboot,
    CMpanic,
};
@


<<global rebootmsg>>=
Cmdtab rebootmsg[] =
{
    CMhalt,     "halt",     1,
    CMreboot,   "reboot",   0,
    CMpanic,    "panic",    0,
};
@

\section{[[/dev/random]]}

<<global randn>>=
static  ulong   randn;
@


<<function seedrand>>=
static void
seedrand(void)
{
    if(!waserror()){
        randomread((void*)&randn, sizeof(randn));
        poperror();
    }
}
@


<<function nrand>>=
int
nrand(int n)
{
    if(randn == 0)
        seedrand();
    randn = randn*1103515245 + 12345 + CPUS(0)->ticks;
    return (randn>>16) % n;
}
@

%//int
%//rand(void)
%//{
%//  nrand(1);
%//  return randn;
%//}



\chapter{Conclusion}

% already 900 pages ... so network, graphics, security in another volume
% actually even fs in other volume, and advanced subjects like:
%  SMP, storage (scsi, ata, floppy, ...) real time scheculing EDF, 

\section{Security}

<<global eve>>=
char    *eve;
@


<<function iseve>>=
bool iseve(void) { 
  return strcmp(eve, up->user) == 0; 
}
@

<<systab security syscalls>>=
    [FAUTH]     sysfauth,
    [FVERSION]  sysfversion,
@ 

\section{Network}
% put also RPC and devmnt here?

\section{Graphics}

\appendix

\chapter{Debugging}

%TODO
% what to do when have panic, e.g. when I mixed some fields
% and I got a pc error, how do I fix it? how do I find the relevant code?

% see also printf section all this fmt stuff

% getcallerpc

% use of getconf("*debugstart*") to setup some global tracing stuff

\section{[[cgapost()]]}
%first line of "defense" (using sound could be nice too)

<<function cgapost>>=
char hex[] = "0123456789ABCDEF";

void
cgapost(int code)
{
    uchar *cga;

    cga = CGASCREENBASE;
    cga[Width*Height-Postcodelen*2] = hex[(code>>4) & 0x0F];
    cga[Width*Height-Postcodelen*2+1] = Attr;
    cga[Width*Height-Postcodelen*2+2] = hex[code & 0x0F];
    cga[Width*Height-Postcodelen*2+3] = Attr;
}
@

\section{[[sysnop()]]}
% use sysnop to show example of debugging session?
%(was called sysr1) 


\section{Special keys [[C-t C-t]]}

% Ctrl-t Ctrl-t <debugcode>

<<[[echo()]] C-t C-t special keys handler>>=
        /* ^T escapes */
        ctrlt = 0;
        switch(*p){
        case 's':
            dumpstack();
            return;
        case 'S':
            x = splhi();
            dumpstack();
            procdump();
            splx(x);
            return;
        case 'x':
            xsummary();
            tmp = xalloc(1000);
            xalloc(1000);
            xfree(tmp);
            xsummary();
            return;
        case 'X':
            xsummary();
            ixsummary();
            mallocsummary();
            memorysummary();
            pagersummary();
            return;
        case 'm':
            memorysummary();
            return;
        case 'd':
            if(consdebug == nil)
                consdebug = rdb;
            else
                consdebug = nil;
            print("consdebug now %#p\n", consdebug);
            return;
        case 'D':
            if(consdebug == nil)
                consdebug = rdb;
            consdebug();
            return;
        case 'p':
            x = spllo();
            procdump();
            splx(x);
            return;
        case 'q':
            scheddump();
            return;
        case 'k':
            killbig("^t ^t k");
            return;
        case 'r':
            exit(0);
            return;
        }
@

<<function trap_dumpstack>>=
void
trap_dumpstack(void)
{
    callwithureg(_dumpstack);
}
@ 

<<function _dumpstack>>=
static void
_dumpstack(Ureg *ureg)
{
    uintptr l, v, i, estack;
    extern ulong etext;
    int x;
    char *s;

    if((s = getconf("*nodumpstack")) != nil && strcmp(s, "0") != 0){
        iprint("dumpstack disabled\n");
        return;
    }
    iprint("dumpstack\n");

    x = 0;
    x += iprint("ktrace /kernel/path %.8lux %.8lux <<EOF\n", ureg->pc, ureg->sp);
    i = 0;
    if(up
    && (uintptr)&l >= (uintptr)up->kstack
    && (uintptr)&l <= (uintptr)up->kstack+KSTACK)
        estack = (uintptr)up->kstack+KSTACK;
    else if((uintptr)&l >= (uintptr)cpu->stack
    && (uintptr)&l <= (uintptr)cpu+CPUSIZE)
        estack = (uintptr)cpu+CPUSIZE;
    else
        return;
    x += iprint("estackx %p\n", estack);

    for(l = (uintptr)&l; l < estack; l += sizeof(uintptr)){
        v = *(uintptr*)l;
        if((KTZERO < v && v < (uintptr)&etext) || estack-l < 32){
            /*
             * Could Pick off general CALL (((uchar*)v)[-5] == 0xE8)
             * and CALL indirect through AX
             * (((uchar*)v)[-2] == 0xFF && ((uchar*)v)[-2] == 0xD0),
             * but this is too clever and misses faulting address.
             */
            x += iprint("%.8p=%.8p ", l, v);
            i++;
        }
        if(i == 4){
            i = 0;
            x += iprint("\n");
        }
    }
    if(i)
        iprint("\n");
    iprint("EOF\n");

    if(ureg->trap != VectorNMI)
        return;

    i = 0;
    for(l = (uintptr)&l; l < estack; l += sizeof(uintptr)){
        iprint("%.8p ", *(uintptr*)l);
        if(++i == 8){
            i = 0;
            iprint("\n");
        }
    }
    if(i)
        iprint("\n");
}
@ 

<<function callwithureg>>=
/*
 * Fill in enough of Ureg to get a stack trace, and call a function.
 * Used by debugging interface rdb.
 */
void
callwithureg(void (*fn)(Ureg*))
{
    Ureg ureg;
    ureg.pc = getcallerpc(&fn);
    ureg.sp = (ulong)&fn;
    fn(&ureg);
}
@ 


<<function xsummary>>=
void
xsummary(void)
{
    int i;
    Hole *h;

    for(i = 0; i < Nhole && xlists.hole[i].top != 0; i++) {
        print("|i| = %d (0x%luX), addr 0x%luX, top = 0x%luX, size = %ld, link = 0x%luX\n",
              i, &xlists.hole[i],
              xlists.hole[i].addr, xlists.hole[i].top, xlists.hole[i].size,
              xlists.hole[i].link
              );
    }
    print("flists = 0x%luX, table = 0x%luX\n", xlists.flist, xlists.table);
    i = 0;
    for(h = xlists.flist; h; h = h->link)
        i++;

    print("%d holes free", i);
    i = 0;
    for(h = xlists.table; h; h = h->link) {
        if (0) {
            print("addr %#.8lux top %#.8lux size %lud\n",
                h->addr, h->top, h->size);
            delay(10);
        }
        i += h->size;
        if (h == h->link) {
            print("xsummary: infinite loop broken\n");
            break;
        }
    }
    print(" %d bytes free\n", i);
}
@

<<function mallosummary>>=
void
mallocsummary(void)
{
    poolsummary(mainmem);
    poolsummary(imagmem);
}
@

<<function poolsummary>>=
void
poolsummary(Pool *p)
{
    print("%s max %lud cur %lud free %lud alloc %lud\n", p->name,
        p->maxsize, p->cursize, p->curfree, p->curalloc);
}
@

<<function memorysummary>>=
void
memorysummary(void)
{
  int i;

  print("\n");
  print("etext = 0x%luX, edata = 0x%luX, eend = 0x%luX, sizeof long = %d\n",
        etext, edata, end, sizeof(long));
  for(i=0; i<nelem(conf.mem); i++) {
       print("conf mem %d start = 0x%luX, npage = %ld\n", 
          i,
          conf.mem[i].base,
          conf.mem[i].npage
          );
  }
  print("\n");
  memdebug();
}
@

<<function memdebug>>=
void
memdebug(void)
{
    ulong maxpa, maxpa1, maxpa2;

    maxpa = (nvramread(0x18)<<8)|nvramread(0x17);
    maxpa1 = (nvramread(0x31)<<8)|nvramread(0x30);
    maxpa2 = (nvramread(0x16)<<8)|nvramread(0x15);
    print("maxpa = %luX -> %luX, maxpa1 = %luX maxpa2 = %luX\n",
        maxpa, MB+maxpa*KB, maxpa1, maxpa2);

    mapprint(&rmapram);
    mapprint(&rmapumb);
    mapprint(&rmapumbrw);
    mapprint(&rmapupa);
}
@


<<function mapprint>>=
void
mapprint(RMap *rmap)
{
    Map *mp;

    print("%s\n", rmap->name);  
    for(mp = rmap->map; mp->size; mp++)
        print("\t%8.8luX %8.8luX (%lud)\n", mp->addr, mp->addr+mp->size, mp->size);
}
@

<<function pagersummary>>=
void
pagersummary(void)
{
    print("%lud/%lud memory %lud/%lud swap %d iolist\n",
        palloc.user-palloc.freecount,
        palloc.user, conf.nswap-swapalloc.free, conf.nswap,
        ioptr);
}
@


<<function ixsummary>>=
void
ixsummary(void)
{
    debugging ^= 1;
    iallocsummary();
    print("pad %lud, concat %lud, pullup %lud, copy %lud\n",
        padblockcnt, concatblockcnt, pullupblockcnt, copyblockcnt);
    print("consume %lud, produce %lud, qcopy %lud\n",
        consumecnt, producecnt, qcopycnt);
}
@

<<function iallocsummary>>=
void
iallocsummary(void)
{
    print("ialloc %lud/%lud\n", ialloc.bytes, conf.ialloc);
}
@

<<function scheddump>>=
void
scheddump(void)
{
    Proc *p;
    Schedq *rq;

    for(rq = &runq[Nrq-1]; rq >= runq; rq--){
        if(rq->head == 0)
            continue;
        print("rq%ld:", rq-runq);
        for(p = rq->head; p; p = p->rnext)
            print(" %lud(%lud)", p->pid, cpu->ticks - p->readytime);
        print("\n");
        delay(150);
    }
    print("nrdy %d\n", nrdy);
}
@ 

<<function procdump>>=
void
procdump(void)
{
    int i;
    Proc *p;

    if(up)
        print("up %lud\n", up->pid);
    else
        print("no current process\n");
    for(i=0; i<conf.nproc; i++) {
        p = &procalloc.arena[i];
        if(p->state == Dead)
            continue;

        dumpaproc(p);
    }
}
@ 

<<function dumpaproc>>=
void
proc_dumpaproc(Proc *p)
{
    ulong bss;
    char *s;

    if(p == 0)
        return;

    bss = 0;
    if(p->seg[BSEG])
        bss = p->seg[BSEG]->top;

    s = p->psstate;
    if(s == 0)
        s = statename[p->state];
    print("%3lud:%10s pc %8lux dbgpc %8lux  %8s (%s) ut %ld st %ld bss %lux qpc %lux nl %lud nd %lud lpc %lux pri %lud\n",
        p->pid, p->text, p->pc, dbgpc(p),  s, statename[p->state],
        p->time[0], p->time[1], bss, p->qpc, p->nlocks.ref, p->delaysched, p->lastlock ? p->lastlock->pc : 0, p->priority);
}
@ 

\section{[[/dev/kmesg]]}

<<constant KMESGSIZE>>=
// used in devcons.c
KMESGSIZE = (256*1024),  /* lots, for acpi debugging */ // default is 16*1024
@

<<struct KMesg>>=
/*
 * Log console output so it can be retrieved via /dev/kmesg.
 * This is good for catching boot-time messages after the fact.
 */
struct KMesg {
    Lock lk;
    char buf[KMESGSIZE];
    uint n;
};
@ 


<<global kmesg>>=
struct KMesg kmesg;
@ 


<<function kmesgputs>>=
static void
kmesgputs(char *str, int n)
{
    uint nn, d;

    ilock(&kmesg.lk);
    /* take the tail of huge writes */
    if(n > sizeof kmesg.buf){
        d = n - sizeof kmesg.buf;
        str += d;
        n -= d;
    }

    /* slide the buffer down to make room */
    nn = kmesg.n;
    if(nn + n >= sizeof kmesg.buf){
        d = nn + n - sizeof kmesg.buf;
        if(d)
            memmove(kmesg.buf, kmesg.buf+d, sizeof kmesg.buf-d);
        nn -= d;
    }

    /* copy the data in */
    memmove(kmesg.buf+nn, str, n);
    nn += n;
    kmesg.n = nn;
    iunlock(&kmesg.lk);
}
@ 

\section{[[/dev/kprint]]}

<<global kprintoq>>=
Queue*  kprintoq;       /* console output, for /dev/kprint */
@ 

% why use tas() on it? why not use a Ref? because core debugging?
% so don't want to rely on anything fancy?
<<global kprintinuse>>=
ulong   kprintinuse;        /* test and set whether /dev/kprint is open */
@



\section{Remote debugger}
% rdb.c
% related to serial line code?
% TODO: how does it work? can make it work via qemu?

<<hook consdebug>>=
void    (*consdebug)(void) = nil; // for rdb
@ 

\section{Debugging user processes}

% Should cooperate with Debugger.tex.nw at some point

% there are 2 processes involved: the debuggee, and the debugger.
% In the following, could call slave and master?

\subsection{XTODO}

<<[[Proc]] debugger fields>>=
void  *dbgreg;  /* User registers for devproc */
@

% old: int scallnr;  /* sys call number - known by db */
% put back? db will still work?

%TODO: Qreg section of /dev/proc
<<function setregisters>>=
/* This routine must save the values of registers the user is not permitted
 * to write from devproc and then restore the saved values before returning.
 */
void
setregisters(Ureg* ureg, char* pureg, char* uva, int n)
{
    ulong cs, ds, es, flags, fs, gs, ss;

    ss = ureg->ss;
    flags = ureg->flags;
    cs = ureg->cs;
    ds = ureg->ds;
    es = ureg->es;
    fs = ureg->fs;
    gs = ureg->gs;
    memmove(pureg, uva, n);
    ureg->gs = gs;
    ureg->fs = fs;
    ureg->es = es;
    ureg->ds = ds;
    ureg->cs = cs;
    ureg->flags = (ureg->flags & 0x00FF) | (flags & 0xFF00);
    ureg->ss = ss;
}
@ 

<<enum procctl cases>>=
    Proc_exitme,
    Proc_traceme,
    Proc_exitbig,
@

<<[[procctl()]] Proc_traceme case (and fallthrough [[Proc_stopme]])>>=
    case Proc_traceme:
        if(p->nnote == 0)
            return;
        /* No break */
@

<<[[procctl()]] Proc_exitbig case>>=
    case Proc_exitbig:
        spllo();
        pexit("Killed: Insufficient physical memory", true);
@

<<[[procctl()]] Proc_exitme case>>=
    case Proc_exitme:
        spllo();        /* pexit has locks in it */
        pexit("Killed", true);
@


\subsection{Stopping a process}

% multi usage: strace, debugger

% If want to implement a debugger or strace, what do you need?
% Need a way to control and inspect another process. First for
% the control you need a way to stop him.
% For instance before it gets to his second syscall you got a chance
% to print the trace of the first syscall. 

<<enum procstate cases>>=
Stopped,
@
% Who can set this state? only when do procttl() where have a Proc_stopme.
% So who can set Proc_stopme for the procctl?


<<enum procctl>>=
enum procctl
{
    Proc_nothing = 0,
    Proc_stopme,
    <<enum procctl cases>>
};
@ 


<<[[Proc]] debugger fields>>=
// enum<procctl>
int procctl;  /* Control for /proc debugging */
@
% who can set to Proc_stopme? 
%  - when have up->hang
%  - when have Proc_tracesyscall
%    then at the entry the syscall sets the process to Stopme,



<<function procctl>>=
/*
 *  called splhi() by notify().  See comment in notify for the
 *  reasoning.
 */
void
procctl(Proc *p)
{
    char *oldstate;
    ulong s;

    switch(p->procctl) {
    <<[[procctl()]] Proc_traceme case (and fallthrough [[Proc_stopme]])>>
    case Proc_stopme:
        p->procctl = Proc_nothing;
        oldstate = p->psstate;
        p->psstate = "Stopped";
        s = spllo();
        <<[[procctl()]] wakeup waiting debugger>>
        splhi();
        p->state = Stopped;
        sched();
        // here when the debugger ready p back
        p->psstate = oldstate;
        splx(s);
        return;
    <<[[procctl()]] Proc_exitbig case>>
    <<[[procctl()]] Proc_exitme case>>
    }
}
@ 
% why pass p? it's always called via procctl(up), so why not using
% up directly? in the end we call sched()
% why set p->state = Stopped inside splhi(), would make more sense
% actually to set it before wakeing up the debugger that is sleeping
% on the condition that the process was stopped!

% so how a process can cause procctl() for another process to
% be executed? can't just do  procctl(other_process)?
% but this other process is executing ... maybe at next trap
% it can look?

% overview steps on 'strace ls' or 'db ls':
% - strace: fork (to later exec ls)
% - child: before exec(), will 'echo hang > /proc/child/ctl'
%   (exec will use this info)
% - child: exec ls, because of hang will get his procctl to Proc_stopme,
%   which later when return from sysexec will get back to syscall() which
%   check if procctl, call notify() which then call procctl() which
%   will effectively stop ls!


<<[[Proc]] debugger fields>>=
bool hang;   /* hang at next exec for debug */
@

<<[[procctlreq()]] CMhang case>>=
    case CMhang:
        p->hang = true;
        break;
@
<<[[procctlreq()]] CMnohang case>>=
    case CMnohang:
        p->hang = false;
        break;
@


<<[[sysfork()]] inherit hang>>=
    p->hang = up->hang;
@

<<[[sysexec()]] if hang>>=
    if(up->hang)
        up->procctl = Proc_stopme;
@
% why not do procctl(up) here? when the process will stop? because
% at return of sysexec there will be a call to notify and procctl(up),
% but looks a bit dirty, why they abused notify for that?
% because for the debugger they need more than just procctl? they need
% notes?


% so now we know how to stop another (your child at least), but
% how tracer can wait? can't just call await(), we don't wait
% for the child to die...


% debug also (ab?)used in pexit when freeing memory
<<[[Proc]] debugger fields>>=
Proc  *pdbg;    /* the debugging process */
@

<<[[Proc]] debugger fields>>=
QLock debug;    /* to access debugging elements */ // used for many things
@
% used by strace, but also db


<<function procstopwait>>=
// assumes p->debug is held
void
procstopwait(Proc *p, int ctl)
{
    int pid;

    if(p->pdbg)
        error(Einuse);
    if(procstopped(p) || p->state == Broken)
        return;

    if(ctl != Proc_nothing)
        p->procctl = ctl;

    p->pdbg = up;
    pid = p->pid;

    qunlock(&p->debug);
    up->psstate = "Stopwait";
    if(waserror()) {
        p->pdbg = nil;
        qlock(&p->debug);
        nexterror();
    }

    sleep(&up->sleepr, procstopped, p);

    poperror();
    qlock(&p->debug);
    if(p->pid != pid) // p was reallocated to a new process
        error(Eprocdied);
}
@

<<function procstopped>>=
bool
procstopped(void *a)
{
    Proc *p = a;
    return p->state == Stopped;
}
@


<<[[procctl()]] wakeup waiting debugger>>=
        /* free a waiting debugger */
        qlock(&p->debug);
        if(p->pdbg) {
            wakeup(&p->pdbg->sleepr);
            p->pdbg = nil;
        }
        qunlock(&p->debug);
@





\subsection{[[/bin/strace]]}
% was actually called ratrace, but prefer strace

% overview steps on 'strace ls':
% - strace: echo 'startsyscall' > /proc/child/ctl
%   which should ready the child (ls) process and write Proc_tracesyscall
%   to procctl of child! (which was stopped so no race).
%   it will also trigger a sleep for strace until the other proc get
%   stopped again via procstopwait()

% loop:
% - ls could continue, and at first syscall entry will stop again
%   and wakeup tracer
% - strace: can read /proc/child/syscall content
% - strace: write back 'startsyscall' to /proc/child/ctl (and sleep)
% - ls continue and do actual syscall, and stop again
% - strace: can read /proc/child/syscall of return value of syscall
% - strace: write back 'startsyscall' to /proc/child/ctl (which will
%   make strace sleep at the same time)

% show sequence diagram? cos complex.
% why abuse notify()?

% alternative approach? 

<<enum procctl cases>>=
    Proc_tracesyscall,
@
% but who can set the procctl to Proc_tracesyscall?

<<[[syscall()]] Proc_tracesyscall if, syscall entry>>=
    if(up->procctl == Proc_tracesyscall){
        /*
         * Redundant validaddr.  Do we care?
         * Tracing syscalls is not exactly a fast path...
         * Beware, validaddr currently does a pexit rather
         * than an error if there's a problem; that might
         * change in the future.
         */
        if(sp < (USTKTOP-BY2PG) || sp > (USTKTOP-sizeof(Sargs)-BY2WD))
            validaddr(sp, sizeof(Sargs)+BY2WD, 0);

        syscallfmt(scallnr, ureg->pc, (va_list)(sp+BY2WD));
        up->procctl = Proc_stopme;
        // this will call sched() and wakeup the tracer process
        procctl(up); 
        // back here when the tracer process readied us back and
        // should have set procctl back to Proc_tracesyscall
        if(up->syscalltrace)
            free(up->syscalltrace);
        up->syscalltrace = nil;
        startns = todget(nil);
    }
@

<<[[syscall()]] Proc_tracesyscall if, syscall exit>>=
    if(up->procctl == Proc_tracesyscall){
        stopns = todget(nil);
        up->procctl = Proc_stopme;
        sysretfmt(scallnr, (va_list)(sp+BY2WD), ret, startns, stopns);
        s = splhi();
        procctl(up); // again, will call sched() and wakeup tracer process
        splx(s);
        if(up->syscalltrace)
            free(up->syscalltrace);
        up->syscalltrace = nil;
    }
@
% why protect procctl(up) with splhi here and not before?
% both the entry and exit are not perfectly symetric :( TOFIX?

<<[[newproc()]] inherit Proc_tracesyscall>>=
    if(up && up->procctl == Proc_tracesyscall)
        p->procctl = Proc_tracesyscall;
    else
        p->procctl = Proc_nothing;
@


% communicate info via syscalltrace! accessible at /proc/x/syscall
% the 'inspect' mechanism needed
<<[[Proc]] debugger fields>>=
char  *syscalltrace;  /* syscall trace */
@


% /proc/x/syscall
<<[[procread()]] Qsyscall case>>=
    case Qsyscall:
        if(!p->syscalltrace)
            return 0;
        n = readstr(offset, a, n, p->syscalltrace);
        return n;
@


% note that 'up' here is the process of the tracer! he is the one
% writing to /proc/x/ctl 
<<[[procctlreq()]] CMstartsyscall case>>=
    case CMstartsyscall:
        if(p->state != Stopped)
            error(Ebadctl);
        p->procctl = Proc_tracesyscall;
        ready(p);
        procstopwait(p, Proc_tracesyscall); // will sleep
        break;
@
% but how x was stopped in the first place? get hang to true
% but then it just leads to Proc_stopme, there was no call to procctl(up)
% in sysexec, so who stopped it?









<<function syscallfmt>>=
void
syscallfmt(int syscallno, ulong pc, va_list list)
{
    long l;
    Fmt fmt;
    void *v;
    vlong vl;
    uintptr p;
    int i[2], len;
    char *a, **argv;

    fmtstrinit(&fmt);
    fmtprint(&fmt, "%uld %s ", up->pid, up->text);

    if(syscallno > nsyscall)
        fmtprint(&fmt, " %d ", syscallno);
    else
        fmtprint(&fmt, "%s ", sysctab[syscallno]?
            sysctab[syscallno]: "huh?");

    fmtprint(&fmt, "%ulx ", pc);
    if(up->syscalltrace != nil)
        free(up->syscalltrace);

    switch(syscallno){
    case NOP:
        p = va_arg(list, uintptr);
        fmtprint(&fmt, "%#p", p);
        break;
    case CHDIR:
    case EXITS:
    case REMOVE:
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, "");
        break;
    case BIND:
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        i[0] = va_arg(list, int);
        fmtprint(&fmt, "%#ux",  i[0]);
        break;
    case CLOSE:
    case NOTED:
        i[0] = va_arg(list, int);
        fmtprint(&fmt, "%d", i[0]);
        break;
    case DUP:
        i[0] = va_arg(list, int);
        i[1] = va_arg(list, int);
        fmtprint(&fmt, "%d %d", i[0], i[1]);
        break;
    case ALARM:
        l = va_arg(list, unsigned long);
        fmtprint(&fmt, "%#lud ", l);
        break;
    case EXEC:
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, "");
        argv = va_arg(list, char**);
        evenaddr(PTR2UINT(argv));
        for(;;){
            validaddr((ulong)argv, sizeof(char**), 0);
            a = *(char **)argv;
            if(a == nil)
                break;
            fmtprint(&fmt, " ");
            fmtuserstring(&fmt, a, "");
            argv++;
        }
        break;
    case FAUTH:
        i[0] = va_arg(list, int);
        a = va_arg(list, char*);
        fmtprint(&fmt, "%d", i[0]);
        fmtuserstring(&fmt, a, "");
        break;
    case SEGBRK:
    case RENDEZVOUS:
        v = va_arg(list, void*);
        fmtprint(&fmt, "%#p ", v);
        v = va_arg(list, void*);
        fmtprint(&fmt, "%#p", v);
        break;
    case OPEN:
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        i[0] = va_arg(list, int);
        fmtprint(&fmt, "%#ux", i[0]);
        break;
    case SLEEP:
        l = va_arg(list, long);
        fmtprint(&fmt, "%ld", l);
        break;
    case RFORK:
        i[0] = va_arg(list, int);
        fmtprint(&fmt, "%#ux", i[0]);
        break;
    case PIPE:
    case BRK:
        v = va_arg(list, int*);
        fmtprint(&fmt, "%#p", v);
        break;
    case CREATE:
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        i[0] = va_arg(list, int);
        i[1] = va_arg(list, int);
        fmtprint(&fmt, "%#ux %#ux", i[0], i[1]);
        break;
    case FD2PATH:
    case FSTAT:
    case FWSTAT:
        i[0] = va_arg(list, int);
        a = va_arg(list, char*);
        l = va_arg(list, unsigned long);
        fmtprint(&fmt, "%d %#p %lud", i[0], a, l);
        break;
    case NOTIFY:
    case SEGDETACH:
        v = va_arg(list, void*);
        fmtprint(&fmt, "%#p", v);
        break;
    case SEGATTACH:
        i[0] = va_arg(list, int);
        fmtprint(&fmt, "%d ", i[0]);
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        /*FALLTHROUGH*/
    case SEGFREE:
    case SEGFLUSH:
        v = va_arg(list, void*);
        l = va_arg(list, unsigned long);
        fmtprint(&fmt, "%#p %lud", v, l);
        break;
    case UNMOUNT:
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, "");
        break;
    case SEMACQUIRE:
    case SEMRELEASE:
        v = va_arg(list, int*);
        i[0] = va_arg(list, int);
        fmtprint(&fmt, "%#p %d", v, i[0]);
        break;
    case TSEMACQUIRE:
        v = va_arg(list, long*);
        l = va_arg(list, ulong);
        fmtprint(&fmt, "%#p %ld", v, l);
        break;
    case SEEK:
        v = va_arg(list, vlong*);
        i[0] = va_arg(list, int);
        vl = va_arg(list, vlong);
        i[1] = va_arg(list, int);
        fmtprint(&fmt, "%#p %d %#llux %d", v, i[0], vl, i[1]);
        break;
    case FVERSION:
        i[0] = va_arg(list, int);
        i[1] = va_arg(list, int);
        fmtprint(&fmt, "%d %d ", i[0], i[1]);
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        l = va_arg(list, unsigned long);
        fmtprint(&fmt, "%lud", l);
        break;
    case WSTAT:
    case STAT:
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        /*FALLTHROUGH*/
    case ERRSTR:
    case AWAIT:
        a = va_arg(list, char*);
        l = va_arg(list, unsigned long);
        fmtprint(&fmt, "%#p %lud", a, l);
        break;
    case MOUNT:
        i[0] = va_arg(list, int);
        i[1] = va_arg(list, int);
        fmtprint(&fmt, "%d %d ", i[0], i[1]);
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        i[0] = va_arg(list, int);
        fmtprint(&fmt, "%#ux ", i[0]);
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, "");
        break;
    case PREAD:
        i[0] = va_arg(list, int);
        v = va_arg(list, void*);
        l = va_arg(list, long);
        fmtprint(&fmt, "%d %#p %ld", i[0], v, l);
        if(syscallno == PREAD){
            vl = va_arg(list, vlong);
            fmtprint(&fmt, " %lld", vl);
        }
        break;
    case PWRITE:
        i[0] = va_arg(list, int);
        v = va_arg(list, void*);
        l = va_arg(list, long);
        fmtprint(&fmt, "%d ", i[0]);
        len = MIN(l, 64);
        fmtrwdata(&fmt, v, len, " ");
        fmtprint(&fmt, "%ld", l);
        if(syscallno == PWRITE){
            vl = va_arg(list, vlong);
            fmtprint(&fmt, " %lld", vl);
        }
        break;
    }

    up->syscalltrace = fmtstrflush(&fmt);
}
@ 


<<function sysretfmt>>=
void
sysretfmt(int syscallno, va_list list, long ret, uvlong start, uvlong stop)
{
    long l;
    void* v;
    Fmt fmt;
    vlong vl;
    int i, len;
    char *a, *errstr;

    fmtstrinit(&fmt);

    if(up->syscalltrace)
        free(up->syscalltrace);

    errstr = "\"\"";
    switch(syscallno){
    default:
    case ALARM:
    case PWRITE:
        if(ret == -1)
            errstr = up->syserrstr;
        fmtprint(&fmt, " = %ld", ret);
        break;
    case EXEC:
    case SEGBRK:
    case SEGATTACH:
    case RENDEZVOUS:
        if((void *)ret == (void*)-1)
            errstr = up->syserrstr;
        fmtprint(&fmt, " = %#p", (void *)ret);
        break;
    case AWAIT:
        a = va_arg(list, char*);
        l = va_arg(list, unsigned long);
        if(ret > 0){
            fmtuserstring(&fmt, a, " ");
            fmtprint(&fmt, "%lud = %ld", l, ret);
        }
        else{
            fmtprint(&fmt, "%#p/\"\" %lud = %ld", a, l, ret);
            errstr = up->syserrstr;
        }
        break;
    case ERRSTR:
        a = va_arg(list, char*);
        l = va_arg(list, unsigned long);
        if(ret > 0){
            fmtuserstring(&fmt, a, " ");
            fmtprint(&fmt, "%lud = %ld", l, ret);
        }
        else{
            fmtprint(&fmt, "\"\" %lud = %ld", l, ret);
            errstr = up->syserrstr;
        }
        break;
    case FD2PATH:
        i = va_arg(list, int);
        USED(i);
        a = va_arg(list, char*);
        l = va_arg(list, unsigned long);
        if(ret > 0){
            fmtuserstring(&fmt, a, " ");
            fmtprint(&fmt, "%lud = %ld", l, ret);
        }
        else{
            fmtprint(&fmt, "\"\" %lud = %ld", l, ret);
            errstr = up->syserrstr;
        }
        break;
    case PREAD:
        i = va_arg(list, int);
        USED(i);
        v = va_arg(list, void*);
        l = va_arg(list, long);
        if(ret > 0){
            len = MIN(ret, 64);
            fmtrwdata(&fmt, v, len, "");
        }
        else{
            fmtprint(&fmt, "/\"\"");
            errstr = up->syserrstr;
        }
        fmtprint(&fmt, " %ld", l);
        if(syscallno == PREAD){
            vl = va_arg(list, vlong);
            fmtprint(&fmt, " %lld", vl);
        }
        fmtprint(&fmt, " = %ld", ret);
        break;
    }
    fmtprint(&fmt, " %s %#llud %#llud\n", errstr, start, stop);
    up->syscalltrace = fmtstrflush(&fmt);
}
@ 

<<function fmtrwdata>>=
// WE ARE OVERRUNNING SOMEHOW
static void
fmtrwdata(Fmt* f, char* a, int n, char* suffix)
{
    int i;
    char *t;

    if(a == nil){
        fmtprint(f, "0x0%s", suffix);
        return;
    }
    validaddr((ulong)a, n, 0);
    t = smalloc(n+1);
    for(i = 0; i < n; i++)
        if(a[i] > 0x20 && a[i] < 0x7f)  /* printable ascii? */
            t[i] = a[i];
        else
            t[i] = '.';

    fmtprint(f, " %#p/\"%s\"%s", a, t, suffix);
    free(t);
}
@ 


<<function fmtuserstring>>=
static void
fmtuserstring(Fmt* f, char* a, char* suffix)
{
    int n;
    char *t;

    if(a == nil){
        fmtprint(f, "0/\"\"%s", suffix);
        return;
    }
    validaddr((ulong)a, 1, 0);
    n = ((char*)vmemchr(a, 0, 0x7fffffff) - a) + 1;
    t = smalloc(n+1);
    memmove(t, a, n);
    t[n] = 0;
    fmtprint(f, "%#p/\"%s\"%s", a, t, suffix);
    free(t);
}
@ 


\subsection{[[/proc/trace]] and [[/bin/trace]]}
% /proc/trace contains events from the kernel scheduler

<<[[Proc]] debugger fields>>=
bool trace;    /* process being traced? */
@
% rename to schedtrace?

% echo 'trace 1' > proc/x/ctl

<<[[procctlreq()]] CMtrace case>>=
    case CMtrace:
        switch(cb->nf){
        case 1:
            p->trace ^= true;
            break;
        case 2:
            p->trace = (atoi(cb->f[1]) != 0);
            break;
        default:
            error("args");
        }
        break;
@


<<hook proctrace>>=
void (*proctrace)(Proc*, /*enum<tevent>*/int, vlong) = 0; // was in devproc.c
@ 

<<enum Tevent>>=
enum Tevent {
 SReady = 0,		/* runnable but not running  */
 SRun,		/* running best effort */
 SDead,		/* proc dies */
 SSleep,		/* blocked */
 SUser,		/* user event */

        /* real-time extensions */
        <<[[enum Tevent]] real-time scheduling events>>

 Nevent, // must be last
};
@

<<struct Traceevent>>=
struct Traceevent {
 ulong	pid;	
        // enum<tevent>
 ulong	etype;	/* Event type */
 vlong	time;	/* time stamp  */ // dimention?
};
@

%TODO: code of trace.h here

% Always code like:
%    pt = proctrace
%    if(pt) pt(...)
% Why not just if(proctrace) proctrace(...)? because of race!
% After the 'if' proctrace could be null!

% could draw automata :)

<<ready()]] hook proctrace>>=
    pt = proctrace;
    if(pt)
        pt(p, SReady, 0);
@

<<[[runproc()]] hook proctrace>>=
    pt = proctrace;
    if(pt)
        pt(p, SRun, 0);
@

<<[[pexit()]] hook proctrace>>=
    pt = proctrace;
    if(pt)
        pt(up, SDead, 0);
@


<<[[sleep()]] hook proctrace>>=
        pt = proctrace;
        if(pt)
            pt(up, SSleep, 0);
@

% this one is a little bit different
<<[[procctlreq()]] CMevent case>>=
    case CMevent:
        pt = proctrace;
        if(up->trace && pt)
            pt(up, SUser, 0);
        break;
@
%TODO: can remove the up->trace, pt does this internally

%TODO could put all of that in a struct, and a Lock, would be cleaner
<<global trace txxx>>=
// array<Traceevent>
static Traceevent *tevents;
static int topens;
static int tproduced, tconsumed;
static Lock tlock;
@
% topens can be > 1 ??? use a bool no?

<<function eventsavailable>>=
static int
eventsavailable(void *)
{
    return tproduced > tconsumed;
}
@



% no locks?
<<function _proctrace>>=
static void
_proctrace(Proc* p, Tevent etype, vlong ts)
{
    Traceevent *te;

    if (p->trace == false || topens == 0 ||
        tproduced - tconsumed >= Nevents)
        return;

    te = &tevents[tproduced&Emask];
    te->pid = p->pid;
    te->etype = etype;
    if (ts == 0)
        te->time = todget(nil);
    else
        te->time = ts;
    tproduced++;
}
@

<<constant Nevents>>=
    Nevents = 0x4000,
@

<<constant Emask>>=
    Emask = Nevents - 1,
@

<<[[procopen()]] Qtrace if>>=
    if(QID(c->qid) == Qtrace){
        if (omode != OREAD) 
            error(Eperm);
        lock(&tlock);
        if (waserror()){
            unlock(&tlock);
            nexterror();
        }
        if (topens > 0)
            error("already open");
        topens++;
        if (tevents == nil){
            tevents = (Traceevent*)malloc(sizeof(Traceevent) * Nevents);
            if(tevents == nil)
                error(Enomem);
            tproduced = tconsumed = 0;
        }
        proctrace = _proctrace;
        unlock(&tlock);
        poperror();

        c->mode = openmode(omode);
        c->flag |= COPEN;
        c->offset = 0;
        return c;
    }
@

<<[[procclose()]] Qtrace if>>=
    if(QID(c->qid) == Qtrace){
        lock(&tlock);
        if(topens > 0)
            topens--;
        if(topens == 0)
            proctrace = nil;
        unlock(&tlock);
    }
@

<<[[procread()]] Qtrace if>>=
    if(QID(c->qid) == Qtrace){
        if(!eventsavailable(nil))
            return 0;

        rptr = (uchar*)va;
        navail = tproduced - tconsumed;
        if(navail > n / sizeof(Traceevent))
            navail = n / sizeof(Traceevent);
        while(navail > 0) {
            ne = ((tconsumed & Emask) + navail > Nevents)? 
                    Nevents - (tconsumed & Emask): navail;
            memmove(rptr, &tevents[tconsumed & Emask], 
                    ne * sizeof(Traceevent));

            tconsumed += ne;
            rptr += ne * sizeof(Traceevent);
            navail -= ne;
        }
        return rptr - (uchar*)va;
    }
@



\subsection{[[/bin/db]]}



\chapter{Profiling}

\section{Counters}

<<struct Perf>>=
/*
 *  performance timers, all units in perfticks
 */
struct Perf
{
    // intr-ts? interrupt time stamp?
    ulong intrts;   /* time of last interrupt */
    ulong inintr;   /* time since last clock tick in interrupt handlers */
    ulong avg_inintr; /* avg time per clock tick in interrupt handlers */
    ulong inidle;   /* time since last clock tick in idle loop */
    ulong avg_inidle; /* avg time per clock tick in idle loop */
    ulong last;   /* value of perfticks() at last clock tick */
    ulong period;   /* perfticks() per clock tick */
};
@ 

<<[[Cpu]] stat fields>>=
Perf  perf;     /* performance counters */
@ 

<<[[Cpu]] stat fields>>=
int cs; // context switch, sched() and sleep() call
int syscall;
int load;
int tlbfault;
int tlbpurge;
int pfault;
int intr;
ulong spuriousintr;
@

<<[[Cpu]] [[Arch]] other fields>>=
int pdballoc;
int pdbfree;
@

% also lockcycles here?

\section{[[/dev/kprof]]}
% devkprof.c?

<<hook kproftimer>>=
void (*kproftimer)(ulong);
@ 

\section{Profiling user processes}

% should cooperate with Profiling.tex.nw at some point

\subsection{[[/bin/time]]}

<<enum proctimer>>=
enum proctime 
{
    TUser = 0,    /* Proc.time */
    TSys,
    TReal,

    // accumulates also the time of its children
    TCUser, 
    TCSys, 
    TCReal,
};
@ 

<<[[Proc]] stats and profiling fields>>=
// hash<enum<proctime>, ulong>
ulong time[6];  /* User, Sys, Real; child U, S, R */
@

<<[[Proc]] stats and profiling fields>>=
uvlong  kentry;   /* Kernel entry time stamp (for profiling) */
/*
 * pcycles: cycles spent in this process (updated on procsave/restore)
 * when this is the current proc and we're in the kernel
 * (procrestores outnumber procsaves by one)
 * the number of cycles spent in the proc is pcycles + cycles()
 * when this is not the current process or we're in user mode
 * (procrestores and procsaves balance), it is pcycles.
 */
vlong pcycles;
@ 


\chapter{Error Managment}

\section{[[panic()]]}

<<global panicking>>=
bool panicking;
@

<<function panic>>=
void
devcons_panic(char *fmt, ...)
{
    int n, s;
    va_list arg;
    char buf[PRINTSIZE];

    kprintoq = nil; /* don't try to write to /dev/kprint */

    if(panicking)
        for(;;);
    panicking = true;

    s = splhi();
    strcpy(buf, "panic: ");
    va_start(arg, fmt);
    n = vseprint(buf+strlen(buf), buf+sizeof(buf), fmt, arg) - buf;
    va_end(arg);
    iprint("%s\n", buf);
    if(consdebug)
        (*consdebug)();
    splx(s);
    prflush();
    buf[n] = '\n';
    putstrn(buf, n+1);
    //TODO: put in comment for now because already got some panic with
    // lapic, but it seems to work still :)
    //dumpstack();
    //exit(1);
}
@ 


<<function sysfatal>>=
/* libmp at least contains a few calls to sysfatal; simulate with panic */
//@Scheck: no dead, override also sysfatal from libc/9sys/sysfatal.c
// note that this is not a system call, even though it's prefixed with sys
void
sysfatal(char *fmt, ...)
{
    char err[256];
    va_list arg;

    va_start(arg, fmt);
    vseprint(err, err + sizeof err, fmt, arg);
    va_end(arg);
    panic("sysfatal: %s", err);
}
@ 

<<function _assert>>=
void
devcons__assert(char *fmt)
{
    panic("assert failed at %#p: %s", getcallerpc(&fmt), fmt);
}
@ 

\section{[[error()]]}

<<global Exxx errors>>=
char Emount[] = "inconsistent mount";
char Eunmount[] = "not mounted";
char Eismtpt[] = "is a mount point";
char Eunion[] = "not in union";
char Emountrpc[] = "mount rpc error";
char Eshutdown[] = "device shut down";
char Enocreate[] = "mounted directory forbids creation";
char Enonexist[] = "file does not exist";
char Eexist[] = "file already exists";
char Ebadsharp[] = "unknown device in # filename";
char Enotdir[] = "not a directory";
char Eisdir[] = "file is a directory";
char Ebadchar[] = "bad character in file name";
char Efilename[] = "file name syntax";
char Eperm[] = "permission denied";
char Ebadusefd[] = "inappropriate use of fd";
char Ebadarg[] = "bad arg in system call";
char Einuse[] = "device or object already in use";
char Eio[] = "i/o error";
char Etoobig[] = "read or write too large";
char Etoosmall[] = "read or write too small";
char Ehungup[] = "i/o on hungup channel";
char Ebadctl[] = "bad process or channel control request";
char Enodev[] = "no free devices";
char Eprocdied[] = "process exited";
char Enochild[] = "no living children";
char Eioload[] = "i/o error in demand load";
char Enovmem[] = "virtual memory allocation failed";
char Ebadfd[] = "fd out of range or not open";
char Enofd[] = "no free file descriptors";
char Eisstream[] = "seek on a stream";
char Ebadexec[] = "exec header invalid";
char Etimedout[] = "connection timed out";
char Econrefused[] = "connection refused";
char Econinuse[] = "connection in use";
char Eintr[] = "interrupted";
char Enomem[] = "kernel allocate failed";
char Esoverlap[] = "segments overlap";
char Emouseset[] = "mouse type already set";
char Eshort[] = "i/o count too small";
char Egreg[] = "jmk added reentrancy for threads";
char Ebadspec[] = "bad attach specifier";
char Enoreg[] = "process has no saved registers";
char Enoattach[] = "mount/attach disallowed";
char Eshortstat[] = "stat buffer too small";
char Ebadstat[] = "malformed stat buffer";
char Enegoff[] = "negative i/o offset";
char Ecmdargs[] = "wrong #args in control message";
char Ebadip[] = "bad ip address syntax";
char Edirseek[] = "seek in directory";
char Echange[] = "media or partition has changed";
@ 


<<[[Proc]] error managment fields>>=
// array<Label>, error labels, poor's man exceptions in C
Label errlab[NERR];
// length(errlab) used.
int nerrlab;

// ref<string> point to errbuf0 or to syserrstr (which points to errbuf1)
char  *errstr;  /* reason we're unwinding the error stack, errbuf1 or 0 */
char  errbuf0[ERRMAX];
char  errbuf1[ERRMAX];
@ 

<<function error>>=
void
proc_error(char *err)
{
    spllo();

    assert(up->nerrlab < NERR);
    kstrcpy(up->errstr, err, ERRMAX);
    setlabel(&up->errlab[NERR-1]);
    nexterror();
}
@ 
% todo: there is a top waserror() in trap and syscall? so will
% always jump somewhere?

<<function exhausted>>=
void
exhausted(char *resource)
{
    char buf[ERRMAX];

    snprint(buf, sizeof buf, "no free %s", resource);
    iprint("%s\n", buf);
    error(buf);
}
@ 


\section{[[waserror()]], [[nexterror()]], [[poperror()]]}
% waserror(), nexterror(), etc
% =~ poor's man exn mechanism (=> improve C!!)

<<macro waserror poperror>>=
// poor's man exceptions in C
//  - waserror() =~ try  
//     * if (!waserror()) { } else { } <=> try { } catch { }
//     * if (waserror()) { }  <=> finally { }
//  - poperror() = nothing
//  - error() =~ raise
//  - nexterror() =~ re raise from exn handler
// note, setlabel() return false, so the branch is never taken first
// but nexterror() is using gotolabel() which returns true, see l_switch.s
#define waserror()  (up->nerrlab++, setlabel(&up->errlab[up->nerrlab-1]))
#define poperror()    up->nerrlab--
@ 


<<function nexterror>>=
// raise an exception
void
proc_nexterror(void)
{
    gotolabel(&up->errlab[--up->nerrlab]);
}
@ 


\section{[[syserrstr()]]}

<<[[Proc]] error managment fields>>=
char  *syserrstr; /* last error from a system call, errbuf0 or 1 */
@

<<syscall errstr>>=
// int errstr(char *err, uint nerr);
long
syserrstr(ulong *arg)
{
    return generrstr((char*)arg[0], arg[1]);
}
@ 

<<function generrstr>>=
static long
generrstr(char *buf, uint nbuf)
{
    char tmp[ERRMAX];

    if(nbuf == 0)
        error(Ebadarg);
    validaddr((ulong)buf, nbuf, 1);
    if(nbuf > sizeof tmp)
        nbuf = sizeof tmp;
    memmove(tmp, buf, nbuf);

    /* make sure it's NUL-terminated */
    tmp[nbuf-1] = '\0';
    memmove(buf, up->syserrstr, nbuf);
    buf[nbuf-1] = '\0';
    memmove(up->syserrstr, tmp, nbuf);
    return 0;
}
@ 

<<function werrstr>>=
//@Scheck: this is also defined in libc, so it's supposed to override it? TODO
void
werrstr(char *fmt, ...)
{
    va_list va;

    if(up == nil)
        return;

    va_start(va, fmt);
    vseprint(up->syserrstr, up->syserrstr+ERRMAX, fmt, va);
    va_end(va);
}
@ 

\chapter{Mini Libc}

% use malloc internally?

\section{Memory areas operations}

% ugly that memmove is actually not a move but a copy, and ugly
% that take dest first and src second ...
% actually memmove can handle when memory area overlap!
<<lib.h mem functions decl>>=
extern  void* memccpy(void*, void*, int, ulong);
extern  void* memset(void*, int, ulong);
extern  int memcmp(void*, void*, ulong);
extern  void* memmove(void*, void*, ulong);
extern  void* memchr(void*, int, ulong);
@ 

% memchr reverse?
<<function memrchr>>=
void*
memrchr(void *va, int c, long n)
{
    uchar *a, *e;

    a = va;
    for(e=a+n-1; e>a; e--)
        if(*e == c)
            return e;
    return nil;
}
@

\section{String functions}

<<lib.h string functions decl>>=
extern  char* strchr(char*, int);
extern  char* strrchr(char*, int);
extern  int strcmp(char*, char*);
extern  char* strcpy(char*, char*);
extern  char* strecpy(char*, char*, char*);
extern  char* strncpy(char*, char*, long);
extern  int strncmp(char*, char*, long);
extern  long  strlen(char*);
extern  char* strstr(char*, char*);
extern  int atoi(char*);
extern  int fullrune(char*, int);
@ 
%//unused: extern  char* strcat(char*, char*);
%//unused: extern  char* strncat(char*, char*, long);


%todo: put the isdot, isfrog here?

<<function kstrcpy>>=
/*
 * Rather than strncpy, which zeros the rest of the buffer, kstrcpy
 * truncates if necessary, always zero terminates, does not zero fill,
 * and puts ... at the end of the string if it's too long.  Usually used to
 * save a string in up->genbuf;
 */
void
kstrcpy(char *s, char *t, int ns)
{
    int nt;

    nt = strlen(t);
    if(nt+1 <= ns){
        memmove(s, t, nt+1);
        return;
    }
    /* too long */
    if(ns < 4){
        /* but very short! */
        strncpy(s, t, ns);
        return;
    }
    /* truncate with ... at character boundary (very rare case) */
    memmove(s, t, ns-4);
    ns -= 4;
    s[ns] = '\0';
    /* look for first byte of UTF-8 sequence by skipping continuation bytes */
    while(ns>0 && (s[--ns]&0xC0)==0x80)
        ;
    strcpy(s+ns, "...");
}
@


<<function kstrdup>>=
/*
 * Atomically replace *p with copy of s
 */
void
kstrdup(char **p, char *s)
{
    int n;
    char *t, *prev;

    n = strlen(s)+1;
    /* if it's a user, we can wait for memory; if not, something's very wrong */
    if(up){
        t = smalloc(n);
        setmalloctag(t, getcallerpc(&p));
    }else{
        t = malloc(n);
        if(t == nil)
            panic("kstrdup: no memory");
    }
    memmove(t, s, n);
    prev = *p;
    *p = t;
    free(prev);
}
@


\section{Conversion functions}

<<lib.h strto functions decl>>=
extern  long  strtol(char*, char**, int);
extern  ulong strtoul(char*, char**, int);
extern  vlong strtoll(char*, char**, int);
extern  uvlong  strtoull(char*, char**, int);
@ 

<<function readnum>>=
int
readnum(ulong off, char *buf, ulong n, ulong val, int size)
{
    char tmp[64];

    snprint(tmp, sizeof(tmp), "%*lud", size-1, val);
    tmp[size-1] = ' ';
    if(off >= size)
        return 0;
    if(off+n > size)
        n = size-off;
    memmove(buf, tmp+off, n);
    return n;
}
@


<<function readstr>>=
int
readstr(ulong off, char *buf, ulong n, char *str)
{
    int size;

    size = strlen(str);
    if(off >= size)
        return 0;
    if(off+n > size)
        n = size-off;
    memmove(buf, str+off, n);
    return n;
}
@

\section{Pool allocation}

% set things from lib_core/libc/...?pool.c mainmem? imagmem?

\section{Printf and [[Fmt]]}

<<lib.h printf functions decl>>=
extern  char* seprint(char*, char*, char*, ...);
extern  char* vseprint(char*, char*, char*, va_list);
extern  int snprint(char*, int, char*, ...);
extern  int sprint(char*, char*, ...);
@
%//unused: extern  int vsnprint(char*, int, char*, va_list);


% see print.c which overrides functions defined in lib_core/libc/fmt/fmtlock.c 

<<struct Fmt>>=
struct Fmt{
  uchar runes;      /* output buffer is runes or chars? */
  void  *start;     /* of buffer */
  void  *to;      /* current place in the buffer */
  void  *stop;      /* end of the buffer; overwritten if flush fails */
  int (*flush)(Fmt *);  /* called when to == stop */
  void  *farg;      /* to make flush a closure */
  int nfmt;     /* num chars formatted so far */
  va_list args;     /* args passed to dofmt */
  int r;      /* % format Rune */
  int width;
  int prec;
  ulong flags;
};
@ 

<<lib.h fmt functions decl>>=
extern  int fmtstrinit(Fmt*);
extern  int fmtinstall(int, int (*)(Fmt*));
extern  void  quotefmtinstall(void);
extern  int fmtprint(Fmt*, char*, ...);
extern  int fmtstrcpy(Fmt*, char*);
extern  char* fmtstrflush(Fmt*);
@ 

<<lib.h pragmas>>=
#pragma varargck  argpos  fmtprint  2
#pragma varargck  argpos  print   1
#pragma varargck  argpos  seprint   3
#pragma varargck  argpos  snprint   3
#pragma varargck  argpos  sprint    2

#pragma varargck  type  "lld" vlong
#pragma varargck  type  "llx" vlong
#pragma varargck  type  "lld" uvlong
#pragma varargck  type  "llx" uvlong
#pragma varargck  type  "ld"  long
#pragma varargck  type  "lx"  long
#pragma varargck  type  "ld"  ulong
#pragma varargck  type  "lx"  ulong
#pragma varargck  type  "d" int
#pragma varargck  type  "x" int
#pragma varargck  type  "c" int
#pragma varargck  type  "C" int
#pragma varargck  type  "d" uint
#pragma varargck  type  "x" uint
#pragma varargck  type  "c" uint
#pragma varargck  type  "C" uint
#pragma varargck  type  "s" char*
#pragma varargck  type  "q" char*
#pragma varargck  type  "S" Rune*
#pragma varargck  type  "%" void
#pragma varargck  type  "p" uintptr
#pragma varargck  type  "p" void*
#pragma varargck  flag  ','
@


\section{Runes, a.k.a unicode}

<<enum utf>>=
enum
{
  UTFmax    = 4,    /* maximum bytes per rune */
  Runeself  = 0x80,   /* rune and UTF sequences are the same (<) */
};
@
%//unused: Runesync  = 0x80,   /* cannot represent part of a UTF sequence (<) */
%//unused: Runeerror = 0xFFFD, /* decoding error in UTF */
%//unused: Runemax   = 0x10FFFF, /* 24 bit rune */
%//unused: Runemask  = 0x1FFFFF, /* bits used by runes (see grep) */

<<lib.h rune functions decl>>=
extern  int runetochar(char*, Rune*);
extern  int chartorune(Rune*, char*);
extern  char* utfrune(char*, long);
extern  int utfnlen(char*, long);
@ 
%//unused: extern  int utflen(char*);
%//unused: extern  int runelen(long);




\chapter{Extra Code}

\ifallcode
#include "Kernel_extra.tex.nw"
\fi

\chapter{Changelog}
\label{sec:changelog}

\chapter{Glossary}
\label{sec:glossary}

\begin{verbatim}
UP = User Process
PC = Program Counter
SPL = Set Priority Level
UMB = Upper Memory Block
RMAP = RAM map
PDB = Page Directory Base
PTE = Page Table Entry
TOD = Time Of Day
AP = Application Processor
EDF = Earliest Deadline First
RPC = Remote Procedure Call
EGRP = Environment GRouP
FGRP = File descriptor GRouP (chans)
PGRP = Process GRouP (namespace)
VNO = Vector Number (interrupt)
ISR = Interrupt Service Routine
TSC = Time Stamp Counter
INTR = INTeRrupt (not INT, probably to avoid ambiguity with integer)
APIC = Advanded Programmable Interrupt Controller (a next gen 8259)
ACPI = Advanced Configuration & Power Interface
QID = uniQue IDentifier (uid is taken for user id)
VPT = Virtual Page Table
GDT = Global Descriptor Table
\end{verbatim}
%cistrcmp= ??


\chapter*{Indexes}
\addcontentsline{toc}{section}{Index}

%\chapter{References} 
\addcontentsline{toc}{section}{References}

\begin{thebibliography}{99}

\bibitem[1]{wp-literate-programming} Donald Knuth,,
{\em Literate Programming}, 
\url{http://en.wikipedia.org/wiki/Literate\_Program}

\bibitem[2]{noweb} Norman Ramsey,
{\em Noweb}, 
\url{http://www.cs.tufts.edu/~nr/noweb/}

\bibitem[3]{syncweb} Yoann Padioleau,
{\em Syncweb, literate programming meets unison}, 
\url{http://padator.org/software/project-syncweb/readme.txt}

% TECS, STEPS, MINIX, etc

\end{thebibliography}

%******************************************************************************
% Postlude
%******************************************************************************

\end{document}
