\documentclass[twocolumn, landscape]{report}

%******************************************************************************
% Prelude
%******************************************************************************
\newif\iffinal
\newif\ifverbose
\finaltrue\verbosefalse % see also other newif in Macros.tex

%------------------------------------------------------------------------------
%history: 
%------------------------------------------------------------------------------

%thx to LP, I changed for the better a few things :)
% - removed deadcode (e.g. field Proc.qlock, semalock, Arch_Conf, etc)
% - moved code in init/user such as preboot vs boot vs init
% - introduced syssema.c (found while going through Kernel_extra.nw)
% - introduced notion of IPC and Time (TODO change files accordingly)
% - better grouping of things in devcons.c, present together the Qxxx,
%   same for /proc/ and its many uses
% - boolified, typeified, ...
% - add some arch_ and Arch_ prefix to see more cleary what are the
%   arch-specific callbacks or structures
% - too many things to be put here

%thx to codemap/codegraph:
% - see pad.txt#reorganization section

%thx to this manual, better understand Unix:
%  - child/parent relation and zombie process, the fact that a parent
%    exiting does not mean it will kill its children
%  - child/parent relation and wait, the fact that wait will return
%    also for already-finished children
%  - SEMI malloc internals
%  - time, user vs sys vs real, and inherited time of children
%  - TODO debugger
%  - strace
%  - TODO profiler
%  - coverage sample-based profiler
%  - virtual memory
%  - the keyboard and the special accents :) compose mode
%  - SEMI buffered input and the console and raw mode :)

%history LP-ization:
% - skeleton; a not too bad TOC
% - put all content of files in the Extra section, via 'syncweb -lpize'
% - split the files in chunks (for type, helpers, ...), using
%   my emacs macro, and prefixing the chunk with special names:
%    * function, global, struct, enum
%    * method (for Dev), constructor, destructor, TODO class??(for xxxdevtab?)
%    * syscall, interrupt callback, clock callback, kernel process, hook, 
%      TODO dumper
%    * xxx decl, xxx.c forward decl, xxx.c debugging macro, xxx.c Exxx errors,
%    * [[xxx]] other fields, [[xxx]] extra fields
%    * [[xxx()]] yyy case>>, <<enum xxx cases>>
% - distribute parts of the file before
% - TODO add figures (hand made), so many things will be easier to understand
%   once you have a picture of data structures and their relations

%TODO:
% - lots of things could be reduced if C had better support for lists or hash;
%   there are lots of duplicated code adding/removing stuff in list
%   (e.g. tdel(), tadd(), etc)
% - put some "lemma/theorem" in the code, which are prolog/datalog queries
%   explaining some invariants :)

%------------------------------------------------------------------------------
% Packages
%------------------------------------------------------------------------------

\usepackage{../docs/latex/noweb}
 \noweboptions{footnotesizecode,nomargintag}
 %note: allow chunk on different pages, less white space at bottom of pages
 \def\nwendcode{\endtrivlist \endgroup}
 \let\nwdocspar=\par
\usepackage{xspace}
\usepackage{verbatim}
%note: required by noweblatexpad for the \t \l \n in this file
\usepackage{fancyvrb}
\usepackage{url}
\usepackage{hyperref}
 \hypersetup{colorlinks=true}
\usepackage[pageref]{backref}
 \def\backref{{\footnotesize cited page(s)}~}
%\usepackage{cleveref} %\cref
%\usepackage{multirow}
\usepackage{booktabs} 
 \newcommand{\otoprule}{\midrule[\heavyrulewidth]}
\usepackage{graphicx}
%\usepackage{minitoc}
\def\minitoc{}

%------------------------------------------------------------------------------
% Macros
%------------------------------------------------------------------------------
\input{../docs/latex/Macros}

%------------------------------------------------------------------------------
% Config
%------------------------------------------------------------------------------
\allcodefalse
% ifallcode is used for:
%  - forward decl, func decl, extern decl, #ifdef, pragmas (stuff in Extra.nw)
%  - stats, 
%  - debugging macros

\addtolength{\topmargin}{-.850in}
\addtolength{\textheight}{1.70in}

\begin{document}
%******************************************************************************
% Title
%******************************************************************************
\title{
{\Huge 
Principia Softwarica: The Plan~9 Kernel [[9]]
}\\
x86 (32 bits) edition\\
{version 0.1}
}
% hopefully one day an even cleaner ARM (32 bits) Raspberry Pi edition!

\author{
Yoann Padioleau\\
\texttt{yoann.padioleau@gmail.com}\\
\\
with code from\\
Ken Thompson, 
Rob Pike, 
Dave Presotto, 
Phil Winterbottom
}
% hmm actually this volume does not contain the networking code,
% so maybe can put just Pike and Thompson? or maybe just Thompson?
% Richard Miller for bcm/

\maketitle 
\onecolumn
\hrule
\input{../docs/latex/Copyright}
\input{../docs/latex/CopyrightPlan9}
\hrule
\twocolumn

\begingroup
\hypersetup{linkcolor=blue}
% need to s/onecolumn/twocolumn in report.cls :) for \tableofcontents
\tableofcontents
\endgroup

%******************************************************************************
% Body
%******************************************************************************

\chapter{Introduction}

The goal of this book is to present in full details the source code of
a {kernel}.

\section{Motivations}

Why a kernel? 
Because I think you are a better programmer if
you fully understand how things work under the hood, and the
kernel is the program that everything else rely on.

Here are a few questions I hope this book will answer:
\begin{itemize}
\item What happens when the user turn on the computer?
Which code gets executed? How the kernel initialises itself?

\item What happens when the user type [[ls]] in a terminal?
What are the set of software involved in such a command? What
is the trace of such a command through the different layers
of the software stack, from the keyboard interrupt to
the display of text glyphs on the screen?
\l actually different if do ls and ls RET

\item Where the kernel stores meta data about its processes?

\item Why the kernel code and some kernel data are in the virtual
memory space of every process?

\item What is the trace of a system call?

\item What is the memory image of the kernel and its
processes?

\end{itemize}
% how read from /dev/cons? how know until newline? need specify
%  size for read? but then how know the size? it's a maxsize
%  but if newlines it is passed before?

\section{The \plan kernel, [[9]]}

% We chose plan9 kernel. A good basis for the other books.

% some disadvantages of 9: more general but also probably less
% efficient, no buffer cache really, graphic stack in the kernel,
% hardcoded split for kernel mem vs images mem and user mem,
% other stuff?


\section{Other kernels}

Here are a few kernels that were considered for this book but 
which were ultimately discarded:
\begin{itemize}

\item Unix V6 (or its modern incarnation xv6) is too simple;
there is no graphics, no network.
% actually I will not cover graphics or network in this book, but I will
% make other books and so want to explain something coherent.
% Also V6 didn't handle multi processors (but xv6 does though).
% grokking xv6: http://experiments.oskarth.com/unix00/

\item XINU has a network stack but the kernel itself
is too simple with no virtual memory for instance
% and has multi processor support?

\item Minix is fairly small but it does not provide a simple windowing
system as it relies on X11 (which is far more complicated than plan9
Rio windowing system)
% minix3 is said to be 13 000 LOC

\item Linux is really big.
% LOC?
Of course the Linux kernel contains thousands of specific device drivers
and those things could be discarded when
presenting the core of the Linux kernel, but this core is still far
bigger than \plan equivalent core.


\end{itemize}

%industry:
% - Window kernel? doc somewhere?
% - XNU, Mach
% - Linux
% - Symbian
%history:
% - CTSS
% - Multics
% - Unix
% - ...
%other: so many ...
% - nuttx, ils ont meme une graphic stack, widget, window manager
% - oberon, see www.qemu-advent-calendar.org day 12
% - templeos: http://www.codersnotes.com/notes/a-constructive-look-at-templeos
% - a tentative in Rust: https://redox-os.org/
% - another tentative, documented in a blog: http://os.phil-opp.com/
% - http://littleosbook.github.io/book.pdf
% - http://ulixos.org/ literate unix, but just kernel though. 30 000 L for .nw
%   600 pages
% - beos
%microkernel:
% - gnumach and gnu hurd?
% - L4
% - minix3
%research:
% - boyer moore proved os
% - sel4, even proved stuff, with model in haskell!! using .lhs files!


%linux/freebsd bazaar critique, with ugly libtool/configure/autoconf/...
% https://queue.acm.org/detail.cfm?id=2349257&ref=fullrss


\section{Getting started}

To get started you first need to get the source of the \plan
version described in this book. See \urlprincipia.

Then you need to compile using a regular C compiler (e.g. gcc)
the \plan C cross compilers written by Ken Thompson:
 \url{https://github.com/aryx/fork-kencc}.

Then you need to cross compile, e.g. from MacOS or Linux, the \plan kernel
using the \plan C cross compilers installed in the previous step.
You can also cross compile the whole \plan operating
system with all its libraries and utilities.

Finally you can test this compiled kernel and utilities using
QEMU.
% or a real PC.
% see qemu-system-i386 -device ?
% or Raspberry Pi!!

As a bonus step you can also now compile \plan under \plan itself!

\section{Requirements}

We assume you actually know a lot:
\begin{itemize}
\item C: most of this book is made of C source code, so
you'll need to have a good knowledge of 
the C programming language~\cite{k-r}.
% see also comp.ps

\item Assembly:
% ref?
% see also asm.ps

\item Operating system: (yep)
% ref?

\item The x86 architecture:
%\item The ARM architecture:

\end{itemize}

This book is not an introduction to operating systems. The goal
of this book is to present in full details a kernel but we assume
you already have a vague idea of how an operating system
works and so that you are familiar with concepts such as 
{virtual memory}, 
{critical regions}, 
{interrupts}, 
{system calls}, etc.
We assume you already know most of the theory; this book is here to
cover the practice.

\section{About this document}
#include "../docs/latex/About.nw"

\section{Copyright}
\input{../docs/latex/CopyrightPlan9Text}

\section{Acknowledgments}

I would like to acknowledge of course Plan9's authors who wrote
most of this book: Ken Thompson, Rob Pike, Dave Presotto, Phil
Winterbottom, Russ Cox, and many other people from Bell Labs.

Thanks also to Federic Balesteros who wrote a lengthy note about
the \plan kernel.
% Richard Miller for Raspberry Pi port.







\chapter{Overview}
\minitoc

\section{Operating system principles}

An operating system is a meta-program: A program that {manages} other
programs.
\n a shell and windowing system is too a program managing other programs
It provides convenient {abstractions} of the hardware and {multiplex}
those hardware resources for the benefit of user programs.
The operating system usually provides:
\begin{itemize}

\item a virtual CPU, so that each process thinks it has all the CPU 
for itself (via preemptive scheduling and the timer interrupt)

\item a virtual memory, so that each process thinks it has all memory
for itself (via hardware virtual memory features such as paging)

\item a virtual screen, so that each process thinks it has all the screen
for itself (via the windowing system)

\item a file abstraction, so a process can read and store data
whether it's on a disk, network, floppy, etc
% continous even though spreaded on concrete disk (like mm)

\item a directory abstraction, so a process can organize data
whether it's on a disk, network, floppy, etc

% also continous, even though spread over network and devices
%\item a virtual storage (filesystem)
%\item a virtual network (NFS)
\end{itemize}

% unix (and so plan9) and its shell are also a kind of universal interpreter.
% There is some lisp machine, prolog machine, alto, etc, specialized to run
% program in one language. Unix is universal and have general
% mechanism (e.g. shell repl, environment to transmit globals, or
% argv to pass parameter). Universal! Can then have programs
% written in C/Asm, pascal, prolog, scheme, whatever but launched
% from the shell.

% ostep: virtualization, concurrency, persistence

Entire books have been written on those subjects.
We assume you already know what is an operating system
and we will now focus on the concrete services (API) a kernel
provides to the user programs.

%classic os: supervisor, master control program, kernel, os, ...

\section{[[9]] system calls}

% see 9.ps, excellent introduction to Plan9 advanced features
% see also docs/doc/ and docs/man/

% user point of view:
% - start the whole thing, first program!
%   (like a cell, can build new process only by division from a previous one:)
% - process managment, shell, fork, exec, multi task
% - system calls, =~ APIs of user program
% - interrupt handling, =~ devices and also syscalls and preemptive multi task
% - IO operations, =~ devices and files
% - file managment, =~ filesystem

% microkernel point of view: kernel should only support
%  address spaces, threads, scheduling, and IPC

% in lib_core/libc/9syscall/ but really part of kernel (interface to kernel)
<<sys.h>>=
#define	NOP		0
<<sys.h process syscalls>>
<<sys.h memory syscalls>>
<<sys.h file syscalls>>
<<sys.h directory syscalls>>
<<sys.h namespace syscalls>>
<<sys.h time syscalls>>
<<sys.h ipc syscalls>>
<<sys.h concurrency syscalls>>
<<sys.h special file syscalls>>
<<sys.h security syscalls>>
#define	ERRSTR		39
@ 

% use an enum instead in sys.h? but then the script that generates
%  the .s in libc/ will be a bit more complicated and the syscall numbers
% are accessed from assembly so need to use #define


<<sys.h process syscalls>>=
#define	RFORK		1
#define	EXEC		2
#define	EXITS		3
#define	AWAIT		4
@
% for EXITS it generates _exits assembly function, not exits
%  because exits is a C function in libc/port/atexit.c

% alternative to fork? just exec? but then fork allows easily to have
% pipe or things that adjust the environment before executing other programs.
% cells are using fork so it must be a good API :)

<<sys.h memory syscalls>>=
#define	BRK		5
@ 
% this used to be BRK_, because I think of APE. Some applications
% call brk() but POSIX brk() has a different semantic than Plan9
% brk, and making brk() a syscall makes things difficult to change.
% but it's ugly to have this _, so instead I've modified ape
% and assume nobody calls directly brk()!

% alternative to brk? if were using full segmentation power a la multics
% then could have better scheme, and for instance hardware checked array
% bound! if the array was in his own segment!
% bad name btw, not sure what it means

<<sys.h file syscalls>>=
#define	OPEN		6
#define	CLOSE		7
#define	PREAD		8
#define	PWRITE		9
#define	SEEK		10
@
% pread/pwrite? what is the p for? page read? page write?
% it does have an extra arg for seek, so have atomic seek;read? 

<<sys.h directory syscalls>>=
#define	CREATE		11
#define	REMOVE		12
#define	CHDIR		13
#define	FD2PATH		14
#define	STAT		15
#define	FSTAT		16
#define	WSTAT		17
#define	FWSTAT		18
@
% why so many stat, ugly a bit. each time variant where take name
% or file descriptor (the f stands for fd)
% could remove maybe.

<<sys.h namespace syscalls>>=
#define	BIND		19
#define	MOUNT		20
#define	UNMOUNT		21
@

%plan9 specific. vs general os principles, e.g. namespace so have
% nice /dev/cons, /dev/draw, which enable easier network and graphics

% alternative to namespace and fileservers and uniondir?
% once go to a "device is a file", and want a clean /dev/cons and 
% clean xterm, that means you need to have programs that provides
% a fake /dev/cons so need easy fileservers and namespace. Union dir
% then is natural too, goes with having flexible namespace.
% ??alternative would be if /dev/cons??

<<sys.h time syscalls>>=
#define	SLEEP		22
#define	ALARM		23
@
% alarm very useful, e.g. for timeout in a program
% SLEEP is also for sleep/wakeup and synchronization?

<<sys.h ipc syscalls>>=
#define	PIPE		26

#define	NOTIFY		24
#define	NOTED		25

#define	SEGATTACH	27
#define	SEGDETACH	28
#define	SEGFREE		29
#define	SEGFLUSH	30
#define	SEGBRK		31
@
% pipe! one of unix greatest invention!

% user level concurrency of course, the kernel itself uses
% lots of concurrency mechanisms (often mimiced also in userland)
<<sys.h concurrency syscalls>>=
#define	RENDEZVOUS	32
#define	SEMACQUIRE	33
#define	SEMRELEASE	34
#define	TSEMACQUIRE	35
@

<<sys.h special file syscalls>>=
#define	DUP		    36
@
% meh

<<sys.h security syscalls>>=
#define	FVERSION	37
#define	FAUTH		38
@
%??

% no SELECT? how does listen to multiple devices at the same time?
% how alts() in lib_thread can work?
% via rendez_vous syscall?
% see http://swtch.com/~rsc/thread/ "plan9 has no select call"

%http://sysdigcloud.com/fascinating-world-linux-system-calls/

% and that's it! that's the only API with userspace!
% amazing that can do everything with only those 38 syscalls!
% (hmm actually we cheat because we have generic API for file that are
%  then abused by file server to provide more services, e.g. for graphics)
% API access via int 64 (but again the API is also
% the filesystem layout and different fileservers)

% no getpid? no done via open/read on a special fileserver.

% missing stuff in plan9:
% - shared library (help save some memory, but complicated)
%   but: http://www.kix.in/2008/06/19/an-alternative-to-shared-libraries/ ??
%   (also it's not a 9 issue, it's more a plan9 issue, the kernel does not
%    have to know about dynamic linking I think. no?)
% - select syscall

% missing stuff in 9 kernel compared to Linux:
% - buffer cache (but because distributed nature, can have cache, but in fileserver)
% - reuse kernel memory?

% see also uriel plan9 slide 9, things plan9 does not have


%TODO
%things plan9 make so much easier to implement/understand:
% tty, xterm
% X11
% nfs
% fuse
% ioctl
%
%Plan9 approach is good? abuse files? could use different API?
%For instance /dev/draw has a very specific format, so it's
%a bit abusing files.
%But at the same time one for sure needs to store things in files,
%so one need files, at which point you want to define the minimum of 
%concepts and so make files more generic => device can be files,
%but also pipes, etc, and so plan9 just push to its conclusion
%this idea.
% also once have 9p then have X11 for free as /dev/draw can be on the network

% supervisor calls, system call, syscall, software interrupt

\section{The [[x86]] machine}
%http://g.oswego.edu/dl/jmm/cookbook.html references many architecture spec

%PC vs raspberry pi?

% actually will take 386, not 486, nor x86_64 or amd64, so simpler.

% little endian, big endian, the le2xxx function?

<<ureg.h>>=
struct Ureg
{
 ulong	di;		/* general registers */
 ulong	si;		/* ... */
 ulong	bp;		/* ... */
 ulong	nsp;
 ulong	bx;		/* ... */
 ulong	dx;		/* ... */
 ulong	cx;		/* ... */
 ulong	ax;		/* ... */

 ulong	gs;		/* data segments */
 ulong	fs;		/* ... */
 ulong	es;		/* ... */
 ulong	ds;		/* ... */

 ulong	trap;		/* trap type */
 ulong	ecode;		/* error code (or zero) */
 ulong	pc;		/* pc */
 ulong	cs;		/* old context */
 ulong	flags;		/* old flags */
 union {
  ulong	usp;
  ulong	sp;
 };
 ulong	ss;		/* old stack segment */
};
@
% complicated ... ARM simpler.

% intro segmentation and pagination? or ref to vm chapter?

% on qemu use C-Alt-2 and then 'info registers' 'info cpus' etc :)

%\section{The [[ARM]] machine}
% Actually lots of different ARM. Raspberry Pi.

\section{C and assembly}

% compilation scheme of kernel assumes pass parameters in stack,
% return value in ax, and caller save registers it needs
% after call before calling (so Label structure is simple).
% hmm unless return a vlong in which case pass an extra pointer
% to the function for the callee to set the value
% also assumes structures are 4bytes aligned? see PG_ONSWAP

% kencc extensions: anon field. e.g. Lock; but sugar, not that important.

% the lock+0(FP) is intriguing and must be used when using (FP).
% it's probably forcing the user to give a name to what debugger
% could then display when giving the list of parameters to an assembly
% function?

% maybe a bit of rappel on bit manip :) 2 complementary arithmetic,
%  e.g. pa > -KZERO, or in bcm have  pa & ~KSEGM

<<portdat.h macros>>=
#define ROUND(s, sz)  (((s)+(sz-1)) & ~(sz-1))
@
%old: was in portdat.h but now in portfns.h, more logical
%ex: ROUND(2045, 1024) -> 3072 (3 * 1024), it rounds up
% the round down would be just: s&~(sz-1), ex: va &= ~(BY2PG-1);
% BY2PG-1 means you get all the bits to 1, and then you reverse
% so you really just reset the lower bits
% rename ROUNDUP?

% why C? because OS is at the very bottom, so need low-level features,
% and if OS is slower, everything on top of it is slower ... so need
% fast language; no compromise here (but have to suffer and do lots
% of things manually)

% Some coding conventions: xxxp -> pointer on xxx, so cp is really
% a ref pointer to a chang, mp = ref pointer to a mount (head)
% nx, x = "new" x


% about C:
% “Pretty much everything on the web uses those two things: C and
% UNIX,” Pike tells Wired. “The browsers are written in C. The UNIX
% kernel — that pretty much the entire Internet runs on — is written
% in C. Web servers are written in C, and if they’re not, they’re
% written in Java or C++, which are C derivatives, or Python or Ruby,
% which are implemented in C. And all of the network hardware running
% these programs I can almost guarantee were written in C.
% http://www.wired.com/2011/10/thedennisritchieeffect/
%
% would be better at some point though to rewrite part of it in Rust,
% the modern C. 
% tool to help https://github.com/jameysharp/corrode C->Rust (in haskell)

\section{[[helloworld.c]]}
% always good to start with concrete example of interaction

% illustrate a few syscalls!
% illustrate also relation with shell?

% show asm? so really low level!

\section{Code organization}
% codemap and codegraph screenshot?
% graph dependencies? (where remove artificial edges, or use thickness of edge?)

<<kernel basic includes>>=
#include <u.h>
#include "../port/lib.h"
#include "../port/error.h"
#include "mem.h"
#include "dat.h"
#include "fns.h"
@ 
%pad: I added the error.h

% u.h for uchar, uint, ... can be seen also as universal :)
% lib.h =~ libc like utilities, see Section XX
% error.h see Section YY
% mem.h see memory overview, important constants such as address kernel.

<<dat.h>>=

<<enum misc_constants(x86)>>
<<pad memory pointer types(x86)>>

#include "dat_forward.h"
#include "../port/portdat_forward.h"

// defines Lock (used inline in Cpu in portdat_core.h so must be before)
#include "../port/portdat_concurrency.h"

// defines Conf, Cpu, ... Label
#include "dat_core.h"
#include "../port/portdat_core.h"

// defines Page, Pagetable, Segment, KImage
#include "dat_memory.h"
#include "../port/portdat_memory.h"

// defines Chan
#include "../port/portdat_files.h"

// defines PCArch, a few arch-specific constants
#include "dat_arch.h"

// defines Timer
#include "dat_time.h"
#include "../port/portdat_time.h"

// defines Vctl
#include "dat_interrupts.h"

// defines Proc
#include "dat_processes.h"
#include "../port/portdat_processes.h"

// defines Cmd
#include "../port/portdat_misc.h"

// defines Uart
#include "../port/portdat_buses.h"

// defines keyboard queue, consdevtab
#include "../port/portdat_console.h"

// defines DevConf, DevPort (not that used)
#include "../port/portdat_devices.h"

// ref<Cpu>, the actual Cpu is where??
extern Cpu *cpu;

<<macro up(x86)>>

<<portdat.h pragmas(x86)>>
@

% some dat_xxx.h before portdat_xxx.h sometimes because
% the dat_xxx.h defines some arch specific structure referenced
% in the portable one. dat_core.h defines Arch_Cpu. dat_memory.c
% defines Arch_ProcMMU.

<<fns.h>>=
#include "../port/portfns_core.h"
#include "../port/portfns_concurrency.h"
#include "../port/portfns_memory.h"
#include "../port/portfns_files.h"
#include "../port/portfns_time.h"
#include "../port/portfns_interrupts.h"
#include "../port/portfns_processes.h"
#include "../port/portfns_misc.h"
#include "../port/portfns_console.h"
#include "../port/portfns_buses.h"
#include "../port/portfns_devices.h"
#include "../port/portfns_security.h"
#include "../port/portfns_network.h"
#include "../port/portfns_syscalls.h"
#include "../port/portfns_init.h"

<<fns.h declarations(x86)>>
@


\ifallcode
<<pad basic types>>=
typedef int bool;
enum _bool {
  false = 0,
  true = 1
};
typedef uchar byte;
typedef ushort bool_ushort;
typedef int fdt; // file descriptor type
#define OK_0 0
#define OK_1 1
#define ERROR_0 0
#define ERROR_1 1
#define ERROR_NEG1 (-1)
typedef int error0;
typedef int error1;
typedef int errorneg1;
@ 
\fi
% actually in the "Go in Go" tech talk by Pike, he mentionned
% they had to annotate code using int when the int was really a bool :)
% so they like bool (and types), they just didn't know better at that
% time


\ifallcode
\subsection{Backward dependencies}

% This does not break backward dependencies. 
% See the other chunk with the same name below for the real dependency breaker.

%<<portfns_core.h backward deps breaker>>=
%int devcons_print(char*, ...);
%int devcons_pprint(char*, ...);
%void devcons_panic(char*, ...);
%void devcons__assert(char*);
%void trap_dumpstack(void);
%void proc_dumpaproc(Proc *p);
%void proc_error(char*);
%void proc_nexterror(void);
%void i8253_delay(int millisecs);
%void i8253_microdelay(int microsecs);
%//void proc_sched(void);
%void sched(void);
%void proc_ready(Proc*);
%void proc_sleep(Rendez*, int(*)(void*), void*);
%void proc_tsleep(Rendez *r, int (*fn)(void*), void *arg, ulong ms);
%Proc* proc_wakeup(Rendez*);
%void proc_pexit(char *exitstr, bool freemem);
%Proc* proc_proctab(int i);
%int proc_postnote(Proc *p, int dolock, char *n, int flag);
%void chan_cclose(Chan *c);
%void main_exit(int ispanic);
%int  main_isaconfig(char *class, int ctlrno, ISAConf *isa);
%void nop(void);
%uvlong devarch_fastticks(uvlong *hz);
%void devarch_hook_ioalloc();
%
%int   (*iprint)(char*, ...);
%int devcons_iprint(char*, ...);
%@
%
%% I currently #define the backward func to the actual func.
%% I can not do it for sched() because then you get a parse error 
%% with a sched field.
%% It does not work for iprint either because redeclared in memdraw.h.
%% It does not work for coherence but need like that a pointer.
%
%<<portfns_core.h backward deps breaker>>=
%#define print         devcons_print
%//#define iprint        devcons_iprint
%#define pprint        devcons_pprint
%#define panic         devcons_panic
%#define _assert       devcons__assert
%#define error         proc_error
%#define nexterror     proc_nexterror
%#define dumpstack     trap_dumpstack
%#define dumpaproc     proc_dumpaproc
%//#define devtab        conf_devtab
%#define delay         i8253_delay
%#define microdelay    i8253_microdelay
%#define wakeup        proc_wakeup
%//#define sched()         proc_sched()
%#define ready         proc_ready
%#define sleep         proc_sleep
%#define tsleep        proc_tsleep
%#define exit          main_exit
%#define isaconfig     main_isaconfig
%//#define coherence     nop
%//#define arch_fastticks     devarch_fastticks
%#define cclose        chan_cclose
%#define proctab       proc_proctab
%#define postnote      proc_postnote
%#define pexit         proc_pexit
%//#define hook_ioalloc  devarch_hook_ioalloc
%@
%
%<<portfns.c backward deps breaker>>=
%void (*coherence)(void) = nil;
%int (*iprint)(char*, ...) = nil;
%@
%
%<<main.c forward decl for backward deps(x86)>>=
%@
%
%<<[[main()]] initial assignments for backward deps(x86)>>=
%iprint = devcons_iprint;
%hook_ioalloc = devarch_hook_ioalloc;
%devtab = conf_devtab;
%/*
% * On a uniprocessor, you'd think that coherence could be nop,
% * but it can't.  We still need a barrier when using coherence() in
% * device drivers.
% *
% * On VMware, it's safe (and a huge win) to set this to nop.
% * Aux/vmware does this via the #P/archctl file.
% */
%arch_coherence = nop;
%@

%-------------------------------------------------

% The real backward dependencies breaker
<<portfns_core.h backward deps breaker>>=
// console/devcons.c
int   (*iprint)(char*, ...);
int   (*pprint)(char*, ...);
void  (*panic)(char*, ...);
void  (*_assert)(char*);
@
<<portfns_core.h backward deps breaker>>=
// process/386/trap.c
void    (*dumpstack)(void);
@
<<portfns_core.h backward deps breaker>>=
// process/proc.c
void    (*dumpaproc)(Proc*);
@
<<portfns_core.h backward deps breaker>>=
// process/proc.c
void    (*error)(char*);
void    (*nexterror)(void);
@
<<portfns_core.h backward deps breaker>>=
// process/proc.c
void    (*sleep)(Rendez*, int(*)(void*), void*);
void    (*tsleep)(Rendez*, int (*)(void*), void*, ulong);
Proc*   (*wakeup)(Rendez*);
void    (*sched)(void);
void    (*ready)(Proc*);
@
<<portfns_core.h backward deps breaker>>=
// process/proc.c
Proc*   (*proctab)(int);
int     (*postnote)(Proc*, int, char*, int);
void    (*pexit)(char*, bool);
@
<<portfns_core.h backward deps breaker>>=
// files/chan.c
void    (*cclose)(Chan*);
@
<<portfns_core.h backward deps breaker>>=
// init/main.c
void    (*exit)(int);
@
<<portfns_core.h backward deps breaker>>=
//misc/386/devarch.c
void    (*arch_coherence)(void);
uvlong  (*arch_fastticks)(uvlong*);
@
<<portfns_core.h backward deps breaker>>=
// processes/386/i8253.c
void    (*microdelay)(int);
void    (*delay)(int);

bool (*isaconfig)(char*, int, ISAConf*);
@






<<portfns.c backward deps breaker>>=
// console/devcons.c
int (*print)(char*, ...) = nil;
int (*iprint)(char*, ...) = nil;
int (*pprint)(char *fmt, ...) = nil;

void (*panic)(char*, ...) = nil;
void (*_assert)(char *fmt) = nil;

// process/386/trap.c
void (*dumpstack)(void) = nil;

// process/proc.c
void (*dumpaproc)(Proc*) = nil;

// process/proc.c
void (*error)(char*) = nil;
void (*nexterror)(void) = nil;

void (*sched)(void) = nil;
void (*ready)(Proc*) = nil;
Proc* (*wakeup)(Rendez*) = nil;
void (*sleep)(Rendez*, int(*)(void*), void*) = nil;
void (*tsleep)(Rendez*, int (*)(void*), void*, ulong) = nil;

Proc* (*proctab)(int) = nil;
int (*postnote)(Proc*, int, char*, int) = nil;
void (*pexit)(char*, bool) = nil;

// files/chan.c
void (*cclose)(Chan*);

// init/main.c
void (*exit)(int ispanic) = nil;

// misc/386/devarch.c
void (*arch_coherence)(void) = nil;

// misc/386/devarch.c
uvlong (*arch_fastticks)(uvlong*) = nil;

// processes/386/i8253.c
void (*delay)(int) = nil;
void (*microdelay)(int) = nil;
@


<<main.c forward decl for backward deps(x86)>>=
int devcons_print(char*, ...);
int devcons_iprint(char*, ...);
int devcons_pprint(char*, ...);
void devcons_panic(char*, ...);
void devcons__assert(char*);

void trap_dumpstack(void);
void proc_dumpaproc(Proc *p);

void proc_error(char*);
void proc_nexterror(void);

void i8253_delay(int millisecs);
void i8253_microdelay(int microsecs);

void proc_sched(void);
void proc_ready(Proc*);
void proc_sleep(Rendez*, int(*)(void*), void*);
void proc_tsleep(Rendez *r, int (*fn)(void*), void *arg, ulong ms);
Proc* proc_wakeup(Rendez*);

void proc_pexit(char *exitstr, bool freemem);
Proc* proc_proctab(int i);
int proc_postnote(Proc *p, int dolock, char *n, int flag);

void chan_cclose(Chan *c);

void main_exit(int ispanic);

int  main_isaconfig(char *class, int ctlrno, ISAConf *isa);

void nop(void);
uvlong devarch_arch_fastticks(uvlong *hz);
void devarch_hook_ioalloc();
@


<<[[main()]] initial assignments for backward deps(x86)>>=
print = devcons_print;
iprint = devcons_iprint;
pprint = devcons_pprint;

panic = devcons_panic;
_assert = devcons__assert;

error = proc_error;
nexterror = proc_nexterror;

dumpstack = trap_dumpstack;
dumpaproc = proc_dumpaproc;

devtab = conf_devtab;

delay = i8253_delay;
microdelay = i8253_microdelay;

wakeup = proc_wakeup;
sched = proc_sched;
ready = proc_ready;
sleep = proc_sleep;
tsleep = proc_tsleep;

/*
 * On a uniprocessor, you'd think that coherence could be nop,
 * but it can't.  We still need a barrier when using coherence() in
 * device drivers.
 *
 * On VMware, it's safe (and a huge win) to set this to nop.
 * Aux/vmware does this via the #P/archctl file.
 */
arch_coherence = nop;
arch_fastticks = devarch_arch_fastticks;

cclose = chan_cclose;

proctab = proc_proctab;
postnote = proc_postnote;
pexit = proc_pexit;

hook_ioalloc = devarch_hook_ioalloc;

exit = main_exit;
isaconfig = main_isaconfig;
@

\fi

\section{Software architecture}

% will need a big picture ...

\subsection{Booting overview (x86)}

% maybe screenshot of boot sequence? and simple example of use
% where illustrate that under the hood there is shell process,
% reading stdin, fork, exec, etc?

% there is
%  - loading the kernel in memory
%  - initializing the kernel environment
%  - initializing the user environment
%  - running first user program (boot/boot)

% kernel that creates first user process!
% introduce dichotomy kernel/user

% see also:
% http://arjunsreedharan.org/post/82710718100/kernel-101-lets-write-a-kernel

%for linux:
% https://github.com/0xAX/linux-insides/blob/master/linux-bootstrap-1.md
% ...
% https://github.com/0xAX/linux-insides/blob/master/Initialization/linux-initialization-10.md

% steps:
% - hardware detection, populate Conf
% - initialization, populate allocators
% - create first process

% then user/preboot setup env, boot is responbile to mount root
% and then init assumes a root and setup last things.
% show also rootfs and data2txt

\subsection{Memory overview (x86)}

% many dimensions:
% - physical vs virtual
% - kernel vs user memory
%   and even per-process kernel stack kstack, user stack, main kernel stack
% - dynamic vs static (the static allocator so can bootstrap things)


%figure: need precise physical map of memory
%with first empty page?, idt, gdt, pd intel, pt intel, 
%io RAM, vga ram,  then KZERO header, KTZERO, 
%code,  data with important globals like xlist, and array holes,
%palloc with pointer page, and then on top of that confmem area

%see bcm/words with nice physical map and virtual map with hexa address and size
%see pad.txt#physical-memory

%the data section of the kernel binary is as important as
%the code section. For the code section can also give name
%of procedures, and devtab (in data section) pointing back to it
%via the static "classes" in the data section again).

%need also precise virtual map of memory for regular process,
% actually for 2 processes
%need also precise virtual map of memory for first handcrafted process?

%binary image has been compiled with -TKZERO_AND_HEADER!! important
% and assume loading phase setup physical mapping from KZERO to 0 physical
% and so by having kernel at KTZERO beyond all special memory so no overlap
% with sensitive area.
% maybe figure with the binary composition (a.out header, multiboot header, 
%  code, data, empty bss, etc)

<<pad memory pointer types(x86)>>=
// physical address
typedef uintptr phys_addr;
// virtual address (which should be a user address)
typedef uintptr virt_addr;
// kernel address (mostly physical + KZERO)
typedef uintptr kern_addr;
@

% all structure pointers in the code are kernel addresses.
% e.g. Page*, Segment*, be it in fields or in globals.

\ifallcode
<<pad memory pointer types(x86)>>=
typedef ulong* kern_addr2;
typedef ulong* virt_addr2;
typedef void* virt_addr3;
typedef void* kern_addr3;
@
\fi
%less: I think the void* is the best form, so should s/xxx_addr3/xxx_add/

% in <arch>/mem.h
<<constant KZERO(x86)>>=
//coupling: with mkfile KZERO_AND_HEADER
#define KZERO   0xE0000000    /* base of kernel address space */
@
% last 512Mo of virtual memory space

% why not use different segments? because convenient to be in same
% virtual space, can read/write stuff on and from userspace

<<constant KTZERO(x86)>>=
#define KTZERO    (KZERO+0x100000)  /* first address in kernel text */
@
% why + 0x100000? because will map kzero to physical memory addr 0,
% and lots of address before 1Mo are reserved, used by device, e.g.
% screen cga is at 0xb8000

<<constant UZERO(x86)>>=
#define UZERO   0     /* base of user address space */
@


<<constant UTZERO(x86)>>=
#define UTZERO    (UZERO+BY2PG)   /* first address in user text */
@
% because first page will be marked as protected to detect null pointer
% dereference


<<function paddr(x86)>>=
phys_addr
arch_paddr(kern_addr3 v)
{
    kern_addr va;
    
    va = (kern_addr)v;
    if(va < KZERO)
        panic("arch_paddr: va=%#.8lux pc=%#p", va, getcallerpc(&v));
    return va-KZERO;
}
@
%less: not symetric, phys_addr vs kern_addr3, but hard to make
% symetric because then got lots of type errors

% pa must be <= MAXKPA, we use kaddr to access kernel data.
% if want to access different pa, then must use tmpmap or arch_kmap.
<<function kaddr(x86)>>=
/*
 * These could go back to being macros once the kernel is debugged,
 * but the extra checking is nice to have.
 */
kern_addr3
arch_kaddr(phys_addr pa)
{
    if(pa > MAXKPA)
        panic("arch_kaddr: pa=%#.8lux", pa);
    return (kern_addr3)(pa+KZERO);
}
@
%todo: should return a kern_addr

<<constant MAXKPA(x86)>>=
// -KZERO = 0xFFFFFFFF-KZERO in two's complement arithmetic
#define MAXKPA (phys_addr)(-KZERO)
@
% rename KEND? but it's not really kernel end. KADDREND? MAXKADDR? KADDREND?

<<function cankaddr(x86)>>=
/*
 * Return the number of bytes that can be accessed via KADDR(pa).
 * If pa is not a valid argument to KADDR, return 0.
 */
ulong
arch_cankaddr(phys_addr pa)
{
    if(pa >= MAXKPA)
        return 0;
    return MAXKPA - pa;
}
@
% used in xinit



% why trivial macro? because in other archi can be different
<<function KADDR(x86)>>=
#define KADDR(pa)  arch_kaddr(pa)
@

<<function PADDR(x86)>>=
#define PADDR(ka)  arch_paddr((kern_addr3)(ka))
@
%less: remove cast? more symetric with KADDR then
% actually all those intermediate types are very ugly, could simplify!
% but not easy

% in l.s:
%#define PADDR(ka)        ((ka)&~KZERO)
%#define KADDR(pa)        (KZERO|(pa))


%put CPUADDR here!! because we talk about it later with cpu and cpus
% also IDT, GDT, PD0, PT0


% need to talk about Confmem, otherwise will not understand xalloc and palloc.mem
% very well.

% start from Confmem + kernel binary.
% then Confmem split in xlists and palloc.mem
% then from xlists allocate nproc, pages (that will cover palloc.mem), 
% images, and rest for kernel malloc.

%real-world: Linux maybe better cos kernel memory really small (actually
% it even reuses its own memory at some point) and all the rest
% for programs. In plan9 you need to preallocate a lot for the kernel
% because lots of graphics stuff (imagmem but also the Client allocated
% for each process connecting to /dev/draw/nww) are managed by the kernel.
% So it wastes space possibly.

% annotate with __user and __kernel? matters? what kind of checks
% we could do then? what kind of bugs we could prevent?



%http://duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory/

\subsection{Syscall overview}
% kernel vs user code



<<typedef Syscall>>=
typedef long Syscall(ulong*);
@
% parameter = pointer in stack of user, start of array of parameters

<<systab.h>>=
// used by systab.c but also by trap.c for certain codes
#include "/sys/src/libc/9syscall/sys.h"

<<typedef Syscall>>

extern Syscall *systab[];
extern int nsyscall;
extern char *sysctab[];
@


<<global systab>>=
Syscall *systab[] = {
    [NOP]     sysnop,
<<systab process syscalls>>
<<systab memory syscalls>>
<<systab file syscalls>>
<<systab directory syscalls>>
<<systab namespace syscalls>>
<<systab time syscalls>>
<<systab ipc syscalls>>
<<systab concurrency syscalls>>
<<systab special file syscalls>>
<<systab security syscalls>>
    [ERRSTR]    syserrstr,
};
int nsyscall = nelem(systab);
@

<<syscall nop>>=
// void nop(void);
long
sysnop(ulong*)
{
    print("Hello World\n");
    return 0;
}
@ 
% the parameter virt_addr2 should be a pointer to the stack to the start
% of the arguments

<<constant VectorSYSCALL(x86)>>=
//!!! int 64 (0x40), way to jump in plan9 OS !!!
#define VectorSYSCALL 64
@

% show small ex of asm that call this hello world

% sequence diagram?
% show example of generated assembly code
% maybe can even show an example where abuse sysnop so can see things :)


% related work: http://lwn.net/Articles/604287/

%http://sysdigcloud.com/fascinating-world-linux-system-calls/


%\section{File overview}
% because everything is a fileserver can confuse things
%  many concepts aggregated: device, filesystem, server


\section{Book structure}





%###############################################################################

\chapter{Core Data Structures}
\minitoc

% mini libc: bool, int, strings, Rune (unicode), etc

% shown already [[Syscall]] and [[systab]] global.

\section{[[Conf]] and [[conf]]}

<<struct Conf>>=
struct Conf
{
    ulong ncpu;    /* processors */
    Confmem mem[4];   /* physical memory */

    ulong nproc;    /* processes */
    <<[[Conf]] other fields>>
};
@ 
%old: 'ulong monitor;'
\t nproc used? have proc arena anyway no?
%// TODO arm 
%//	ulong	hz;		/* processor cycle freq */
%//	ulong	mhz;

% mem[4] to allow to have up to 4 free not contiguous memory regions.
% On the PC we have 2, one in the low memory before the kernel, and
% one after the kernel bss. On the bcm they just have 1.
% note that the physical memory used by the kernel is excluded
% because we will use mem for giving memory to kernel heap or user.

<<global conf>>=
Conf conf;
@ 

<<struct Confmem>>=
// memory "bank"
struct Confmem
{
    phys_addr base;
    ulong npage;
    <<[[Confmem]] other fields>>

    uintptr	limit; // TODO bcm/ specific?
};
@ 
% show concrete value for qemu! see C-t C-t m
% will use that later! set in main() in confinit(), and use for xalloc, and palloc



<<globals confname and confvar>>=
// conf (boot) parameters *e.g. { "*kernelpercent*" => "60" }
// hash<string, string>
char *confname[MAXCONF];
char *confval[MAXCONF];
// Hashtbl.length(confname)
int nconf;
@ 

<<constant MAXCONF>>=
#define MAXCONF         64
@ 
%old: used to be duplicated in every main.c, now factorized

<<function getconf>>=
char* getconf(char *name)
{
        int i;
        for(i = 0; i < nconf; i++)
                if(cistrcmp(confname[i], name) == 0)
                        return confval[i];
        return nil;
}
@
% cistrcmp???

% see also confegrp

\section{[[Cpu]] and [[cpu]]}

<<struct Cpu>>=
struct Cpu
{
    int cpuno;     /* physical id of processor (KNOWN TO ASSEMBLY) */
    <<[[Cpu]] second field>>
  
    // ref<Proc>, or None if halting?
    Proc* proc;     /* current process on this processor */

    ulong ticks;      /* of the clock since boot time */

    uvlong  cpuhz;
    int cpumhz; // cpuhz / 1_000_000

    <<[[Cpu]] stat fields>>
    <<[[Cpu]] other fields>>
    struct Arch_Cpu;
  
    // must be at the end of the structure!
    int stack[1];
};
@ 
%history: %old:
% Cpu used to be called Mach, but in the end it didn't make sense.
% Maybe they originally used Mach for "machine" because back in the day
% there was only  monoprocessor machines, but now with multiprocessor
% machines having names like Mach to represent one cpu, or field names
% like machno, mach0init, etc seems wrong. So I've renamed it!
% A nice side effect is also that it avoids conflicts with libmach! 
% There it acually makes sense to use the Mach name because they speak 
% about a machine.

% not that the stack actually is until CPUSIZE


<<struct ArchCpu(x86)>>=
struct Arch_Cpu {
    <<[[Cpu]] [[Arch]] cpuid fields(x86)>>
    <<[[Cpu]] [[Arch]] other fields(x86)>>
};
@ 

% more on ticks in Time chapter, number of clock interrupts
% in hzclock():    cpu->ticks++;



% cpu must be "something" that is local to each processor. How to achieve
%  that? if there was a special instruction like MYCPUID then could
%  make cpu a macro to cpus[MYCPUID()]. Could also use one register
%  to hold it and so have something like extern register Cpu* cpu;
%  This is actually the case on some archi like bcm. 
%     extern register Mach* m;			/* R10 */
%  for sure this is a technique leading to a local value and different
%  in each processor.
%  But on PC we can't do that because there is not enough registers to
%  spare. 
%  So cpu is a variable holding an addr that points to an area that
%  is different on each processor, thx to a trick involving the page table.
% could also have instead of cpu and cpus have cpus and a Int *mycpu; where
% mycpu points to the per-processor memory area and hold the value
% of the processor, but then each access to cpu will be more costly
% than a direct access as it's done above.

% note that cpuinit just set cpus[0], not cpu, cpu is set in clearbss
<<global cpu(x86)>>=
// ref<Cpu>, assigned to CPUADDR in _clearbss
Cpu *cpu;
@ 
%old: was called [[m]]
% x86 because differ in different archi

<<global cpus>>=
/*
 * Each processor sees its own Cpu structure at address CPUADDR.
 * However, the Cpu structures must also be available via the per-processor
 * MMU information array cpus, mainly for disambiguation and access to
 * the clock which is only maintained by the bootstrap processor (0).
 */
// array<ref<Cpu>>
Cpu* cpus[MAXCPUS];
@
%old: machaddr

% note that cpus[0] will not be CPUADDR! it will be
% CPU0CPU (this will defeat the purpose otherwise)

<<constant MAXCPUS(x86)>>=
/*
 * In 32-bit mode, the MAXCPUS limit is 32 without
 * changing the way active.cpus is defined and used
 * (unfortunately, it is also used in the port code).
 */
#define MAXCPUS   32      /* max # cpus system can run */
@
%old: MAXMACH

% why macro? because again in other archi it could be more complex
<<macro CPUS>>=
#define CPUS(n)  (cpus[n])
@
%old: MACHP

<<struct Active>>=
struct Active
{
    // array<bool> (coupling: sizeof(int) must be >= MAXCPUS)
    int cpus;      /* bitmap of active CPUs */
    bool exiting;    /* shutdown */
    <<[[Active]] other fields>>
    // extra
    Lock;
};
@ 

<<global active>>=
struct Active active;
@ 


\section{[[Proc]] and [[up]]}

% the big one

<<struct Proc>>=
struct Proc
{
//--------------------------------------------------------------------
// Assembly requirements, Low level, have to be first
//--------------------------------------------------------------------
    <<[[Proc]] assembly fields>>
//--------------------------------------------------------------------
// State
//--------------------------------------------------------------------
    <<[[Proc]] state fields>>
//--------------------------------------------------------------------
// Memory
//--------------------------------------------------------------------
    <<[[Proc]] memory fields>>

    struct Arch_ProcMMU;
//--------------------------------------------------------------------
// Scheduling
//--------------------------------------------------------------------
    <<[[Proc]] scheduling fields>>
//--------------------------------------------------------------------
// Files
//--------------------------------------------------------------------
    <<[[Proc]] files fields>>
//--------------------------------------------------------------------
// Notes
//--------------------------------------------------------------------
    <<[[Proc]] notes fields>>
//--------------------------------------------------------------------
// Process hierarchy
//--------------------------------------------------------------------
    <<[[Proc]] hierarchy fields>>
//--------------------------------------------------------------------
// Synchronization
//--------------------------------------------------------------------
    <<[[Proc]] synchronization fields>>
//--------------------------------------------------------------------
// Error management
//--------------------------------------------------------------------
    <<[[Proc]] error managment fields>>
//--------------------------------------------------------------------
// Stats, profiling
//--------------------------------------------------------------------
    <<[[Proc]] stats and profiling fields>>
//--------------------------------------------------------------------
// Debugging (the kernel itself)
//--------------------------------------------------------------------
    <<[[Proc]] debugging fields>>
//--------------------------------------------------------------------
// For debugger, strace
//--------------------------------------------------------------------
    <<[[Proc]] debugger fields>>
//--------------------------------------------------------------------
// Other
//--------------------------------------------------------------------
    <<[[Proc]] other fields>>
//--------------------------------------------------------------------
// Extra
//--------------------------------------------------------------------
    <<[[Proc]] extra fields>>
};
@ 
% apparently this uses 3004 bytes ... huge. procalloc is 6Mo!

<<struct ArchProcMMU(x86)>>=
struct Arch_ProcMMU
{
  <<[[Proc]] [[Arch]] memory fields(x86)>>
};
@
%old: PMMU

<<[[Proc]] state fields>>=
// enum<procstate> 
int state; // Dead, Queuing, etc, (used by /proc/#/status if psstate==nil)
@


<<enum procstate>>=
/* Process states, Proc.state */
enum procstate
{
    Dead = 0,
    Running,
    <<enum procstate cases>>
};
@ 
%TODO: hmm LP split but need then to LP split also statename below no?

% 
<<global statename>>=
// hash<enum<procstate>, string>, coupling: with enum procstate
char *statename[] =
{
    "Dead",
    "Running",
    "Queueing",
    "QueueingR",
    "QueueingW",
    "Moribund",
    "Ready",
    "Scheding",
    "Wakeme",
    "Broken",
    "Stopped",
    "Rendez",
    "Waitrelease",
};
@ 
% put /proc/#/status and part of Qstatus here? no too early
% but maybe could put some of the state thing later in Proc section of
% Process chapter

<<macro up(x86)>>=
// up = user process
#define up (cpu->proc)
@
%history: 
% Just like for 'cpu', we want 'up' to be something local to each processor.
% up used to be '#define up ((MACH*)MACHADDR)->externup' because:
% - doing just (m->externup) was conflicting with some functions using
%   a local variables called 'm'. Indeed up is a macro, not a closure so
%   any code introducing a local variable 'm' will not be able to use up
%   => rename m to cpu so less conflict (still some but rare) 
%   and can now do (cpu->externup)
% - why externup? because in other architectures such as bcm one can do
%     extern register Mach* m;			/* R10 */
%     extern register Proc* up;			/* R9 */
%   and so m and up are really extern registers (for sure local and different
%   in each processor). On the PC we don't have that many registers so
%   have to emulate per-processor data via the virtual memory and the CPUADDR
%   trick
% - => because in the end we don't use registers, there is no need
%   to have both a cpu->proc and cpu->externup field, one can just
%   use cpu->proc for up!
%TODO: still true now that use bcm/?

% process table? see procalloc, but can think of a global array.

\section{[[Chan]]}
% and proc->fd[]? in title?

% everything is a file/Chan :)
% diff with file descriptor? fd = index in chan table (fgrp), 
% chan = opened/active file

<<struct Chan>>=
struct Chan
{
    ushort type; // idx in devtab
    ulong dev;
    Qid qid;

    Path* path;

    vlong offset;     /* in fd */

    //enum<open>, actually restricted to the OREAD|OWRITE|ORDWR of open type
    ushort mode;     /* read/write */

    bool ismtpt; // is a mount point

    union {
       void* aux; // generic pointer, for specific usages
       <<[[Chan]] union other fields>>
    };
    <<[[Chan]] other fields>>

    // extra
    Ref; /* the Lock in this Ref is also Chan's lock */
    <<[[Chan]] extra fields>>
};
@
% more LP split? type put closer to devtab?
% could put 'dev' closer to device for fs where want more than just type

% type =~ major, and dev =~ minor

<<[[Proc]] files fields>>=
// ref<Chan>
Chan  *slash; // The root! used by namec()
// ref_counted<Chan>
Chan  *dot; // The current directory
@

% on pathchar() :) why DOS used '\' instead of '/'
%http://blogs.msdn.com/b/larryosterman/archive/2005/06/24/432386.aspx
% because IBM was already using / for utility flag marker, e.g. ls /a


% rob pike: "q for unique"
% qid =~ inode =~ internal representation of a file on a filesystem(fileserver)
<<struct Qid>>=
struct Qid
{
  // note that this is not a string, but an int! it's kind of an inode
  uvlong  path;
  // for cache invalidation
  ulong vers;
  // enum<qidtype>
  byte type;
};
@ 
%coupling: this structure ir also defined in libc.h

<<enum qidtype>>=
/* bits in Qid.type */
enum qidtype {
  QTFILE = 0x00,    /* plain file */
  QTDIR = 0x80,    /* type bit for directories */
  <<enum qidtype cases>>
};
@ 
%TODO: reaffect the bit? 1<<1, 1<<2, 1<<3, etc?


<<function eqqid>>=
bool
eqqid(Qid a, Qid b)
{
    return a.path==b.path && a.vers==b.vers;
}
@

<<function mkqid>>=
void
mkqid(Qid *q, vlong path, ulong vers, int type)
{
    q->type = type;
    q->vers = vers;
    q->path = path;
}
@

% seems always called with skipvers == true
<<function eqchan>>=
bool
eqchan(Chan *a, Chan *b, bool skipvers)
{
    if(a->qid.path != b->qid.path)
        return false;
    if(!skipvers && a->qid.vers!=b->qid.vers)
        return false;

    if(a->type != b->type)
        return false;
    if(a->dev != b->dev)
        return false;
    return true;
}
@
% have a gqid type? type + dev + qid?

% mostly dupe, so could factorize? or put in ifallcode?
<<function eqchantdqid>>=
bool
eqchantdqid(Chan *a, int type, int dev, Qid qid, bool skipvers)
{
    if(a->qid.path != qid.path)
        return false;
    if(!skipvers && a->qid.vers!=qid.vers)
        return false;
    if(a->type != type)
        return false;
    if(a->dev != dev)
        return false;
    return true;
}
@

\section{[[Dev]] and [[devtab]]}
% actually Device also plays the role of filesystem and even fileserver!
% everything is a file ... server!

% so devtab = major/minor + VFS +??? . Devices are often a special case
% of a one-level directory containing a single file and thx to union
% dir we can gather them in one directory such as /dev/

% concrete device like kbd, screen, are exported via the
%  read() method below from /dev/cons, write() method to /dev/cons, and then
%  fancy graphics are write() to /dev/vga!

% open take a Chan? how bootstrap? how to get an handle to a file
% you want to open? first attach to get Chan from root?

<<struct Dev>>=
struct Dev
{
    Rune dc; // dev character code, e.g. '/' (devroot), 'e' (devenv), ...
    char* name;

    <<[[Dev]] methods>>
};
@ 
% no seek? seek is managed generically? actually read and write take an
% offset as a parameter. from read(2)
%  "By combining the operations in a single atomic call, they more closely
%   match the 9P protocol"
% does it match 9p? I guess it closely match 9p

<<global devtab>>=
// array<ref_own<Dev>>
Dev** devtab = nil;
@

% ex of conf_devtab:
% Dev* conf_devtab[]={
%	&rootdevtab,
%	&consdevtab,
%       ...
%  };
% devtab = conf_devtab;

% ex of device:
% Dev consdevtab = {
%  ...
% }


% ls -l /dev
%  and will see the different device driver owner of the files

\section{[[PCArch]] and [[arch]] (x86)}

<<struct PCArch(x86)>>=
struct PCArch
{
  char* id;

  int (*ident)(void);   /* this should be in the model */
  void  (*reset)(void);   /* this should be in the model */
  void  (*resetothers)(void); /* put other cpus into reset */

  // interrupts
  <<[[PCArch]] interrupt methods fields(x86)>>
  // clock, timer
  <<[[PCArch]] time methods fields(x86)>>
  // power
  <<[[PCArch]] power methods fields(x86)>>
};
@ 

% could add cycles and cmpswap here? and also pcmspecial, fps?

<<global arch(x86)>>=
PCArch* arch;
@ 

<<global archgeneric(x86)>>=
PCArch archgeneric = {
    .id=        "generic",
    .ident=     nil,
    .reset=     archreset,

    // interrupt: Intel i8259 controller
    <<[[archgeneric]] interrupt methods(x86)>>
    // clock: Intel i8253 controller
    <<[[archgeneric]] time methods(x86)>>
    // power: none
    <<[[archgeneric]] power methods(x86)>>
};
@
% what ident is for?

% SMP is more complex arch: 'archmp'










%###############################################################################

%\part{CPU and memory}

\chapter{Concurrency}
\minitoc

%the little book on semaphores
%http://www.greenteapress.com/semaphores/downey08semaphores.pdf

\t make sure that if use arch_splhi, then no use of lock! (only canqlock is ok) 

% when think about concurrency in a userspace program, one have
% shared memory of multiple program threads and need to mediate
% access to shared data via semaphore/lock/monitor/whatever.

% well an OS is a kind of program and it has also mutiple
% "threads" (different activities the processes) and lots of shared data
% (kernel meta data about user processes and its own data, shared resources, etc)
% This is why lots of the concurrency issues arised first
% for OS programmers long before the other.

% In fact with input devices, even more source of concurrency! 

% for userspace concurrency, see IPC chapter, here this is
% kernel concurrency!

% torvalds on semaphore vs spinlocks and mutual exclusion in general
%http://yarchive.net/comp/linux/semaphores.html

\section{Critical regions}

% There are different code/data "regions": 
% - user code/data
% - kernel data about user process
% - kernel data
% - kernel init code
% - kernel code of syscalls (soft interrupt), acting on behalf of user process
% - kernel code of interrupt handlers (hard interrupt).
% - kernel code of kernel processes (e.g. the alarm kernel process)
%
% There is no mutual exclusion need between user and kernel code. 
% Same for init code as only one processor is used during the
% uninterrupted sequential initialization.
% There is also no need between different user processes (except
% when they share segment, see IPC chapter)
%
% For the kernel code one wants mutual exclusion because of possible race 
% on shared data structures between the syscalls themselves when run
% on different processors (or even when run on one processor as one syscall
% can be interrupted causing a scheduling that will then lead later to
% another syscall), but also between the syscalls and interrupts.
% The flow of control on one processor can be 
%  - User -> Syscall, 
%  - User -> Interrupt,
%  - or even User -> Syscall -> Interrupt
%  - one can even have User -> Syscall -> Interrupt -> Interrupt!!
%
% This is on one processor. Multiple processors lead to more combinations
% where 2 processors can run at the same time 2 interrupt handlers for instance.
% 
% One must take care when using locks inside interrupts as one can deadlock
% if the same lock was used in the enclosing syscall (hence ilock/iunlock)
%
% For protecting kernel syscall code from interrupt kernel code: arch_splhi(), splo()
% For very small critical region: taslock
% For bigger region, or when have lots of contention on a lock: qlock
%  where the process will actually go to sleep (useful e.g. for IO queues
%  producer/consumer)


\section{[[arch_splhi()]], [[arch_spllo()]] (x86)}

% cli

<<function splhi(x86)>>=
// bool   arch_splhi(void);
TEXT arch_splhi(SB), $0
shi:
        PUSHFL
        POPL    AX
        TESTL   $0x200, AX /* pad: interrupt bit */
        JZ      alreadyhi
        MOVL    $(CPUADDR+0x04), CX            /* save PC in cpu->splpc */
        MOVL    (SP), BX
        MOVL    BX, (CX)
alreadyhi:
        CLI
        RET
@ 
%$
% interrupt state is in x86 flags register, accessible via pushfl
% this function is actually used quite a lot, not just internally in ilock

<<[[Cpu]] second field>>=
// must be second field at 0x04, used by arch_splhi()
ulong splpc;      /* pc of last caller to arch_splhi */
@ 



<<function spllo(x86)>>=
// bool   arch_spllo(void);
TEXT arch_spllo(SB), $0
slo:
        PUSHFL
        POPL    AX
        TESTL   $0x200, AX
        JNZ     alreadylo
        MOVL    $(CPUADDR+0x04), CX            /* clear cpu->splpc */
        MOVL    $0, (CX)
alreadylo:
        STI
        RET
@ 


<<function splx(x86)>>=
// void    arch_splx(bool);
TEXT arch_splx(SB), $0
        MOVL    s+0(FP), AX
        TESTL   $0x200, AX
        JNZ     slo
        JMP     shi
@ 
% ref label in arch_splhi and spllot

<<function islo(x86)>>=
// bool arch_islo(void);
TEXT arch_islo(SB), $0
        PUSHFL
        POPL    AX
        ANDL    $0x200, AX                      /* interrupt enable flag */
        RET
@ 
%$


\section{[[arch_tas()]] (x86)}

% building block of concurrency

% call we will see later as arch_tas(&lock->key)
<<function tas(x86)>>=
TEXT arch_tas(SB), $0
        MOVL    $0xDEADDEAD, AX
        MOVL    l+0(FP), BX
        XCHGL   AX, (BX)                        /* lock->key */
        RET
@ 
% XCHGL is atomic! can't have 2 cpu doing same thing at the same time
% only one will win!

%        // Exchange AX (0xDEADDEAD) to lock->key. So:
%        //  - if the lock was not held, lock->key was 0 and so AX will be 0
%        //     and lock->key will be 0xdeaddead
%        //  - if the lock was held, AX will be 0xdeaddead and lock->key will
%        //    still be 0xdeaddead.

% return in AX, so can read that as what was the value in the lock, and if
% nul then set it! So arch_tas() == 0 mean? arch_tas() == 0xDEADEAD mean?
% return in AX see C conventions.

% movl l+0(FP) is because we use 0(FP) and 8a forces the programmer
% to give a name to accessed parameters. Used in debugger?


\section{Atomic [[arch_xinc()]] and [[arch_xdec()]] (x86)}

% arch_tas() is to make sure one arrive first on something.
% another fundamental concurrency operation is increment/decrement atomically
% (actually can simulate second one with first, see Ref later, but can be
% useful to have something faster on certain architecture)

<<function _xinc(x86)>>=
/* void arch_xinc(long*); */
TEXT arch_xinc(SB), $0
        MOVL    l+0(FP), AX
        LOCK;   INCL 0(AX)
        RET
@ 


<<function _xdec(x86)>>=
/* long arch_xdec(long*); */
TEXT arch_xdec(SB), $0
        MOVL    l+0(FP), BX
        XORL    AX, AX
        LOCK;   DECL 0(BX)
        JLT     _xdeclt
        JGT     _xdecgt
        RET
_xdecgt:
        INCL    AX
        RET
_xdeclt:
        DECL    AX
        RET
@ 

\section{Spin [[Lock]]}
% actually have something similar at user level! see libc.h Lock
% and also QLock, RLock, RWLock, etc.

<<struct Lock>>=
struct Lock
{
    ulong key; // 0 when unset, 0xDEADDEAD when acquired, could be a bool
    <<[[Lock]] ilock fields>>
    <<[[Lock]] debugging fields>>
    <<[[Lock]] other fields>>
};
@ 
% rename SpinLock?

\ifallcode
<<[[Lock]] other fields>>=
// option<ref<Cpu>>, None when key = 0?
Cpu  *cpu; // not that used, only in iprintcanlock apparently
@
\fi

<<[[Lock]] debugging fields>>=
// option<ref<Proc>>, None when key == 0
Proc  *p; // the process who did the locking should be the same unlocking
// for debugging, the caller who did the lock()
kern_addr pc; 
@

<<[[Proc]] debugging fields>>=
Lock* lastlock;
@

<<[[Proc]] synchronization fields>>=
// As long as the current process hold spinlocks (to kernel data structures),
// we will not schedule another process in unlock(); only the last unlock
// will eventually cause a rescheduling.
Ref nlocks;   /* number of locks held by proc */
@ 

% actually returns ret_code, 1 means ok but there was some contention
%  but does not look used, so TODO return void?
<<function lock>>=
int
lock(Lock *l)
{
    int i;
    ulong pc;

    pc = getcallerpc(&l);

    lockstats.locks++;
    if(up)
        inccnt(&up->nlocks);    /* prevent being scheded */
    if(arch_tas(&l->key) == 0){ // lock old value was 0, the lock was not held
        if(up)
            up->lastlock = l;
        l->pc = pc;
        l->p = up;
        l->isilock = false;
        l->cpu = CPUS(cpu->cpuno); // pad's third bugfix
<<lock ifdef LOCKCYCLES>>
        return 0;
    }

    // the lock was already held, need to spin
    if(up)
        deccnt(&up->nlocks);

    lockstats.glare++;
    for(;;){
        lockstats.inglare++;
        i = 0;
        while(l->key){
           <<[[lock()]] optional priority-inversion for real-time process>>
            if(i++ > 100000000){
                i = 0;
                lockloop(l, pc);
            }
        }
        // try again
        if(up)
            inccnt(&up->nlocks);
        if(arch_tas(&l->key) == 0){
            if(up)
                up->lastlock = l;
            l->pc = pc;
            l->p = up;
            l->isilock = false;
<<lock ifdef LOCKCYCLES>>
            return 1;
        }
        if(up)
            deccnt(&up->nlocks);
    }
    return -1; // unreachable
}
@
%bug: see pad's bugfix above
% could maybe use a dowhile? could factorize code
%    // why not just l->cpu = cpu? because it would always be the same addr!


<<function unlock>>=
void
unlock(Lock *l)
{
<<unlock ifdef LOCKCYCLES>>

    if(l->key == 0)
        print("unlock: not locked: pc %#p\n", getcallerpc(&l));
    if(l->isilock)
        print("unlock of ilock: pc %lux, held by %lux\n", getcallerpc(&l), l->pc);
    if(l->p != up)
        print("unlock: up changed: pc %#p, acquired at pc %lux, lock p %#p, unlock up %#p\n", getcallerpc(&l), l->pc, l->p, up);

    l->cpu = nil;
    l->key = 0;
    // for processor caches, to ensure the lock value is seen by other
    // processors so that if they were doing while(l->key) { ... } they
    // can finally exit the while loop.
    arch_coherence();

    <<[[unlock()]] if delaysched>>
}
@ 

% note that if it can it actually gets the lock. does not spin if it can not get it.
% it can be used also to make sure your caller have the lock by doing
%  if(canlock(x)) panic("lock not held by caller")
<<function canlock>>=
bool
canlock(Lock *l)
{
    if(up)
        inccnt(&up->nlocks);
    if(arch_tas(&l->key) != 0){ // lock old value != 0, lock was already held
        if(up)
            deccnt(&up->nlocks);
        return false;
    }

    if(up)
        up->lastlock = l;
    l->pc = getcallerpc(&l);
    l->p = up;
    l->cpu = CPUS(cpu->cpuno);
    l->isilock = false;
<<lock ifdef LOCKCYCLES>>
    return true;
}
@ 

% what about deadlock when need 2 locks? need to have
% an ordering! and use always the same! could use the
% address of the lock trick of linux? could also use the lexical ordering
% of the enclosing structure :) Palloc after Page!

\section{Uninterruptable [[ILock]]}

% do we always use a Lock in a consistent way? In some cases I hope so
<<struct ILock>>=
typedef Lock ILock;
@

% can formalize a checking rule? if access any field
% accessed from a xxxintr, then need to use ilock

%ilock = interrupt safe version of lock (disable interruptions)

<<[[Lock]] ilock fields>>=
bool_ushort isilock; // false when from lock(), true when from ilock()
ulong sr; // saved priority level when using ilock() to restore in iunlock()
@ 
%// Lock.sr was u32int on bcm/. Matters?

<<[[Proc]] debugging fields>>=
Lock  *lastilock;
@ 

<<[[Cpu]] other fields>>=
int ilockdepth;
@ 

% usage vs just arch_splhi? for critical regions between different interrupt handlers?
<<function ilock>>=
// To provide mutual exclusion with interrupt code and avoiding deadlock.
// By using arch_splhi() we disable interrupts while running the critical region
// code.
void
ilock(Lock *l)
{
    ulong x;
    ulong pc;

    pc = getcallerpc(&l);
    lockstats.locks++;

    x = arch_splhi();
    // no need to take care of up->nlock++ here, we have disabled interrupt
    // so no risk of getting scheduled
    if(arch_tas(&l->key) != 0){
        lockstats.glare++;
        /*
         * Cannot also check l->pc, l->cpu, or l->isilock here
         * because they might just not be set yet, or
         * (for pc and m) the lock might have just been unlocked.
         */
        for(;;){
            lockstats.inglare++;
            arch_splx(x);
            while(l->key)
                ;
            // let's try again
            x = arch_splhi();
            if(arch_tas(&l->key) == 0)
                goto acquire;
        }
    }
acquire:
    cpu->ilockdepth++;
    if(up)
        up->lastilock = l;
    l->sr = x;
    l->pc = pc;
    l->p = up;
    l->isilock = true;
    l->cpu = CPUS(cpu->cpuno);
<<lock ifdef LOCKCYCLES>>
}
@ 


<<function iunlock>>=
void
iunlock(Lock *l)
{
    ulong sr;

<<iunlock ifdef LOCKCYCLES>>
    if(l->key == 0)
        print("iunlock: not locked: pc %#p\n", getcallerpc(&l));
    if(!l->isilock)
        print("iunlock of lock: pc %#p, held by %#lux\n", getcallerpc(&l), l->pc);
    if(arch_islo())
        print("iunlock while lo: pc %#p, held by %#lux\n", getcallerpc(&l), l->pc);

    sr = l->sr;
    l->cpu = nil;
    arch_coherence(); // added in latest bcm/
    l->key = 0;
    arch_coherence();
    cpu->ilockdepth--;
    if(up)
        up->lastilock = nil;
    arch_splx(sr);
}
@ 

\section{Waiting [[QLock]]}
% can be seen also as a Waiting queue, Sleepable Lock?

<<struct QLock>>=
// Kernel basic lock with Queue (renamed to avoid ambiguity with libc.h QLock)
struct KQLock
{
    bool  locked;   /* flag */
  
    // list<ref<Proc>> (next = Proc.qnext)
    Proc  *head;    /* next process waiting for object */
    // option<ref<Proc>> (direct access to tail, queue)
    Proc  *tail;    /* last process waiting for object */
  
    kern_addr qpc;    /* pc of the holder */ // for debugging?
  
    Lock  use;    /* to access Qlock structure */
};
@ 
%old: was QLock (but the typedef is still with QLock so no need change code)

% note that QLock use Lock! building block!

<<[[Proc]] debugging fields>>=
ulong qpc;    /* pc calling last blocking qlock */
@

<<[[Proc]] extra fields>>=
// list<ref<Proc>> KQlock.head or RWLock.head (or Procalloc.free)
Proc  *qnext;   /* next process on queue for a QLock */
@ 

<<enum procstate cases>>=
Queueing, // see qlock()
@

<<function qlock>>=
void
qlock(QLock *q)
{
    Proc *p;

    if(cpu->ilockdepth != 0)
        print("qlock: %#p: ilockdepth %d\n", getcallerpc(&q), cpu->ilockdepth);
    if(up != nil && up->nlocks.ref)
        print("qlock: %#p: nlocks %lud\n", getcallerpc(&q), up->nlocks.ref);
    if(q->use.key == 0x55555555) // dead code??
        panic("qlock: q %#p, key 5*\n", q);

    lock(&q->use);
    rwstats.qlock++;
    if(!q->locked) {
        q->locked = true;
        q->qpc = getcallerpc(&q);
        unlock(&q->use);
        return;
    }
    if(up == nil)
        panic("qlock");
    rwstats.qlockq++;

    // add_queue(q, up)
    p = q->tail;
    if(p == nil)
        q->head = up;
    else
        p->qnext = up;
    q->tail = up;
    // up->qnext could be non nil before? no otherwise that means
    // the process is already waiting for a lock and so had no occasion
    // to run another qlock() instruction.
    up->qnext = nil;

    up->state = Queueing;
    up->qpc = getcallerpc(&q);
    unlock(&q->use);
    // switch to another process! 
    sched(); 
    // will resume here when another process unlock() the lock and ready() us
    q->qpc = getcallerpc(&q);
}
@ 
% call to sched() function! = kinda of a sleep
% hmmm not dangerous? sched() sometimes if nlock > 0 actually returns!!

<<function qunlock>>=
void
qunlock(QLock *q)
{
    Proc *p;

    lock(&q->use);
    if (q->locked == false)
        print("qunlock called with qlock not held, from %#p\n",
            getcallerpc(&q));

    p = q->head;
    if(p){
        // dequeue(q)
        q->head = p->qnext;
        if(q->head == nil)
            q->tail = nil;

        unlock(&q->use);
        ready(p);
    }else{
        q->locked = false;
        q->qpc = nilptr;
        unlock(&q->use);
    }
}
@ 
%call to ready() function! could put the Ready state here then?

% does not sleep if can not get it (but if can get it then it does!)
% what is the point of using a qlock if everybody uses it via canqlock??
<<function canqlock>>=
bool
canqlock(QLock *q)
{
    if(!canlock(&q->use))
        return false;
    if(q->locked){
        unlock(&q->use);
        return false;
    }
    q->locked = true;
    q->qpc = getcallerpc(&q);
    unlock(&q->use);
    return true;
}
@ 

\section{Readers/Writer [[RWLock]]}

% used in Mhead, Pgrp, Egrp

<<struct RWlock>>=
struct RWlock
{
    int readers;  /* number of readers */
    bool writer;   /* have a writer? */
  
    // list<ref<Proc>> (next = Proc.qnext)
    Proc  *head;    /* list of waiting processes */
    // option<ref<Proc>> (direct access to tail, queue)
    Proc  *tail;
    // option<ref<Proc>> 
    Proc  *wproc;   /* writing proc */
  
    uintptr wpc;    /* pc of writer */
  
    Lock  use;
};
@ 

<<enum procstate cases>>=
QueueingR, // see rlock()
@

<<function rlock>>=
void
rlock(RWlock *q)
{
    Proc *p;

    lock(&q->use);
    rwstats.rlock++;
    if(q->writer == false && q->head == nil){
        /* no writer, go for it */
        q->readers++;
        unlock(&q->use);
        return;
    }

    if(up == nil)
        panic("rlock");
    rwstats.rlockq++;

    // add_queue(q, up)
    p = q->tail;
    if(p == nil)
        q->head = up;
    else
        p->qnext = up;
    q->tail = up;
    up->qnext = nil;

    up->state = QueueingR;
    unlock(&q->use);
    sched();
    // will resume here when another process unlock() the lock and ready() us
}
@ 

<<function runlock>>=
void
runlock(RWlock *q)
{
    Proc *p;

    lock(&q->use);
    p = q->head;
    if(--(q->readers) > 0 || p == nil){
        unlock(&q->use);
        return;
    }

    /* start waiting writer */
    if(p->state != QueueingW)
        panic("runlock");

    // dequeue(q)
    q->head = p->qnext;
    if(q->head == nil)
        q->tail = nil;

    q->writer = true;
    unlock(&q->use);
    ready(p);
}
@ 

<<enum procstate cases>>=
QueueingW, // see wlock()
@

<<function wlock>>=
void
wlock(RWlock *q)
{
    Proc *p;

    lock(&q->use);
    rwstats.wlock++;
    if(q->readers == 0 && q->writer == false){
        /* noone waiting, go for it */
        q->wpc = getcallerpc(&q);
        q->wproc = up;
        q->writer = true;
        unlock(&q->use);
        return;
    }

    /* wait */
    if(up == nil)
        panic("wlock");
    rwstats.wlockq++;

    // add_queue(q, up)
    p = q->tail;
    if(p == nil)
        q->head = up;
    else
        p->qnext = up;
    q->tail = up;
    up->qnext = nil;

    up->state = QueueingW;
    unlock(&q->use);
    sched();
}
@ 


<<function wunlock>>=
void
wunlock(RWlock *q)
{
    Proc *p;

    lock(&q->use);
    p = q->head;
    if(p == nil){
        q->writer = false;
        unlock(&q->use);
        return;
    }
    if(p->state == QueueingW){
        /* start waiting writer */
        // dequeue(q)
        q->head = p->qnext;
        if(q->head == nil)
            q->tail = nil;

        unlock(&q->use);
        ready(p);
        return;
    }

    if(p->state != QueueingR)
        panic("wunlock");

    /* waken waiting readers */
    while(q->head != nil && q->head->state == QueueingR){
        p = q->head;
        q->head = p->qnext;
        q->readers++;
        ready(p);
    }

    if(q->head == nil)
        q->tail = nil;
    q->writer = false;
    unlock(&q->use);
}
@ 


<<function canrlock>>=
/* same as rlock but punts if there are any writers waiting */
bool
canrlock(RWlock *q)
{
    lock(&q->use);
    rwstats.rlock++;
    if(q->writer == false && q->head == nil){
        /* no writer, go for it */
        q->readers++;
        unlock(&q->use);
        return true;
    }
    unlock(&q->use);
    return false;
}
@ 

\section{Atomic [[Ref]]erences and [[Counter]]}

<<struct Ref>>=
// For reference counting shared things (e.g. a Page)
struct Ref
{
    long ref;
    Lock;
};
@ 

<<function incref>>=
long
incref(Ref *r)
{
    long x;

    lock(r);
    x = ++r->ref;
    unlock(r);
    return x;
}
@ 


<<function decref>>=
long
decref(Ref *r)
{
    long x;

    lock(r);
    x = --r->ref;
    unlock(r);
    if(x < 0)
        panic("decref pc=%#p", getcallerpc(&r));
    return x;
}
@ 

<<struct Counter>>=
typedef struct Ref Counter;
@ 


<<function inccnt>>=
// See also ref.c incref() and decref(), but we can't use them here as they
// themselves rely on lock() and unlock(). 
static void
inccnt(Ref *r)
{
    arch_xinc(&r->ref);
}
@ 
% so why use incref()/decref()? why not use arch_xinc()/arch_xdec()?


<<function deccnt>>=
static int
deccnt(Ref *r)
{
    int x;

    x = arch_xdec(&r->ref);
    if(x < 0)
        panic("deccnt pc=%#p", getcallerpc(&r));
    return x;
}
@ 
% actually used in Lock ... mutually recursive, but used for nlocks

\section{Synchronization}
% different from critical regions
% what if want to do producer/consumer? 
% consumer has to wait for producer to produce. How do that
% with the locking stuff we have seen before? Enough?

% already have seen kinda of synchro with sched()/ready()

% could put sysrendezvous actually here? or too early?
% maybe yes, after all in Qlock we already have seen
% some calls to sched()/ready()

% see sleep.ps in plan9 documents

\subsection{Rendez-vous}
% sleep/wakeup?

\subsection{Producer/Consumer Queue}
%IO Queue
% will see later

\subsection{Semaphore}
% those are actually used for user-level locks, see libcore/libc/port/lock.c







\chapter{Memory}
\minitoc

<<systab memory syscalls>>=
    [BRK]      sysbrk,
@ 

%http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory/

\section{Overview}
% kernel vs user memory

%allocation memory kinds:
% - static and initialized (data) in binary itself! "allocated" by 
%    kernel loader
% - static and unitiliaized (bss), "allocated" by kernel loader again,
%   initialized to zero in asm (via 'edata', 'end' linker info)
% - dynamic
%    - via static arena (and trick to maintain free list)
%    - via malloc (heap)

% malloc/free memory does not appear from thin air, need data structure
% to remember what was malloced, where, how much memory remains,
% so need memory to talk about memory ... chichen and egg.

% approach: 
% - end, edata fixed area
% - confmem detection (and mapram)
% - xalloc static metadata about mem
%  - then from it build pools
%    - then from it get malloc
%  - orthogonally also use xalloc for procs, pages, more??
% - palloc.mem

% then for user, pages is the granularity. see brk too.

% => figure of physical memory with zoom on kernel data and bss section,
%   conf.confmem, xalloc metadata, procallocs and pageallog, all procs,
%   all pages,  and then kernel memory area malloc. The user memory area
%   is made of all those pages.
% get the actual number (and try optimize? less % for kernel more for user,
%  reduce Page data structure? less conf.nproc?

\section{[[xalloc()]]}

%// Memory allocator for long lived allocated structures
%// e.g. array of Proc (procalloc), array of Pages (palloc.pages), but
%// also pool provider for kernel malloc()
%long lived because xalloc does not support well fragmentation
% can only have certain number of disparate holes

% kinda of a first-fit no-compacting allocator?

% kernel memory allocator. This is for the kernel! For user
% it will be Palloc.mem (and Pages that is actually metadata about
% pages that are in kernel memory allocated by xalloc). Also all the
% memory here can be only before MAXKPA.

% start with Confmem, huge bank, now we want to use some memory.
% draw figure with idea. Draw also figures with many holes in memory. 
% Can't support too much fragmentation (no compact() function)

% alternatives? why not just free bitmaps? instead we use
% free (linked) list below (and also for pages)

<<constants holes>>=
enum
{
    Nhole   = 128,
    Magichole = 0x484F4C45,     /* HOLE */
};
@

<<struct Hole>>=
struct Hole
{
    // between addr and top the memory is free, this is the "hole"
    phys_addr addr; 
    phys_addr top; 
    ulong size; // top - addr
    // extra
    <<[[Hole]] extra fields>>
};
@
%phys_addr should be all < MAXKPA
% they could use kern_addr, it would be simpler, require less conversions

<<struct Xalloc>>=
// Long lived data structure allocator (singleton)
struct Xalloc
{
    // array<Hole> where each Hole is linked to another hole
    Hole  hole[Nhole];
  
    // list<ref<Hole>> (next = Hole.next) list of free hole entries (addr=top=size=0)
    Hole* unused_slots; 

    // list<ref<Hole>> (next = Hole.next) memory holes, sorted by their top addr
    Hole* sorted_holes; 
  
    // extra
    Lock;
};
@
% note that the hole entry is free means the metadata is free.
% a used hole in sorted_holes means actually the hole entry is valid
% and describe some free memory there


<<[[Hole]] extra fields>>=
Hole* next; // list<ref<Hole>> of Xalloc.sorted_holes or Xalloc.unused_slots
@

<<global xlists>>=
static Xalloc   xlists;
@

% complex data structure, show concrete example, C-t C-t x
% where does xalloc(1000); xalloc(1000) and then free first => new hole used
%  see complex linking and role of table and flist,
% recall what confmem was, so can understand the small split of the first
%  bank and then the huge bank

% this does not handle well many alloc/free, each free in the middle
% will allocate a new hole. Does not handle fragmentation.
% example of bad case: if does 12 * 2 xalloc, and then free
% one in two, then will use all the holes. Which is why xalloc
% is really used as the building block for the other memory allocators
% for things that are never free (long-lived data structures e.g. procs,
% pages, etc)


<<struct Xhdr>>=
// What is the connection with Hole? A Hole that get used will gets
// its top and size decremented, and this newly allocated part will describe
// a portion of used memory, and at this memory there will be a header
// and then just after the actual memory xalloc'ed by someone
struct Xhdr
{
    // bookkeeping area
    ulong size;
    ulong magix;
  
    char  data[]; // memory pointer returned by xalloc
};
@
% so Confmem will be essentially a succession of either Xhdr, or
% some free mem represented by a used slot Hole.

% can show a config where have big hole and then do 2 xalloc so that
% this same hole will be smaller but have multiple xhdr inside it
% in spirit (and if xfree the top one then hole gets bigger, and if
% free lower one, then a new hole is used (because of top addr sorted
% requirment)

<<function xalloc>>=
kern_addr3
xalloc(ulong size)
{
    return xallocz(size, true);
}
@

<<function xallocz>>=
kern_addr3
xallocz(ulong size, bool zero)
{
    Xhdr *p;
    Hole *h, **l;

    /* add room for magix & size overhead, round up to nearest vlong */
    size += BY2V + offsetof(Xhdr, data[0]);
    size &= ~(BY2V-1);

    ilock(&xlists);
    l = &xlists.sorted_holes;
    for(h = *l; h; h = h->next) {
        // found an appropriate hole
        if(h->size >= size) {
            p = (Xhdr*)KADDR(h->addr);
            h->addr += size; // shrink towards top
            h->size -= size;

            // This hole is now fully used (which is rare because one
            // rarely does an xalloc with the remaining size of a hole).
            // We can put it back in the list of free hole entries.
            if(h->size == 0) {
                *l = h->next;
                h->next = xlists.unused_slots;
                xlists.unused_slots = h;
            }

            iunlock(&xlists);
            if(zero)
                memset(p, 0, size);
            p->magix = Magichole;
            p->size = size;
            return p->data;
        }
        l = &h->next;
    }
    iunlock(&xlists);
    return nil;
}
@

% this is very rarely used in the kernel
% why use it at all? apparently in intrdisable, but why they dont
% use malloc/free? because in interrupt code?
% actually this is so rarely used that we could simplify even more
% and have a alloc-only thing with just confmem that get reduces
% gradually.
<<function xfree>>=
void
xfree(kern_addr3 p)
{
    Xhdr *x;

    x = (Xhdr*)((ulong)p - offsetof(Xhdr, data[0]));
    if(x->magix != Magichole) {
        xsummary();
        panic("xfree(%#p) %#ux != %#lux", p, Magichole, x->magix);
    }
    xhole(PADDR((kern_addr)x), x->size);
}
@

% This may have to allocate a new Hole from the free list.
% called by xinit! This is the function that actually got memory
% from Confmem.
<<function xhole>>=
void
xhole(phys_addr addr, ulong size)
{
    phys_addr top;
    Hole *h, *c, **l;

    if(size == 0)
        return;

    top = addr + size;
    ilock(&xlists);
    l = &xlists.sorted_holes;
    for(h = *l; h; h = h->next) {
        if(h->top == addr) {
            h->size += size;
            h->top = h->addr+h->size;
            c = h->next;
            if(c && h->top == c->addr) {
                h->top += c->size;
                h->size += c->size;
                h->next = c->next;
                c->next = xlists.unused_slots;
                xlists.unused_slots = c;
            }
            iunlock(&xlists);
            return;
        }
        if(h->addr > addr)
            break;
        l = &h->next;
    }
    if(h && top == h->addr) {
        h->addr -= size;
        h->size += size;
        iunlock(&xlists);
        return;
    }

    if(xlists.unused_slots == nil) {
        iunlock(&xlists);
        print("xfree: no free holes, leaked %lud bytes\n", size);
        return;
    }

    h = xlists.unused_slots;
    xlists.unused_slots = h->next;
    h->addr = addr;
    h->top = top;
    h->size = size;
    h->next = *l;
    *l = h;
    iunlock(&xlists);
}
@

%-----------------------------------------------------------------------

% used by malloc Pool below
<<function xmerge>>=
bool
xmerge(kern_addr3 vp, kern_addr3 vq)
{
    Xhdr *p, *q;

    p = (Xhdr*)(((ulong)vp - offsetof(Xhdr, data[0])));
    q = (Xhdr*)(((ulong)vq - offsetof(Xhdr, data[0])));

    if(p->magix != Magichole || q->magix != Magichole) {
        <<[[xmerge()]] debug info when not magichole>>
        panic("xmerge(%#p, %#p) bad magic %#lux, %#lux",
            vp, vq, p->magix, q->magix);
    }
    if((byte*)p+p->size == (byte*)q) {
        p->size += q->size;
        return true;
    }
    return false;
}
@

\ifallcode
<<[[xmerge()]] debug info when not magichole>>=
        int i;
        ulong *wd;
        void *badp;

        xsummary();
        badp = (p->magix != Magichole? p: q);
        wd = (ulong *)badp - 12;
        for (i = 24; i-- > 0; ) {
            print("%#p: %lux", wd, *wd);
            if (wd == badp)
                print(" <-");
            print("\n");
            wd++;
        }
@
\fi

% used by mmuwalk, dma allocator, smp, etc
% e.g. xspanalloc(64*1024*i8237dma, BY2PG, 64*1024);
% e.g. xspanalloc(4*BY2PG, BY2PG, 0);
<<function xspanalloc>>=
kern_addr3
xspanalloc(ulong size, int align, ulong span)
{
    ulong a, v, t;
    a = (kern_addr)xalloc(size+align+span);
    if(a == nilptr)
        panic("xspanalloc: %lud %d %lux", size, align, span);

    if(span > 2) {
        v = (a + span) & ~(span-1);
        t = v - a;
        if(t > 0)
            xhole(PADDR(a), t);
        t = a + span - v;
        if(t > 0)
            xhole(PADDR(v+size+align), t);
    }
    else
        v = a;

    if(align > 1)
        v = (v + align) & ~(align-1);

    return (kern_addr3)v;
}
@



\section{[[Pool]]}
% pool allocation, aka arena?
% yes, but used for a best-fit allocator I think

\begin{verbatim}

// from pool.h
//struct Pool {
//  char* name;
//  ulong maxsize;
//
//  ulong cursize;
//  ulong curfree;
//  ulong curalloc;
//
//  ulong minarena; /* smallest size of new arena */
//  ulong quantum;  /* allocated blocks should be multiple of */
//  ulong minblock; /* smallest newly allocated block */
//
//  void* freeroot; /* actually Free* */
//  void* arenalist;  /* actually Arena* */
//
//  void* (*alloc)(ulong);
//  int (*merge)(void*, void*);
//  void  (*move)(void* from, void* to);
//
//  int flags;
//  int nfree;
//  int lastcompact;
//
//  void  (*lock)(Pool*);
//  void  (*unlock)(Pool*);
//  void  (*print)(Pool*, char*, ...);
//  void  (*panic)(Pool*, char*, ...);
//  void  (*logstack)(Pool*);
//
//  void* private;
//};
\end{verbatim}

<<pool.c struct Private>>=
struct Private {
    Lock        lk;
    char        msg[256]; /* a rock for messages to be printed at unlock */
};
@

<<function plock>>=
static void
plock(Pool *p)
{
    Private *pv;

    pv = p->private;
    ilock(&pv->lk);
    pv->lk.pc = getcallerpc(&p);
    pv->msg[0] = 0;
}
@

% use ilock! don't want interrupt in middle of kernel malloc?

<<function punlock>>=
static void
punlock(Pool *p)
{
    Private *pv;
    char msg[sizeof pv->msg];

    pv = p->private;
    if(pv->msg[0] == 0){
        iunlock(&pv->lk);
        return;
    }

    memmove(msg, pv->msg, sizeof msg);
    iunlock(&pv->lk);
    iprint("%.*s", sizeof pv->msg, msg);
}
@

% note that no xfree() or xhole() here ... so it always grow
% (which is good for the fragmentation issue of xalloc anyway)
% kernel memory = 4Mo max? this is actually adjusted in confinit()
<<global pmainmem>>=
static Private pmainpriv;
static Pool pmainmem = {
    .name=  "Main",
    .maxsize=   4*MB,
    .minarena=  128*KB,
    .quantum=   32,
    .alloc= xalloc,
    .merge= xmerge,
    .flags= POOL_TOLERANCE,

    .lock=plock,
    .unlock= punlock,
    .print= poolprint,
    .panic= ppanic,

    .private=   &pmainpriv,
};
@


% this is really for image ... for kernel draw, 16Mo, not for KImage
% this is also adjusted in confinit
<<global pimagmem>>=
static Private pimagpriv;
static Pool pimagmem = {
    .name=  "Image",
    .maxsize=   16*MB,
    .minarena=  2*MB,
    .quantum=   32,
    .alloc= xalloc,
    .merge= xmerge,
    .flags= 0,

    .lock= plock,
    .unlock= punlock,
    .print= poolprint,
    .panic= ppanic,

    .private=   &pimagpriv,
};
@


<<global mainmem and imagmem>>=
// exported in include/pool.h, defined here!
Pool*   mainmem = &pmainmem;
Pool*   imagmem = &pimagmem;
@

%--------------------------------------------------------------------------

<<function poolprint>>=
/*
 * because we can't print while we're holding the locks, 
 * we have the save the message and print it once we let go.
 */
static void
poolprint(Pool *p, char *fmt, ...)
{
    va_list v;
    Private *pv;

    pv = p->private;
    va_start(v, fmt);
    vseprint(pv->msg+strlen(pv->msg), pv->msg+sizeof pv->msg, fmt, v);
    va_end(v);
}
@



<<function ppanic>>=
static void
ppanic(Pool *p, char *fmt, ...)
{
    va_list v;
    Private *pv;
    char msg[sizeof pv->msg];

    pv = p->private;
    va_start(v, fmt);
    vseprint(pv->msg+strlen(pv->msg), pv->msg+sizeof pv->msg, fmt, v);
    va_end(v);
    memmove(msg, pv->msg, sizeof msg);
    iunlock(&pv->lk);
    panic("%s", msg);
}
@


\section{Kernel [[malloc()]]}

% the memcpy, memmove, functions of libc use malloc? probably not

<<function malloc>>=
kern_addr3
malloc(ulong size)
{
    kern_addr3 v;

    v = poolalloc(mainmem, size+Npadlong*sizeof(ulong));
    if(v == nil)
        return nil;
    if(Npadlong){
        v = (ulong*)v+Npadlong;
        setmalloctag(v, getcallerpc(&size));
        setrealloctag(v, 0);
    }
    memset(v, 0, size);
    return v;
}
@

% note that don't need to precise the size here! because the size is stored
% in section before the returned pointer in malloc
<<function free>>=
void
free(kern_addr3 v)
{
    if(v != nil)
        poolfree(mainmem, (ulong*)v-Npadlong);
}
@
% not that we do not panic when it's == nil, because at many places
% we free(x); and then do x = nil; to avoid double free and because
% we are not sure free will be called again on x (for instance in sysexec()
% we have a waserror finally handler that free even though if free and
% didn't pop the error yet.


<<function setmalloctag>>=
void
setmalloctag(kern_addr3 v, kern_addr pc)
{
    kern_addr2 u;
    USED(v, pc); //??
    if(Npadlong <= MallocOffset || v == nil)
        return;
    u = v;
    u[-Npadlong+MallocOffset] = pc;
}
@


<<function setrealloctag>>=
void
setrealloctag(kern_addr3 v, kern_addr pc)
{
    kern_addr2 u;
    USED(v, pc);
    if(Npadlong <= ReallocOffset || v == nil)
        return;
    u = v;
    u[-Npadlong+ReallocOffset] = pc;
}
@


% sleep malloc, probably can't be called from interrupt code! 
% also memset to 0! so should be called smallocz no?
<<function smalloc>>=
// non failing malloc! will repeat until it can
kern_addr3
smalloc(ulong size)
{
    kern_addr3 v;

    for(;;) {
        v = poolalloc(mainmem, size + Npadlong*sizeof(ulong));
        if(v != nil)
            break;
        tsleep(&up->sleepr, returnfalse, 0, 100);
    }
    if(Npadlong){
        v = (ulong*)v+Npadlong;
        setmalloctag(v, getcallerpc(&size));
    }
    memset(v, 0, size); // clear
    return v;
}
@
% will see tsleep and rendez vous later. why use tsleep vs sched()?
% because what state it would be? you want sleeping state, so that's what tsleep
% is for!

<<function returnfalse>>=
// usually used as default callback for sleep/tsleep
bool
returnfalse(void*)
{
    return false;
}
@
%old: return0

<<function mallocz>>=
kern_addr3
mallocz(ulong size, bool clr)
{
    kern_addr3 v;

    v = poolalloc(mainmem, size+Npadlong*sizeof(ulong));
    if(Npadlong && v != nil){
        v = (ulong*)v+Npadlong;
        setmalloctag(v, getcallerpc(&size));
        setrealloctag(v, 0);
    }
    if(clr && v != nil)
        memset(v, 0, size);
    return v;
}
@


%-----------------------------------------------------------------------

<<function mallocalign>>=
kern_addr3
mallocalign(ulong size, ulong align, long offset, ulong span)
{
    kern_addr3 v;

    v = poolallocalign(mainmem, size+Npadlong*sizeof(ulong), align, 
                           offset-Npadlong*sizeof(ulong), span);
    if(Npadlong && v != nil){
        v = (ulong*)v+Npadlong;
        setmalloctag(v, getcallerpc(&size));
        setrealloctag(v, 0);
    }
    if(v)
        memset(v, 0, size);
    return v;
}
@

<<function realloc>>=
kern_addr3
realloc(kern_addr3 v, ulong size)
{
    kern_addr3 nv;

    if(v != nil)
        v = (ulong*)v-Npadlong;
    if(Npadlong !=0 && size != 0)
        size += Npadlong*sizeof(ulong);

    if(nv = poolrealloc(mainmem, v, size)){
        nv = (ulong*)nv+Npadlong;
        setrealloctag(nv, getcallerpc(&v));
        if(v == nil)
            setmalloctag(nv, getcallerpc(&v));
    }       
    return nv;
}
@


\section{User [[malloc()]]}
%actually brk

% from OS point of view the user malloc granularity is
% done via brk at a page level. malloc is actually
% done in libc on top of brk (cf insa and aubourg :) )

% in lib_core/libc/port/malloc.c 

%Pool *mainmem = &sbrkmem;
%Pool *imagmem = &sbrkmem;

% note also here that it always grow! brk always bigger.




\section{[[Page]] and [[palloc]]}

% already kindof virtual memory! but generic one.
% virtual because we have this indirection notion! of va vs pa. and segment
% with pagedir and pagetab. but more on this later in virtual memory chapter.
% cf famous quote on indirection

% Page will be building blocks for memory for user. We'll see later that
% they have a huge number of use.

<<struct Page>>=
// Page metadata. We will allocate as many Page as to cover all physical memory
// available for the user. xalloc'ed in Palloc.pages
struct Page
{
    phys_addr pa;     /* Physical address in memory */
    virt_addr va;     /* Virtual address for user */

    <<[[Page]] other fields>>
  
    // Why not Ref? to save space (same reason they use char below)
    // but that means needs to use Lock below to access this non-atomic ref.
    ushort  ref;      /* Reference count */ // Pages are shared!

    // set<enum<modref>>
    char  modref;     /* Simulated modify/reference bits */

    // enum<cachectl>??
    char color;			/* Cache coloring */
    // array<enum<cachectl>>
    char cachectl[MAXCPUS];	/* Cache flushing control for putmmu */

    // extra
    Lock;
    <<[[Page]] extra fields>>
};
@
% use 'ref', will be used to share, copy on write!
% note that pa is constant! set once and for all in pageinit and that's it

% Note that it's not a Page! It's some metadata about a Page. It's actually
% a kind of PTE if compare to the terminology in Intel MMU.
% But it does more than a PTE as it also the reverse index of va -> pa
% by storing also the pa -> va binding.
% less: rename PageInfo? Pte?

% when do we need va? 
% - when it's part of a segment to check that in the boundary in segpage()
%   (aka attach_page_to_segment) and put it at the right place in the pagedir
%   and pagetab
% - in dma transfer apparently

<<enum modref>>=
enum modref 
{
    PG_NOTHING = 0x00, // nothing

    PG_MOD    = 0x01,   /* software modified bit */
    PG_REF    = 0x02,   /* software referenced bit */
};
@
% TODO LP split, put just PG_NOTHING for now

% PG_REF is set in fixfault when access for the first time the page
%  why useful?
% PG_MOD is set in fixfault too when writing in the page
%  why useful? 
%   - for DATA? to know whether when we swapit whether we
%     can maybe if it was not modified just retrived it back from an KImage?



<<struct Palloc>>=
// Page Allocator (singleton)
struct Palloc
{
    Pallocmem mem[4]; // = Conf.mem minus memory allocated for the kernel
    // sum of mem.npage (which should be conf.upages)
    ulong user;     /* how many user pages */
  
    // array<Page>, xalloc'ed in pageinit(), huge, cover physical user space
    Page  *pages; /* array of all pages */ 
  
    // list<ref<Page>> (next = Page.next), list of free pages
    Page  *head;      /* most recently used */
    // list<ref<Page>> (prev = Page.prev), list of free pages (backward)
    Page  *tail;      /* least recently used */

    ulong freecount;    /* how many pages on free list now */

    <<[[Palloc]] other fields>>
  
    // extra
    Lock; // LOCK ORDERING: always do lock(&palloc); lock(&page)!!
    <<[[Palloc]] extra fields>>
};
@

<<global palloc>>=
// Page allocator
struct Palloc palloc;
@

% could merge with Confmem, because kbase and klimit could be removed
<<struct Pallocmem>>=
// memory banks for user memory, similar to Confmem (and RMap)
struct Pallocmem
{
    phys_addr base;
    ulong npage;
};
@


<<[[Page]] extra fields>>=
// list<ref<Page>> Palloc.head, or Proc.mmuused or Proc.mmufree, or in mfreeseg
Page  *next; /* Lru free list */ 
// list<ref<Page>> Palloc.tail
Page  *prev; 
@





<<function pagenumber>>=
ulong
pagenumber(Page *p)
{
    return p-palloc.pages;
}
@


% can set s to nil at exit in case of ???
<<constructor newpage>>=
Page*
newpage(bool clear, Segment **s, virt_addr va)
{
    Page *p;
    Arch_KMap *k;
    bool dontalloc;
 uchar ct;
    int i, color;

    lock(&palloc);
 color = getpgcolor(va);

    <<[[newpage()]] loop waiting freecount > highwater>>

    //when no color: p = palloc.head;
 /* First try for our colour */
 for(p = palloc.head; p; p = p->next)
  if(p->color == color)
   break;

 ct = PG_NOFLUSH;
 if(p == 0) {
  p = palloc.head;
  p->color = color;
  ct = PG_NEWCOL;
 }

    pageunchain(p);

    lock(p);
    if(p->ref != 0)
        panic("newpage: p->ref %d != 0", p->ref);

    <<[[newpage()]] uncachepage>>
    p->ref = 1;
    p->va = va;
    p->modref = PG_NOTHING;

 for(i = 0; i < MAXCPUS; i++)
  p->cachectl[i] = ct;

    unlock(p);
    unlock(&palloc);

    if(clear) {
        k = arch_kmap(p);
        memset((void*)VA(k), 0, BY2PG);
        arch_kunmap(k);
    }
    return p;
}
@
% arch_kmap()? see later
%old: was storing highwater in intermediate hw, useful?
%old: stuff with cachectl I now removed

<<function pageunchain>>=
// assumes palloc is held
static void
pageunchain(Page *p)
{
    if(canlock(&palloc))
        panic("pageunchain (palloc %p)", &palloc);

    // remove_queue(p, palloc);
    if(p->prev)
        p->prev->next = p->next;
    else
        palloc.head = p->next;
    if(p->next)
        p->next->prev = p->prev;
    else
        palloc.tail = p->prev;
    p->prev = p->next = nil;
    palloc.freecount--;
}
@

<<destructor putpage>>=
void
putpage(PageOrSwap *p)
{
    <<[[putpage]] if p is a swap address>>

    lock(&palloc);
    lock(p);

    if(p->ref == 0)
        panic("putpage");

    if(--p->ref > 0) {
        unlock(p);
        unlock(&palloc);
        return;
    }

    <<[[putpage]] if p has an image>>
    else 
        pagechainhead(p);

    if(palloc.freememr.p != nil)
        wakeup(&palloc.freememr);

    unlock(p);
    unlock(&palloc);
}
@
% LP split freememr?



<<function pagechainhead>>=
// assumes palloc is held
void
pagechainhead(Page *p)
{
    if(canlock(&palloc))
        panic("pagechainhead");
    // add_head(p, palloc)
    if(palloc.head) {
        p->next = palloc.head;
        palloc.head->prev = p;
    }
    else {
        palloc.tail = p;
        p->next = nil;
    }
    palloc.head = p;
    p->prev = nil;
    palloc.freecount++;
}
@

<<function pagechaintail>>=
// assumes palloc is held
void
pagechaintail(Page *p)
{
    if(canlock(&palloc))
        panic("pagechaintail");

    // add_tail(p, palloc)
    if(palloc.tail) {
        p->prev = palloc.tail;
        palloc.tail->next = p;
    }
    else {
        palloc.head = p;
        p->prev = nil;
    }
    palloc.tail = p;
    p->next = nil;
    palloc.freecount++;
}
@
% why chaintail? for Page Cache! see later

% far more about Pages in Page fault section in virtual memory chapter
% but for now enough, we have some functions to allocate and free
% pages for user space



\section{[[Segment]] and [[Pagetable]]}

% a bit like CS, DS, SS, etc. Maybe we should use Intel advanced features!
<<enum segtype>>=
/* Segment types */
enum segtype
{
    SG_TEXT   = 00,
    SG_DATA   = 01,
    SG_BSS    = 02,
    SG_STACK  = 03,
    <<enum segtype other cases>>
    SG_TYPE   = 07,   /* Mask type of segment */
  
    SG_RONLY  = 0040,   /* Segment is read only */
    <<enum segtype other flags>>
};
@

<<global sname>>=
// hash<enum<segtype, string>>
static char *sname[]={ "Text", "Data", "Bss", "Stack",   "Shared", "Phys", };
@
%TODO: coupling, make sure they are in the same order ...

<<struct Segment>>=
// smalloc'ed by newseg()
struct Segment
{
    // enum<segtype>
    ushort  type;   /* segment type */
  
    virt_addr base;   /* virtual base */
    virt_addr top;    /* virtual top */
    ulong size;   /* size in pages */ // top - base / BY2PG?
  
    // Kind of a page directory table. Points to smallpagedir if small enough.
    // array<option<ref_own<Pagetable>>>, smalloc'ed (or smallpagedir alias)
    // can map up to 2G of memory
    Pagetable **pagedir; // array of PAGEDIRSIZE max
    // array<option<ref_own<Pagetable>>
    Pagetable *smallpagedir[SMALLPAGEDIRSIZE];
    int pagedirsize; // nelem(pagedir)

 bool	flushme;	/* maintain icache for this segment */
  
    <<[[Segment]] other fields>>
  
    // extra
    Ref; // LOCK ORDERING: always do lock(img); lock(s) ??
    QLock lk;
};
@
%dead? int flushme;
%old: map -> pagedir, ssegmap -> smallpagedir

% Segment acts as a kind of Page directory per process, but
% archi-independent.

<<constant PAGEDIRSIZE(x86)>>=
#define PAGEDIRSIZE  1984
@
%old: SEGMAPSIZE
% why this size? 1984 Mo = 2Go - 16 Mo, not sure why

<<constant SMALLPAGEDIRSIZE(x86)>>=
#define SMALLPAGEDIRSIZE 16
@
%old: SSEGMAPSIZE


<<struct Pagetable>>=
// ptalloc'ed (malloc'ed)
struct Pagetable
{
    //array<option<ref<PageOrSwap>> will map 1M of memory
    PageOrSwap  *pagetab[PAGETABSIZE];
  
    //to avoid iterate over all entries in pagetab
    // ref<ref<Page>> in Pagetable.pages
    Page  **first;    /* First used entry */
    // ref<ref<Page>> in Pagetable.pages
    Page  **last;     /* Last used entry */
};
@
%old: was called Pte, but really it's not a page table entry but
% the whole pagetable!
%old: pages -> pagetab

% (first and last optimize a bit as many of the Page* can be null in pagetab)
% actually really PageOrSwapOrNil!

<<constant PAGETABMAPMEM(x86)>>=
#define PAGETABMAPMEM (1024*1024) // 1MB
@
%old: PTEMAPMEM

<<constant PAGETABSIZE(x86)>>=
#define PAGETABSIZE 256 // (PAGETABMAPMEM/BY2PG)
@
%old: PTEPERTAB


% Each Pagetable have PageInfo *pagetab[256]; so 256 pointers
% to PageInfo. each PageInfo speak about a page of 4Ko. so
% with 256 PageInfo you can speak about 256 * 4096 = 1M of memory.
% then later will have a segment that can have 1984 Pagetable,
% and each of this Pagetable have 256 PageInfo so 1984 * 256 * 4096 = 2Go
% of mapped virtual memory

% start here glossary about PD, PT, PDX, PTX? because we'll use it in segpage
% below

<<constructor ptalloc>>=
Pagetable*
ptalloc(void)
{
    Pagetable *new;

    new = smalloc(sizeof(Pagetable));
    new->first = &new->pagetab[PAGETABSIZE];
    new->last = new->pagetab;
    return new;
}
@
% note that use kernel memory here! and then we will user memory for the actual
% pages

<<destructor freept>>=
void
freept(Segment *s, Pagetable *p)
{
    PageOrSwap **pte;
    int ref;
    Page *pt, **ptop;

    switch(s->type&SG_TYPE) {
    <<[[freept()]] SG_PHYSICAL case>>
    default:
        for(pte = p->first; pte <= p->last; pte++)
            if(*pte) {
                putpage(*pte);
                *pte = nil;
            }
    }
    free(p);
}
@

% does not really copy, it's more about sharing and reference counting
% why not called duppte? to be more consistent with the rest?
<<function ptcpy>>=
Pagetable*
ptcpy(Pagetable *old)
{
    Pagetable *new;
    PageOrSwap **src, **dst;

    new = ptalloc();
    dst = &new->pagetab[old->first-old->pagetab];
    new->first = dst;
    for(src = old->first; src <= old->last; src++, dst++)
        if(*src) {
            <<[[ptcpy()]] if src is a swap page>>
            else {
                lock(*src);
                (*src)->ref++;
                unlock(*src);
            }
            new->last = dst;
            *dst = *src;
        }
    return new;
}
@
% why called copy? it looks like it shares, so when actually use copypage()?
% because when not have RFMEM we do dupseg and ptcpy, but I don't see
% how it's different since we still share. the pagedir and pagetab
% are new, but they contain the same pointers ...





% size is in pages (we really need dimention types)
<<constructor newseg>>=
Segment *
newseg(int type, virt_addr base, ulong size)
{
    Segment *s;
    int pagedirsize;

    if(size > (PAGEDIRSIZE*PAGETABSIZE))
        error(Enovmem);

    s = smalloc(sizeof(Segment));
    s->ref = 1;
    s->type = type;
    s->base = base;
    s->top = base+(size*BY2PG);
    s->size = size;

    <<[[newseg()]] sema initialization>>

    pagedirsize = ROUND(size, PAGETABSIZE)/PAGETABSIZE;
    if(pagedirsize > nelem(s->smallpagedir)){
        pagedirsize *= 2;
        if(pagedirsize > PAGEDIRSIZE)
            pagedirsize = PAGEDIRSIZE; // pad's first bugfix :)
        s->pagedir = smalloc(pagedirsize*sizeof(Pagetable*));
        s->pagedirsize = pagedirsize;
    }else{
        s->pagedir = s->smallpagedir;
        s->pagedirsize = nelem(s->smallpagedir);
    }
    return s;
}
@
%bug: see pad's bugfix above
%
% ok but who actually allocate the pages? allocate just pagedir here?
% what about pagetable? and pages?  This will be done in fixfault later! Lazy!
% for text it will be demand loaded, for memory it will be on read/write.
% newpage() is called lazily, in fixfault or pio. Here just setup the limits
% that fixfault will operate on.

<<destructor putseg>>=
void
putseg(Segment *s)
{
    Pagetable **pde, **emap;
    KImage *img;

    if(s == nil)
        return; // TODO: panic("putseg") instead?

    <<[[putseg()]] if s has an image>>
    else
        lock(s);

    s->ref--;
    if(s->ref != 0) {
        unlock(s);
        return;
    }
    unlock(s);

    qlock(&s->lk);
    <<[[putseg()]] if s had an image>>

    emap = &s->pagedir[s->pagedirsize];
    for(pde = s->pagedir; pde < emap; pde++)
        if(*pde)
            freept(s, *pde);

    qunlock(&s->lk);
    if(s->pagedir != s->smallpagedir)
        free(s->pagedir);
    <<[[putseg()]] free profile>>
    free(s);
}
@


% used by userinit(), explain well relation between a Page and a segment
% rename attach_page_to_segment?
<<function segpage>>=
void
segpage(Segment *s, Page *p)
{
    Pagetable **pt;
    ulong off;
    Page **pg;

    if(p->va < s->base || p->va >= s->top)
        panic("segpage");

    off = p->va - s->base;
    pt = &s->pagedir[off/PAGETABMAPMEM]; // PDX
    if(*pt == nil)
        *pt = ptalloc();

    pg = &(*pt)->pagetab[(off&(PAGETABMAPMEM-1))/BY2PG]; // PTX
    *pg = p;

    if(pg < (*pt)->first)
        (*pt)->first = pg;
    if(pg > (*pt)->last)
        (*pt)->last = pg;
}
@
% could assert old value of *pg was 0?

<<enum procseg>>=
/*
 *  process memory segments - NSEG always last !
 */
enum procseg
{
    SSEG, TSEG, DSEG, BSEG, // Stack, Text, Data, Bss

    ESEG, // E = Extra (used for temporary stack segment),
    _SEG0, _SEG1, _SEG2, _SEG3, _SEG4, // free slots for for segattach

    NSEG // to count, see Proc.seg array
};
@
% a bit weird that SSEG first, but some code assumes that as they do
% for i from SSEG to BSEG
% there was a LSEG, not sure why, I've renamed it to _SEG0

<<[[Proc]] memory fields>>=
// hash<enum<procseg>, option<ref_own<Segment>>>, elt smalloc'ed? ref_counted?
Segment *seg[NSEG];
QLock seglock;  /* locked whenever seg[] changes */
@ 


<<[[procread()]] cases>>=
case Qsegment:
    j = 0;
    for(i = 0; i < NSEG; i++) {
        sg = p->seg[i];
        if(sg == nil)
            continue;
        j += snprint(statbuf+j, sizeof statbuf - j,
            "%-6s %c%c %.8lux %.8lux %4ld\n",
            sname[sg->type&SG_TYPE],
            sg->type&SG_RONLY ? 'R' : ' ',
            sg->profile ? 'P' : ' ',
            sg->base, sg->top, sg->ref);
    }
    if(offset >= j)
        return 0;
    if(offset+n > j)
        n = j-offset;
    if(n == 0 && offset == 0)
        exhausted("segments");
    memmove(a, &statbuf[offset], n);
    return n;
@



<<function seg>>=
Segment*
seg(Proc *p, virt_addr addr, bool dolock)
{
    Segment **s, **et, *sg;

    et = &p->seg[NSEG];
    for(s = p->seg; s < et; s++) {
        sg = *s;
        if(sg == nil)
            continue;
        if(addr >= sg->base && addr < sg->top) {
            if(dolock == false)
                return sg;

            qlock(&sg->lk);
            // can have a race, need to check again
            if(addr >= sg->base && addr < sg->top)
                return sg;
            qunlock(&sg->lk);
        }
    }
    return nil;
}
@

<<function okaddr>>=
/*
 * Called only in a system call
 */
bool
okaddr(virt_addr addr, ulong len, bool write)
{
    Segment *s;

    if((long)len >= 0) {
        for(;;) {
            s = seg(up, addr, false);
            if(s == nil || (write && (s->type&SG_RONLY)))
                break;

            if(addr+len > s->top) {
                len -= s->top - addr;
                addr = s->top;
            }else{
                return true;
            }
        }
    }
    pprint("suicide: invalid address %#lux/%lud in sys call pc=%#lux\n", addr, len, arch_userpc());
    return false;
}
@
% the loop show a bit the limitation of just-paging model where all segments
% are put next to each other and are not in independent memory space.


<<function validaddr>>=
void
validaddr(virt_addr addr, ulong len, bool write)
{
    if(!okaddr(addr, len, write)){
        postnote(up, 1, "sys: bad address in syscall", NDebug);
        error(Ebadarg);
    }
}
@



% used by sysrfork(), dup or share actually
<<function dupseg>>=
Segment*
dupseg(Segment **seg, int segno, bool share)
{
    int i, size;
    Pagetable *pt;
    Segment *n, *s;

    SET(n); //????

    s = seg[segno];

    qlock(&s->lk);
    if(waserror()){
        qunlock(&s->lk);
        nexterror();
    }
    switch(s->type&SG_TYPE) {
    case SG_TEXT:       /* New segment shares pt set */
        goto sameseg;

    case SG_DATA:       /* Copy on write plus demand load info */

        if(segno == TSEG){ // why not SG_TEXT then?
            poperror();
            qunlock(&s->lk);
            return data2txt(s);// ????
        }

        if(share)
            goto sameseg; // threads! clone()

        n = newseg(s->type, s->base, s->size);
        <<[[dupseg()]] SG_DATA case, attach image to new segment n>>
        break;

    case SG_BSS:        /* Just copy on write */
        if(share)
            goto sameseg; // threads! clone()

        n = newseg(s->type, s->base, s->size);
        break;

    case SG_STACK:
        n = newseg(s->type, s->base, s->size);
        break;

    case SG_SHARED:
    case SG_PHYSICAL:
        goto sameseg;

    }
    // not sameseg, we have allocated a new seg in n above

    size = s->pagedirsize;
    for(i = 0; i < size; i++)
        if(pt = s->pagedir[i])
            n->pagedir[i] = ptcpy(pt); // will actually share the pages

    n->flushme = s->flushme;

    if(s->ref > 1)
        procflushseg(s); // ??
    poperror();
    qunlock(&s->lk);
    return n;

sameseg:
    incref(s);
    poperror();
    qunlock(&s->lk);
    return s;
}
@


<<function data2txt>>=
Segment*
data2txt(Segment *s)
{
    Segment *ps;

    ps = newseg(SG_TEXT, s->base, s->size);
    ps->image = s->image;
    incref(ps->image);
    ps->fstart = s->fstart;
    ps->flen = s->flen;
    ps->flushme = true;

    return ps;
}
@
% LP split that? what is that?

% used by sysexec() to relocate the stack that was in ESEG
<<function relocateseg>>=
void
relocateseg(Segment *s, ulong offset)
{
    Page **pg, *x;
    Pagetable *pt, **p, **endpt;

    endpt = &s->pagedir[s->pagedirsize];
    for(p = s->pagedir; p < endpt; p++) {
        if(*p == nil)
            continue;
        pt = *p;
        for(pg = pt->first; pg <= pt->last; pg++) {
            if(x = *pg)
                x->va += offset;
        }
    }
}
@

% used in ibrk() and segfree()
% when called from ibrk() we know s->ref == 1, so the procflushseg
% is really used only for extra segment and people using segfree()
<<function mfreeseg>>=
/*
 *  called with s->lk locked
 */
void
mfreeseg(Segment *s, ulong start, int pages)
{
    int i, j, size;
    ulong soff;
    PageOrSwap *pg;
    Page *list;

    soff = start-s->base;
    j = (soff&(PAGETABMAPMEM-1))/BY2PG; // PTX

    size = s->pagedirsize;
    list = nil;
    for(i = soff/PAGETABMAPMEM; i < size; i++) { // PDX
        if(pages <= 0)
            break;
        if(s->pagedir[i] == nil) { // space was never accessed, good, easier
            pages -= PAGETABSIZE-j;
            j = 0;
            continue;
        }
        while(j < PAGETABSIZE) {
            pg = s->pagedir[i]->pagetab[j];
            /*
             * We want to zero s->pagedir[i]->page[j] and putpage(pg),
             * but we have to make sure other processors flush the
             * entry from their TLBs before the page is freed.
             * We construct a list of the pages to be freed, zero
             * the entries, then (below) call procflushseg, and call
             * putpage on the whole list.
             *
             * Swapped-out pages don't appear in TLBs, so it's okay
             * to putswap those pages before procflushseg.
             */
            if(pg){
                <<[[mfreeseg]] if pg is a swap address>>
                else{
                    pg->next = list;
                    list = pg;
                }
                s->pagedir[i]->pagetab[j] = nil;
            }
            if(--pages == 0)
                goto out;
            j++;
        }
        j = 0;
    }
out:
    /* flush this seg in all other processes */
    if(s->ref > 1)
        procflushseg(s);

    /* free the pages */
    for(pg = list; pg != nil; pg = list){
        list = list->next;
        putpage(pg);
    }
}
@

%-------------------------------------------------------------------------

% used by sysexec() and other syscalls
% memchr on virtual address? and so that can span different pages, and 
% even different segments! can generate faults? I think so.
<<function vmemchr>>=
/*
 * &s[0] is known to be a valid address.
 */
void*
vmemchr(virt_addr3 s, int c, int n)
{
    int m;
    virt_addr a;
    virt_addr3 t;

    a = (virt_addr)s;
    while(PGROUND(a) != PGROUND(a+n-1)){
        /* spans pages; handle this page */
        m = BY2PG - (a & (BY2PG-1));
        t = memchr((void*)a, c, m);
        if(t)
            return t;
        a += m;
        n -= m;
        if(a < KZERO)
            validaddr(a, 1, false);
    }

    /* fits in one page */
    return memchr((void*)a, c, n);
}
@





\section{[[sysbrk()]]}

<<syscall brk>>=
// int brk(void*);
long
sysbrk(ulong* arg)
{
    return ibrk(arg[0], BSEG); // BSS, the heap size is changed
}
@ 
% see segfree for the other segments, which also call ibrk

% return the current base when called with 0
% ret_code?
<<function ibrk>>=
long
ibrk(ulong addr, int seg)
{
    Segment *s, *ns;
    ulong newtop, newsize;
    int i, mapsize;
    Pagetable **map;

    s = up->seg[seg];
    if(s == nil)
        error(Ebadarg);

    if(addr == nilptr)
        return s->base;

    qlock(&s->lk);

    /* We may start with the bss overlapping the data */
    if(addr < s->base) {
        if(seg != BSEG || up->seg[DSEG] == nil || addr < up->seg[DSEG]->base) {
            qunlock(&s->lk);
            error(Enovmem);
        }
        addr = s->base;
    }

    newtop = PGROUND(addr);
    newsize = (newtop-s->base)/BY2PG;
    if(newtop < s->top) {
        /*
         * do not shrink a segment shared with other procs, as the
         * to-be-freed address space may have been passed to the kernel
         * already by another proc and is past the validaddr stage.
         */
        if(s->ref > 1){
            qunlock(&s->lk);
            error(Einuse);
        }
        mfreeseg(s, newtop, (s->top-newtop)/BY2PG);
        s->top = newtop;
        s->size = newsize;
        qunlock(&s->lk);
        arch_flushmmu();
        return 0;
    }

    for(i = 0; i < NSEG; i++) {
        ns = up->seg[i];
        if(ns == nil || ns == s)
            continue;
        if(newtop >= ns->base && newtop < ns->top) {
            qunlock(&s->lk);
            error(Esoverlap);
        }
    }

    if(newsize > (PAGEDIRSIZE*PAGETABSIZE)) {
        qunlock(&s->lk);
        error(Enovmem);
    }

    // similar to code in newseg()
    mapsize = ROUND(newsize, PAGETABSIZE)/PAGETABSIZE;
    if(mapsize > s->pagedirsize){
        map = smalloc(mapsize*sizeof(Pagetable*));
        memmove(map, s->pagedir, s->pagedirsize*sizeof(Pagetable*));
        if(s->pagedir != s->smallpagedir)
            free(s->pagedir);
        s->pagedir = map;
        s->pagedirsize = mapsize;
    }

    s->top = newtop;
    s->size = newsize;
    qunlock(&s->lk);
    return 0;
}
@





\chapter{Processes}
\minitoc

<<systab process syscalls>>=
    [RFORK]     sysrfork,
    [EXEC]      sysexec,
    [EXITS]     sysexits,
    [AWAIT]     sysawait,
@ 

\section{Overview}

\section{[[Proc]] and [[procalloc]]}

<<[[Proc]] state fields>>=
ulong pid;
@

<<struct Procalloc>>=
struct Procalloc
{
    // array<Proc>, xalloc'ed in procinit() (conf.nproc)
    Proc* arena;
  
    // list<ref<Proc>> (next = Proc.qnext, hmmm abuse qnext)
    Proc* free;

    // hash<Proc.pid, ref<Proc>> (next = Proc.pidhash)>
    Proc* ht[128];
  
    // extra
    Lock;
};
@ 

<<global procalloc>>=
static struct Procalloc procalloc;
@ 


% reuse proc, but increment pidalloc each time, so 
% if have ref to Proc, can save pid and make sure when resume
% that the pid is the same. if not, means proc died and got reused.

<<global pidalloc>>=
static Counter  pidalloc;
@ 


% this is used to get from pid to the Proc. For instance
% useful in /proc/x/... to get the Proc of x. 
<<[[Proc]] extra fields>>=
// hash<Proc.pid, ref<Proc>> Procalloc.ht
Proc  *pidhash; /* next proc in pid hash */ 
@

% define phash(p) p->pid%nelem(procalloc.ht) ?

<<function pidhash>>=
static void
pidhash(Proc *p)
{
    int h;

    h = p->pid % nelem(procalloc.ht);
    lock(&procalloc);
    // add_hash(procalloc.ht, p->pid, p)
    p->pidhash = procalloc.ht[h];
    procalloc.ht[h] = p;
    unlock(&procalloc);
}
@ 


<<function pidunhash>>=
static void
pidunhash(Proc *p)
{
    int h;
    Proc **l;

    h = p->pid % nelem(procalloc.ht);
    lock(&procalloc);
    // remove_hash(procalloc.ht, p->pid, p)
    for(l = &procalloc.ht[h]; *l != nil; l = &(*l)->pidhash)
        if(*l == p){
            *l = p->pidhash;
            break;
        }
    unlock(&procalloc);
}
@ 

<<function procindex>>=
int
procindex(ulong pid)
{
    Proc *p;
    int h;
    int s;

    s = -1;
    h = pid % nelem(procalloc.ht);
    lock(&procalloc);
    for(p = procalloc.ht[h]; p != nil; p = p->pidhash)
        if(p->pid == pid){
            s = p - procalloc.arena;
            break;
        }
    unlock(&procalloc);
    return s;
}
@ 
%pid_or_errorneg


<<[[Proc]] state fields>>=
// some debugging information, e.g. "New", "PageOut", or name of syscall
char  *psstate; /* used by /proc/#/status */
bool insyscall; // true when process inside a syscall

// e.g. "*init*", or name of executable
char  *text;
@
% text is used by pprint() to print the name of the process in addition
% to its pid, which is convenient.


<<enum procstate cases>>=
Scheding,
@

% dtor = pexit() + schedinit
<<constructor newproc>>=
Proc*
newproc(void)
{
    char msg[64];
    Proc *p;

    lock(&procalloc);
    while((p = procalloc.free) == nil) {
        unlock(&procalloc);

        snprint(msg, sizeof msg, "no procs; %s forking", up?up->text:"kernel");
        /*
         * the situation is unlikely to heal itself.
         * dump the proc table and restart by default.
         * *noprocspersist in plan9.ini will yield the old
         * behaviour of trying forever.
         */
        if(getconf("*noprocspersist") == nil)
            noprocpanic(msg);
        resrcwait(msg);
        lock(&procalloc);
    }
    procalloc.free = p->qnext;
    unlock(&procalloc);
    p->qnext = nil;

    p->state = Scheding;
    p->pid = incref(&pidalloc);
    p->noteid = incref(&noteidalloc);
    if(p->pid==0 || p->noteid==0)
        panic("pidalloc");
    pidhash(p);
    p->notepending = false;
    p->notified = false;
    p->psstate = "New";
    p->cpu = nil;
    if(p->kstack == nil)
        p->kstack = smalloc(KSTACK);
    kstrdup(&p->user, "*nouser");
    kstrdup(&p->text, "*notext");
    kstrdup(&p->args, "");
    memset(p->seg, nilptr, sizeof p->seg);
    p->nargs = 0;
    p->setargs = false;

    /* sched params */
    procpriority(p, PriNormal, false);
    p->lastcpu = nil;
    p->wired = nil;
    p->cpuavg = 0;
    p->lastupdate = CPUS(0)->ticks*Scaling;
    p->edf = nil;

    p->parent = nil;
    p->nchild = 0;
    p->nwait = 0;
    p->waitq = nil;

    p->fgrp = nil;
    p->pgrp = nil;
    p->egrp = nil;
    p->rgrp = nil;

    <<[[newproc()]] fb init>>
    p->kp = false;

    p->pdbg = nil;
    p->procctl = Proc_nothing;
    p->syscalltrace = nil; 
    p->trace = false;
    p->dbgreg = nil;
   
    p->ureg = nil;
    p->privatemem = false;
    p->noswap = false;

    p->nerrlab = 0;
    p->errstr = p->errbuf0;
    p->syserrstr = p->errbuf1;
    p->errbuf0[0] = '\0';
    p->errbuf1[0] = '\0';

    p->nlocks.ref = 0;
    p->delaysched = 0;

    return p;
}
@ 

%----------------------------------------------------------------------------

<<function noprocpanic>>=
void
noprocpanic(char *msg)
{
    /*
     * setting exiting will make hzclock() on each processor call exit(0).
     * clearing our bit in cpus avoids calling exit(0) from hzclock()
     * on this processor.
     */
    lock(&active);
    active.cpus &= ~(1<<cpu->cpuno);
    active.exiting = true;
    unlock(&active);

    procdump();
    delay(1000);
    panic(msg);
}
@ 
% seems a bit rude to reboot because can't allocate newproc, why not just return
% error?

<<function resrcwait>>=
void
resrcwait(char *reason)
{
    ulong now;
    char *p;
    static ulong lastwhine;

    if(up == nil)
        panic("resrcwait");

    p = up->psstate;
    if(reason) {
        up->psstate = reason;
        now = seconds();
        /* don't tie up the console with complaints */
        if(now - lastwhine > Whinesecs) {
            lastwhine = now;
            print("%s\n", reason);
        }
    }
    tsleep(&up->sleepr, returnfalse, 0, 300);
    up->psstate = p;
}
@ 

<<constant Whinesecs>>=
    Whinesecs = 10,     /* frequency of out-of-resources printing */
@


\section{The user}

<<[[Proc]] state fields>>=
// e.g.. "eve" (no uid/gid in plan9, because of its distributed nature?)
char  *user;
@ 
% how can change user??? all the code here mostly duplicate the user
%  from a fork from eve. Can become none via userwrite() on /proc I think
% or via hostowner()

% no really uid, gid in plan9, just char* user; for process.
% have a uid/gid in struct Dir but it's also a char*.

% plan9 is not so much a multi-user OS?

% put that in security section?
<<function renameuser>>=
/*
 *  change ownership to 'new' of all processes owned by 'old'.  Used when
 *  eve changes.
 */
void
renameuser(char *old, char *new)
{
    Proc *p, *ep;

    ep = procalloc.arena+conf.nproc;
    for(p = procalloc.arena; p < ep; p++)
        if(p->user!=nil && strcmp(old, p->user)==0)
            kstrdup(&p->user, new);
}
@ 

<<function hostownerwrite>>=
/*
 *  called by devcons() for host owner/domain
 *
 *  writing hostowner also sets user
 */
long
hostownerwrite(char *a, int n)
{
    char buf[128];

    if(!iseve())
        error(Eperm);
    if(n <= 0 || n >= sizeof buf)
        error(Ebadarg);
    memmove(buf, a, n);
    buf[n] = 0;

    renameuser(eve, buf);
    kstrdup(&eve, buf);
    kstrdup(&up->user, buf);
    up->basepri = PriNormal;
    return n;
}
@ 


\section{[[sysrfork()]]}

<<enum rfork>>=
//coupling: with libc.h
enum rfork
{
    RFPROC      = (1<<4), // fork a new process!! (if unset then set props for up)
    RFMEM       = (1<<5), // share data and bss (kinda thread, a la Linux clone)
    RFNOWAIT    = (1<<6), // child will not leave a waitmsg

    RFNAMEG     = (1<<0), // copy namespace (if unset then share)
    RFENVG      = (1<<1), // copy environment variables (if unset then share)
    RFFDG       = (1<<2), // copy file descriptor table (if unset then share)

    RFCNAMEG    = (1<<10), // clean new namespace
    RFCENVG     = (1<<11), // clean new empty environment variables
    RFCFDG      = (1<<12), // clean new file descriptor table

    RFNOTEG     = (1<<3), // start new group for notes
    RFREND      = (1<<13), // start a new group for rendezvous
    RFNOMNT     = (1<<14), // # paths forbidden, sandboxing
};
@ 
% explain? RF = resource fork, G = ? group? because of Fgrp, Egrp, Pgrp?

% actually plan9 process can play the role of thread too, can share
% memory too (even though libthread/ is not using them).
% linux threads with raw syscalls:
%  http://nullprogram.com/blog/2015/05/15/

<<[[Proc]] state fields>>=
ulong parentpid;
@

<<syscall rfork>>=
// int rfork(int flags);
long
sysrfork(ulong* arg)
{
    Proc *p;
    int i;
    bool share;
    Fgrp *ofg;
    Pgrp *opg;
    Rgrp *org;
    Egrp *oeg;
    ulong pid, flag;
    Cpu *wm;

    flag = arg[0];
    /* Check flags before we commit */
    if((flag & (RFFDG|RFCFDG)) == (RFFDG|RFCFDG))
        error(Ebadarg);
    if((flag & (RFNAMEG|RFCNAMEG)) == (RFNAMEG|RFCNAMEG))
        error(Ebadarg);
    if((flag & (RFENVG|RFCENVG)) == (RFENVG|RFCENVG))
        error(Ebadarg);

    if((flag&RFPROC) == 0) { // not a fork, just setting properties for up
        if(flag & (RFMEM|RFNOWAIT))
            error(Ebadarg);
        if(flag & (RFFDG|RFCFDG)) {
            ofg = up->fgrp;
            if(flag & RFFDG)
                up->fgrp = dupfgrp(ofg);
            else
                up->fgrp = dupfgrp(nil);
            closefgrp(ofg);
        }
        if(flag & (RFNAMEG|RFCNAMEG)) {
            opg = up->pgrp;
            up->pgrp = newpgrp();
            if(flag & RFNAMEG)
                pgrpcpy(up->pgrp, opg);
            <<[[sysrfork()]] inherit noattach, RFPROC==0 case>>
            closepgrp(opg);
        }
       <<[[sysrfork()]] set noattach to true when RFNOMNT, RFPROC==0 case>>
        if(flag & RFREND) {
            org = up->rgrp;
            up->rgrp = newrgrp();
            closergrp(org);
        }
        if(flag & (RFENVG|RFCENVG)) {
            oeg = up->egrp;
            up->egrp = smalloc(sizeof(Egrp)); // newegrp()
            up->egrp->ref = 1;
            if(flag & RFENVG)
                envcpy(up->egrp, oeg);
            closeegrp(oeg);
        }
        if(flag & RFNOTEG)
            up->noteid = incref(&noteidalloc);
        return 0;
    }
    // ok RFPROC is set, let's create a new process

    p = newproc();
    pid = p->pid;

    p->sargs = up->sargs;
    p->slash = up->slash;
    p->dot = up->dot;
    incref(p->dot);
    memmove(p->note, up->note, sizeof(p->note));
    p->privatemem = up->privatemem;
    p->noswap = up->noswap;
    p->nnote = up->nnote;
    p->lastnote = up->lastnote;
    p->notify = up->notify;
    p->ureg = up->ureg;
    <<[[sysrfork()]] propagate fpsave>>

    /* Make a new set of memory segments */
    share = flag & RFMEM;
    qlock(&p->seglock);
    if(waserror()){
        qunlock(&p->seglock);
        nexterror();
    }
    for(i = 0; i < NSEG; i++)
        if(up->seg[i])
            p->seg[i] = dupseg(up->seg, i, share);
    qunlock(&p->seglock);
    poperror();

    /* File descriptors */
    if(flag & (RFFDG|RFCFDG)) {
        if(flag & RFFDG)
            p->fgrp = dupfgrp(up->fgrp);
        else
            p->fgrp = dupfgrp(nil);
    }
    else {
        p->fgrp = up->fgrp;
        incref(p->fgrp);
    }

    /* Process groups */
    if(flag & (RFNAMEG|RFCNAMEG)) {
        p->pgrp = newpgrp();
        if(flag & RFNAMEG)
            pgrpcpy(p->pgrp, up->pgrp);
        <<[[sysrfork()]] inherit noattach, RFPROC==1 case>>
    }
    else {
        p->pgrp = up->pgrp;
        incref(p->pgrp);
    }
    <<[[sysrfork()]] set noattach to true when RFNOMNT, RFPROC==1 case>>

    if(flag & RFREND)
        p->rgrp = newrgrp();
    else {
        incref(up->rgrp);
        p->rgrp = up->rgrp;
    }

    /* Environment group */
    if(flag & (RFENVG|RFCENVG)) {
        p->egrp = smalloc(sizeof(Egrp)); // newegrp
        p->egrp->ref = 1;
        if(flag & RFENVG)
            envcpy(p->egrp, up->egrp);
    }
    else {
        p->egrp = up->egrp;
        incref(p->egrp);
    }

    <<[[sysrfork()]] inherit hang>>
    p->procmode = up->procmode;

    /* Craft a return frame which will cause the child to pop out of
     * the scheduler in user mode with the return register zero
     */
    arch_forkchild(p, up->dbgreg);

    p->parent = up;
    p->parentpid = up->pid;
    if(flag&RFNOWAIT)
        p->parentpid = 0;
    else {
        lock(&up->exl);
        up->nchild++;
        unlock(&up->exl);
    }
    if((flag&RFNOTEG) == 0)
        p->noteid = up->noteid;

    <<[[sysrfork()]] propagate fpstate>>
    <<[[sysrfork()]] setting time field>>

    kstrdup(&p->text, up->text);
    kstrdup(&p->user, up->user);

    /*
     *  since the bss/data segments are now shareable,
     *  any mmu info about this process is now stale
     *  (i.e. has bad properties) and has to be discarded.
     */
    arch_flushmmu();

    p->basepri = up->basepri;
    p->priority = up->basepri;
    p->fixedpri = up->fixedpri;
    p->lastcpu = up->lastcpu;
    wm = up->wired;
    if(wm)
        procwired(p, wm->cpuno);

    ready(p);
    sched();
    return pid;
}
@ 
% LP split

\subsection{[[arch_forkchild()]] (x86)}

<<function forkchild(x86)>>=
void
arch_forkchild(Proc *p, Ureg *ureg)
{
    Ureg *cureg;

    /*
     * Add 2*BY2WD to the stack to account for
     *  - the return PC
     *  - trap's argument (ur)
     */
    p->sched.sp = (ulong)p->kstack+KSTACK-(sizeof(Ureg)+2*BY2WD);
    p->sched.pc = (ulong)arch_forkret;

    cureg = (Ureg*)(p->sched.sp+2*BY2WD);
    memmove(cureg, ureg, sizeof(Ureg));
    /* return value of syscall in child */
    cureg->ax = 0;

    /* Things from bottom of syscall which were never executed */
    p->psstate = nil;
    p->insyscall = false;
}
@
% have to fake a return of syscall here, of sysrfork

<<function forkret(x86)>>=
TEXT arch_forkret(SB), $0
        POPL    AX
        POPAL
        POPL    GS
        POPL    FS
        POPL    ES
        POPL    DS
        ADDL    $8, SP                  /* pop error code and trap type */
        IRETL
@
%?? POPAL? need to look at core code for returning from syscall as this is
% what we emulate here

\section{[[sysexec()]]}

%http://dbp-consulting.com/tutorials/debugging/linuxProgramStartup.html

%http://lwn.net/Articles/630727/

<<constant AOUT_MAGIC(x86)>>=
/*
 *  parameters for sysproc.c
 */
// I_MAGIC is defined in include/a.out.h, I for INTEL?
#define AOUT_MAGIC  (I_MAGIC)
@

% struct Exec = binary header in include/a.out.h



% logical chain: string -> tc -> exec -> segment
<<[[sysexec()]] locals>>=
char *file;
char *elem; // last element of binary, for up->text
char *file0;
@
% rename lastelem?

<<[[sysexec()]] locals>>=
Chan *tc;
@

<<[[sysexec()]] locals>>=
Exec exec;
ulong magic, text, entry, data, bss;
@

<<[[sysexec()]] locals>>=
ulong t, d, b; // text, data, bss sizes in bytes rounded to pages
Segment *s, *ts;
@

<<[[sysexec()]] locals>>=
char **argv, **argp;
char *a, *charp, *args;
ulong ssize, spage, nargs, nbytes;
@

<<[[Proc]] state fields>>=
char  *args;
int nargs;    /* number of bytes of args */
@


\ifallcode
<<[[sysexec()]] locals>>=
int i, n;
@
\fi

<<syscall exec>>=
// void* exec(char *name, char* argv[]);
long
sysexec(ulong* arg)
{

    <<[[sysexec()]] locals>>

    elem = nil;
    validaddr(arg[0], 1, false);
    file0 = validnamedup((char*)arg[0], true);
    if(waserror()){
        free(file0);
        free(elem);
        nexterror();
    }
    file = file0;
    for(;;){
        // this will also adjust up->genbuf to contain the last element of file path
        <<[[sysexec()]] call namec() to get a channel in tc from file>>
        if(waserror()){
            cclose(tc);
            nexterror();
        }
        if(!indir)
            kstrdup(&elem, up->genbuf);

        n = devtab[tc->type]->read(tc, &exec, sizeof(Exec), 0);
        if(n < 2) // need at least 2 bytes to decide if a #! or real binary
            error(Ebadexec);
        magic = l2be(exec.magic);
        text = l2be(exec.text);
        entry = l2be(exec.entry);

        if(n==sizeof(Exec) && (magic == AOUT_MAGIC)){
            if(text >= USTKTOP-UTZERO
            || entry < UTZERO+sizeof(Exec)
            || entry >= UTZERO+sizeof(Exec)+text)
                error(Ebadexec);
            break; /* for binary */
        }

        <<[[sysexec()]] process sharpbang>>
    }

    data = l2be(exec.data);
    bss = l2be(exec.bss);
    t = UTROUND(UTZERO+sizeof(Exec)+text);
    // data is put at page boundary after text (see also _multibootentry)
    d = ROUND(t + data, BY2PG);
    // note that not t + d + bss but t + data + bss here
    b = ROUND(t + data + bss, BY2PG);
    if(t >= KZERO || d >= KZERO || b >= KZERO)
        error(Ebadexec);

    /*
     * Args: pass 1: count
     */
    nargs = 0;
    nbytes = 0;

    <<[[sysexec()]] nbytes tos adjustments>>
    <<[[sysexec()]] if indir arg adjustments>>

    arch_validalign(arg[1], sizeof(char**));
    argp = (char**)arg[1];
    validaddr((ulong)argp, BY2WD, false);
    while(*argp){
        a = *argp++;
        if(((ulong)argp&(BY2PG-1)) < BY2WD)
            validaddr((ulong)argp, BY2WD, false);
        validaddr((ulong)a, 1, false);
        nbytes += ((char*)vmemchr(a, 0, 0x7FFFFFFF) - a) + 1;
        nargs++;
    }
    ssize = BY2WD*(nargs+1) + ROUND(nbytes, BY2WD);

    /*
     * 8-byte align SP for those (e.g. sparc) that need it.
     * arch_execregs() will subtract another 4 bytes for argc.
     */
    if((ssize+4) & 7)
        ssize += 4;
    spage = (ssize+(BY2PG-1)) >> PGSHIFT;

    /*
     * Build the stack segment, putting it in kernel virtual for the moment
     */
    if(spage > TSTKSIZ)
        error(Enovmem);

    qlock(&up->seglock);
    if(waserror()){
        qunlock(&up->seglock);
        nexterror();
    }
    // why ESEG? and why not TSTKTOP?? ESEG because will free later
    // the current SSEG. If we have an error in sysexec we don't want
    // to have messed up with the current stack. TSTKTOP-USTKSIZE for
    // the same reason, because we don't want overwrite old stack
    // all of that will be relocated later.
    up->seg[ESEG] = newseg(SG_STACK, TSTKTOP-USTKSIZE, USTKSIZE/BY2PG);

    /*
     * Args: pass 2: assemble; the pages will be faulted in
     */
    <<[[sysexec()]] tos settings>>

    argv = (char**)(TSTKTOP - ssize);
    charp = (char*)(TSTKTOP - nbytes);
    args = charp;
    <<[[sysexec()]] if indir argp adjustments>>
    else
        argp = (char**)arg[1];

    for(i=0; i<nargs; i++){
        <<[[sysexec()]] if indir argp adjustments again>>
        *argv++ = charp + (USTKTOP-TSTKTOP);
        n = strlen(*argp) + 1;
        memmove(charp, *argp++, n);
        charp += n;
    }
    free(file0);
    // file0 = nil? to avoid double free?

    free(up->text);
    up->text = elem;
    elem = nil; /* so waserror() won't free elem */
    USED(elem);

    /* copy args; easiest from new process's stack */
    n = charp - args;
    if(n > 128) /* don't waste too much space on huge arg lists */
        n = 128;
    a = up->args;
    up->args = nil;
    free(a);
    up->args = smalloc(n);
    memmove(up->args, args, n);

    if(n>0 && up->args[n-1]!='\0'){
        /* make sure last arg is NUL-terminated */
        /* put NUL at UTF-8 character boundary */
        for(i=n-1; i>0; --i)
            if(fullrune(up->args+i, n-i))
                break;
        up->args[i] = 0;
        n = i+1;
    }
    up->nargs = n;

    /*
     * Committed.
     * Free old memory.
     * Special segments are maintained across exec
     */
    for(i = SSEG; i <= BSEG; i++) {
        putseg(up->seg[i]);
        /* prevent a second free if we have an error */
        up->seg[i] = nil;
    }
    for(i = BSEG+1; i < NSEG; i++) {
        s = up->seg[i];
        if(s != nil && (s->type&SG_CEXEC)) { // close on exec
            putseg(s);
            up->seg[i] = nil;
        }
    }

    <<[[sysexec()]] close files marked as opened with close on exec>>

    /* Text.  Shared. Attaches to cache image if possible */
    <<[[sysexec()]] get text segment ts via demand loading on tc>>
    up->seg[TSEG] = ts;

    /* Data. Shared. */
    s = newseg(SG_DATA, t, (d-t)>>PGSHIFT);
    up->seg[DSEG] = s;
    <<[[sysexec()]] adjust data segment s for demand loading on tc>>

    /* BSS. Zero fill on demand */
    up->seg[BSEG] = newseg(SG_BSS, d, (b-d)>>PGSHIFT); // 0 fill! see fixfault

    /*
     * Move the stack
     */
    s = up->seg[ESEG];
    up->seg[ESEG] = nil;
    up->seg[SSEG] = s;
    qunlock(&up->seglock);
    poperror(); /* seglock */
    poperror(); /* elem */ // really? I think this matches more the cclose(tc)
    s->base = USTKTOP-USTKSIZE;
    s->top = USTKTOP;
    relocateseg(s, USTKTOP-TSTKTOP);

    /*
     *  '/' processes are higher priority (hack to make /ip more responsive).
     */
    if(devtab[tc->type]->dc == L'/')
        up->basepri = PriRoot;
    up->priority = up->basepri;
    poperror();
    cclose(tc); // tc has still a reference in the img

    /*
     *  At this point, the mmu contains info about the old address
     *  space and needs to be flushed
     */
    arch_flushmmu();

    qlock(&up->debug);
    up->nnote = 0;
    up->notify = nil;
    up->notified = false;
    up->privatemem = false;
    arch_procsetup(up);
    qunlock(&up->debug);

    <<[[sysexec()]] if hang>>

    return arch_execregs(entry, ssize, nargs);
}
@ 

\subsection{[[procsetup()]] (x86)}

<<function procsetup(x86)>>=
void
arch_procsetup(Proc* p)
{
  <<[[procsetup()]] fp setup(x86)>>
}
@ 


% could mv in lib.h? 
<<function l2be>>=
ulong
l2be(long l)
{
    byte *cp;

    cp = (byte*)&l;
    return (cp[0]<<24) | (cp[1]<<16) | (cp[2]<<8) | cp[3];
}
@ 
% >> >> >>

<<function UTROUND(x86)>>=
#define UTROUND(t)  ROUNDUP((t), BY2PG)
@

% Temporary STacK TOP
<<constant TSTKTOP(x86)>>=
#define TSTKTOP   (USTKTOP-USTKSIZE)  /* end of new stack in sysexec */ // just below
@

<<constant TSTKSIZ(x86)>>=
#define TSTKSIZ   100     /* pages in new stack; limits exec args */
@




<<function execregs(x86)>>=
long
arch_execregs(ulong entry, ulong ssize, ulong nargs)
{
    ulong *sp;
    Ureg *ureg;

    <<[[execregs()]] fp adjustments(x86)>>

    sp = (ulong*)(USTKTOP - ssize);
    *--sp = nargs;

    ureg = up->dbgreg;
    ureg->usp = (ulong)sp;
    ureg->pc = entry;
    return USTKTOP
     <<[[execregs()]] return adjustments(x86)>>
     ;     /* address of kernel/user shared data */
}
@ 



\section{[[sysawait()]]}
% better show sysawait before sysexits, parent point of view, then child pov

\t can have race where parent is calling wait too late
\t  and the child already terminated?
\t NO! you wait for child already terminated!! but kernel records
\t  only last 128 finished children.

% can have zombies in plan9? no ... if parent exit
% and have blocked children (on a pipe) then those children
% will never finish? no they should finish because the fd of the pipe
% will have been closed

<<[[Proc]] hierarchy fields>>=
// option<ref<Proc>> nil for the boot process
Proc  *parent;
int nchild;   /* Number of living children */
@
% subtle: it's useful to also have parentpid field because
% the parent may have died, and so freed in procalloc and then
% reused for another process! so have to check that 
% parent->pid == (saved)parentpid
% similar thing was done in quake3 :)
% http://blog.noctua-software.com/entity-references.html

<<[[Proc]] hierarchy fields>>=
// list<ref_own<Waitq>>> =~ list<ref_own<Waitmsg>>
Waitq *waitq;   /* Exited processes wait children */
int nwait;    /* Number of uncollected wait records */ // len(waitq)
Lock  exl;    /* Lock count and waitq */
@

% also in libc.h
<<struct Waitmsg>>=
struct Waitmsg
{
  int pid;    /* of loved one */ // pid of the child
  <<[[Waitmsg]] time field>>
  char  msg[ERRMAX];  /* actually variable-size in user mode */
};
@ 

<<struct Waitq>>=
// essentially a stack<ref_own<Waitmsg>>
struct Waitq
{
    Waitmsg w;
  
    // extra
    // list<ref_own<Waitq>> Proc.waitq
    Waitq *next;
};
@ 

<<[[Proc]] hierarchy fields>>=
Rendez  waitr;    /* Place to hang out in wait */
@ 

% when canqlock return false? who else access qwaitr? users via /proc/!
% seems too subtle the need for this
% put with the code for Qwait if want to talk about it
<<[[Proc]] hierarchy fields>>=
QLock qwaitr;
@

<<syscall await>>=
// int await(char *s, int n);
long
sysawait(ulong* arg)
{
    int i;
    int pid;
    Waitmsg w; // allocated in stack!
    ulong n;

    n = arg[1];
    validaddr(arg[0], n, true);
    pid = pwait(&w);
    if(pid < 0)
        return -1;
    i = snprint((char*)arg[0], n, "%d %lud %lud %lud %q",
        w.pid,
        <<[[sysawait()]] snprint time field arguments>>
        w.msg);

    return i;
}
@ 

<<function pwait>>=
ulong
pwait(Waitmsg *w)
{
    ulong cpid; // child pid
    Waitq *wq;

    if(!canqlock(&up->qwaitr))
        error(Einuse); // someone is reading /proc/pid/wait?

    if(waserror()) {
        qunlock(&up->qwaitr);
        nexterror();
    }

    lock(&up->exl);
    if(up->nchild == 0 && up->waitq == nil) {
        unlock(&up->exl);
        error(Enochild);
    }
    unlock(&up->exl);

    sleep(&up->waitr, haswaitq, up); // qwaitr is still locked

    // wq = pop(up->waitq), // can't be null, see haswaitq()
    lock(&up->exl);
    wq = up->waitq; 
    up->waitq = wq->next;
    up->nwait--;
    unlock(&up->exl);

    qunlock(&up->qwaitr);
    poperror();

    if(w)
        memmove(w, &wq->w, sizeof(Waitmsg));
    cpid = wq->w.pid;
    free(wq);
    return cpid;
}
@ 


<<function haswaitq>>=
int
haswaitq(void *x)
{
    Proc *p;
    p = (Proc *)x;
    return p->waitq != nil;
}
@ 


\section{[[sysexits()]]}

% return a string! far more useful than an exit code
% as anyway will have then to interpret this error code

% semantic of exits? what happens if still have children?
% the children will still be there! the parent closes all its
% filedescriptor but if have pipe with children, then the pipe
% will still be there and have hanging process?
% but does it sends a notes to the children? By default this not
% is handled and the child continue? or child stops also?
% Why this design choice whatever it is?

<<syscall exits>>=
// void exits(char *msg);
long
sysexits(ulong* arg)
{
    char *status;
    char *inval = "invalid exit string";
    char buf[ERRMAX];

    status = (char*)arg[0];
    if(status){
        if(waserror())
            status = inval;
        else{
            validaddr((ulong)status, 1, false);
            if(vmemchr(status, 0, ERRMAX) == 0){
                memmove(buf, status, ERRMAX);
                buf[ERRMAX-1] = 0;
                status = buf;
            }
            poperror();
        }

    }
    pexit(status, /*freemem*/true);
    panic("pexit: should never reach this point");
    return -1; // unreachable
}
@ 

% != Dead. Why the logic of killing process is split in pexit()
% here and schedinit()? Because to kill a process we need to free
% everything, but right now we are executing code using the per-process
% kernel stack itself, so by going to schedinit() we switch to
% the main kernel stack which is exterior to the process.
% Note that we never free the per-process kernel stack so we could
% in theory get rid of schedinit, but maybe it's more elegant that way.

<<enum procstate cases>>=
Moribund,
@

% todo: split in purely deallocate stuff and then the children/parent part
% rename freemem to addbroken? hmmm no
<<function pexit>>=
void
proc_pexit(char *exitstr, bool freemem)
{
    Proc *p; // parent
    Segment **s, **es;
    long utime, stime;
    Waitq *wq, *f, *next;
    Fgrp *fgrp;
    Egrp *egrp;
    Rgrp *rgrp;
    Pgrp *pgrp;
    Chan *dot;
    void (*pt)(Proc*, int, vlong);

    if(up->syscalltrace)
        free(up->syscalltrace);
    up->alarm = 0;
    if (up->tt)
        timerdel(up);

    <<[[pexit()]] hook proctrace>>

    /* nil out all the resources under lock (free later) */
    qlock(&up->debug);
    fgrp = up->fgrp;
    up->fgrp = nil;
    egrp = up->egrp;
    up->egrp = nil;
    rgrp = up->rgrp;
    up->rgrp = nil;
    pgrp = up->pgrp;
    up->pgrp = nil;
    dot = up->dot;
    up->dot = nil;
    qunlock(&up->debug);

    if(fgrp)
        closefgrp(fgrp);
    if(egrp)
        closeegrp(egrp);
    if(rgrp)
        closergrp(rgrp);
    if(dot)
        cclose(dot);
    if(pgrp)
        closepgrp(pgrp);

    /*
     * if not a kernel process and have a parent,
     * do some housekeeping.
     */
    if(up->kp == false) {
        p = up->parent;
        // no parent pointer, must be the very first process
        if(p == nil) {
            if(exitstr == nil)
                exitstr = "unknown";
            panic("boot process died: %s", exitstr);
        }

        while(waserror())
            ;

        wq = smalloc(sizeof(Waitq));
        poperror();

        wq->w.pid = up->pid;
        <<[[pexit()]] set wait msg time field>>
        if(exitstr && exitstr[0])
            snprint(wq->w.msg, sizeof(wq->w.msg), "%s %lud: %s", up->text, up->pid, exitstr);
        else
            wq->w.msg[0] = '\0';

        lock(&p->exl);
        /*
         * Check that parent is still alive.
         */
        // the parent pointer may not be your parent anymore, the parent
        // could have died and its slot reallocated to another process
        if(p->pid == up->parentpid && p->state != Broken) {
            p->nchild--;
            <<[[pexit()]] update TC time of parent>>
            /*
             * If there would be more than 128 wait records
             * processes for my parent, then don't leave a wait
             * record behind.  This helps prevent badly written
             * daemon processes from accumulating lots of wait
             * records.
             */
            if(p->nwait < 128) {
                // push(wq, p->waitq)
                wq->next = p->waitq;
                p->waitq = wq;
                p->nwait++;

                wq = nil; // the parent will do the free
                wakeup(&p->waitr); // haswaitq() is true now
            }
        }
        unlock(&p->exl);
        if(wq)
            free(wq);
    }

    // instead of a core dump we just keep the process around
    if(!freemem)
        addbroken(up); // will call sched()

    qlock(&up->seglock);
    //todo: rewrite using nelem(seg?)
    es = &up->seg[NSEG];
    for(s = up->seg; s < es; s++) {
        if(*s) {
            putseg(*s);
            *s = nil;
        }
    }
    qunlock(&up->seglock);

    lock(&up->exl);     /* Prevent my children from leaving waits */
    pidunhash(up);
    // so my children will not generate a waitq, I will not be here anymore
    up->pid = 0; 
    wakeup(&up->waitr); // wakeup process reading /proc/pid/wait
    unlock(&up->exl);

    for(f = up->waitq; f; f = next) {
        next = f->next;
        free(f);
    }

    /* release debuggers */
    qlock(&up->debug);
    if(up->pdbg) {
        wakeup(&up->pdbg->sleepr);
        up->pdbg = nil;
    }
    qunlock(&up->debug);

    /* Sched must not loop for these locks */
    lock(&procalloc);
    lock(&palloc);

    <<[[pexit()]] optional [[edfstop()]] for real-time scheduling>>
    up->state = Moribund;
    // will arch_gotolabel() to schedinit() which has special code around Moribund
    sched(); 
    panic("pexit: should never reach this point"); 
}
@ 
% (why not doing more simply arch_gotolabel(cpu->sched)? to reuse some of
%  sched() code?)

% What about zombie process? There is no zombie in plan9!
% Nicer design! the child write in the parent (if it has still one)
% the information the parent may need and then die!

\section{Kernel processes}

% examples of kernel processes? page collector (pager), closing channel
% collector (clunker?)

<<[[Proc]] other fields>>=
bool kp;   /* true if a kernel process */
void  (*kpfun)(void*);
void  *kparg;
@

<<function kproc>>=
// kernel process (aka kernel_thread in Linux?)
void
kproc(char *name, void (*func)(void *), void *arg)
{
    Proc *p;
    static Pgrp *kpgrp;

    p = newproc();

    p->psstate = nil;
    p->procmode = 0640;
    p->kp = true; // Kernel Process
    p->ureg = nil;
    p->noswap = true;

    p->slash = up->slash;
    p->dot = up->dot;
    if(p->dot)
        incref(p->dot);

    p->fpsave = up->fpsave;
    p->sargs = up->sargs;

    memmove(p->note, up->note, sizeof(p->note));
    p->nnote = up->nnote;
    p->lastnote = up->lastnote;
    p->notify = up->notify;

    procpriority(p, PriKproc, false);

    arch_kprocchild(p, func, arg);

    kstrdup(&p->user, eve);
    kstrdup(&p->text, name);

    if(kpgrp == nil)
        kpgrp = newpgrp();
    p->pgrp = kpgrp;
    incref(kpgrp);
    <<[[kproc()]] setting time field>>
    ready(p);
}
@ 

\subsection{[[arch_kprocchild()]] (x86)}

<<function kprocchild(x86)>>=
void
arch_kprocchild(Proc* p, void (*func)(void*), void* arg)
{
    p->kpfun = func;
    p->kparg = arg;

    /*
     * arch_gotolabel() needs a word on the stack in
     * which to place the return PC used to jump
     * to linkproc().
     */
    p->sched.pc = (ulong)linkproc;
    p->sched.sp = (ulong)p->kstack+KSTACK-BY2WD;
}
@ 

<<function linkproc(x86)>>=
static void
linkproc(void)
{
    arch_spllo();
    up->kpfun(up->kparg);
    // should never reach this place?? kernel processes are supposed
    // to run forever??
    pexit("kproc dying", /*freemem*/false); 
}
@ 


\section{Process control [[/proc/#/ctl]]}

% see /proc, /proc/x/ctl, procctl()
% see section on Debugging where explain procctl
% see also section on notifications

% TODO: How implement C-z on plan9? how shell can stop user process?
% actually on linux C-z is something interpreted by the tty maybe,
% and send SIGSTOP, but why resume to the shell then? because shell was
% waitpid and a SIGSTOP makes this waitpid resume?
% actually echo kill /proc/x/ctl?


% used by 'echo kill > /proc/x/ctl, and used by pager if not enough free memory
<<enum procctl cases>>=
    Proc_exitme,
@

<<[[procctl()]] Proc_exitme case>>=
    case Proc_exitme:
        arch_spllo();        /* pexit has locks in it */
        pexit("Killed", true);
@
%procctl() is executed by notify() executed itself usually
% at syscall boundary or trap

% lock on p->debug hold while doing that?
<<[[procctlreq()]] CMkill case>>=
    case CMkill:
        switch(p->state) {
        <<[[procctlreq()]] CMkill case, Broken case>>
        case Stopped:
            p->procctl = Proc_exitme;
            postnote(p, 0, "sys: killed", NExit);
            ready(p);
            break;
        default:
            p->procctl = Proc_exitme;
            postnote(p, 0, "sys: killed", NExit);
        }
        break;
@



\chapter{Interrupts}
\minitoc

%todo: would be nice to have a /sys/interrupts like Linux
% has a /proc/interrupts

\section{Overview}

% fault/trap vs irq? irq is a request from "outside", generating an interrupt
% fault/trap is also generating an interrupt, but more from "inside"

% from wikipedia IRQ page:
%  - at beginning had one PIC, IRQ0 ot IRQ7
%  - then 2 PICs, IRQ0 to IRQ15 (and one IRQ used for the chaining I think)
%  - then APIC, up to 255 IRQ lines per APIC

% used for many things, virtual memory, swap, ... even debugging I think

\section{[[Vctl] (x86)]}

<<struct Vctl(x86)>>=
struct Vctl {

    bool isintr;     /* interrupt or fault/trap */
    int irq; // if interrupt
  
    void  (*f)(Ureg*, void*); /* handler to call */
    void* a;      /* argument to call it with */
  
    char  name[KNAMELEN];   /* of driver */
    int tbdf; // /* type+bus+device+function */ ??
  
    <<[[Vctl]] other fields(x86)>>
    // extra
    <<[[Vctl]] extra fields(x86)>>
};
@
% V?? Vector? Interrupt vector?

<<global vctl(x86)>>=
// array<list<ref_own<Vctl>>> (next = Vctl.next)
static Vctl *vctl[256];
@ 

<<enum vector(x86)>>=
enum {
    <<enum vector cases(x86)>>
};
@


<<[[Vctl]] extra fields(x86)>>=
// list<ref_own<Vctl> of vctl[vno], xalloc'ed (should not have that many so ok)
Vctl* next;     /* handlers on this vector */
@

<<global vctllock(x86)>>=
static Lock vctllock;
@ 



% for /dev/irqalloc via devarch.c addarchfile
<<function irqallocread(x86)>>=
static long
irqallocread(Chan*, void *vbuf, long n, vlong offset)
{
    char *buf, *p, str[2*(11+1)+KNAMELEN+1+1];
    int m, vno;
    long oldn;
    Vctl *v;

    if(n < 0 || offset < 0)
        error(Ebadarg);

    oldn = n;
    buf = vbuf;
    for(vno=0; vno<nelem(vctl); vno++){
        for(v=vctl[vno]; v; v=v->next){
            m = snprint(str, sizeof str, "%11d %11d %.*s\n", vno, v->irq, KNAMELEN, v->name);
            if(m <= offset) /* if do not want this, skip entry */
                offset -= m;
            else{
                /* skip offset bytes */
                m -= offset;
                p = str+offset;
                offset = 0;

                /* write at most max(n,m) bytes */
                if(m > n)
                    m = n;
                memmove(buf, p, m);
                n -= m;
                buf += m;

                if(n == 0)
                    return oldn;
            }
        }
    }
    return oldn - n;
}
@ 


\section{Faults (x86)}
% fault/trap/exceptions

<<enum vector cases(x86)>>=
    VectorNMI = 2,    /* non-maskable interrupt */
    VectorBPT = 3,    /* breakpoint */
    VectorUD  = 6,    /* invalid opcode exception */
    VectorCNA = 7,    /* coprocessor not available */
    Vector2F  = 8,    /* double fault */
    VectorCSO = 9,    /* coprocessor segment overrun */
    VectorPF  = 14,   /* page fault */ //!!! page fault interrupt
    Vector15  = 15,   /* reserved */
    VectorCERR  = 16,   /* coprocessor error */
@
% very important page fault, base of virtual memory

% called by trapinit() (trap vs intr?)
<<function trapenable(x86)>>=
void
trapenable(int vno, void (*f)(Ureg*, void*), void* a, char *name)
{
    Vctl *v;

    if(vno < 0 || vno >= VectorPIC)
        panic("trapenable: vno %d", vno);

    v = xalloc(sizeof(Vctl));
    v->tbdf = BUSUNKNOWN;
    v->f = f;
    v->a = a;
    v->isintr = false;
    strncpy(v->name, name, KNAMELEN);
    v->name[KNAMELEN-1] = 0;

    ilock(&vctllock);
    //add_list(vctl[vno], v)
    v->next = vctl[vno];
    vctl[vno] = v;
    iunlock(&vctllock);
}
@ 


\section{IRQs (x86)}

<<enum vector cases(x86)>>=
    VectorPIC = 32,   /* external i8259 interrupts */
@

<<enum irq(x86)>>=
enum {
    IrqCLOCK  = 0, // !!! clock interrupt
    IrqKBD    = 1,
    IrqUART1  = 3,
    IrqUART0  = 4,
    IrqPCMCIA = 5,
    IrqFLOPPY = 6,
    IrqLPT    = 7,
    IrqIRQ7   = 7,
    IrqAUX    = 12,   /* PS/2 port */
    IrqIRQ13  = 13,   /* coprocessor on 386 */
    IrqATA0   = 14,
    IrqATA1   = 15,

    MaxIrqPIC = 15,
  
    IrqLINT0  = 16,   /* LINT[01] must be offsets 0 and 1 */
    IrqLINT1  = 17,
    IrqTIMER  = 18, // for alarms
    IrqERROR  = 19,
    IrqPCINT  = 20,
    IrqSPURIOUS = 31,   /* must have bits [3-0] == 0x0F */

    MaxIrqLAPIC = 31,
};
@
% LINT? Low interrupt? PCINT?
% very important: clock interrupt, base of preemptive scheduling!


<<[[Vctl]] other fields(x86)>>=
// interrupt service routine
int (*isr)(int);    /* get isr bit for this irq */
int (*eoi)(int);    /* eoi */
@


<<function intrenable(x86)>>=
void
arch_intrenable(int irq, void (*f)(Ureg*, void*), void* a, int tbdf, char *name)
{
    int vno;
    Vctl *v;

    if(f == nil){
        print("intrenable: nil handler for %d, tbdf 0x%uX for %s\n",
            irq, tbdf, name);
        return;
    }

    v = xalloc(sizeof(Vctl));
    v->isintr = true;
    v->irq = irq;
    v->tbdf = tbdf;
    v->f = f;
    v->a = a;
    strncpy(v->name, name, KNAMELEN-1);
    v->name[KNAMELEN-1] = 0;

    ilock(&vctllock);
    vno = arch->intrenable(v); // this should also set v->isr or v->eoi
    if(vno == -1){
        iunlock(&vctllock);
        print("intrenable: couldn't enable irq %d, tbdf 0x%uX for %s\n",
            irq, tbdf, v->name);
        xfree(v);
        return;
    }
    // add_list(vctl[vno], v) and extra check
    if(vctl[vno]){
        if(vctl[vno]->isr != v->isr || vctl[vno]->eoi != v->eoi)
            panic("intrenable: handler: %s %s %#p %#p %#p %#p",
                vctl[vno]->name, v->name,
                vctl[vno]->isr, v->isr, vctl[vno]->eoi, v->eoi);
        v->next = vctl[vno];
    }
    vctl[vno] = v;
    iunlock(&vctllock);
}
@ 
% why use xalloc? because malloc forbidden in interrupt code?

<<function intrdisable(x86)>>=
int
intrdisable(int irq, void (*f)(Ureg *, void *), void *a, int tbdf, char *name)
{
    Vctl **pv, *v;
    int vno;

    /*
     * For now, none of this will work with the APIC code,
     * there is no mapping between irq and vector as the IRQ
     * is pretty meaningless.
     */
    if(arch->intrvecno == nil)
        return -1;
    vno = arch->intrvecno(irq);
    ilock(&vctllock);
    pv = &vctl[vno];
    while (*pv &&
          ((*pv)->irq != irq || (*pv)->tbdf != tbdf || (*pv)->f != f || (*pv)->a != a ||
           strcmp((*pv)->name, name)))
        pv = &((*pv)->next);
    assert(*pv);

    v = *pv;
    *pv = (*pv)->next;  /* Link out the entry */

    if(vctl[vno] == nil && arch->intrdisable != nil)
        arch->intrdisable(irq);
    iunlock(&vctllock);
    xfree(v);
    return 0;
}
@ 

%\section{Interrupt controller [[i8259]]}

<<[[PCArch]] interrupt methods fields(x86)>>=
void  (*intrinit)(void);
int (*intrenable)(Vctl*);
int (*intrvecno)(int);
int (*intrdisable)(int);
void  (*introff)(void);
void  (*intron)(void);
@

<<[[archgeneric]] interrupt methods(x86)>>=
.intrinit=  i8259init,
.intrenable=    i8259enable,
.intrvecno= i8259vecno,
.intrdisable=   i8259disable,
.intron=    i8259on,
.introff=   i8259off,
@

<<function i8259init(x86)>>=
void
i8259init(void)
{
    int x;

    ioalloc(Int0ctl, 2, 0, "i8259.0");
    ioalloc(Int1ctl, 2, 0, "i8259.1");
    ilock(&i8259lock);

    /*
     *  Set up the first 8259 interrupt processor.
     *  Make 8259 interrupts start at CPU vector VectorPIC.
     *  Set the 8259 as master with edge triggered
     *  input with fully nested interrupts.
     */
    outb(Int0ctl, (1<<4)|(0<<3)|(1<<0));    /* ICW1 - master, edge triggered,
                           ICW4 will be sent */
    outb(Int0aux, VectorPIC);       /* ICW2 - interrupt vector offset */
    outb(Int0aux, 0x04);            /* ICW3 - have slave on level 2 */
    outb(Int0aux, 0x01);            /* ICW4 - 8086 mode, not buffered */

    /*
     *  Set up the second 8259 interrupt processor.
     *  Make 8259 interrupts start at CPU vector VectorPIC+8.
     *  Set the 8259 as slave with edge triggered
     *  input with fully nested interrupts.
     */
    outb(Int1ctl, (1<<4)|(0<<3)|(1<<0));    /* ICW1 - master, edge triggered,
                           ICW4 will be sent */
    outb(Int1aux, VectorPIC+8);     /* ICW2 - interrupt vector offset */
    outb(Int1aux, 0x02);            /* ICW3 - I am a slave on level 2 */
    outb(Int1aux, 0x01);            /* ICW4 - 8086 mode, not buffered */
    outb(Int1aux, (i8259mask>>8) & 0xFF);

    /*
     *  pass #2 8259 interrupts to #1
     */
    i8259mask &= ~0x04;
    outb(Int0aux, i8259mask & 0xFF);

    /*
     * Set Ocw3 to return the ISR when ctl read.
     * After initialisation status read is set to IRR.
     * Read IRR first to possibly deassert an outstanding
     * interrupt.
     */
    inb(Int0ctl);
    outb(Int0ctl, Ocw3|0x03);
    inb(Int1ctl);
    outb(Int1ctl, Ocw3|0x03);

    /*
     * Check for Edge/Level register.
     * This check may not work for all chipsets.
     * First try a non-intrusive test - the bits for
     * IRQs 13, 8, 2, 1 and 0 must be edge (0). If
     * that's OK try a R/W test.
     */
    x = (inb(Elcr2)<<8)|inb(Elcr1);
    if(!(x & 0x2107)){
        outb(Elcr1, 0);
        if(inb(Elcr1) == 0){
            outb(Elcr1, 0x20);
            if(inb(Elcr1) == 0x20)
                i8259elcr = x;
            outb(Elcr1, x & 0xFF);
            print("ELCR: %4.4uX\n", i8259elcr);
        }
    }
    iunlock(&i8259lock);
}
@
% >> >> >> >> >> >>

<<global i8259lock(x86)>>=
static Lock i8259lock;
@

<<function i8259isr(x86)>>=
int
i8259isr(int vno)
{
    int irq, isr;

    if(vno < VectorPIC || vno > VectorPIC+MaxIrqPIC)
        return 0;
    irq = vno-VectorPIC;

    /*
     *  tell the 8259 that we're done with the
     *  highest level interrupt (interrupts are still
     *  off at this point)
     */
    ilock(&i8259lock);
    isr = inb(Int0ctl);
    outb(Int0ctl, EOI);
    if(irq >= 8){
        isr |= inb(Int1ctl)<<8;
        outb(Int1ctl, EOI);
    }
    iunlock(&i8259lock);

    return isr & (1<<irq);
}
@
% >> >>

<<function i8259enable(x86)>>=
int
i8259enable(Vctl* v)
{
    int irq, irqbit;

    /*
     * Given an IRQ, enable the corresponding interrupt in the i8259
     * and return the vector to be used. The i8259 is set to use a fixed
     * range of vectors starting at VectorPIC.
     */
    irq = v->irq;
    if(irq < 0 || irq > MaxIrqPIC){
        print("i8259enable: irq %d out of range\n", irq);
        return -1;
    }
    irqbit = 1<<irq;

    ilock(&i8259lock);
    if(!(i8259mask & irqbit) && !(i8259elcr & irqbit)){
        print("i8259enable: irq %d shared but not level\n", irq);
        iunlock(&i8259lock);
        return -1;
    }
    i8259mask &= ~irqbit;
    if(irq < 8)
        outb(Int0aux, i8259mask & 0xFF);
    else
        outb(Int1aux, (i8259mask>>8) & 0xFF);

    if(i8259elcr & irqbit)
        v->eoi = i8259isr;
    else
        v->isr = i8259isr;
    iunlock(&i8259lock);

    return VectorPIC+irq;
}
@

<<function i8259vecno(x86)>>=
int
i8259vecno(int irq)
{
    return VectorPIC+irq;
}
@

<<function i8259disable(x86)>>=
int
i8259disable(int irq)
{
    int irqbit;

    /*
     * Given an IRQ, disable the corresponding interrupt
     * in the 8259.
     */
    if(irq < 0 || irq > MaxIrqPIC){
        print("i8259disable: irq %d out of range\n", irq);
        return -1;
    }
    irqbit = 1<<irq;

    ilock(&i8259lock);
    if(!(i8259mask & irqbit)){
        i8259mask |= irqbit;
        if(irq < 8)
            outb(Int0aux, i8259mask & 0xFF);
        else
            outb(Int1aux, (i8259mask>>8) & 0xFF);
    }
    iunlock(&i8259lock);
    return 0;
}
@

<<function i8259on(x86)>>=
void
i8259on(void)
{
    outb(Int0aux, i8259mask&0xFF);
    outb(Int1aux, (i8259mask>>8)&0xFF);
}
@


<<function i8259off(x86)>>=
void
i8259off(void)
{
    outb(Int0aux, 0xFF);
    outb(Int1aux, 0xFF);
}
@


\section{Interrupt [[vectortable]] and [[idt]] (x86)}

<<constant IDTADDR(x86)>>=
#define IDTADDR   (KZERO+0x10800)   /* idt */
@
% why 800? why not 0x10000?

<<global vectortable(x86)>>=
TEXT vectortable(SB), $0
        CALL _strayintr(SB); BYTE $0x00         /* divide error */
        CALL _strayintr(SB); BYTE $0x01         /* debug exception */
        CALL _strayintr(SB); BYTE $0x02         /* NMI interrupt */
        CALL _strayintr(SB); BYTE $0x03         /* breakpoint */
        CALL _strayintr(SB); BYTE $0x04         /* overflow */
        CALL _strayintr(SB); BYTE $0x05         /* bound */
        CALL _strayintr(SB); BYTE $0x06         /* invalid opcode */
        CALL _strayintr(SB); BYTE $0x07         /* no coprocessor available */
        CALL _strayintrx(SB); BYTE $0x08        /* double fault */
        CALL _strayintr(SB); BYTE $0x09         /* coprocessor segment overflow */
        CALL _strayintrx(SB); BYTE $0x0A        /* invalid TSS */
        CALL _strayintrx(SB); BYTE $0x0B        /* segment not available */
        CALL _strayintrx(SB); BYTE $0x0C        /* stack exception */
        CALL _strayintrx(SB); BYTE $0x0D        /* general protection error */
        CALL _strayintrx(SB); BYTE $0x0E        /* page fault */
        CALL _strayintr(SB); BYTE $0x0F         /*  */
        CALL _strayintr(SB); BYTE $0x10         /* coprocessor error */
        CALL _strayintrx(SB); BYTE $0x11        /* alignment check */
        CALL _strayintr(SB); BYTE $0x12         /* machine check */
        CALL _strayintr(SB); BYTE $0x13
        CALL _strayintr(SB); BYTE $0x14
        CALL _strayintr(SB); BYTE $0x15
        CALL _strayintr(SB); BYTE $0x16
        CALL _strayintr(SB); BYTE $0x17
        CALL _strayintr(SB); BYTE $0x18
        CALL _strayintr(SB); BYTE $0x19
        CALL _strayintr(SB); BYTE $0x1A
        CALL _strayintr(SB); BYTE $0x1B
        CALL _strayintr(SB); BYTE $0x1C
        CALL _strayintr(SB); BYTE $0x1D
        CALL _strayintr(SB); BYTE $0x1E
        CALL _strayintr(SB); BYTE $0x1F
        CALL _strayintr(SB); BYTE $0x20         /* VectorLAPIC */
        CALL _strayintr(SB); BYTE $0x21
        CALL _strayintr(SB); BYTE $0x22
        CALL _strayintr(SB); BYTE $0x23
        CALL _strayintr(SB); BYTE $0x24
        CALL _strayintr(SB); BYTE $0x25
        CALL _strayintr(SB); BYTE $0x26
        CALL _strayintr(SB); BYTE $0x27
        CALL _strayintr(SB); BYTE $0x28
        CALL _strayintr(SB); BYTE $0x29
        CALL _strayintr(SB); BYTE $0x2A
        CALL _strayintr(SB); BYTE $0x2B
        CALL _strayintr(SB); BYTE $0x2C
        CALL _strayintr(SB); BYTE $0x2D
        CALL _strayintr(SB); BYTE $0x2E
        CALL _strayintr(SB); BYTE $0x2F
        CALL _strayintr(SB); BYTE $0x30
        CALL _strayintr(SB); BYTE $0x31
        CALL _strayintr(SB); BYTE $0x32
        CALL _strayintr(SB); BYTE $0x33
        CALL _strayintr(SB); BYTE $0x34
        CALL _strayintr(SB); BYTE $0x35
        CALL _strayintr(SB); BYTE $0x36
        CALL _strayintr(SB); BYTE $0x37
        CALL _strayintr(SB); BYTE $0x38
        CALL _strayintr(SB); BYTE $0x39
        CALL _strayintr(SB); BYTE $0x3A
        CALL _strayintr(SB); BYTE $0x3B
        CALL _strayintr(SB); BYTE $0x3C
        CALL _strayintr(SB); BYTE $0x3D
        CALL _strayintr(SB); BYTE $0x3E
        CALL _strayintr(SB); BYTE $0x3F
        CALL _syscallintr(SB); BYTE $0x40       /* VectorSYSCALL */
        CALL _strayintr(SB); BYTE $0x41
        CALL _strayintr(SB); BYTE $0x42
        CALL _strayintr(SB); BYTE $0x43
        CALL _strayintr(SB); BYTE $0x44
        CALL _strayintr(SB); BYTE $0x45
        CALL _strayintr(SB); BYTE $0x46
        CALL _strayintr(SB); BYTE $0x47
        CALL _strayintr(SB); BYTE $0x48
        CALL _strayintr(SB); BYTE $0x49
        CALL _strayintr(SB); BYTE $0x4A
        CALL _strayintr(SB); BYTE $0x4B
        CALL _strayintr(SB); BYTE $0x4C
        CALL _strayintr(SB); BYTE $0x4D
        CALL _strayintr(SB); BYTE $0x4E
        CALL _strayintr(SB); BYTE $0x4F
        CALL _strayintr(SB); BYTE $0x50
        CALL _strayintr(SB); BYTE $0x51
        CALL _strayintr(SB); BYTE $0x52
        CALL _strayintr(SB); BYTE $0x53
        CALL _strayintr(SB); BYTE $0x54
        CALL _strayintr(SB); BYTE $0x55
        CALL _strayintr(SB); BYTE $0x56
        CALL _strayintr(SB); BYTE $0x57
        CALL _strayintr(SB); BYTE $0x58
        CALL _strayintr(SB); BYTE $0x59
        CALL _strayintr(SB); BYTE $0x5A
        CALL _strayintr(SB); BYTE $0x5B
        CALL _strayintr(SB); BYTE $0x5C
        CALL _strayintr(SB); BYTE $0x5D
        CALL _strayintr(SB); BYTE $0x5E
        CALL _strayintr(SB); BYTE $0x5F
        CALL _strayintr(SB); BYTE $0x60
        CALL _strayintr(SB); BYTE $0x61
        CALL _strayintr(SB); BYTE $0x62
        CALL _strayintr(SB); BYTE $0x63
        CALL _strayintr(SB); BYTE $0x64
        CALL _strayintr(SB); BYTE $0x65
        CALL _strayintr(SB); BYTE $0x66
        CALL _strayintr(SB); BYTE $0x67
        CALL _strayintr(SB); BYTE $0x68
        CALL _strayintr(SB); BYTE $0x69
        CALL _strayintr(SB); BYTE $0x6A
        CALL _strayintr(SB); BYTE $0x6B
        CALL _strayintr(SB); BYTE $0x6C
        CALL _strayintr(SB); BYTE $0x6D
        CALL _strayintr(SB); BYTE $0x6E
        CALL _strayintr(SB); BYTE $0x6F
        CALL _strayintr(SB); BYTE $0x70
        CALL _strayintr(SB); BYTE $0x71
        CALL _strayintr(SB); BYTE $0x72
        CALL _strayintr(SB); BYTE $0x73
        CALL _strayintr(SB); BYTE $0x74
        CALL _strayintr(SB); BYTE $0x75
        CALL _strayintr(SB); BYTE $0x76
        CALL _strayintr(SB); BYTE $0x77
        CALL _strayintr(SB); BYTE $0x78
        CALL _strayintr(SB); BYTE $0x79
        CALL _strayintr(SB); BYTE $0x7A
        CALL _strayintr(SB); BYTE $0x7B
        CALL _strayintr(SB); BYTE $0x7C
        CALL _strayintr(SB); BYTE $0x7D
        CALL _strayintr(SB); BYTE $0x7E
        CALL _strayintr(SB); BYTE $0x7F
        CALL _strayintr(SB); BYTE $0x80         /* Vector[A]PIC */
        CALL _strayintr(SB); BYTE $0x81
        CALL _strayintr(SB); BYTE $0x82
        CALL _strayintr(SB); BYTE $0x83
        CALL _strayintr(SB); BYTE $0x84
        CALL _strayintr(SB); BYTE $0x85
        CALL _strayintr(SB); BYTE $0x86
        CALL _strayintr(SB); BYTE $0x87
        CALL _strayintr(SB); BYTE $0x88
        CALL _strayintr(SB); BYTE $0x89
        CALL _strayintr(SB); BYTE $0x8A
        CALL _strayintr(SB); BYTE $0x8B
        CALL _strayintr(SB); BYTE $0x8C
        CALL _strayintr(SB); BYTE $0x8D
        CALL _strayintr(SB); BYTE $0x8E
        CALL _strayintr(SB); BYTE $0x8F
        CALL _strayintr(SB); BYTE $0x90
        CALL _strayintr(SB); BYTE $0x91
        CALL _strayintr(SB); BYTE $0x92
        CALL _strayintr(SB); BYTE $0x93
        CALL _strayintr(SB); BYTE $0x94
        CALL _strayintr(SB); BYTE $0x95
        CALL _strayintr(SB); BYTE $0x96
        CALL _strayintr(SB); BYTE $0x97
        CALL _strayintr(SB); BYTE $0x98
        CALL _strayintr(SB); BYTE $0x99
        CALL _strayintr(SB); BYTE $0x9A
        CALL _strayintr(SB); BYTE $0x9B
        CALL _strayintr(SB); BYTE $0x9C
        CALL _strayintr(SB); BYTE $0x9D
        CALL _strayintr(SB); BYTE $0x9E
        CALL _strayintr(SB); BYTE $0x9F
        CALL _strayintr(SB); BYTE $0xA0
        CALL _strayintr(SB); BYTE $0xA1
        CALL _strayintr(SB); BYTE $0xA2
        CALL _strayintr(SB); BYTE $0xA3
        CALL _strayintr(SB); BYTE $0xA4
        CALL _strayintr(SB); BYTE $0xA5
        CALL _strayintr(SB); BYTE $0xA6
        CALL _strayintr(SB); BYTE $0xA7
        CALL _strayintr(SB); BYTE $0xA8
        CALL _strayintr(SB); BYTE $0xA9
        CALL _strayintr(SB); BYTE $0xAA
        CALL _strayintr(SB); BYTE $0xAB
        CALL _strayintr(SB); BYTE $0xAC
        CALL _strayintr(SB); BYTE $0xAD
        CALL _strayintr(SB); BYTE $0xAE
        CALL _strayintr(SB); BYTE $0xAF
        CALL _strayintr(SB); BYTE $0xB0
        CALL _strayintr(SB); BYTE $0xB1
        CALL _strayintr(SB); BYTE $0xB2
        CALL _strayintr(SB); BYTE $0xB3
        CALL _strayintr(SB); BYTE $0xB4
        CALL _strayintr(SB); BYTE $0xB5
        CALL _strayintr(SB); BYTE $0xB6
        CALL _strayintr(SB); BYTE $0xB7
        CALL _strayintr(SB); BYTE $0xB8
        CALL _strayintr(SB); BYTE $0xB9
        CALL _strayintr(SB); BYTE $0xBA
        CALL _strayintr(SB); BYTE $0xBB
        CALL _strayintr(SB); BYTE $0xBC
        CALL _strayintr(SB); BYTE $0xBD
        CALL _strayintr(SB); BYTE $0xBE
        CALL _strayintr(SB); BYTE $0xBF
        CALL _strayintr(SB); BYTE $0xC0
        CALL _strayintr(SB); BYTE $0xC1
        CALL _strayintr(SB); BYTE $0xC2
        CALL _strayintr(SB); BYTE $0xC3
        CALL _strayintr(SB); BYTE $0xC4
        CALL _strayintr(SB); BYTE $0xC5
        CALL _strayintr(SB); BYTE $0xC6
        CALL _strayintr(SB); BYTE $0xC7
        CALL _strayintr(SB); BYTE $0xC8
        CALL _strayintr(SB); BYTE $0xC9
        CALL _strayintr(SB); BYTE $0xCA
        CALL _strayintr(SB); BYTE $0xCB
        CALL _strayintr(SB); BYTE $0xCC
        CALL _strayintr(SB); BYTE $0xCD
        CALL _strayintr(SB); BYTE $0xCE
        CALL _strayintr(SB); BYTE $0xCF
        CALL _strayintr(SB); BYTE $0xD0
        CALL _strayintr(SB); BYTE $0xD1
        CALL _strayintr(SB); BYTE $0xD2
        CALL _strayintr(SB); BYTE $0xD3
        CALL _strayintr(SB); BYTE $0xD4
        CALL _strayintr(SB); BYTE $0xD5
        CALL _strayintr(SB); BYTE $0xD6
        CALL _strayintr(SB); BYTE $0xD7
        CALL _strayintr(SB); BYTE $0xD8
        CALL _strayintr(SB); BYTE $0xD9
        CALL _strayintr(SB); BYTE $0xDA
        CALL _strayintr(SB); BYTE $0xDB
        CALL _strayintr(SB); BYTE $0xDC
        CALL _strayintr(SB); BYTE $0xDD
        CALL _strayintr(SB); BYTE $0xDE
        CALL _strayintr(SB); BYTE $0xDF
        CALL _strayintr(SB); BYTE $0xE0
        CALL _strayintr(SB); BYTE $0xE1
        CALL _strayintr(SB); BYTE $0xE2
        CALL _strayintr(SB); BYTE $0xE3
        CALL _strayintr(SB); BYTE $0xE4
        CALL _strayintr(SB); BYTE $0xE5
        CALL _strayintr(SB); BYTE $0xE6
        CALL _strayintr(SB); BYTE $0xE7
        CALL _strayintr(SB); BYTE $0xE8
        CALL _strayintr(SB); BYTE $0xE9
        CALL _strayintr(SB); BYTE $0xEA
        CALL _strayintr(SB); BYTE $0xEB
        CALL _strayintr(SB); BYTE $0xEC
        CALL _strayintr(SB); BYTE $0xED
        CALL _strayintr(SB); BYTE $0xEE
        CALL _strayintr(SB); BYTE $0xEF
        CALL _strayintr(SB); BYTE $0xF0
        CALL _strayintr(SB); BYTE $0xF1
        CALL _strayintr(SB); BYTE $0xF2
        CALL _strayintr(SB); BYTE $0xF3
        CALL _strayintr(SB); BYTE $0xF4
        CALL _strayintr(SB); BYTE $0xF5
        CALL _strayintr(SB); BYTE $0xF6
        CALL _strayintr(SB); BYTE $0xF7
        CALL _strayintr(SB); BYTE $0xF8
        CALL _strayintr(SB); BYTE $0xF9
        CALL _strayintr(SB); BYTE $0xFA
        CALL _strayintr(SB); BYTE $0xFB
        CALL _strayintr(SB); BYTE $0xFC
        CALL _strayintr(SB); BYTE $0xFD
        CALL _strayintr(SB); BYTE $0xFE
        CALL _strayintr(SB); BYTE $0xFF
@ 

%$


<<global excname(x86)>>=
static char* excname[32] = {
    "divide error",
    "debug exception",
    "nonmaskable interrupt",
    "breakpoint",
    "overflow",
    "bounds check",
    "invalid opcode",
    "coprocessor not available",
    "double fault",
    "coprocessor segment overrun",
    "invalid TSS",
    "segment not present",
    "stack exception",
    "general protection violation",
    "page fault",
    "15 (reserved)",
    "coprocessor error",
    "alignment check",
    "machine check",
    "19 (reserved)",
    "20 (reserved)",
    "21 (reserved)",
    "22 (reserved)",
    "23 (reserved)",
    "24 (reserved)",
    "25 (reserved)",
    "26 (reserved)",
    "27 (reserved)",
    "28 (reserved)",
    "29 (reserved)",
    "30 (reserved)",
    "31 (reserved)",
};
@ 

\section{[[trap()]] (x86)}

<<function _strayintr(x86)>>=
/*
 * Interrupt/exception handling.
 * Each entry in the vector table calls either _strayintr or _strayintrx depending
 * on whether an error code has been automatically pushed onto the stack
 * (_strayintrx) or not, in which case a dummy entry must be pushed before retrieving
 * the trap type from the vector table entry and placing it on the stack as part
 * of the Ureg structure.
 * The size of each entry in the vector table (6 bytes) is known in trapinit().
 */
TEXT _strayintr(SB), $0
        PUSHL   AX                      /* save AX */
        MOVL    4(SP), AX               /* return PC from vectortable(SB) */
        JMP     intrcommon
@


<<function _strayintrx(x86)>>=
TEXT _strayintrx(SB), $0
        XCHGL   AX, (SP)                /* swap AX with vectortable CALL PC */
intrcommon:
        PUSHL   DS                      /* save DS */
        PUSHL   $(KDSEL)
        POPL    DS                      /* fix up DS */
        MOVBLZX (AX), AX                /* trap type -> AX */
        XCHGL   AX, 4(SP)               /* exchange trap type with saved AX */

        PUSHL   ES                      /* save ES */
        PUSHL   $(KDSEL)
        POPL    ES                      /* fix up ES */

        PUSHL   FS                      /* save the rest of the Ureg struct */
        PUSHL   GS
        PUSHAL

        PUSHL   SP                      /* Ureg* argument to trap */
        CALL    trap(SB)
@ 

% todo: [[Cpu]] debugging fields?
<<[[Cpu]] other fields>>=
int lastintr; // debugging
@

<<function trap(x86)>>=
/*
 *  All traps come here.  It is slower to have all traps call trap()
 *  rather than directly vectoring the handler. However, this avoids a
 *  lot of code duplication and possible bugs. The only exception is
 *  VectorSYSCALL.
 *  Trap is called with interrupts disabled via interrupt-gates.
 */
//@Scheck: not dead, called from assembly by _strayintr
void trap(Ureg* ureg)
{
    bool clockintr;
    bool user;
    int i, vno;
    char buf[ERRMAX];
    Vctl *ctl, *v;
    Cpu *mach;

    if(!trapinited){
        /* fault386 can give a better error message */
        if(ureg->trap == VectorPF)
            fault386(ureg, nil);
        panic("trap %lud: not ready", ureg->trap);
    }

    cpu->perf.intrts = arch_perfticks();

    user = (ureg->cs & 0xFFFF) == UESEL; // TODO: arch_userureg

    if(user){
        up->dbgreg = ureg;
        <<[[trap()]] adjust kentry when interrupt user(x86)>>
    }
    // else if !user, then that means we interrupted a syscall() which should
    // already have done those things, so no need for redundancy

    clockintr = false;

    vno = ureg->trap;
    if(ctl = vctl[vno]){
        if(ctl->isintr){
            cpu->intr++;
            if(vno >= VectorPIC && vno != VectorSYSCALL)
                cpu->lastintr = ctl->irq;
        }

        if(ctl->isr)
            ctl->isr(vno);
        for(v = ctl; v != nil; v = v->next){
            if(v->f) // this can be null?
                v->f(ureg, v->a);
        }
        if(ctl->eoi)
            ctl->eoi(vno);

        if(ctl->isintr){
            intrtime(cpu, vno);

            if(ctl->irq == IrqCLOCK || ctl->irq == IrqTIMER)
                clockintr = true;

            if(up && !clockintr)
                preempt();
        }
    } // no Vctl?
    else if(vno < nelem(excname) && user){
        arch_spllo();
        snprint(buf, sizeof buf, "sys: trap: %s", excname[vno]);
        postnote(up, 1, buf, NDebug);
    }
    else if(vno >= VectorPIC && vno != VectorSYSCALL){
        /*
         * An unknown interrupt.
         * Check for a default IRQ7. This can happen when
         * the IRQ input goes away before the acknowledge.
         * In this case, a 'default IRQ7' is generated, but
         * the corresponding bit in the ISR isn't set.
         * In fact, just ignore all such interrupts.
         */

        /* call all interrupt routines, just in case */
        for(i = VectorPIC; i <= MaxIrqLAPIC; i++){
            ctl = vctl[i];
            if(ctl == nil)
                continue;
            if(!ctl->isintr)
                continue;
            for(v = ctl; v != nil; v = v->next){
                if(v->f)
                    v->f(ureg, v->a);
            }
            /* should we do this? */
            if(ctl->eoi)
                ctl->eoi(i);
        } // remove? ugly?

        /* clear the interrupt */
        i8259isr(vno);
        <<[[trap()]] debugging(x86)>>
        cpu->spuriousintr++;
        if(user)
            kexit(ureg);
        return;
    }else{
        if(vno == VectorNMI){
            /*
             * Don't re-enable, it confuses the crash dumps.
            nmienable();
             */
            iprint("cpu%d: NMI PC %#8.8lux\n", cpu->cpuno, ureg->pc);
            while(cpu->cpuno != 0)
                ;
        }
        dumpregs(ureg);
        if(!user){
            ureg->sp = (ulong)&ureg->sp;
            _dumpstack(ureg);
        }
        if(vno < nelem(excname))
            panic("%s", excname[vno]);
        panic("unknown trap/intr: %d", vno);
    }
    arch_splhi(); // possible arch_spllo() done above

    <<[[trap()]] if delaysched(x86)>>

    if(user){
        if(up->procctl || up->nnote)
            notify(ureg);
        kexit(ureg);
    }
}
@ 

<<function kexit(x86)>>=
/* go to user space */
void
kexit(Ureg*)
{
    <<[[kexit()]] tos adjustments(x86)>>
}
@ 
% should be called hook_before_exit_syscall note that
% take Ureg*, so the address is in the stack and the actual
% value are where?


% ---------------------------------------------------------------------------


\ifallcode
<<[[trap()]] debugging(x86)>>=
        if(0)print("cpu%d: spurious interrupt %d, last %d\n",
            cpu->cpuno, vno, cpu->lastintr);
        if(0)if(conf.ncpu > 1){
            for(i = 0; i < MAXCPUS; i++){
                if(!(active.cpus & (1<<i)))
                    continue;
                mach = CPUS(i);
                if(cpu->cpuno == mach->cpuno)
                    continue;
                print(" cpu%d: last %d",
                    mach->cpuno, mach->lastintr);
            }
            print("\n");
        }
@
\fi




\section{[[syscall()]] (x86)}
%Software interrupts (a.k.a syscalls)

<<enum vector cases(x86)>>=
    //!!! int 64, or int 0x40 = way to jump in plan9 OS !!!
    // VectorSYSCALL = 64, in mem.h because used by Assembly too
@


<<constant MAXSYSARG>>=
#define MAXSYSARG  5 /* for mount(fd, afd, mpt, flag, arg) */
@
% used to be arch specific, but same value in every arch

<<struct Sargs>>=
// syscall arguments copied from user stack
struct Sargs
{
    ulong args[MAXSYSARG];
};
@ 

<<[[Proc]] other fields>>=
Sargs sargs;    /* address of this is known by db */
@ 
%old: s -> sargs


<<function _syscallintr(x86)>>=
/*
 * This is merely _strayintr from l.s optimised to vector
 * to syscall() without going through trap().
 */
TEXT _syscallintr(SB), $0
        PUSHL   $VectorSYSCALL                  /* trap type */

        PUSHL   DS
        PUSHL   ES
        PUSHL   FS
        PUSHL   GS
        PUSHAL
        MOVL    $(KDSEL), AX
        MOVW    AX, DS
        MOVW    AX, ES
        PUSHL   SP
        CALL    syscall(SB)

        POPL    AX
        POPAL
        POPL    GS
        POPL    FS
        POPL    ES
        POPL    DS
        ADDL    $8, SP                          /* pop error code and trap type */
        IRETL
@ 

<<function syscall(x86)>>=
/*
 *  Syscall is called directly from assembler without going through trap().
 */
//@Scheck: not dead, called from assembly by _syscallintr
void syscall(Ureg* ureg)
{
    char *e;
    ulong   sp;
    long    ret;
    int i, s;
    ulong scallnr;
    vlong startns, stopns;

    if((ureg->cs & 0xFFFF) != UESEL) // TODO: arch_userureg
        panic("syscall: cs 0x%4.4luX", ureg->cs);

    <<[[syscall()]] adjust kentry(x86)>>

    cpu->syscall++;
    up->insyscall = true;

    up->pc = ureg->pc;
    up->dbgreg = ureg;
    sp = ureg->usp;

    // syscall number!
    scallnr = ureg->ax;

    <<[[syscall()]] Proc_tracesyscall if, syscall entry(x86)>>

    <<[[syscall()]] fp adjustments if fork(x86)>>
    arch_spllo();

    up->nerrlab = 0;
    ret = -1;

    if(!waserror()){
        if(scallnr >= nsyscall || systab[scallnr] == nil){
            pprint("bad sys call number %lud pc %lux\n",
                scallnr, ureg->pc);
            postnote(up, 1, "sys: bad sys call", NDebug);
            error(Ebadarg);
        }

        if(sp<(USTKTOP-BY2PG) || sp>(USTKTOP-sizeof(Sargs)-BY2WD)) // adjust Tos ?
            validaddr(sp, sizeof(Sargs)+BY2WD, false);

        // copy syscall arguments from user stack to up->sargs
        up->sargs = *((Sargs*)(sp+BY2WD)); // 1 word for? return pc?
        up->psstate = sysctab[scallnr];

        //!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
        //IMPORTANT: The actual system call
        ret = systab[scallnr](up->sargs.args);
        //!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

        poperror();
    }else{
        /* failure: save the error buffer for errstr */
        e = up->syserrstr;
        up->syserrstr = up->errstr;
        up->errstr = e;
    }

    if(up->nerrlab){
        print("bad errstack [%lud]: %d extra\n", scallnr, up->nerrlab);
        for(i = 0; i < NERR; i++)
            print("sp=%lux pc=%lux\n",
                up->errlab[i].sp, up->errlab[i].pc);
        panic("error stack");
    }

    /*
     *  Put return value in frame.  On the x86 the syscall is
     *  just another trap and the return value from syscall is
     *  ignored.  On other machines the return value is put into
     *  the results register by caller of syscall.
     */
    ureg->ax = ret;

    <<[[syscall()]] Proc_tracesyscall if, syscall exit(x86)>>

    up->insyscall = false;
    up->psstate = nil;

    <<[[syscall()]] call noted()(x86)>>
    <<[[syscall()]] call notify()(x86)>>

    <<[[syscall()]] if delaysched(x86)>>
    kexit(ureg);
}
@ 
%        //if(0 && up->pid == 1)
%        //    print("syscall %lud error %s\n", scallnr, up->syserrstr);

<<function userpc(x86)>>=
/*
 *  return the userpc the last exception happened at
 */
ulong
arch_userpc(void)
{
    Ureg *ureg;

    ureg = (Ureg*)up->dbgreg;
    return ureg->pc;
}
@ 

\chapter{Virtual Memory}
% rename x86 virtual memory? but now that have swapping and demand loading
% sections here, it makes less sense to rename.
% less: could add (page fault) in title to relate to Interrupt chapter

\section{Overview}

% What a system would look like (including for a programmer) without Virtual mem?
% Virtual memory, via the indirection trick, enables many many things:
% - isolated processes, safer! (see DOS ...) a malicious/buggy process can't harm
% - can access more than physical, hence virtual in some sense, swapping
% - sharing optimization: shared text pages, but also in fork copy on write
% - lazy optimization: can have demand loading
% - easier for loading programs, no need relocation, they all start at 0
% - ??

% segmentation + pagination on intel, but like most OS, pagination
% offers most of the advantages so less need segmentation once use
% pagination. Will use segmentation only for security to differentiate
% kernel vs user.

% kernel and user in same virtual space (user then vpt then kernel), so
% convenient, kernel need access user data: syscall have arguments
% that can point to user area that we will need to read/modify.

% what a system with only segmentation? can do a lot too.
% what a system with only pagination? can do security kernel vs user with this?

\section{Segmentation and [[gdt]] (x86)}

% see Basic segmentation intialization section too

% use segments mostly for security, for kernel vs user different
% level. CS will contain a selector in gdt (user can't change
% CS?) with gdt describe ring.

% could be an enum, but has to be used from assembly too
<<constant x86 segments>>=
/*
 *  known x86 segments (in GDT) and their selectors
 */
#define NULLSEG 0 /* null segment */
#define KDSEG 1 /* kernel data/stack */
#define KESEG 2 /* kernel executable */ 
#define UDSEG 3 /* user data/stack */
#define UESEG 4 /* user executable */
#define TSSSEG  5 /* task segment */
<<constant x86 other segments>>
#define NGDT    10  /* number of GDT entries required */
@

% will do MOVE XXSEG, AX; MOVE AX, ES
% can't do MOVE AX, CS, for that we do jmp XXSEG:ADDR
% actually will use XXSEL, not XXSEG, see below

% also used for IDT
<<struct Segdesc(x86)>>=
struct Segdesc
{
    ulong d0; // ??
    ulong d1; // ??
};
@ 
% rename, first is size and second is flag

% #define ring0, ring3? instead of 0 and 3 below?


<<constant segment field extractors(x86)>>=
/*
 *  fields in segment descriptors
 */
#define SEGDATA (0x10<<8) /* data/stack segment */
#define SEGEXEC (0x18<<8) /* executable segment */
#define SEGTSS  (0x9<<8)  /* TSS segment */
//#define SEGCG (0x0C<<8) /* call gate */
#define SEGIG (0x0E<<8) /* interrupt gate */
//#define SEGTG (0x0F<<8) /* trap gate */

//#define SEGTYPE (0x1F<<8)

#define SEGP  (1<<15)   /* segment present */

#define SEGPL(x) ((x)<<13)  /* priority level */

#define SEGB  (1<<22)   /* granularity 1==4k (for expand-down) */
#define SEGG  (1<<23)   /* granularity 1==4k (for other) */
//#define SEGE  (1<<10)   /* expand down */

#define SEGW  (1<<9)    /* writable (for data/stack) */
#define SEGR  (1<<9)    /* readable (for code) */

#define SEGD  (1<<22)   /* default 1==32bit (for code) */
@



<<global gdt(x86)>>=
Segdesc gdt[NGDT] =
{
[NULLSEG]   { 0, 0},        /* null descriptor */
[KDSEG]     DATASEGM(0),        /* kernel data/stack */
[KESEG]     EXECSEGM(0),        /* kernel code */
[UDSEG]     DATASEGM(3),        /* user data/stack */
[UESEG]     EXECSEGM(3),        /* user code */
[TSSSEG]    TSSSEGM(0,0),       /* tss segment */
<<[[gdt]] other elements(x86)>>
};
@
% copied in cpu->gdt (at CPU0GDT addresS) in mmuinit0
% speaks about user! as opposed to the more basic tgdt in _setup_segmentation

<<macros xxxSEGM(x86)>>=
/*
 * Simple segment descriptors with no translation.
 */
#define DATASEGM(p) { 0xFFFF, SEGG|SEGB|(0xF<<16)|SEGP|SEGPL(p)|SEGDATA|SEGW }
#define EXECSEGM(p) { 0xFFFF, SEGG|SEGD|(0xF<<16)|SEGP|SEGPL(p)|SEGEXEC|SEGR }
#define TSSSEGM(b,p) { ((b)<<16)|sizeof(Tss),\
                   ((b)&0xFF000000)|(((b)>>16)&0xFF)|SEGTSS|SEGPL(p)|SEGP }
<<macros other xxxSEGM(x86)>>
@
% maybe could define redundant C structure with bitfield to make
% this clearer. kencc supports bitfield? but has to be used from asm too no?





<<[[Cpu]] [[Arch]] other fields(x86)>>=
// array<Segdesc>
Segdesc *gdt;     /* gdt for this processor */
@

% CPU0GDT? and the other? mostly similar, just the 
% TSS change I think. Why use TSS?


<<constant x86 segment selectors>>=
//#define NULLSEL SELECTOR(NULLSEG, SELGDT, 0)
#define KDSEL SELECTOR(KDSEG, SELGDT, 0)
#define KESEL SELECTOR(KESEG, SELGDT, 0)
#define UESEL SELECTOR(UESEG, SELGDT, 3)
#define UDSEL SELECTOR(UDSEG, SELGDT, 3)
#define TSSSEL  SELECTOR(TSSSEG, SELGDT, 0)
<<constant x86 other segment selectors>>
@
% why need that?

<<function userureg(x86)>>=
//#define userureg(ur) (((ur)->cs & 0xFFFF) == UESEL)
int
arch_userureg(Ureg* ur)
{
  return (((ur)->cs & 0xFFFF) == UESEL);
}
@
% ->cs, see Ureg in x86 section in overview chapter
%todo: could be used at more places actually



<<constant SELGDT(x86)>>=
#define SELGDT  (0<<2)  /* selector is in gdt */
@

<<macro SELECTOR(x86)>>=
#define SELECTOR(idx, type, prio) (((idx)<<3) | (type) | (prio))
@

% could put code of tgdt of initialization here? but the real gdt
% is the one above, the tgdt is just used at the beginning

\section{Pagination and [[mmupd]], [[mmupt]] (x86)} 
%http://wiki.osdev.org/Paging

% see Basic pagination intialization too

% different levels:
%  tlb, mmupd, mmupt
%  Segment itself have pagedir, pagetab,
%  and cpu have pdproto, and proc avec mmupd ... very complex.

% glossary: 
% PD (page directory), PDE (page directory entry), PDX (page directory idx)
% PT (page table),     PTE (page table entry),     PTX (page table index)

% page, 4096, so when give page address, don't need 12 low bits! PGSHIFT
% PGSHIFT here?

% each time switch process, they have different segments, and
% different pages they use, so will need to empty tlb and
% reassign based on per-process info?

% sections: MMUPD section (=~ Segment), MMUPT section (=~ Pagetable)

% properties of 1 page, 1 byte
% PTE = page table entry, so spec about one page (also for entries in PD)
<<constant PTExxx(x86)>>=
/*
 *  physical MMU
 */
#define PTEVALID  (1<<0)

#define PTEWRITE  (1<<1)
#define PTERONLY  (0<<1)

// x86 specific constants
//#define PTEKERNEL (0<<2)
#define PTEUSER   (1<<2)

#define PTEWT       (1<<3) // Write Through, e.g. VGA memory, mean??
#define PTEUNCACHED (1<<4) // ??
#define PTESIZE   (1<<7) // Big pages (x86 extension)
#define PTEGLOBAL (1<<8) // do not clear from TLB kernel pages (x86 extension)
@
% pa is aligned at page, so can use low 12 bytes hence 1<<8
% in a PTE what is implicit is the va. the va is the index
% in the PD (Page Directory) + index in the PT (Page table)

% PTESIZE is used to say this entry actually maps a big page (4Mo, not 4Ko)
% but is used only for vmap mapping

% how set 1-to-1 mapping for KZERO and more?

% complicated to access to physical memory if have lots of memory :)
% so let's first do a simple version? see advanced memory chapter for more



% on tmpmap, tmpunmap. For now assume just alias to XXX
% on arch_kmap, arch_kunmap, VA. Assume alias to XXX.
% see Advanced memory chapter for the actual definitions when
% have machine with lots of memory where MAXKPA is not enough
% and so can't just do KADDR(page->pa) to get a virtual address
% when can access the content of a physical page.




%pd is always cpu->pdproto so a kern_addr.
% returns something created by xpanalloc so return a kern_addr too.
<<function mmuwalk(x86)>>=
/*
 * Walk the page-table pointed to by pd and return a pointer
 * to the entry for virtual address va at the requested level.
 * If the entry is invalid and create isn't requested then bail
 * out early. Otherwise, for the 2nd level walk, allocate a new
 * page-table page and register it in the 1st level.  This is used
 * only to edit kernel mappings, which use pages from kernel memory,
 * so it's okay to use KADDR to look at the tables.
 */
kern_addr2
mmuwalk(kern_addr2 pd, kern_addr va, int level, bool create)
{
    ulong *table;
    void *map;

    table = &pd[PDX(va)];
    if(!(*table & PTEVALID) && create == false)
        return nil;

    switch(level){
    default:
        return nil; //todo: panic? invalid value no?
    case 1:
        return table;
    case 2:
        if(*table & PTESIZE)
            panic("mmuwalk2: va %luX entry %luX", va, *table);
        if(!(*table & PTEVALID)){
            /*
             * Have to call low-level allocator from
             * memory.c if we haven't set up the xalloc
             * tables yet.
             */
            if(didmmuinit)
                map = xspanalloc(BY2PG, BY2PG, 0);
            else
                map = rampage();  //when called from meminit()
            if(map == nil)
                panic("mmuwalk xspanalloc failed");
            *table = PADDR(map)|PTEWRITE|PTEVALID;
        }
        table = KADDR(PPN(*table));
        return &table[PTX(va)];
    }
}
@
% s/table/pde_or_pte/?




<<[[Cpu]] [[Arch]] other fields(x86)>>=
kern_addr2   pdproto;      /* page directory base for this processor (va) */
@
% this pd is super important!! see arch_mmuswitch, he's the one
% that will map specially the CPUADDR for each CPU!
% it is actually a prototype that is copied in the mmupagedir of each
% new process

<<[[Cpu]] [[Arch]] other fields(x86)>>=
Page* mmupdpool;
int mmupdcnt;
@
%// TODO: have a Arch_CpuMMU like in bcm/
% mv later? when used? opti to not wait for newpage()


% pointers in kern_addr? no! but the page->pa there is real mem.
<<[[Proc]] [[Arch]] memory fields(x86)>>=
Page* mmupd;     /* page directory base */
@

<<[[Proc]] [[Arch]] memory fields(x86)>>=
// type? list<ref<?? > >
Page* mmufree;    /* unused page table pages */
Page* mmuused;    /* used page table pages */
@
% rename! mmupt_used, mmupt_free?
% so mmu release should release mmupd and those pages

<<function upallocmmupd(x86)>>=
/*
 * Allocate and install pd for the current process.
 */
static void
upallocmmupd(void)
{
    int s;
    kern_addr2 mmupd;
    Page *page;
    
    if(up->mmupd != nil)
        return;
    page = mmupdalloc();
    s = arch_splhi();
    if(up->mmupd != nil){
        /*
         * Perhaps we got an interrupt while
         * mmupdalloc was sleeping and that
         * interrupt allocated an mmupd?
         * Seems unlikely.
         */
        mmupdfree(up, page);
        arch_splx(s);
        return;
    }
    mmupd = tmpmap(page);
    mmupd[PDX(CPUADDR)] = cpu->pdproto[PDX(CPUADDR)]; // for up
    tmpunmap(mmupd);
    up->mmupd = page;
    putcr3(up->mmupd->pa); //!!!! bootstrap! putcr3 take a PA of course
    arch_splx(s);
}
@



%ctor
<<function mmupdalloc(x86)>>=
/*
 * Allocate a new page for a page directory.
 * We keep a small cache of pre-initialized
 * page directories in each cpu (see mmupdfree).
 */
static Page*
mmupdalloc(void)
{
    int s;
    Page *page;
    kern_addr2 mmupd;

    s = arch_splhi();
    cpu->mmupdalloc++;
    if(cpu->mmupdpool == nil){
        arch_spllo();
        page = newpage(false, nil, nilptr);
        arch_splhi();
        mmupd = tmpmap(page);
        memmove(mmupd, cpu->pdproto, BY2PG);
        <<[[mmupdalloc()]] vpt adjustments(x86)>>
        tmpunmap(mmupd);
    }else{
        page = cpu->mmupdpool;
        cpu->mmupdpool = page->next;
        cpu->mmupdcnt--;
    }
    arch_splx(s);
    return page;
}
@
% why not using kernel memory for that? after all use kernel memory
% for Segment and Pagetable
% how sure what is put back in the mmupdpool has virgin mapping?
% because of arch_mmurelease?


%dtor
<<function mmupdfree(x86)>>=
static void
mmupdfree(Proc *proc, Page *page)
{
    if(arch_islo())
        panic("mmupdfree: arch_islo");
    cpu->mmupdfree++;
    if(cpu->mmupdcnt >= 10){ // 10??? keep small cache of mmupd page, but not too big, don't want to eat too much memory for that.
        page->next = proc->mmufree;
        proc->mmufree = page;
    }else{
        page->next = cpu->mmupdpool;
        cpu->mmupdpool = page;
        cpu->mmupdcnt++;
    }
}
@
% but the Page is a pd that have all entries correct? who initialize it?
% it has the good entries for the mapping of the kernel, but before KZERO?
% assumes have called mmuptefree before I think in arch_mmurelease





%dtor
<<function mmuptefree(x86)>>=
/*
 * A user-space memory segment has been deleted, or the
 * process is exiting.  Clear all the pde entries for user-space
 * memory mappings and device mappings.  Any entries that
 * are needed will be paged back in as necessary.
 */
static void
mmuptefree(Proc* proc)
{
    int s;
    kern_addr2 mmupd;
    Page **last, *page;

    if(proc->mmupd == nil || proc->mmuused == nil)
        return; // panic? bug to be called with that?

    s = arch_splhi();
    mmupd = tmpmap(proc->mmupd);
    last = &proc->mmuused;
    for(page = *last; page; page = page->next){
        mmupd[page->daddr] = 0; //???? use daddr??
        last = &page->next;
    }
    tmpunmap(mmupd);
    arch_splx(s);
    *last = proc->mmufree;
    proc->mmufree = proc->mmuused;
    proc->mmuused = nil;
}
@


<<function mmurelease(x86)>>=
/*
 * Release any pages allocated for a page directory or page-tables
 * for this process:
 *   switch to the prototype pd for this processor (cpu->pdproto);
 *   call mmuptefree() to place all pages used for page-tables (proc->mmuused)
 *   onto the process' free list (proc->mmufree). This has the side-effect of
 *   cleaning any user entries in the pdb (proc->mmupd);
 *   if there's a pd put it in the cache of pre-initialised pd's
 *   for this processor (cpu->mmupdpool) or on the process' free list;
 *   finally, place any pages freed back into the free pool (palloc).
 * This routine is only called from schedinit() with palloc locked.
 */
void
arch_mmurelease(Proc* proc)
{
    Page *page, *next;

    if(arch_islo())
        panic("arch_mmurelease: arch_islo");
    taskswitch(PADDR(cpu->pdproto), (ulong)cpu + BY2PG);


    <<[[mmurelease()]] handle kmaptable(x86)>>

    if(proc->mmupd){
        mmuptefree(proc);
        mmupdfree(proc, proc->mmupd);
        proc->mmupd = nil;
    }
    for(page = proc->mmufree; page; page = next){
        next = page->next;
        if(--page->ref)
            panic("arch_mmurelease: page->ref %d", page->ref);
        pagechainhead(page);
    }
    if(proc->mmufree && palloc.freememr.p)
        wakeup(&palloc.freememr);
    proc->mmufree = nil;
}
@


% this is the fundamental operation, put earlier?
% can some of the code here generate itself a fault?
<<function putmmu(x86)>>=
/*
 * Update the mmu in response to a user fault.  pa may have PTEWRITE set.
 */
void
arch_putmmu(virt_addr va, ulong mmupte, Page*)
{
    int old;
    Page *page;
    kern_addr2 mmupd;
    kern_addr2 mmupt;

    if(up->mmupd == nil)
        upallocmmupd();
    <<[[putmmu()]] adjustments(x86)>>
}
@

<<[[putmmu()]] adjustments(x86)>>=
// pad's code for simplified virtual memory, no VPT
mmupd = KADDR(up->mmupd->pa);
if(!(mmupd[PDX(va)]&PTEVALID)) {
    if(up->mmufree == nil){
        arch_spllo();
        page = newpage(false, nil, nilptr);
        arch_splhi();
    }
    else{
        page = up->mmufree;
        up->mmufree = page->next;
    }
    mmupd[PDX(va)] = PPN(page->pa)|PTEUSER|PTEWRITE|PTEVALID;
    mmupt = KADDR(page->pa);
    memset(mmupt, 0, BY2PG);
    page->daddr = PDX(va); // ???
    page->next = up->mmuused;
    up->mmuused = page;
}
mmupt = KADDR(PPN(mmupd[PDX(va)]));
old = mmupt[PTX(va)];
mmupt[PTX(va)] = mmupte|PTEUSER|PTEVALID;

if(old&PTEVALID)
    flushpg(va);
if(getcr3() != up->mmupd->pa)
     print("bad cr3 %#.8lux %#.8lux\n", getcr3(), up->mmupd->pa);
@
% there are called to newpage, so use user memory for pagedir/pagetable
% of process, which kinda make sense, but is it dangerous? can those
% pages containing pagedir/pagetable data be swapped out? No because
% the swapping procedure iterate over the pages used by segments of
% processes, not on pages in Proc->mmupd or Proc->mmused. So it's safe.




<<[[Proc]] memory fields>>=
bool newtlb;   /* Pager has changed my pte's, I must flush */
@ 

<<function flushmmu(x86)>>=
/*
 * Flush all the user-space and device-mapping mmu info
 * for this process, because something has been deleted.
 * It will be paged back in on demand.
 */
void
arch_flushmmu(void)
{
    int s;

    s = arch_splhi();
    up->newtlb = true;
    arch_mmuswitch(up);
    arch_splx(s);
}
@


<<function flushpg(x86)>>=
/*
 * Flush a single page mapping from the tlb.
 */
void
flushpg(virt_addr va)
{
    if(X86FAMILY(cpu->cpuidax) >= 4)
        invlpg(va);
    else
        putcr3(getcr3());
}
@



\section{Page fault (x86)}

% see also trapinit

% insyscall saving? means can have trap in a syscall itself?

% addr be kernel (virtual) address or user (virtual) address?
% can it be kernel address? I don't think so. should panic in that case
% at least to understand.

<<function fault386>>=
static void
fault386(Ureg* ureg, void*)
{
    virt_addr addr; 
    bool read, insyscall, user;
    int n; // ret_code
    char buf[ERRMAX];

    addr = getcr2(); // faulting va
    read = !(ureg->ecode & 2);
    user = (ureg->cs & 0xFFFF) == UESEL;

    if(!user){
        if(vmapsync(addr))
            return;
        if(addr >= USTKTOP)
            panic("kernel fault: bad address pc=0x%.8lux addr=0x%.8lux", ureg->pc, addr);
        if(up == nil)
            panic("kernel fault: no user process pc=0x%.8lux addr=0x%.8lux", ureg->pc, addr);
    }
    if(up == nil)
        panic("user fault: up=0 pc=0x%.8lux addr=0x%.8lux", ureg->pc, addr);

    insyscall = up->insyscall;
    up->insyscall = true; // really?

    n = fault(addr, read); // portable code

    if(n < 0){
        if(!user){
            dumpregs(ureg);
            panic("fault: 0x%lux", addr);
        }
        checkpages();
        //checkfault(addr, ureg->pc);
        snprint(buf, sizeof buf, "sys: trap: fault %s addr=0x%lux",
            read ? "read" : "write", addr);
        postnote(up, 1, buf, NDebug);
    }
    up->insyscall = insyscall;
}
@ 
% LP split hide error managment code in first pass


% ret_code2?
<<function fault>>=
int
fault(virt_addr addr, bool read)
{
    Segment *s;
    char *sps;

    if(up == nil)
        panic("fault: nil up");
    if(up->nlocks.ref)
        print("fault: addr %#p: nlocks %ld\n", addr, up->nlocks.ref);

    sps = up->psstate;
    up->psstate = "Fault";
    arch_spllo();

    cpu->pfault++;
    for(;;) {
        s = seg(up, addr, /*dolock*/true); /* leaves s->lk qlocked if seg != nil */
        if(s == nil) {
            up->psstate = sps;
            return -1;
        }
        if(!read && (s->type&SG_RONLY)) {
            qunlock(&s->lk);
            up->psstate = sps;
            return -1;
        }

        if(fixfault(s, addr, read, /*putmmu*/true) == 0) /* qunlocks s->lk */
            break;

        // else? try again?
    }

    up->psstate = sps;
    return 0;
}
@
% why loop?


% The big one! very important function!
%ret_code
<<function fixfault>>=
int
fixfault(Segment *s, virt_addr addr, bool read, bool doputmmu)
{
    int type;
    int ref;
    Pagetable **pde, *pt;
    Page **pte, *lkp, *new;
    ulong mmupte = nilptr;
    ulong soff;

    addr &= ~(BY2PG-1);
    soff = addr - s->base;

    // walk
    pde = &s->pagedir[soff/PAGETABMAPMEM];
    if(*pde == nil)
        *pde = ptalloc();
    pt = *pde;
    pte = &pt->pagetab[(soff&(PAGETABMAPMEM-1))/BY2PG];
    if(pte < pt->first)
        pt->first = pte;
    if(pte > pt->last)
        pt->last = pte;

    type = s->type&SG_TYPE;

    switch(type) {
    case SG_TEXT:           /* Demand load */
        <<[[fixfault()]] page in for SG_TEXT pte if pagedout>>

        mmupte = PPN((*pte)->pa) | PTERONLY|PTEVALID;
        (*pte)->modref = PG_REF;
        break;

    case SG_BSS:
    case SG_SHARED:         /* Zero fill on demand */
    case SG_STACK:
        if(*pte == nil) {
            new = newpage(true, &s, addr); // true so clear! zeroed BSS & heap!
            if(s == nil) //?? when can be nil at exit?
                return -1;
            *pte = new;
        }
        goto common;

    case SG_DATA:
    common:         /* Demand load/pagein/copy on write */
        <<[[fixfault()]] page in for SG_DATA or swapin (SG_BSS, etc) pte if pagedout>>

        <<[[fixfault()]] if read and copy on write, adjust mmupte and break>>

        lkp = *pte;

        lock(lkp);

        if(lkp->image == &swapimage)
            ref = lkp->ref + swapcount(lkp->daddr);
        else
            ref = lkp->ref;
        <<[[fixfault()]] if one ref and page has an image>>
        unlock(lkp);

        <<[[fixfault()]] if write and more than one ref then copy page>>

        mmupte = PPN((*pte)->pa) | PTEWRITE | PTEVALID;
        (*pte)->modref = PG_MOD|PG_REF;
        break;

    <<[[fixfault()]] SG_PHYSICAL case>>

    default:
        panic("fault");
        break;
    }
    qunlock(&s->lk);

    if(doputmmu)
        arch_putmmu(addr, mmupte, *pte);

    return 0; // OK
}
@





%-----------------------------------------------------------------------------

<<function checkpages>>=
void
checkpages(void)
{
    int checked;
    ulong addr, off;
    Pagetable *p;
    Page *pg;
    Segment **sp, **ep, *s;
    
    if(up == nil)
        return;

    checked = 0;
    // foreach(up->seg)
    for(sp=up->seg, ep=&up->seg[NSEG]; sp<ep; sp++){
        s = *sp;
        if(s == nil)
            continue;
        qlock(&s->lk);
        for(addr=s->base; addr<s->top; addr+=BY2PG){
            off = addr - s->base;
            p = s->pagedir[off/PAGETABMAPMEM];
            if(p == nil)
                continue;
            pg = p->pagetab[(off&(PAGETABMAPMEM-1))/BY2PG];
            if(pg == nil || pagedout(pg))
                continue;
            arch_checkmmu(addr, pg->pa);
            checked++;
        }
        qunlock(&s->lk);
    }
    print("%ld %s: checked %d page table entries\n", up->pid, up->text, checked);
}
@

<<function checkmmu(x86)>>=
/*
 * Double-check the user MMU.
 * Error checking only.
 */
void
arch_checkmmu(virt_addr va, phys_addr pa)
{
    if(up->mmupd == nil)
        return;
   USED(va); USED(pa);
    <<[[checkmmu()]] pd at pt check(x86)>>
}
@

\section{Copy on write}

<<[[Conf]] other fields>>=
bool copymode; /* 0 is copy on write, 1 is copy on reference */
@
% use enum?

<<[[fixfault()]] if read and copy on write, adjust mmupte and break>>=
/*
 *  It's only possible to copy on write if
 *  we're the only user of the segment.
 */
if(read && conf.copymode == false && s->ref == 1) {
    mmupte = PPN((*pte)->pa)|PTERONLY|PTEVALID;
    (*pte)->modref |= PG_REF;
    break;
}
@

<<[[fixfault()]] if write and more than one ref then copy page>>=
if(ref > 1){
    new = newpage(false, &s, addr);
    if(s == nil)
        return -1;
    *pte = new;
    copypage(lkp, *pte);
    putpage(lkp); //why??
}
@


% memmove? should be called memcopy no? also rename f -> src, t -> dst?
<<function copypage>>=
void
copypage(Page *f, Page *t)
{
    Arch_KMap *ks, *kd;

    ks = arch_kmap(f);
    kd = arch_kmap(t);
    memmove((void*)VA(kd), (void*)VA(ks), BY2PG);
    arch_kunmap(ks);
    arch_kunmap(kd);
}
@


\section{Page cache}
% less: mv in Memory section? but it's an optimisation that we can delay to explain.
% less: have a section Sharing? Text Sharing? put here all forms of Sharing? Kimage
% bad name, call it Text Data cache? Text Data Sharing? but it's used for many things

% When we load(pagein) a page from the Text of a binary, this page now
% contains a "cache" of a portion of a file. If we do another exec
% with the same binary  for instance if we have multiple independent instance
% of rc, then we don't want to load this page from disk again, we need to find 
% it back (and we also want to share this page). 
% Enter the "page cache". Same is true actually for the data section of a binary!
% (also when we free it we could actually put it in the tail of a queue)

% finally when we swap(pageout) a page, we plan to write it on the disk on
% the swap file, and then we can free this page and reuse it for something else.
% But it still contains the content of what will be soon in a file (the swapfile).
% As long as it has not been put on the disk and reallocated, it should be
% in the page cache. 
% (also when we free it we could actually put it in the tail of a queue.
% then if we need to load back from the swap(pagein), we can actually
% get it directly from the cache! hmmm but actually when we swap it's really
% because we need space, so this free page will be in the tail but not for long
% so the page cache is really useful only for the demand-loading and caching
% of TEXT and DATA I think)

% in the following they use the term pagedout to say been swapped or
% just set to nil to go back to demand load. So have func like
% pagepte() that can do different things.

%note1: if we fork we will have the sharing for free, but when run from rc then exec
%note2: note that also do sharing when exec via copy on write, but not for text

%cinap:
%"theres a kernel file cache for cached mounts (see the -C option),
%tho its broken in labs plan9.
%
%pages of executables are cached.
%
%the disk fileservers implement a buffer cache to avoid going to disk
%and do lazy writing out dirty filesystem blocks. (pad: devfs?)
%
%plan9 is a distributed system. the disk fileservers are really
%network fileservers. and the local kernel isnt the only 
%mutator so it cant invalidate the cache without going to
%the fileserver."

% note that different from buffer cache. This is just cache of page of
% executables.
%For real buffer cache see cache.c?? not really, plan9 is a distributed
% system so it's file server that have cache.


<<[[Page]] other fields>>=
// option<ref<Kimage>>
KImage  *image;     /* Associated binary image or swap image */
ulong daddr;      /* Disc address on image */
@
% use same thing image, for swap or executable?
% because for TEXT, no need to swap and better to use free mem
% for BSS than for TEXT because TEXT can be retrieved!
% actually for DATA at the beginning it can also be retrieved, but once
% modified you can't (hence the PG_MOD?)

% daddr is used temporarily also for swapping once we decided to swap out a page
% but still we have not done it; it takes time because of IO, so still need
% to be around. Once it has been written, it is freed and said to be
% in a "cache"; this will be an offet in a file (binary or swap) at 4096 boundaries


<<function pghash>>=
enum
{
    PGHLOG  = 9, // 2^9 = 512
    PGHSIZE = 1<<PGHLOG,  /* Page hash for image lookup */
};
#define pghash(daddr) palloc.hash[(daddr>>PGSHIFT)&(PGHSIZE-1)]
@
% why this hash function? should put Kimage also in the equation no?

<<[[Palloc]] other fields>>=
// hash<Page.daddr, ref<Page>> (next = Page.hash)>
Page  *hash[PGHSIZE];
Lock  hashlock;
@

<<[[Page]] extra fields>>=
// hash<daddr, ref<Page>> Palloc.hash
Page  *hash; /* Image hash chains */ 
@
% rename next? hashnext?

% note that a page can be used and in the page cache, or free and in the page cache



% assume p->daddr has been set and then call cachepage(p, image).
%todo: always called with a locked page too? do the !canlock trick and panic?
<<function cachepage>>=
void
cachepage(Page *p, KImage *i)
{
    Page **l; // list

    /* If this ever happens it should be fixed by calling
     * uncachepage instead of panic. I think there is a race
     * with pio in which this can happen. Calling uncachepage is
     * correct - I just wanted to see if we got here.
     */
    if(p->image)
        panic("cachepage");

    incref(i);
    lock(&palloc.hashlock);
    p->image = i;
    // add_hash(palloc.hash, p->daddr, p)
    l = &pghash(p->daddr);
    p->hash = *l;
    *l = p;
    unlock(&palloc.hashlock);
}
@
% who calls cachepage? when we load the page from disc in pio()


%!! find it back!
<<function lookpage>>=
Page *
lookpage(KImage *i, ulong daddr)
{
    Page *pg;

    lock(&palloc.hashlock);
    for(pg = pghash(daddr); pg; pg = pg->hash) {
        if(pg->image == i && pg->daddr == daddr) {
            unlock(&palloc.hashlock);

            lock(&palloc);
            lock(pg);
            if(pg->image != i || pg->daddr != daddr) { // race, not the one anymore
                unlock(pg);
                unlock(&palloc);
                return nil;
            }
            if(++pg->ref == 1)
                pageunchain(pg);
            unlock(&palloc);
            unlock(pg);

            return pg;
        }
    }
    unlock(&palloc.hashlock);

    return nil;
}
@
% who calls lookpage? before trying to load a page from disk in pio() look if
% it's already in the page cache!



% Moreover if we terminate an executable and so free all his pages, we may
% in the futur rerun this executable and so it would be profitable to put
% the pages corresponding to the text (or unmodified data) in the tail of
% the free pages and keep them im the cache!

<<[[putpage]] if p has an image>>=
if(p->image && p->image != &swapimage)
    pagechaintail(p);
@

<<[[newpage()]] uncachepage>>=
uncachepage(p);
@

<<function uncachepage>>=
/* Always called with a locked page */
void
uncachepage(Page *p)
{
    Page **l, *f;

    if(p->image == nil)
        return;

    lock(&palloc.hashlock);
    // remove_hash(palloc.hash, p->daddr, p)
    l = &pghash(p->daddr);
    for(f = *l; f; f = f->hash) {
        if(f == p) {
            *l = p->hash;
            break;
        }
        l = &f->hash;
    }
    unlock(&palloc.hashlock);
    putimage(p->image);
    p->image = nil;
    p->daddr = 0;
}
@



% used by pagepte(), the image is always a swapimage.
% different signature than uncachepage because for swap daddr we don't have
% like for Page the information contained in the Page so we must pass
% this information directly. but quite similar to uncachepage really.
% rename uncacheswapdaddr?
<<function cachedel>>=
void
cachedel(KImage *i, ulong daddr)
{
    Page *f, **l;

    lock(&palloc.hashlock);
    l = &pghash(daddr);
    for(f = *l; f; f = f->hash) {
        if(f->image == i && f->daddr == daddr) {
            lock(f);
            // can have a race? things could have changed, so rested under lock
            if(f->image == i && f->daddr == daddr){
                *l = f->hash;
                putimage(f->image); // =~ decref
                f->image = nil;
                f->daddr = 0;
            }
            unlock(f);
            break;
        }
        l = &f->hash;
    }
    unlock(&palloc.hashlock);
}
@




\section{Demand loading}
% and text/data sharing

% idea is to set to nil the PageOrSwap* entries in Pagetable or even
% to nil the Pagetable* entries in pagedir of Segment.
% then if segment is attached to an image (binary) then we load
% the page from the disk when there is a fault, on demand!

% KImage is demand loading and also a form of sharing so that 10 bash
% dont pay for it (nice opti, but still no shared libs, but less
% a pb because plan9 libs are small (and ld link only the object
% needed, and ld does some form of deadcode removal?)

\subsection{[[Kimage]] and the image cache}

<<struct KImage>>=
// a KImage is essentially a channel to an executable or swapfile
struct KImage
{
    Chan  *c;     /* channel to text file */
    bool  notext;     /* no file associated */ // for swapfile
    <<[[Kimage]] other fields>>
  
    // extra
    Ref;
    <<[[Kimage]] extra fields>>
};
@
% (renamed KImage to avoid name conflict with memdraw Image (picture) and avoid
%  ugly #define Image IMAGE each time one wants to use draw.h from a device driver)
% What is the point of this vs just having Chan? why need this wrapper?
% because for page cache we need to keep them around in a careful way?


%todo: invalidate Kimage when text changes?

<<struct Imagealloc>>=
// Image allocator (internal to segment.c, but important so here, singleton)
struct Imagealloc
{
    // hash<qid.path, ref<Kimage>> (next = Kimage.hash)
    KImage  *hash[IHASHSIZE];

    // list<ref<Kimage> (next = Kimage.next)
    KImage  *free; // originally  xalloc'ed in imageinit() (conf.nimage)
    QLock ireclaim; /* mutex on reclaiming free images */

    <<[[Imagealloc]] other fields>>
 
    // extra
    Lock;
};
@

<<[[Kimage]] extra fields>>=
// list<ref<Kimage>> of Imagealloc.free
KImage  *next; /* Free list */ 
// hash<qid.path, ref<Kimage>> Imagealloc.hash
KImage  *hash; /* Qid hash chains */ 
@

<<function ihash>>=
#define IHASHSIZE 64
// actually internal to page.c, but important so here
#define ihash(qidpath)  imagealloc.hash[qidpath%IHASHSIZE]
@
% why not use the XXXLOG like the other hashes?

<<global imagealloc>>=
static struct Imagealloc imagealloc;
@


\subsection{[[Segment]] and [[KImage]]}

<<[[Segment]] other fields>>=
KImage  *image;   /* text in file attached to this segment */
@


<<[[Kimage]] extra fields>>=
// option<ref<Segment>>?
Segment *s;     /* TEXT segment for image if running */
@
%rename? textseg? nul for swapimage
% the segment attached to an image will be shared so should be the same
% everytime. Note that not have always seg->image->s == seg because
% for DATA we just keep the seg->image link (for demand loading)


% ctor
% called by sysexec(), returns a locked img that will then be assigned to a segment
% always called with SG_TEXT; SG_DATA is handled differently.
<<constructor attachimage>>=
KImage*
attachimage(int type, Chan *c, virt_addr base, ulong len)
{
    KImage *img, **l;

    /* reclaim any free channels from reclaimed segments */
    if(imagealloc.nfreechan)
        imagechanreclaim();

    lock(&imagealloc);

    /*
     * Search the image cache for remains of the text from a previous
     * or currently running incarnation
     */
    for(img = ihash(c->qid.path); img; img = img->hash) {
        if(c->qid.path == img->qid.path) {
            lock(img);
            if(eqqid(c->qid, img->qid) &&
               eqqid(c->mqid, img->mqid) &&
               c->mchan == img->mchan &&
               c->type == img->type) {
                goto found;
            }
            unlock(img);
        }
    }

    /*
     * imagereclaim dumps pages from the free list which are cached by image
     * structures. This should free some image structures.
     */
    while(!(img = imagealloc.free)) {
        unlock(&imagealloc);
        imagereclaim();
        sched();
        lock(&imagealloc);
    }

    imagealloc.free = img->next;

    lock(img);
    incref(c);
    img->c = c;
    img->type = c->type;
    img->qid = c->qid;
    img->mqid = c->mqid;
    img->mchan = c->mchan;
    //add_hash(imagealloc.hash, c->qid.path, img)
    l = &ihash(c->qid.path);
    img->hash = *l;
    *l = img;

found:
    unlock(&imagealloc);

    if(img->s == nil) {
        /* Disaster after commit in exec */
        if(waserror()) {
            unlock(img);
            pexit(Enovmem, /*freemem*/true);
        }
        img->s = newseg(type, base, len);
        img->s->image = img;
        img->ref++;
        poperror();
    }
    else
        incref(img->s);

    return img;
}
@

<<[[Kimage]] other fields>>=
Qid   qid;      /* Qid for page cache coherence */
Chan  *mchan;
Qid   mqid;
ushort  type;     /* Device type of owning channel */
@
% mostly inline of properties of chan Kimage.c no?



% code if exec() related to attachimage here?

<<[[Segment]] other fields>>=
ulong fstart;   /* start address in file for demand load */
ulong flen;   /* length of segment in file */
@
% should get info from a.out header for size of Text or Data.

<<[[sysexec()]] locals>>=
KImage *img;
@

<<[[sysexec()]] get text segment ts via demand loading on tc>>=
    /* attachimage returns a locked cache image */
    img = attachimage(SG_TEXT|SG_RONLY, tc, UTZERO, (t-UTZERO)>>PGSHIFT);
    ts = img->s;
    ts->flushme = true;
    ts->fstart = 0;
    ts->flen = sizeof(Exec)+text;
    unlock(img);
@
% the up->seg[TSEG] = ts used to be inslide the lock, but I don't think
% it matters

<<[[sysexec()]] adjust data segment s for demand loading on tc>>=
/* Attached by hand */
incref(img);
s->image = img;
s->fstart = ts->fstart+ts->flen;
s->flen = data;
// data is also in binary
@


<<[[dupseg()]] SG_DATA case, attach image to new segment n>>=
incref(s->image); // how sure non nil? data always attached to an img
n->image = s->image;
n->fstart = s->fstart;
n->flen = s->flen;
@
% for SG_TEXT it was sameseg and so was shared (with its image)

\subsection{Paging in}

<<function pagedout>>=
#define pagedout(s) (((ulong)s)==0 || onswap(s))
@
% demand loading or on swap


<<[[fixfault()]] page in for SG_TEXT pte if pagedout>>=
if(pagedout(*pte))
    pio(s, addr, soff, pte);
@

<<[[fixfault()]] page in for SG_DATA or swapin (SG_BSS, etc) pte if pagedout>>=
if(pagedout(*pte))
    pio(s, addr, soff, pte);
@



% called by fixfault
% actually p is more SwapOrNil than PageOrSwap
<<function pio>>=
void
pio(Segment *s, virt_addr addr, ulong soff, PageOrSwap **p)
{
    Page *new;
    Arch_KMap *k;
    Chan *c;
    int n, ask;
    char *kaddr;
    ulong daddr; // disk address
    Page *loadrec;

retry:
    loadrec = *p;

    if(loadrec == nil) {  /* from a text/data image */
        daddr = s->fstart+soff;
        new = lookpage(s->image, daddr);
        if(new != nil) {
            *p = new;
            return;
        }

        c = s->image->c;
        ask = s->flen-soff;
        if(ask > BY2PG)
            ask = BY2PG;
    }else{          /* from a swap image */
        daddr = swapaddr(loadrec);
        new = lookpage(&swapimage, daddr);
        if(new != nil) {
            putswap(loadrec);
            *p = new;
            return;
        }
        c = swapimage.c;
        ask = BY2PG;
    }
    qunlock(&s->lk);

    new = newpage(false, nil, addr);
    k = arch_kmap(new);
    kaddr = (char*)VA(k);

    while(waserror()) {
        if(strcmp(up->errstr, Eintr) == 0)
            continue;
        arch_kunmap(k);
        putpage(new);
        faulterror(Eioload, c, false);
    }

    // reading the Page!! slow! which is why it's done without s->lk locked
    n = devtab[c->type]->read(c, kaddr, ask, daddr);

    if(n != ask)
        faulterror(Eioload, c, false);
    if(ask < BY2PG)
        memset(kaddr+ask, 0, BY2PG-ask);

    poperror();
    arch_kunmap(k);
    qlock(&s->lk);

    if(loadrec == nil) {  /* This is demand load */
        /*
         *  race, another proc may have gotten here first while
         *  s->lk was unlocked
         */
        if(*p == nil) { 
            new->daddr = daddr;
            cachepage(new, s->image);
            *p = new;
        }
        else
            putpage(new);
    }else{          /* This is paged out */
        /*
         *  race, another proc may have gotten here first
         *  (and the pager may have run on that page) while
         *  s->lk was unlocked
         */
        if(*p != loadrec){
            if(!pagedout(*p)){
                /* another process did it for me */
                putpage(new);
    goto done; // not return, need cachectl stuff??
            } else {
                /* another process and the pager got in */
                putpage(new);
                goto retry;
            }
        }

        new->daddr = daddr;
        cachepage(new, &swapimage);
        *p = new;
        putswap(loadrec);
    }
done:
 if(s->flushme)
  memset((*p)->cachectl, PG_TXTFLUSH, sizeof((*p)->cachectl));
}
@
% LP split for demand loading vs swapin

% actually always called with freemem = false so will generate a broken process
<<function faulterror>>=
static void
faulterror(char *s, Chan *c, bool freemem)
{
    char buf[ERRMAX];

    if(c && c->path){
        snprint(buf, sizeof buf, "%s accessing %s: %s", s, c->path->s, up->errstr);
        s = buf;
    }
    if(up->nerrlab) {
        postnote(up, 1, s, NDebug);
        error(s);
    }
    pexit(s, freemem);
}
@

\subsection{[[duppage()]]}

%??? don't get duppage


<<[[fixfault()]] if one ref and page has an image>>=
if(ref == 1 && lkp->image){
    /* save a copy of the original for the image cache */
    duppage(lkp);
    ref = lkp->ref;
}
@

<<global dupretries>>=
static int dupretries = 15000;
@


% called only from fixfault.
% type: ret_code?
<<function duppage>>=
/* Always call with p locked */
int
duppage(Page *p)
{
    Page *np;
    int retries;
 int color;

    retries = 0;
retry:

    if(retries++ > dupretries){
        print("duppage %d, up %p\n", retries, up);
        dupretries += 100;
        if(dupretries > 100000)
            panic("duppage\n");
        uncachepage(p);
        return 1;
    }
        

    /* don't dup pages with no image */
    if(p->ref == 0 || p->image == nil || p->image->notext)
        return 0;

    /*
     *  normal lock ordering is to call
     *  lock(&palloc) before lock(p).
     *  To avoid deadlock, we have to drop
     *  our locks and try again.
     */
    if(!canlock(&palloc)){
        unlock(p);
        if(up)
            sched();
        lock(p);
        goto retry;
    }

    /* No freelist cache when memory is very low */
    if(palloc.freecount < swapalloc.highwater) {
        unlock(&palloc);
        uncachepage(p);
        return 1;
    }

 color = getpgcolor(p->va);
 for(np = palloc.head; np; np = np->next)
  if(np->color == color)
   break;

 /* No page of the correct color */
 if(np == 0) {
  unlock(&palloc);
  uncachepage(p);
  return 1;
 }
    //when no color: np = palloc.head;

    pageunchain(np);
    pagechaintail(np);
/*
* XXX - here's a bug? - np is on the freelist but it's not really free.
* when we unlock palloc someone else can come in, decide to
* use np, and then try to lock it.  they succeed after we've 
* run copypage and cachepage and unlock(np).  then what?
* they call pageunchain before locking(np), so it's removed
* from the freelist, but still in the cache because of
* cachepage below.  if someone else looks in the cache
* before they remove it, the page will have a nonzero ref
* once they finally lock(np).
*/
    lock(np);
    unlock(&palloc);

    /* Cache the new version */
    uncachepage(np);
    np->va = p->va;
    np->daddr = p->daddr;
    copypage(p, np);
    cachepage(np, p->image);
    unlock(np);
    uncachepage(p);

    return 0;
}
@


\subsection{Collecting images}

<<[[putseg()]] if s has an image>>=
img = s->image;
if(img != nil) {
    lock(img);
    lock(s);
    if(img->s == s && s->ref == 1) // race?
        img->s = nil;
    unlock(img);
}
@
% segment unattached when was last ref of segment because we will free it
% how img->s can be <> s? what is the race?

<<[[putseg()]] if s had an image>>=
if(img)
    putimage(img);
@



% called by putseg and also by uncachepage
<<destructor putimage>>=
void
putimage(KImage *img)
{
    Chan *c, **cp;
    KImage *f, **l;

    if(img->notext)
        return;

    lock(img);
    if(--img->ref == 0) {
        l = &ihash(img->qid.path);
        mkqid(&img->qid, ~0, ~0, QTFILE);
        unlock(img);
        c = img->c;

        lock(&imagealloc);
        //remove_hash(imagealloc.hash, img)
        for(f = *l; f; f = f->hash) {
            if(f == img) {
                *l = img->hash;
                break;
            }
            l = &f->hash;
        }

        //add_list(imagealloc.free, img)
        img->next = imagealloc.free;
        imagealloc.free = img;

        /* defer freeing channel till we're out of spin lock's */

        if(imagealloc.nfreechan == imagealloc.szfreechan){
            //realloc(imagealloc.freenchan, szfreechan+NFREECHAN)
            imagealloc.szfreechan += NFREECHAN;
            cp = malloc(imagealloc.szfreechan*sizeof(Chan*));
            if(cp == nil)
                panic("putimage");
            memmove(cp, imagealloc.freechan, imagealloc.nfreechan*sizeof(Chan*));
            free(imagealloc.freechan);
            imagealloc.freechan = cp;
        }

        imagealloc.freechan[imagealloc.nfreechan++] = c;
        unlock(&imagealloc);

        return;
    }
    unlock(img);
}
@
% why not actually free the chan? again because want to keep in cache?
% if we close and reopen later we lost all its pages? (but why? because vers
% will have changed?) or because like said in comment defer until out of spinlock?
% but which spinlock? can't just do putchan(c) ? after all there is one less
% reference no? or is it because closing a chan can block? and so what?

<<[[Imagealloc]] other fields>>=
Chan  **freechan; /* free image channels */
int nfreechan;  /* number of free channels */
int szfreechan; /* size of freechan array */
QLock fcreclaim;  /* mutex on reclaiming free channels */
@

% called from attachimage to I guess close the channels of other closed images
% a bit weird?
<<function imagechanreclaim>>=
/*
 *  since close can block, this has to be called outside of
 *  spin locks.
 */
static void
imagechanreclaim(void)
{
    Chan *c;

    /* Somebody is already cleaning the image chans */
    if(!canqlock(&imagealloc.fcreclaim))
        return;

    /*
     * We don't have to recheck that nfreechan > 0 after we
     * acquire the lock, because we're the only ones who decrement 
     * it (the other lock contender increments it), and there's only
     * one of us thanks to the qlock above.
     */
    while(imagealloc.nfreechan > 0){
        lock(&imagealloc);
        imagealloc.nfreechan--;
        c = imagealloc.freechan[imagealloc.nfreechan];
        unlock(&imagealloc);
        cclose(c);
    }

    qunlock(&imagealloc.fcreclaim);
}
@



<<function imagereclaim>>=
static void
imagereclaim(void)
{
    int n;
    Page *p;
    uvlong ticks;

    irstats.calls++;
    /* Somebody is already cleaning the page cache */
    if(!canqlock(&imagealloc.ireclaim))
        return;

    lock(&palloc);
    ticks = arch_fastticks(nil);
    n = 0;
    /*
     * All the pages with images backing them are at the
     * end of the list (see putpage) so start there and work
     * backward.
     */
    for(p = palloc.tail; p && p->image && n<1000; p = p->prev) {
        if(p->ref == 0 && canlock(p)) {
            if(p->ref == 0) {
                n++;
                uncachepage(p); // will call putimage()
            }
            unlock(p);
        }
    }
    ticks = arch_fastticks(nil) - ticks;
    unlock(&palloc);
    irstats.loops++;
    irstats.ticks += ticks;
    if(ticks > irstats.maxt)
        irstats.maxt = ticks;
    //print("T%llud+", ticks);
    qunlock(&imagealloc.ireclaim);
}
@



\section{Swapping}

\subsection{[[Swapalloc]]}

% Palloc.pages contains refs to pages in physical memory allocated to user.
% Swapalloc.swmap here will represent refs to pages in a huge file, the
% swapimage.
% How will adjust segment pagetables to point to swap pages?
% how store meta-data about swap pages? simply address in swapimage?

% lp split?
<<struct Swapalloc>>=
// Swap allocator (singleton)
struct Swapalloc
{
    // array<byte> xalloc'ed in swapinit()
    // each idx represents a chunk of swapimage, each value a ref count
    byte*  swmap;      /* Base of swap map in memory */

    int free;     /* currently free swap pages */

    // ref<byte> in swmap
    byte*  alloc;     /* Round robin allocator */
    // ref<byte> in swmap
    byte*  top;      /* Top of swap map */

    // ref<byte> in swmap
    byte*  last;     /* Speed swap allocation */

    ulong highwater;    /* Pager start threshold */ // = 5% conf.upages
    ulong headroom;   /* Space pager frees under highwater */ // = 1.25*hw

    //extra
    Lock;       /* Free map lock */
    Rendez r;      /* Pager kproc idle sleep */ // needpages()
};
@
% each idx represents a swap page of 4Ko in swapimage, and the number of
% times this swap page is shared

<<global swapalloc>>=
// Swap allocator
struct Swapalloc swapalloc;
@


<<[[Conf]] other fields>>=
ulong nswap;    /* number of swap pages */
@


% good way to summary all we've seen
<<[[consread()]] cases>>=
    case Qswap:
        snprint(tmp, sizeof tmp,
            "%lud memory\n"
            "%d pagesize\n"
            "%lud kernel\n"
            "%lud/%lud user\n"
            "%lud/%lud swap\n"
            "%lud/%lud kernel malloc\n"
            "%lud/%lud kernel draw\n",
            conf.npage*BY2PG,
            BY2PG,
            conf.npage-conf.upages,
            palloc.user-palloc.freecount, palloc.user,
            conf.nswap-swapalloc.free, conf.nswap,
            mainmem->cursize, mainmem->maxsize,
            imagmem->cursize, imagmem->maxsize);

        return readstr((ulong)offset, buf, n, tmp);
@

% at the beginning empty ... especially swapinit() set swaping.notext to true
% rename KImage?
<<global swapimage>>=
KImage  swapimage;
@




% return offsset in swapfile, daddr
% todo: introduce typedef?
<<function newswap>>=
ulong
newswap(void)
{
    byte *look;

    lock(&swapalloc);

    if(swapalloc.free == 0){
        unlock(&swapalloc);
        return ~0; //???
    }

    look = memchr(swapalloc.last, 0, swapalloc.top-swapalloc.last);
    if(look == nil)
        panic("inconsistent swap"); // swapalloc.free != 0, should find a page

    *look = 1;
    swapalloc.last = look;
    swapalloc.free--;
    unlock(&swapalloc);
    return (look-swapalloc.swmap) * BY2PG; // offset in swapfile
}
@


\subsection{[[PageOrSwap]]}

% now that have a swap "page", essentially an offet in swapfile
% at page boundary, how store that in pagetable, segment, etc?

<<constant PG_ONSWAP>>=
#define PG_ONSWAP 1
@
% Page* are pointers to Page big structure, and structures
% are words aligned by cc? so last 4 bits are empty, and they use
% the last bit to encode whether this address space has been swapped out?

<<type PageOrSwap>>=
typedef Page PageOrSwap;
@
% could also do a union, either Page or a daddr_in_swapimage|PG_ONSWAP

<<function onswap>>=
#define onswap(s) (((kern_addr)s)&PG_ONSWAP)
@



% bad type ... it's really not a pointer to a Page ...
<<function putswap>>=
void
putswap(Page *p)
{
    byte *idx;

    lock(&swapalloc);
    idx = &swapalloc.swmap[((ulong)p)/BY2PG];
    if(--(*idx) == 0) {
        swapalloc.free++;
        if(idx < swapalloc.last)
            swapalloc.last = idx;
    }
    if(*idx >= 254)
        panic("putswap %#p == %ud", p, *idx);
    unlock(&swapalloc);
}
@

<<[[putpage]] if p is a swap address>>=
    if(onswap(p)) {
        putswap(p);
        return;
    }
@

<<[[mfreeseg]] if pg is a swap address>>=
if(onswap(pg))
    putswap(pg);
@


<<function dupswap>>=
void
dupswap(Page *p)
{
    lock(&swapalloc);
    if(++swapalloc.swmap[((ulong)p)/BY2PG] == 0)
        panic("dupswap");
    unlock(&swapalloc);
}
@

<<[[ptcpy()]] if src is a swap page>>=
if(onswap(*src))
    dupswap(*src);
@


<<function swapcount>>=
int
swapcount(ulong daddr)
{
    return swapalloc.swmap[daddr/BY2PG];
}
@


\subsection{Swapping plan}

% pte is a pte in a pagetable of a pagedir of a segment of type type
% bad name of function? swappte better?
<<function pagepte>>=
static void
pagepte(int type, Page **pte)
{
    ulong daddr;
    Page *outp;

    outp = *pte;
    switch(type) {
    case SG_TEXT:               /* Revert to demand load */
        putpage(outp);
        *pte = nil;
        break;

    case SG_DATA:
    case SG_BSS:
    case SG_STACK:
    case SG_SHARED:
        /*
         *  get a new swap address and clear any pages
         *  referring to it from the cache
         */
        daddr = newswap();
        if(daddr == ~0)
            break; // return;
        cachedel(&swapimage, daddr);

        lock(outp);

        /* forget anything that it used to cache */
        uncachepage(outp);

        /*
         *  incr the reference count to make sure it sticks around while
         *  being written
         */
        outp->ref++;

        /*
         *  enter it into the cache so that a fault happening
         *  during the write will grab the page from the cache
         *  rather than one partially written to the disk
         */
        outp->daddr = daddr;
        cachepage(outp, &swapimage);
        *pte = (Page*)(daddr|PG_ONSWAP); // turn a Page pte into a Swap pte!
        unlock(outp);

        /* Add page to IO transaction list */
        iolist[ioptr++] = outp;
        break;
    }
}
@



<<[[Conf]] other fields>>=
int nswppo;   /* max # of pageouts per segment pass */
@

<<global iolist>>=
// array<option<ref<Page>>>, xalloc'ed in swapinit(), size = Conf.nswppo
static  Page    **iolist;
@

<<global ioptr>>=
// index in iolist
static  int ioptr;
@



% rename, too close to pagedout, pageout_segment?
<<function pageout>>=
static void
pageout(Proc *p, Segment *s)
{
    int type, i, size;
    ulong age;
    Pagetable *pt;
    Page **pg, *entry;

    if(!canqlock(&s->lk))   /* We cannot afford to wait, we will surely deadlock */
        return;

    if(s->steal) {      /* Protected by /dev/proc */
        qunlock(&s->lk);
        return;
    }

    if(!canflush(p, s)) {   /* Able to invalidate all tlbs with references */
        qunlock(&s->lk);
        putseg(s);
        return;
    }

    if(waserror()) {
        qunlock(&s->lk);
        putseg(s);
        return;
    }

    /* Pass through the tables looking for memory pages to swap out */
    type = s->type&SG_TYPE;
    size = s->pagedirsize;
    for(i = 0; i < size; i++) {
        pt = s->pagedir[i];
        if(pt == nil)
            continue;
        for(pg = pt->first; pg < pt->last; pg++) {
            entry = *pg;
            if(pagedout(entry)) // already swapped, or nil
                continue;

            if(entry->modref & PG_REF) {
                entry->modref &= ~PG_REF;
                entry->gen = genclock;
            }


            if(genclock < entry->gen)
                age = ~(entry->gen - genclock);
            else
                age = genclock - entry->gen;
            gensum += age;
            gencount++;
            if(age <= genage)
                continue;


            pagepte(type, pg);

            if(ioptr >= conf.nswppo)
                goto out;
        }
    }
out:
    poperror();
    qunlock(&s->lk);
    putseg(s);
}
@



\subsection{The [[pager]]}

% when swap is kicked in?

<<[[newpage()]] loop waiting freecount > highwater>>=
    for(;;) {
        if(palloc.freecount > swapalloc.highwater)
            break;
        if(up->kp && palloc.freecount > 0)
            break;

        // in highwater, not so many free pages, need to wait

        unlock(&palloc);
        dontalloc = false;
        if(s && *s) {
            qunlock(&((*s)->lk));
            *s = nil;// !!
            dontalloc = true;
        }
        qlock(&palloc.pwait);   /* Hold memory requesters here */

        while(waserror())   /* Ignore interrupts */
            ;

        kickpager();
        tsleep(&palloc.freememr, hasfreepages, 0, 1000);

        poperror();
        qunlock(&palloc.pwait);

        /*
         * If called from fault and we lost the segment from
         * underneath don't waste time allocating and freeing
         * a page. Fault will call newpage again when it has
         * reacquired the segment locks
         */
        if(dontalloc)
            return nil;

        lock(&palloc);
    }
@

<<[[Palloc]] extra fields>>=
Rendez  freememr; /* Sleep for free mem */ // hasfreepages()
QLock pwait; /* Queue of procs waiting for memory */
@
%old: r -> freememr


<<function hasfreepages>>=
int
hasfreepages(void*)
{
    return palloc.freecount >= swapalloc.highwater;
}
@







<<function kickpager>>=
void
kickpager(void)
{
    static bool started;

    if(started)
        wakeup(&swapalloc.r);
    else {
        kproc("kpager", pager, nil);
        started = true;
    }
}
@


<<function pager>>=
static void
pager(void *junk)
{
    int i;
    Segment *s;
    Proc *p, *ep;

    if(waserror())
        panic("pager: os error");

    p = proctab(0);
    ep = &p[conf.nproc];

loop:
    up->psstate = "Idle";
    wakeup(&palloc.freememr);
    sleep(&swapalloc.r, needpages, nil);

    while(needpages(junk)) {
        if(swapimage.c) {
            p++;
            if(p >= ep){
                p = proctab(0);
                gentick();          
            }

            if(p->state == Dead || p->noswap)
                continue;

            if(!canqlock(&p->seglock))
                continue;       /* process changing its segments */

            for(i = 0; i < NSEG; i++) {
                if(!needpages(junk)){
                    qunlock(&p->seglock);
                    goto loop;
                }

                if(s = p->seg[i]) {
                    switch(s->type&SG_TYPE) {
                    case SG_TEXT:
                        pageout(p, s);
                        break;
                    case SG_DATA:
                    case SG_BSS:
                    case SG_STACK:
                    case SG_SHARED:
                        up->psstate = "Pageout";
                        pageout(p, s);
                        if(ioptr != 0) {
                            up->psstate = "I/O";
                            executeio();
                        }
                        break;
                    default:
                        break;
                    }
                }
            }
            qunlock(&p->seglock);
        } else {
            print("out of memory\n");
            killbig("out of memory");
            freebroken();       /* can use the memory */

            /* Emulate the old system if no swap channel */
            if(!swapimage.c)
                tsleep(&up->sleepr, returnfalse, 0, 5000);
        }
    }
    goto loop;
}
@

<<function needpages>>=
static bool
needpages(void*)
{
    return palloc.freecount < swapalloc.headroom;
}
@


<<[[Proc]] memory fields>>=
bool noswap;   /* process is not swappable */
@

<<[[procctlreq()]] CMnoswap case>>=
case CMnoswap:
    p->noswap = true;
    break;
@








<<function canflush>>=
static bool
canflush(Proc *p, Segment *s)
{
    int i;
    Proc *ep;

    lock(s);
    if(s->ref == 1) {       /* Easy if we are the only user */
        s->ref++;
        unlock(s);
        return canpage(p);
    }
    s->ref++;
    unlock(s);

    /* Now we must do hardwork to ensure all processes which have tlb
     * entries for this segment will be flushed if we succeed in paging it out
     */
    p = proctab(0);
    ep = &p[conf.nproc];
    while(p < ep) {
        if(p->state != Dead) {
            for(i = 0; i < NSEG; i++)
                if(p->seg[i] == s)
                    if(!canpage(p))
                        return false;
        }
        p++;
    }
    return true;
}
@

<<function canpage>>=
int
canpage(Proc *p)
{
    bool ok = false;

    arch_splhi();
    lock(runq);
    /* Only reliable way to see if we are Running */
    if(p->cpu == nil) {
        p->newtlb = true;
        ok = true;
    }
    unlock(runq);
    arch_spllo();

    return ok;
}
@ 





% generation, see later
<<function gentick>>=
static void
gentick(void)
{
    genclock++;
    if(gencount)
        genage = gensum / gencount;
    else
        genage = 0;
    gensum = gencount = 0;
}
@


<<global genxxx>>=
static  ulong   genage, genclock, gencount;
static  uvlong  gensum;
@

<<[[Page]] other fields>>=
ulong gen;      /* Generation counter for swap */
@




\subsection{Paging out}
% Paging out, writing

% called by pager once it has found some pages to swap, so cool
% cos page is a kernel process, so this can happen in the background
% (hmm but actually prio of kproc is high, so maybe not great)
<<function executeio>>=
static void
executeio(void)
{
    Page *out;
    int i, n;
    Chan *c;
    char *kaddr;
    Arch_KMap *k;

    c = swapimage.c;
    qsort(iolist, ioptr, sizeof iolist[0], pageiocomp);
    for(i = 0; i < ioptr; i++) {
        if(ioptr > conf.nswppo)
            panic("executeio: ioptr %d > %d", ioptr, conf.nswppo);
        out = iolist[i];
        k = arch_kmap(out);
        kaddr = (char*)VA(k);

        if(waserror())
            panic("executeio: page out I/O error");

        n = devtab[c->type]->write(c, kaddr, BY2PG, out->daddr);// swap 1 page
        if(n != BY2PG)
            nexterror();

        arch_kunmap(k);
        poperror();

        /* Free up the page after I/O */
        lock(out);
        out->ref--;
        unlock(out);
        putpage(out);
    }
    ioptr = 0;
}
@

<<function pageiocomp>>=
static int
pageiocomp(void *a, void *b)
{
    Page *p1, *p2;

    p1 = *(Page **)a;
    p2 = *(Page **)b;
    if(p1->daddr > p2->daddr)
        return 1;
    else
        return -1;
}
@


\subsection{Paging in}

<<function swapaddr>>=
#define swapaddr(s) (((ulong)s)&~PG_ONSWAP)
@

% put part of pio() here



\subsection{Setting up the swap file}

<<[[conswrite()]] cases>>=
case Qswap:
    if(n >= sizeof buf)
        error(Egreg);
    memmove(buf, va, n);    /* so we can NUL-terminate */
    buf[n] = 0;
    /* start a pager if not already started */
    if(strncmp(buf, "start", 5) == 0){
        kickpager();
        break;
    }
    if(!iseve())
        error(Eperm);
    if(buf[0]<'0' || '9'<buf[0])
        error(Ebadarg);
    fd = strtoul(buf, 0, 0);
    swc = fdtochan(fd, -1, true, true);
    setswapchan(swc);
    break;
@


<<function setswapchan>>=
void
setswapchan(Chan *c)
{
    byte dirbuf[sizeof(DirEntry)+100];
    DirEntry d;
    int n;

    if(swapimage.c) {
        if(swapalloc.free != conf.nswap){
            cclose(c);
            error(Einuse);
        }
        cclose(swapimage.c);
    }

    /*
     *  if this isn't a file, set the swap space
     *  to be at most the size of the partition
     */
    if(devtab[c->type]->dc != L'M'){
        n = devtab[c->type]->stat(c, dirbuf, sizeof dirbuf);
        if(n <= 0){
            cclose(c);
            error("stat failed in setswapchan");
        }
        convM2D(dirbuf, n, &d, nil);
        if(d.length < conf.nswap*BY2PG){
            conf.nswap = d.length/BY2PG;
            swapalloc.top = &swapalloc.swmap[conf.nswap];
            swapalloc.free = conf.nswap;
        }
    }

    swapimage.c = c;
}
@



\chapter{Scheduling}
% virtual CPU?
% less: could add (clock interrupt) in title? to related to Interrupt chapter

\section{Overview}

% in essence the main role of an OS is to manage programs and so in essence
% it is first and foremost a scheduler! 

% first part is cooperative scheduling, with sleep/wakeup
%  and people calling sched themselves
% then will see preemptive scheduling with interrupt clock


% What a system would look like without (preemptive) scheduling?
%  - a malicious/buggy process could never yield (see MacOS 9 ... windows 3.1)
%  - DOS didn't even offer cooperative scheduling, so could just have one
%    process at a time (at least windows 3.1 improved a bit on that)

% see also section in Debugging about /bin/trace that allows to
% trace scheduler events

\section{Process priority}
%adjustable priority actually

<<constant Npriq>>=
Npriq   = 20,   /* number of scheduler priority levels */
@

<<enum priority>>=
enum priority 
{
    PriNormal = 10,   /* base priority for normal processes */
    PriKproc  = 13,   /* base priority for kernel processes */
    PriRoot   = 13,   /* base priority for root processes */

    <<constants for real-time priority>>
};
@ 
% higher is higher priority.

<<[[Proc]] scheduling fields>>=
// enum<priority>
ulong priority; /* priority level */

ulong basepri;  /* base priority level */
bool fixedpri; /* priority level doesn't change */
@ 


<<function procpriority>>=
void
procpriority(Proc *p, int pri, bool fixed)
{
    <<[[procpriority()]] sanity check pri>>
    p->basepri = pri;
    p->priority = pri;
    p->fixedpri = fixed;
}
@ 

<<[[procpriority()]] sanity check pri>>=
if(pri >= Npriq)
    pri = Npriq - 1;
else if(pri < 0)
    pri = 0;
@



<<[[procctlreq()]] CMpri case>>=
case CMpri:
    pri = atoi(cb->f[1]);
    if(pri > PriNormal && !iseve())
        error(Eperm);
    procpriority(p, pri, false);
    break;
@
% complex, but essentially means echo 'pri 3' > /proc/x/ctl

<<[[procctlreq()]] CMfixedpri case>>=
case CMfixedpri:
    pri = atoi(cb->f[1]);
    if(pri > PriNormal && !iseve())
        error(Eperm);
    procpriority(p, pri, true);
    break;
@
% complex, but essentially means echo 'fixedpri 3' > /proc/x/ctl



\section{The [[runq]]ueue}

<<constant Nrq>>=
Nrq   = Npriq+2,  /* number of priority levels including real time */
@
% +2 because of Edf real-time scheduling

<<global runq>>=
// The run queue!!
// hash<enum<priority>, queue<ref<Proc>>>
Schedq  runq[Nrq];
@ 

<<struct Schedq>>=
// essentially a queue<ref<Proc>>
struct Schedq
{
    // list<ref<Proc>> (next = Proc.rnext)
    Proc* head;
    // ref<Proc>, the tail
    Proc* tail;
    // size of list
    int n; 
  
    // extra
    Lock;
};
@ 

<<[[Proc]] extra fields>>=
// list<ref<Proc>> of Schedq.head
Proc  *rnext;   /* next process in run queue */
@



<<global runveq>>=
// array<bool>, each bit i represents whether the runq at pri i has processes
ulong   runvec; // coupling: sizeof(ulong) must be >= Nrq
@ 

<<function anyready>>=
bool
anyready(void)
{
    return runvec;
}
@ 

<<global nrdy>>=
int nrdy;
@ 

<<function queueproc>>=
/*
 * add a process to a scheduling queue
 */
void
queueproc(Schedq *rq, Proc *p)
{
    int pri;

    pri = rq - runq;
    lock(runq);
    p->priority = pri;

    // add_queue(p, rq)
    p->rnext = nil;
    if(rq->tail)
        rq->tail->rnext = p;
    else
        rq->head = p;
    rq->tail = p;
    rq->n++;

    nrdy++;
    runvec |= 1<<pri;
    unlock(runq);
}
@ 
%>>

<<function dequeueproc>>=
/*
 *  try to remove a process from a scheduling queue (called arch_splhi)
 */
// tp should belong to the queue
Proc*
dequeueproc(Schedq *rq, Proc *tp)
{
    Proc *l, *p;

    if(!canlock(runq))
        return nil;

    /*
     *  the queue may have changed before we locked runq,
     *  refind the target process.
     */
    l = nil;
    for(p = rq->head; p; p = p->rnext){
        if(p == tp)
            break;
        l = p;
    }
    // l should be nil most of the time, the queue probably didn't change

    /*
     *  p->cpu==nil only when process state is saved
     */
    if(p == nil || p->cpu){
        unlock(runq);
        return nil;
    }

    // remove_queue(p, rq)
    if(p->rnext == nil)
        rq->tail = l;
    if(l)
        l->rnext = p->rnext;
    else
        rq->head = p->rnext;
    if(rq->head == nil)
        runvec &= ~(1<<(rq-runq));
    rq->n--;

    nrdy--;

    if(p->state != Ready)
        print("dequeueproc %s %lud %s\n", p->text, p->pid, statename[p->state]);

    unlock(runq);
    return p;
}
@ 
% >>

\section{[[sched()]]}

% address from cpus, not MACHADDR, could have used cpuno, don't want 0
<<[[Proc]] scheduling fields>>=
// option<ref<Cpu>>, null when not associated to a processor
Cpu  *cpu;    /* processor running this proc */
@

% and more importantly cpu->proc!!  (so have proc->cpu and cpu->proc)
% sched() will essentially do cpu->proc = newp; (or up = newp)


% actually why could not factorize code with sleep()?
<<function sched>>=
/*
 *  If changing this routine, look also at sleep().  It
 *  contains a copy of the guts of sched().
 */
void
proc_sched(void)
{
    Proc *p;

    if(cpu->ilockdepth)
        panic("cpu%d: ilockdepth %d, last lock %#p at %#p, sched called from %#p",
            cpu->cpuno, cpu->ilockdepth, up? up->lastilock: nil,
            (up && up->lastilock)? up->lastilock->pc: 0, getcallerpc(&p+2));
    if(up){
        <<[[sched()]] if complex condition increment delaysched and return>>
        arch_splhi(); // schedinit requires this
        cpu->cs++;

        arch_procsave(up);
        if(arch_setlabel(&up->sched)){
            //
            // here when the process has been scheduled back
            // from a arch_gotolabel(up->sched) by another process, see below
            //
            arch_procrestore(up);
            arch_spllo();
            return;
        }else{
            //
            // here to go to schedinit() (which will call sched() back)
            //
            arch_gotolabel(&cpu->sched); // goto schedinit()
            panic("sched: should never reach this point");
        }
    }
    // We should execute this code using the main kernel stack, as
    // we should arrive here from schedinit().

    p = runproc();
    <<[[sched()]] optional guard for real-time process>>
    {
        updatecpu(p);
        p->priority = reprioritize(p);
    }
    if(p != cpu->readied)
        cpu->schedticks = cpu->ticks + HZ/10; // 100ms of allocated time
    cpu->readied = nil;

    cpu->proc = p;
    up = p; // same instruction than previous line on some archi (e.g. x86)

    up->state = Running;
    up->cpu = CPUS(cpu->cpuno);

    arch_mmuswitch(up);
    arch_gotolabel(&up->sched);
}
@ 

% Why going to schedinit()? Why not call sched() recursively? or goto common:
% where we would do the p = runproc() ...? See below.




% less: have a [[Cpu]] scheduler fields? 
% this not really related to contextswitch
% the sched of the Cpu is to jump to schedinit that eventually calls sched()
<<[[Cpu]] other fields>>=
Label sched;      /* scheduler wakeup */ // address of schedinit()
@

<<function schedinit>>=
/*
 * Always arch_splhi()'ed.
 */
void
schedinit(void)     /* never returns */
{
    Edf *e;

    arch_setlabel(&cpu->sched);

    if(up) {
        <<[[schedinit()]] optional real-time [[edfrecord()]]>>
        //old: cpu->proc = nil;
        // but now that on x86 up = cpu->proc and not cpu->externup
        // we can't do that anymore. Is there a place that rely on
        // cpu->proc and cpu-externup to not be in sync?
        switch(up->state) {
        case Running:
            ready(up);
            break;
        case Moribund:
            up->state = Dead;
            <<[[schedinit()]] optional real-time [[edfstop()]]>>
            /*
             * Holding locks from pexit:
             *  procalloc
             *  palloc
             */
            arch_mmurelease(up);

            up->qnext = procalloc.free;
            procalloc.free = up;

            unlock(&palloc);
            unlock(&procalloc);
            break;
        }

        up->cpu = nil;
        updatecpu(up);

        cpu->proc = nil;
        up = nil; // same instruction than previous line on some archi (e.g. PC)
    }
    // ok at this point up is nil
    sched();
}
@ 
% Why the logic of scheduling is splitted between sched() and schedinit()?
% could not gather? And doing so remove the need for Cpu->label?
% I think it's related to the per-process stack.
% Once you've called arch_setlabel(), that means you saved the kernel context
% of a certain process, you should not use the kernel stack of
% this process for other things, you should switch to an exterior 
% process-independent task, that is the main() kernel stack!
% Also the dying code is there in schedinit(), maybe because when
% we are releasing the memory of a process, we need a stack ... and we 
% can't use anymore the stack of the process! so have to switch to the
% stack of main()!! (hmmm but actually we never free Proc->kstack ... so
% we could for a few more instructions use it)
% todo: look in balestero's notes



<<function runproc>>=
/*
 *  pick a process to run
 */
Proc*
runproc(void)
{
    Schedq *rq;
    Proc *p;
    ulong start, now;
    int i;
    void (*pt)(Proc*, int, vlong);

    start = arch_perfticks();

    /* cooperative scheduling until the clock ticks */
    if((p=cpu->readied) && p->cpu==nil && p->state==Ready && 
      (p->wired == nil || p->wired == CPUS(cpu->cpuno)) && // pad's bugfix!
      <<[[runproc()]] test for empty real-time scheduling queue>>
    ){
        skipscheds++;
        rq = &runq[p->priority];
        goto found;
    }

    preempts++;

loop:
    /*
     *  find a process that last ran on this processor (affinity),
     *  or one that hasn't moved in a while (load balancing). Every
     *  time around the loop affinity goes down.
     */
    arch_spllo();
    for(i = 0;; i++){
        /*
         *  find the highest priority target process that this
         *  processor can run given affinity constraints.
         *
         */
        for(rq = &runq[Nrq-1]; rq >= runq; rq--){
            for(p = rq->head; p; p = p->rnext){
                if(p->lastcpu == nil || p->lastcpu == CPUS(cpu->cpuno)
                   || (p->wired == nil && i > 0)) // favor affinity for first round
                    goto found;
            }
        }
        // nothing found
        /* waste time or halt the CPU */
        arch_idlehands();

        /* remember how much time we're here */
        now = arch_perfticks();
        cpu->perf.inidle += now-start;
        start = now;
    }

found:
    arch_splhi();
    p = dequeueproc(rq, p);
    if(p == nil)
        goto loop;

    p->state = Scheding;
    p->lastcpu = CPUS(cpu->cpuno);

    <<[[runproc()]] test if p is a real-time process>>
    <<[[runproc()]] hook proctrace>>
    return p;
}
@ 
%bug: see pad's bugfix above

\subsection{Adjusting priority}

<<[[Proc]] scheduling fields>>=
Cpu *lastcpu;    /* processor this process last ran on */
@




% new typedef? Ttick_scaled?
<<[[Proc]] scheduling fields>>=
ulong lastupdate; // dimension?? ticks * Scaling;
ulong cpuavg;    /* cpu average */
@

<<constant Scaling>>=
Scaling=2,
@
<<constant Schedagain>>=
schedgain = 30, /* units in seconds */
@


<<function updatecpu>>=
/*
 * Update the cpu time average for this particular process,
 * which is about to change from up -> not up or vice versa.
 * p->lastupdate is the last time an updatecpu happened.
 *
 * The cpu time average is a decaying average that lasts
 * about D clock ticks.  D is chosen to be approximately
 * the cpu time of a cpu-intensive "quick job".  A job has to run
 * for approximately D clock ticks before we home in on its 
 * actual cpu usage.  Thus if you manage to get in and get out
 * quickly, you won't be penalized during your burst.  Once you
 * start using your share of the cpu for more than about D
 * clock ticks though, your p->cpu hits 1000 (1.0) and you end up 
 * below all the other quick jobs.  Interactive tasks, because
 * they basically always use less than their fair share of cpu,
 * will be rewarded.
 *
 * If the process has not been running, then we want to
 * apply the filter
 *
 *  cpu = cpu * (D-1)/D
 *
 * n times, yielding 
 * 
 *  cpu = cpu * ((D-1)/D)^n
 *
 * but D is big enough that this is approximately 
 *
 *  cpu = cpu * (D-n)/D
 *
 * so we use that instead.
 * 
 * If the process has been running, we apply the filter to
 * 1 - cpu, yielding a similar equation.  Note that cpu is 
 * stored in fixed point (* 1000).
 *
 * Updatecpu must be called before changing up, in order
 * to maintain accurate cpu usage statistics.  It can be called
 * at any time to bring the stats for a given proc up-to-date.
 */
void
updatecpu(Proc *p)
{
    int n, t, ocpu;
    int D = schedgain*HZ*Scaling;

    if(p->edf)
        return;

    t = CPUS(0)->ticks*Scaling + Scaling/2;
    n = t - p->lastupdate;
    p->lastupdate = t;

    if(n == 0)
        return;
    if(n > D)
        n = D;

    ocpu = p->cpuavg;
    if(p != up)
        p->cpuavg = (ocpu*(D-n))/D;
    else{
        t = 1000 - ocpu;
        t = (t*(D-n))/D;
        p->cpuavg = 1000 - t;
    }

//iprint("pid %d %s for %d cpu %d -> %d\n", p->pid,p==up?"active":"inactive",n, ocpu,p->cpuavg);
}
@ 


<<function reprioritize>>=
/*
 * On average, p has used p->cpuavg of a cpu recently.
 * Its fair share is conf.ncpu/cpu->load of a cpu.  If it has been getting
 * too much, penalize it.  If it has been getting not enough, reward it.
 * I don't think you can get much more than your fair share that 
 * often, so most of the queues are for using less.  Having a priority
 * of 3 means you're just right.  Having a higher priority (up to p->basepri) 
 * means you're not using as much as you could.
 */
int
reprioritize(Proc *p)
{
    int fairshare, n, load, ratio;

    load = CPUS(0)->load;
    if(load == 0)
        return p->basepri;

    /*
     *  fairshare = 1.000 * conf.nproc * 1.000/load,
     * except the decimal point is moved three places
     * on both load and fairshare.
     */
    fairshare = (conf.ncpu*1000*1000)/load;
    n = p->cpuavg;
    if(n == 0)
        n = 1;
    ratio = (fairshare+n/2) / n;
    if(ratio > p->basepri)
        ratio = p->basepri;
    if(ratio < 0)
        panic("reprioritize");
//iprint("pid %d cpu %d load %d fair %d pri %d\n", p->pid, p->cpuavg, load, fairshare, ratio);
    return ratio;
}
@ 


\subsection{Delayed [[sched()]]}

% when can have this situation? up->delaysched < 20
% means sched() got called like 20 times, but impossible no?

<<[[Proc]] scheduling fields>>=
ulong delaysched;
@

<<[[sched()]] if complex condition increment delaysched and return>>=
/*
 * Delay the sched until the process gives up the locks
 * it is holding.  This avoids dumb lock loops.
 *
 * But don't delay if the process is Moribund.
 * It called sched to die.
 * But do sched eventually. This avoids a missing unlock
 * from hanging the entire kernel. 
 * But don't reschedule procs holding palloc or procalloc.
 * Those are far too important to be holding while asleep.
 *
 * This test is not exact.  There can still be a few instructions
 * in the middle of taslock when a process holds a lock
 * but Lock.p has not yet been initialized.
 */
if(up->nlocks.ref)
  if(up->state != Moribund)
    if(up->delaysched < 20
      || palloc.Lock.p == up
      || procalloc.Lock.p == up){

        up->delaysched++;
        delayedscheds++; // stats
        return;
    }
up->delaysched = 0;
@


<<[[trap()]] if delaysched(x86)>>=
/* delaysched set because we held a lock or because our quantum ended */
if(up && up->delaysched && clockintr){
    sched();
    arch_splhi();
}
@

<<[[syscall()]] if delaysched(x86)>>=
/* if we delayed sched because we held a lock, sched now */
if(up->delaysched)
    sched();
@

<<[[unlock()]] if delaysched>>=
if(up && deccnt(&up->nlocks) == 0 && up->delaysched && arch_islo()){
    /*
     * Call sched if the need arose while locks were held
     * But, don't do it from interrupt routines, hence the arch_islo() test
     */
    sched();
}
@


\section{Context switch (x86)}
% probably needs to see this section before sched()

<<struct Label>>=
// =~ a jumpbuf in C, for coroutines
struct Label
{
    // or virt_addr? used also for saving context of user code?
    kern_addr sp; 
    kern_addr pc; 
};
@ 

% is this enough? what about the other registers? the kernel code assumes
% compiles with kencc, so the only context we need is this.
% no need save registers, the caller compiled code should have done
% that before calling arch_setlabel(). Note that this is ok because
% arch_gotolabel assumes we jump to other kernel code compiled via kencc!
% for the user switch, this is not the same (also because can
% be interrupted in the middle of anything) and so we save
% everything.

% cflow of syscall e.g. syssleep is: user -> kernel -> sleep ->
% kernel switch arch_gotolabel -> return from kernel code (syscall or trap)
% restore registers back from kernel code to user.

<<[[Proc]] assembly fields>>=
Label sched;    /* known to l.s */
char  *kstack;  /* known to l.s */
@ 
% kstack is smalloc'ed in newproc()

<<constant KSTACK(x86)>>=
#define KSTACK    4096      /* Size of kernel stack */
@

% TSS, mmu, sched labels, ... many switches

<<function gotolabel(x86)>>=
/*
 *  label consists of a stack pointer and a PC
 */
TEXT arch_gotolabel(SB), $0
        MOVL    label+0(FP), AX
        MOVL    0(AX), SP                       /* restore sp */
        MOVL    4(AX), AX                       /* put return pc on the stack */
        MOVL    AX, 0(SP)
        MOVL    $1, AX                          /* return true */
        RET
@
% similar to C setjmp longjmp?


<<function setlabel(x86)>>=
TEXT arch_setlabel(SB), $0
        MOVL    label+0(FP), AX
        MOVL    SP, 0(AX)                       /* store sp */
        MOVL    0(SP), BX                       /* store return pc */
        MOVL    BX, 4(AX)
        MOVL    $0, AX                          /* return false */
        RET

@


<<function mmuswitch(x86)>>=
void
arch_mmuswitch(Proc* proc)
{
    ulong *mmupd;

    if(proc->newtlb){
        mmuptefree(proc);
        proc->newtlb = false;
    }

    if(proc->mmupd){
        mmupd = tmpmap(proc->mmupd);
        mmupd[PDX(CPUADDR)] = cpu->pdproto[PDX(CPUADDR)]; // for up
        tmpunmap(mmupd);
        taskswitch(proc->mmupd->pa, (ulong)(proc->kstack+KSTACK));
    }else
        taskswitch(PADDR(cpu->pdproto), (ulong)(proc->kstack+KSTACK));
}
@



<<struct Tss(x86)>>=
struct Tss {
    ulong link;     /* link (old TSS selector) */
    ulong esp0;     /* privilege level 0 stack pointer */
    ulong ss0;      /* privilege level 0 stack selector */
    ulong esp1;     /* privilege level 1 stack pointer */
    ulong ss1;      /* privilege level 1 stack selector */
    ulong esp2;     /* privilege level 2 stack pointer */
    ulong ss2;      /* privilege level 2 stack selector */
    ulong xcr3;     /* page directory base register - not used because we don't use trap gates */
    ulong eip;      /* instruction pointer */
    ulong eflags;     /* flags register */
    ulong eax;      /* general registers */
    ulong   ecx;
    ulong edx;
    ulong ebx;
    ulong esp;
    ulong ebp;
    ulong esi;
    ulong edi;
    ulong es;     /* segment selectors */
    ulong cs;
    ulong ss;
    ulong ds;
    ulong fs;
    ulong gs;
    ulong ldt;      /* selector for task's LDT */
    ulong iomap;      /* I/O map base address + T-bit */
};
@ 

<<[[Cpu]] [[Arch]] other fields(x86)>>=
Tss*  tss;      /* tss for this processor */
@

<<function taskswitch(x86)>>=
static void
taskswitch(phys_addr mmupd, ulong stack)
{
    Tss *tss;

    tss = cpu->tss;
    tss->ss0 = KDSEL;
    tss->esp0 = stack;
    tss->ss1 = KDSEL;
    tss->esp1 = stack;
    tss->ss2 = KDSEL;
    tss->esp2 = stack;
    putcr3(mmupd);
}
@


<<function procsave(x86)>>=
/*
 *  Save the cpu dependent part of the process state.
 */
void
arch_procsave(Proc *p)
{
    <<[[procsave()]] cycles adjustments(x86)>>
    <<[[procsave()]] fp adjustments(x86)>>
    /*
     * While this processor is in the scheduler, the process could run
     * on another processor and exit, returning the page tables to
     * the free list where they could be reallocated and overwritten.
     * When this processor eventually has to get an entry from the
     * trashed page tables it will crash.
     *
     * If there's only one processor, this can't happen.
     * You might think it would be a win not to do this in that case,
     * especially on VMware, but it turns out not to matter.
     */
    mmuflushtlb(PADDR(cpu->pdproto));
}
@ 


<<function procrestore(x86)>>=
void
arch_procrestore(Proc *p)
{
    uvlong t;
    if(p->kp)
        return;
    <<[[procrestore]] cycles adjustments(x86)>>
}
@ 



\section{Cooperative scheduling}

% see sleep.ps in plan9 documents

%  sleep(similar to sched)/wakeup(calls ready)
%  sleep/wakeup have a condition attached to it, and so a rendez vous,
%  sched and ready are just altruistic, give back without asking

<<function yield>>=
/*
 *  yield the processor and drop our priority
 */
void
yield(void)
{
    if(anyready()){
        /* pretend we just used 1/2 tick */
        up->lastupdate -= Scaling/2;  
        sched();
    }
}
@ 


<<enum procstate cases>>=
Ready,
@

<<[[Cpu]] other fields>>=
Proc* readied;    /* for runproc */
@

<<function ready>>=
/*
 *  ready(p) picks a new priority for a process and sticks it in the
 *  runq for that priority.
 */
void
proc_ready(Proc *p)
{
    int s, pri;
    Schedq *rq;
    void (*pt)(Proc*, int, vlong);

    s = arch_splhi();
    <<[[ready()]] optional [[edfready()]] for real-time scheduling>>

    if(up != p && (p->wired == nil || p->wired == CPUS(cpu->cpuno))) // pad fix
        cpu->readied = p; /* group scheduling */

    updatecpu(p);
    pri = reprioritize(p);
    p->priority = pri;
    rq = &runq[pri];
    p->state = Ready;
    queueproc(rq, p);
    <<[[ready()]] hook proctrace>>
    arch_splx(s);
}
@ 



<<struct Rendez>>=
struct Rendez
{
    // option<ref<Proc>>
    Proc  *p; // sleeping process
    Lock;
};
@ 
% similar DS in libc.h!
% kind of condition variable? can have things like
% Rendez full; Rendez empty; and code like wakeup(x->empty).
% to wakeup the process that are waiting because of empty queues.

% those one are kind of scheduling fields, because they are about
% cooperative scheduling, not so much about inter process synchro via
% sysrendezvous
<<[[Proc]] synchronization fields>>=
// option<ref<Rendez>>, can point to waitr, freememr, sleepr, etc
Rendez  *r;   /* rendezvous point slept on */
Lock  rlock;    /* sync sleep/wakeup with postnote */
@

% p->r, r->p


<<enum procstate cases>>=
Wakeme,
@

<<function sleep>>=
/*
 *  sleep if a condition is not true.  Another process will
 *  awaken us after it sets the condition.  When we awaken
 *  the condition may no longer be true.
 *
 *  we lock both the process and the rendezvous to keep r->p
 *  and p->r synchronized.
 */
void
proc_sleep(Rendez *r, bool (*f)(void*), void *arg)
{
    int s;
    void (*pt)(Proc*, int, vlong);

    s = arch_splhi();

    if(up->nlocks.ref)
        print("process %lud sleeps with %lud locks held, last lock %#p locked at pc %#lux, sleep called from %#p\n",
            up->pid, up->nlocks.ref, up->lastlock, up->lastlock->pc, getcallerpc(&r));

    lock(r);
    lock(&up->rlock);

    if(r->p){
        print("double sleep called from %#p, %lud %lud\n", getcallerpc(&r), r->p->pid, up->pid);
        dumpstack();
    }

    /*
     *  Wakeup only knows there may be something to do by testing
     *  r->p in order to get something to lock on.
     *  Flush that information out to memory in case the sleep is
     *  committed.
     */
    r->p = up;

    if((*f)(arg) || up->notepending){
        /*
         *  if condition happened or a note is pending
         *  never mind
         */
        r->p = nil;
        unlock(&up->rlock);
        unlock(r);
    } else {
        /*
         *  now we are committed to
         *  change state and call scheduler
         */
        <<[[sleep()]] hook proctrace>>

        up->state = Wakeme;
        up->r = r;

        // similar code to sched(), why not call sched()?
        /* statistics */
        cpu->cs++;

        arch_procsave(up);
        if(arch_setlabel(&up->sched)) {
            /*
             *  here when the process is awakened
             */
            arch_procrestore(up);
            arch_spllo();
        } else {
            /*
             *  here to go to sleep (i.e. stop Running)
             */
            unlock(&up->rlock);
            unlock(r);
            arch_gotolabel(&cpu->sched);
            panic("sleep: should never reach this point");
        }
    }

    if(up->notepending) {
        up->notepending = false;
        arch_splx(s);
        <<[[sleep()]] forceclosefgrp>>
        error(Eintr);
    }

    arch_splx(s);
}
@ 

<<function wakeup>>=
/*
 *  Expects that only one process can call wakeup for any given Rendez.
 *  We hold both locks to ensure that r->p and p->r remain consistent.
 *  Richard Miller has a better solution that doesn't require both to
 *  be held simultaneously, but I'm a paranoid - presotto.
 */
Proc*
proc_wakeup(Rendez *r)
{
    Proc *p;
    int s;

    s = arch_splhi();
    lock(r);
    p = r->p;

    if(p != nil){
        lock(&p->rlock);
        if(p->state != Wakeme || p->r != r){
            iprint("%p %p %d\n", p->r, r, p->state);
            panic("wakeup: state");
        }
        r->p = nil;
        p->r = nil;
        ready(p);
        unlock(&p->rlock);
    }
    unlock(r);
    arch_splx(s);
    return p;
}
@ 



\section{Preemptive scheduling}

<<[[Cpu]] other fields>>=
ulong schedticks;   /* next forced context switch */
@

<<function hzsched>>=
/*
 *  here once per clock tick to see if we should resched
 */
void
hzsched(void)
{
    /* once a second, rebalance will reprioritize ready procs */
    if(cpu->cpuno == 0)
        rebalance();

    /* unless preempted, get to run for at least 100ms */
    if(anyhigher()
    || (!up->fixedpri && cpu->ticks > cpu->schedticks && anyready())){

        cpu->readied = nil;   /* avoid cooperative scheduling */
        up->delaysched++;
    }
}
@ 



<<function anyhigher>>=
int
anyhigher(void)
{
    return runvec & ~((1<<(up->priority+1))-1);
}
@ 
% >>


<<global balancetime>>=
/*
 *  recalculate priorities once a second.  We need to do this
 *  since priorities will otherwise only be recalculated when
 *  the running process blocks.
 */
ulong balancetime;
@ 

<<function rebalance>>=
static void
rebalance(void)
{
    int pri, npri, t, x;
    Schedq *rq;
    Proc *p;

    t = cpu->ticks;
    if(t - balancetime < HZ)
        return;
    balancetime = t;

    for(pri=0, rq=runq; pri<Npriq; pri++, rq++){
another:
        p = rq->head;
        if(p == nil)
            continue;
        if(p->lastcpu != CPUS(cpu->cpuno)) // this has been the source of comments on 9fans, todo look if bug (subject = rebalance() funny, nov30)
            continue;
        if(pri == p->basepri)
            continue;
        updatecpu(p);
        npri = reprioritize(p);
        if(npri != pri){
            x = arch_splhi();
            p = dequeueproc(rq, p);
            if(p)
                queueproc(&runq[npri], p);
            arch_splx(x);
            goto another;
        }
    }
}
@ 



<<[[Proc]] scheduling fields>>=
bool preempted;  /* true if this process hasn't finished the interrupt
       *  that last preempted it
       */
@

<<function preempt>>=
/*
 *  here at the end of non-clock interrupts to see if we should preempt the
 *  current process.
 */
void
preempt(void)
{
    if(up && up->state == Running)
      if(up->preempted == false)
        if(anyhigher())
          if(!active.exiting){
              cpu->readied = nil;   /* avoid cooperative scheduling */
              up->preempted = true;
              sched();
              arch_splhi(); // still in interrupt context
              up->preempted = false;
          }
    return;
}
@ 
% servicing an interrupt may have adjusted the readyness of higher priority
% process so preempt!

\subsection{Clock interrupt (x86)}
% see also Time chapter

% number of times per second we want to get a clock interrupt, called
% also a tick
<<constant HZ(x86)>>=
#define HZ    (100)     /* clock frequency */
@

<<constant Freq(x86)>>=
Freq=   1193182,    /* Real clock frequency */
@

<<struct I8253(x86)>>=
struct I8253
{
    ulong   period;     /* current clock period */
    bool    enabled;

    uvlong  hz;

    ushort  last;       /* last value of clock 1 */
    uvlong  ticks;      /* cumulative ticks of counter 1 */

    ulong   periodset;

    // extra
    Lock;
};
@


<<global i8253(x86)>>=
I8253 i8253;
@

<<function i8253init(x86)>>=
void
i8253init(void)
{
    int loops, x;

    ioalloc(T0cntr, 4, 0, "i8253");
    ioalloc(T2ctl, 1, 0, "i8253.cntr2ctl");

    i8253.period = Freq/HZ;

    /*
     *  enable a 1/HZ interrupt for providing scheduling interrupts
     */
    outb(Tmode, Load0|Square);
    outb(T0cntr, (Freq/HZ));    /* low byte */
    outb(T0cntr, (Freq/HZ)>>8); /* high byte */

    /*
     *  enable a longer period counter to use as a clock
     */
    outb(Tmode, Load2|Square);
    outb(T2cntr, 0);        /* low byte */
    outb(T2cntr, 0);        /* high byte */
    x = inb(T2ctl);
    x |= T2gate;
    outb(T2ctl, x);
    
    /*
     * Introduce a little delay to make sure the count is
     * latched and the timer is counting down; with a fast
     * enough processor this may not be the case.
     * The i8254 (which this probably is) has a read-back
     * command which can be used to make sure the counting
     * register has been written into the counting element.
     */
    x = (Freq/HZ);
    for(loops = 0; loops < 100000 && x >= (Freq/HZ); loops++){
        outb(Tmode, Latch0);
        x = inb(T0cntr);
        x |= inb(T0cntr)<<8;
    }
}
@

<<function i8253enable(x86)>>=
void
i8253enable(void)
{
    i8253.enabled = true;
    i8253.period = Freq/HZ;
    arch_intrenable(IrqCLOCK, i8253clock, 0, BUSUNKNOWN, "clock");
}
@

<<interrupt callback i8253clock(x86)>>=
static void
i8253clock(Ureg* ureg, void*)
{
    timerintr(ureg, 0);
}
@

% put in virtual memory section?
<<[[Cpu]] other fields>>=
bool flushmmu;   /* make current proc flush it's mmu state */
@


<<clock callback hzclock>>=
void
hzclock(Ureg *ur)
{
    cpu->ticks++;
    if(cpu->proc) // why not using up here? why cpu->proc?
        cpu->proc->pc = ur->pc;

    if(cpu->flushmmu){
        if(up)
            arch_flushmmu();
        cpu->flushmmu = false;
    }

    accounttime();
    //kmapinval();pc: bcm: a nope in both archs

    if(kproftimer != nil)
        kproftimer(ur->pc);

    if((active.cpus&(1<<cpu->cpuno)) == 0)
        return;

    if(active.exiting) {
        print("someone's exiting\n");
        exit(0);
    }

    checkalarms();

    if(up && up->state == Running)
        hzsched();  /* in proc.c */
}
@ 
% //todo: can be not Running? maybe if checkalarms resched?




\section{Customized scheduling}

<<[[Proc]] scheduling fields>>=
Cpu  *wired;
@

<<[[procctlreq()]] CMwired case>>=
case CMwired:
    procwired(p, atoi(cb->f[1]));
    break;
@

<<function procwired>>=
/*
 * wire this proc to a processor
 */
void
procwired(Proc *p, int bm)
{
    Proc *pp;
    int i;
    char nwired[MAXCPUS];
    Cpu *wm;

    if(bm < 0){
        /* pick a processor to wire to */
        memset(nwired, 0, sizeof(nwired));
        p->wired = nil;
        pp = proctab(0);
        for(i=0; i<conf.nproc; i++, pp++){
            wm = pp->wired;
            if(wm && pp->pid)
                nwired[wm->cpuno]++;
        }
        bm = 0;
        for(i=0; i<conf.ncpu; i++)
            if(nwired[i] < nwired[bm])
                bm = i;
    } else {
        /* use the virtual processor requested */
        bm = bm % conf.ncpu;
    }

    p->wired = CPUS(bm);
    p->lastcpu = p->wired;
}
@ 



\section{Real-time scheduling}
% see EDF section


\section{Halting (x86)}

<<function idlehands(x86)>>=
// current configuration
static bool idle_spin = false;
static int idle_if_nproc = 0;


/*
 *  put the processor in the halt state if we've no processes to run.
 *  an interrupt will get us going again.
 */
void
arch_idlehands(void)
{
    /*
     * we used to halt only on single-core setups. halting in an SMP system 
     * can result in a startup latency for processes that become ready.
     * if idle_spin is false, we care more about saving energy
     * than reducing this latency.
     *
     * the performance loss with idle_spin == false seems to be slight
     * and it reduces lock contention (thus system time and real time)
     * on many-core systems with large values of NPROC.
     */
    if(conf.ncpu == 1 || idle_spin == false ||
        (idle_if_nproc && conf.ncpu >= idle_if_nproc))
        halt();
}
@ 
% was just 'int idle_if_nproc;' but clearbss does the job of setting it to 0

<<function halt(x86)>>=
/*
 * Attempt at power saving. -rsc
 */
TEXT halt(SB), $0
        CLI
        CMPL    nrdy(SB), $0
        JEQ     _nothingready
        STI
        RET

_nothingready:
        STI
        HLT
        RET
@

% see halting just before initializing :)






\chapter{Initialization}
\minitoc

\section{Booting the kernel (x86)}

\subsection{Loading the kernel in physical memory}

% output of inm -n 9qemu  is nice! 2879 symbols!
% explain the text + data + bss part of the binary! see ksize 9qemu too

<<l_multiboot.s>>=
#include "mem.h"
        
TEXT _start(SB), $0

<<global _multibootheader(x86)>>

<<function _multibootentry(x86)>>

<<global multiboot(x86)>>
@

<<global _multibootheader(x86)>>=
/*
 * Must be 4-byte aligned.
 */
TEXT _multibootheader(SB), $0
        LONG    $0x1BADB002                     /* magic */
        LONG    $0x00010003                     /* flags */
        LONG    $-(0x1BADB002 + 0x00010003)     /* checksum */
        
        LONG    $_multibootheader-KZERO(SB)     /* header_addr */
        LONG    $_start-KZERO(SB)          /* load_addr */
        LONG    $edata-KZERO(SB)                /* load_end_addr */
        LONG    $end-KZERO(SB)                  /* bss_end_addr */
        
//      !!!entry point specification!!!
        LONG    $_multibootentry-KZERO(SB)              /* entry_addr */
        
        LONG    $0                              /* mode_type */
        LONG    $0                              /* width */
        LONG    $0                              /* height */
        LONG    $0                              /* depth */
@
% history: was called _startKADDR, but confusing I think

% about the page-aligned requirment:
% indeed, as we will see later binaries when exec'd are
% mapped to memory and we want the data section to be
% separate from text section so they can have different
% properties for their segments

<<function _multibootentry(x86)>>=
/* 
 * the kernel expects the data segment to be page-aligned
 * multiboot bootloaders put the data segment right behind text
 */
TEXT _multibootentry(SB), $0
        MOVL    $etext-KZERO(SB), SI
        MOVL    SI, DI
        ADDL    $0xfff, DI
        ANDL    $~0xfff, DI
        MOVL    $edata-KZERO(SB), CX
        SUBL    DI, CX
        ADDL    CX, SI
        ADDL    CX, DI
        STD
        REP; MOVSB
        CLD
        ADDL    $KZERO, BX
        MOVL    BX, multiboot-KZERO(SB)
//      !!! Jump !!!
        MOVL    $_setup_segmentation(SB), AX
        ANDL    $~KZERO, AX
        JMP*    AX
@
% can't do simply        MOVL    $_setup_segmentation-KZERO(SB), AX ?

<<lib.h exxx decl>>=
extern  char  etext[];
//@Scheck: Assembly, not dead used by 386/l.s
extern  char  edata[];
extern  char  end[];
@ 


<<global multiboot(x86)>>=
/* multiboot structure pointer */
TEXT multiboot(SB), $0
        LONG    $0
@


\subsection{Basic segmentation}

<<function _setup_segmentation(x86)>>=
TEXT _setup_segmentation(SB), $0
        CLI                     /* make sure interrupts are off */

        /* set up the gdt so we have sane plan 9 style gdts. */
        MOVL    $tgdtptr(SB), AX
        ANDL    $~KZERO, AX
        MOVL    (AX), GDTR
        MOVW    $1, AX
        MOVW    AX, MSW

        /* clear prefetch queue (weird code to avoid optimizations) */
        DELAY

        /* set segs to something sane (avoid traps later) */
        MOVW    $(1<<3), AX
        MOVW    AX, DS
        MOVW    AX, SS
        MOVW    AX, ES
        MOVW    AX, FS
        MOVW    AX, GS

/*      JMP     $(2<<3):$_setup_pagination(SB) /**/
         BYTE   $0xEA
         LONG   $_setup_pagination-KZERO(SB)
         WORD   $(2<<3)
@
% 1 << 3 for 1 selector (data segment, see tgdt) and because
% each entry is 8 bytes -> << 3.
%was called _startPADDR, not sure why, not really a PADDR
%old comment not valid anymore I think in qemu -kernel context
% * Entered via a jump to PADDR(entry),
% * the physical address of the virtual kernel entry point of KADDR(entry).




<<global tgdt(x86)>>=
/*
 *  gdt to get us to 32-bit/segmented/unpaged mode
 */
TEXT tgdt(SB), $0

        /* null descriptor */
        LONG    $0
        LONG    $0

        /* data segment descriptor for 4 gigabytes (PL 0) */
        LONG    $(0xFFFF)
        LONG    $(SEGG|SEGB|(0xF<<16)|SEGP|SEGPL(0)|SEGDATA|SEGW)

        /* exec segment descriptor for 4 gigabytes (PL 0) */
        LONG    $(0xFFFF)
        LONG    $(SEGG|SEGD|(0xF<<16)|SEGP|SEGPL(0)|SEGEXEC|SEGR)
@
%$
%tgdt? temporary gdt? compared to global gdt just have entries
% for kernel segments, the global gdt also have entries for user segment
% and TSS

<<global tgdtptr(x86)>>=
/*
 *  pointer to initial gdt
 *  Note the -KZERO which puts the physical address in the gdtptr. 
 *  that's needed as we start executing in physical addresses. 
 */
TEXT tgdtptr(SB), $0
        WORD    $(3*8)
        LONG    $tgdt-KZERO(SB)
@
%$

\subsection{Basic pagination}

<<function _setup_pagination(x86)>>=
/*
 * In protected mode with paging turned off and segment registers setup
 * to linear map all memory.
 * Make the basic page tables for processor 0. Five pages are needed for
 * the basic set:
 *      a page directory;
 *      page table for mapping the first 4MB of physical memory to KZERO;
 *      a page for the GDT;
 *      virtual and physical pages for mapping the Cpu structure.
 * The remaining PTEs will be allocated later when memory is sized.
 *
 * An identity mmu map is also needed for the switch to virtual mode.
 * This identity mapping is removed once the MMU is going and the JMP has
 * been made to virtual memory.
 */
TEXT _setup_pagination(SB), $0
        /* At this point, the GDT setup is done. */

        MOVL    $PADDR(CPU0PD), DI             /* clear 4 pages for the tables etc. */
        XORL    AX, AX
        MOVL    $(4*BY2PG), CX
        SHRL    $2, CX

        CLD
        REP;    STOSL

        MOVL    $PADDR(CPU0PD), AX
        ADDL    $PDO(KZERO), AX                 /* page directory offset for KZERO */
        MOVL    $PADDR(CPU0PT), (AX)           /* PTE's for KZERO */
        MOVL    $(PTEWRITE|PTEVALID), BX        /* page permissions */
        ORL     BX, (AX)


        MOVL    $PADDR(CPU0PT), AX             /* first page of page table */
        MOVL    $1024, CX                       /* 1024 pages in 4MB */
_setpte:
        MOVL    BX, (AX)
        ADDL    $(1<<PGSHIFT), BX
        ADDL    $4, AX
        LOOP    _setpte


        MOVL    $PADDR(CPU0PT), AX
        ADDL    $PTO(CPUADDR), AX              /* page table entry offset for CPUADDR */
        MOVL    $PADDR(CPU0CPU), (AX)          /* PTE for Cpu */
        MOVL    $(PTEWRITE|PTEVALID), BX        /* page permissions */
        ORL     BX, (AX)

/*
 * Now ready to use the new map. Make sure the processor options are what is wanted.
 * It is necessary on some processors to immediately follow mode switching with a JMP instruction
 * to clear the prefetch queues.
 */
        MOVL    $PADDR(CPU0PD), CX             /* load address of page directory */
        MOVL    (PDO(KZERO))(CX), DX            /* double-map KZERO at 0 */
        MOVL    DX, (PDO(0))(CX)

        MOVL    CX, CR3
        DELAY                                   /* JMP .+2 */

        MOVL    CR0, DX
        ORL     $0x80010000, DX                 /* PG|WP */
        ANDL    $~0x6000000A, DX                /* ~(CD|NW|TS|MP) */

        MOVL    $_setup_bss_stack(SB), AX       /* this is a virtual address */
        MOVL    DX, CR0                         /* turn on paging */
        JMP*    AX                              /* jump to the virtual nirvana */
@
%$

\subsection{BSS and stack initialization}

% the x86 archi does not have multi register, so have to use same
% pointer to differently mapped physical page
<<function _setup_bss_stack(x86)>>=
/*
 * Basic machine environment set, can clear BSS and create a stack.
 * The stack starts at the top of the page containing the Cpu structure.
 * The x86 architecture forces the use of the same virtual address for
 * each processor's Cpu structure, so the global Cpu pointer 'cpu' can
 * be initialised here.
 */
TEXT _setup_bss_stack(SB), $0
        MOVL    $0, (PDO(0))(CX)                /* undo double-map of KZERO at 0 */
        MOVL    CX, CR3                         /* load and flush the mmu */

_clearbss:
        MOVL    $edata(SB), DI
        XORL    AX, AX
        MOVL    $end(SB), CX
        SUBL    DI, CX                          /* end-edata bytes */
        SHRL    $2, CX                          /* end-edata doublewords */

        CLD
        REP;    STOSL                           /* clear BSS */

        MOVL    $CPUADDR, SP
        MOVL    SP, cpu(SB)                /* initialise global Cpu pointer */
        MOVL    $0, 0(SP)                       /* initialise cpu->cpuno */


        ADDL    $(CPUSIZE-4), SP               /* initialise stack */

<<end of _setup_bss_stack(x86)>>
@


\subsection{Jumping to C [[main()]]}

% or do another function and in previous code to a JMP _last_before_main?
<<end of _setup_bss_stack(x86)>>=
/*
 * Need to do one final thing to ensure a clean machine environment,
 * clear the EFLAGS register, which can only be done once there is a stack.
 */
        MOVL    $0, AX
        PUSHL   AX
        POPFL

        CALL    main(SB)
@
%$

\section{Kernel initialization (x86)}

<<function main(x86)>>=
//@Scheck: not dead, entry point :) jumped from assembly at _startpg() end
void main(void)
{
    // initial assignment made to avoid circular dependencies in codegraph
    <<[[main()]] initial assignments for backward deps(x86)>>

    cgapost(0);

    cpu0init(); // cpu0 initialization (calls cpuinit())

    options(); // setup values for getconf() from bootloader config
    // example of manual config:
    // TODO confname(``console'') = 1?

    ioinit(); // does some getconf("ioexclude") so must be after options()

    arch_screeninit(); // screenputs = cgascreenputs
    quotefmtinstall(); // libc printf initialization
    i8250console(); // setup optional serial console if getconf("console") == 1
    print("\nPlan 9\n");

    // the init0 means this is really early on (e.g. malloc is not available)
    trapinit0();
    mmuinit0();

    kbdinit(); // kbd is then fully enabled below via kdbenable()
    i8253init(); // clock controller

    cpuidentify(); // setup cpu, to know which advanced features we can enable
    arch_cpuidprint();

    meminit(); // setup conf.mem memory banks and setup more PDEs and PTEs
    confinit(); // setup conf (and mainmem->maxsize, imagmem->maxsize)
    archinit(); // setup arch
    xinit(); // setup xlists for xalloc() and palloc.mem for pageinit()
    if(i8237alloc != nil)
            i8237alloc(); // setup DMA, need low memory below 16MB

    arch_trapinit();
    arch_mmuinit();

    fpsavealloc();
    if(arch->intrinit)      /* launches other processors on an mp */
        arch->intrinit();

    timersinit();
    mathinit();

    kbdqinit(); // setup kbdq
    kbdenable(); // enable interrupts
    lineqinit(); // setup lineq

    if(arch->clockenable)
        arch->clockenable();

    procinit();
    imageinit();

    links();

    // initialize all devices
    chandevreset();
    cgapost(0xcd); // 0xcd, for chandev :)

    pageinit(); // setup palloc.pages and swapalloc.highwater
    swapinit(); // setup swapalloc

    // let's craft our first process (that will then exec("boot/boot"))
    userinit();
    <<[[main()]] before schedinit()(x86)>>
    cgapost(0x99); // done!
    schedinit();
    panic("should never reach this point");
}
@

\subsection{[[cpu]] initialization}

<<function cpu0init(x86)>>=
void
cpu0init(void)
{
    conf.ncpu = 1;
    // note that cpu points to CPUADDR, which then is mapped to CPU0CPU
    // via the page directory/page table setup in cr3 on the first processor
    CPUS(0) = (Cpu*)CPU0CPU;
    cpu->pdproto = (kern_addr2)CPU0PD;
    cpu->gdt = (Segdesc*)CPU0GDT;

    cpuinit();

    active.cpus = 1;
    active.exiting = false;
}
@

% inline in previous func? no? because used in squidboy too!
<<function cpuinit(x86)>>=
void
cpuinit(void)
{
    int cpuno;
    kern_addr2 mmupd;
    Segdesc *gdt;

    cpuno = cpu->cpuno;
    mmupd = cpu->pdproto;
    gdt = cpu->gdt;
    memset(cpu, 0, sizeof(Cpu));
    cpu->cpuno = cpuno;
    cpu->pdproto = mmupd;
    cpu->gdt = gdt;

    cpu->perf.period = 1;
    /*
     * For polled uart output at boot, need
     * a default delay constant. 100000 should
     * be enough for a while. Cpuidentify will
     * calculate the real value later.
     */
    cpu->loopconst = 100000;
}
@


\subsection{CPU detection}

<<[[Cpu]] [[Arch]] cpuid fields(x86)>>=
char  cpuidid[16];
char* cpuidtype;
int cpuidax;
int cpuiddx;
@

% put code guesscpu? guesshz? but quite long and ugly ...
% or maybe can simplify?

<<function cpuidprint(x86)>>=
void
arch_cpuidprint(void)
{
    int i;
    char buf[128];

    i = snprint(buf, sizeof buf, "cpu%d: %s%dMHz ", cpu->cpuno,
        cpu->cpuno < 10? " ": "", cpu->cpumhz);
    if(cpu->cpuidid[0])
        i += sprint(buf+i, "%12.12s ", cpu->cpuidid);
    seprint(buf+i, buf + sizeof buf - 1,
        "%s (cpuid: AX 0x%4.4uX DX 0x%4.4uX)\n",
        cpu->cpuidtype, cpu->cpuidax, cpu->cpuiddx);
    print(buf);
}
@

\subsection{[[arch]] initialization}

% main -> <>
<<function archinit(x86)>>=
void
archinit(void)
{
    PCArch **p;

    arch = nil;
    for(p = knownarch; *p; p++){
        if((*p)->ident && (*p)->ident() == 0){
            arch = *p;
            break;
        }
    }
    if(arch == nil)
        arch = &archgeneric;
    else{
        if(arch->id == 0)
            arch->id = archgeneric.id;
        if(arch->reset == 0)
            arch->reset = archgeneric.reset;
        if(arch->serialpower == 0)
            arch->serialpower = archgeneric.serialpower;
        if(arch->modempower == 0)
            arch->modempower = archgeneric.modempower;
        if(arch->intrinit == 0)
            arch->intrinit = archgeneric.intrinit;
        if(arch->intrenable == 0)
            arch->intrenable = archgeneric.intrenable;
    }

    /*
     *  Decide whether to use copy-on-reference (386 and mp).
     *  We get another chance to set it in mpinit() for a
     *  multiprocessor.
     */
    if(X86FAMILY(cpu->cpuidax) == 3)
        conf.copymode = true;

    if(X86FAMILY(cpu->cpuidax) >= 4)
        arch_cmpswap = cmpswap486;

    if(X86FAMILY(cpu->cpuidax) >= 5)
        arch_coherence = mb586;

    if(cpu->cpuiddx & Sse2)
        arch_coherence = mfence;

    addarchfile("cputype", 0444, cputyperead, nil);
    addarchfile("archctl", 0664, archctlread, archctlwrite);
}
@

\subsection{Memory detection}

<<struct Map(x86)>>=
struct Map {
    phys_addr addr;
    ulong size; // in bytes
};
@
% bad name ... too many Map names


% Ram Map
<<struct RMap(x86)>>=
struct RMap {
    char*   name;
    //ref<Map> in mapram
    Map*    map;
    //ref<Map> in mapram
    Map*    mapend;
    Lock;
};
@
%todo: why not use the simpler approach of Conf.mem and Palloc.mem?

<<enum memkind(x86)>>=
enum memkind {
    MemUPA,        /* unbacked physical address */
    MemRAM,        /* physical memory */
    MemUMB,        /* upper memory block (<16MB) */

    NMemType, // must be last
};
@

<<global mapram(x86)>>=
static Map mapram[16];
static RMap rmapram = {
    "physical memory",
    mapram,
    &mapram[nelem(mapram)-1],
};
@

<<function meminit(x86)>>=
void
meminit(void)
{
    int i;
    Map *mp;
    Confmem *cm;
    phys_addr pa;
    kern_addr2 pte;
    phys_addr maxmem;
    ulong lost;
    char *p;

    if(p = getconf("*maxmem"))
        maxmem = strtoul(p, 0, 0);
    else
        maxmem = 0;

    /*
     * Set special attributes for memory between 640KB and 1MB:
     *   VGA memory is writethrough;
     *   BIOS ROM's/UMB's are uncached;
     * then scan for useful memory.
     */
    for(pa = 0xA0000; pa < 0xC0000; pa += BY2PG){
        pte = mmuwalk(cpu->pdproto, (kern_addr)KADDR(pa), 2, false);
        *pte |= PTEWT;
    }
    for(pa = 0xC0000; pa < 0x100000; pa += BY2PG){
        pte = mmuwalk(cpu->pdproto, (kern_addr)KADDR(pa), 2, false);
        *pte |= PTEUNCACHED;
    }
    mmuflushtlb(PADDR(cpu->pdproto));

    umbscan();
    lowraminit();
    ramscan(maxmem);

    /*
     * Set the conf entries describing banks of allocatable memory.
     */
    for(i=0; i<nelem(mapram) && i<nelem(conf.mem); i++){
        mp = &rmapram.map[i];
        cm = &conf.mem[i];
        cm->base = mp->addr;
        cm->npage = mp->size/BY2PG;
    }
    
    lost = 0;
    for(; i<nelem(mapram); i++)
        lost += rmapram.map[i].size;
    if(lost)
        print("meminit - lost %lud bytes\n", lost);
    if(MEMDEBUG)
        memdebug();
}
@

<<function mmuflushtlb(x86)>>=
#define mmuflushtlb(mmupd) putcr3(mmupd)
@





<<function mapfree(x86)>>=
void
mapfree(RMap* rmap, phys_addr addr, ulong size)
{
    Map *mp;
    ulong t;

    if(size <= 0)
        return;

    lock(rmap);
    for(mp = rmap->map; mp->addr <= addr && mp->size; mp++)
        ;

    if(mp > rmap->map && (mp-1)->addr+(mp-1)->size == addr){
        (mp-1)->size += size;
        if(addr+size == mp->addr){
            (mp-1)->size += mp->size;
            while(mp->size){
                mp++;
                (mp-1)->addr = mp->addr;
                (mp-1)->size = mp->size;
            }
        }
    }
    else{
        if(addr+size == mp->addr && mp->size){
            mp->addr -= size;
            mp->size += size;
        }
        else do{
            if(mp >= rmap->mapend){
                print("mapfree: %s: losing 0x%luX, %ld\n",
                    rmap->name, addr, size);
                break;
            }
            t = mp->addr;
            mp->addr = addr;
            addr = t;
            t = mp->size;
            mp->size = size;
            mp++;
        }while(size = t);
    }
    unlock(rmap);
}
@


<<function mapalloc(x86)>>=
ulong
mapalloc(RMap* rmap, ulong addr, int size, int align)
{
    Map *mp;
    ulong maddr, oaddr;

    lock(rmap);
    for(mp = rmap->map; mp->size; mp++){
        maddr = mp->addr;

        if(addr){
            /*
             * A specific address range has been given:
             *   if the current map entry is greater then
             *   the address is not in the map;
             *   if the current map entry does not overlap
             *   the beginning of the requested range then
             *   continue on to the next map entry;
             *   if the current map entry does not entirely
             *   contain the requested range then the range
             *   is not in the map.
             */
            if(maddr > addr)
                break;
            if(mp->size < addr - maddr) /* maddr+mp->size < addr, but no overflow */
                continue;
            if(addr - maddr > mp->size - size)  /* addr+size > maddr+mp->size, but no overflow */
                break;
            maddr = addr;
        }

        if(align > 0)
            maddr = ((maddr+align-1)/align)*align;
        if(mp->addr+mp->size-maddr < size)
            continue;

        oaddr = mp->addr;
        mp->addr = maddr+size;
        mp->size -= maddr-oaddr+size;
        if(mp->size == 0){
            do{
                mp++;
                (mp-1)->addr = mp->addr;
            }while((mp-1)->size = mp->size);
        }

        unlock(rmap);
        if(oaddr != maddr)
            mapfree(rmap, oaddr, maddr-oaddr);

        return maddr;
    }
    unlock(rmap);
    return nilptr;
}
@



<<function rampage(x86)>>=
/*
 * Allocate from the ram map directly to make page tables.
 * Called by mmuwalk during e820scan.
 */
kern_addr3
rampage(void)
{
    phys_addr m;
    
    m = mapalloc(&rmapram, 0, BY2PG, BY2PG);
    if(m == nilptr)
        return nil;
    return KADDR(m);
}
@



<<function umbscan(x86)>>=
static void
umbscan(void)
{
    byte o[2], *p;

    /*
     * Scan the Upper Memory Blocks (0xA0000->0xF0000) for pieces
     * which aren't used; they can be used later for devices which
     * want to allocate some virtual address space.
     * Check for two things:
     * 1) device BIOS ROM. This should start with a two-byte header
     *    of 0x55 0xAA, followed by a byte giving the size of the ROM
     *    in 512-byte chunks. These ROM's must start on a 2KB boundary.
     * 2) device memory. This is read-write.
     * There are some assumptions: there's VGA memory at 0xA0000 and
     * the VGA BIOS ROM is at 0xC0000. Also, if there's no ROM signature
     * at 0xE0000 then the whole 64KB up to 0xF0000 is theoretically up
     * for grabs; check anyway.
     */
    p = KADDR(0xD0000);
    while(p < KADDR(0xE0000)){
        /*
         * Check for the ROM signature, skip if valid.
         */
        if(p[0] == 0x55 && p[1] == 0xAA){
            p += p[2]*512;
            continue;
        }

        /*
         * Is it writeable? If yes, then stick it in
         * the UMB device memory map. A floating bus will
         * return 0xff, so add that to the map of the
         * UMB space available for allocation.
         * If it is neither of those, ignore it.
         */
        o[0] = p[0];
        p[0] = 0xCC;
        o[1] = p[2*KB-1];
        p[2*KB-1] = 0xCC;
        if(p[0] == 0xCC && p[2*KB-1] == 0xCC){
            p[0] = o[0];
            p[2*KB-1] = o[1];
            mapfree(&rmapumbrw, PADDR(p), 2*KB);
        }
        else if(p[0] == 0xFF && p[1] == 0xFF)
            mapfree(&rmapumb, PADDR(p), 2*KB);
        p += 2*KB;
    }

    p = KADDR(0xE0000);
    if(p[0] != 0x55 || p[1] != 0xAA){
        p[0] = 0xCC;
        p[64*KB-1] = 0xCC;
        if(p[0] != 0xCC && p[64*KB-1] != 0xCC)
            mapfree(&rmapumb, PADDR(p), 64*KB);
    }
}
@




<<function lowraminit(x86)>>=
static void
lowraminit(void)
{
    ulong n, pa, x;
    byte *bda;

    /*
     * Initialise the memory bank information for conventional memory
     * (i.e. less than 640KB). The base is the first location after the
     * bootstrap processor MMU information and the limit is obtained from
     * the BIOS data area.
     */
    x = PADDR(CPU0END);
    bda = (byte*)KADDR(0x400);
    n = ((bda[0x14]<<8)|bda[0x13])*KB-x;
    mapfree(&rmapram, x, n);
    memset(KADDR(x), 0, n);         /* keep us honest */

    x = PADDR(PGROUND((ulong)end));
    pa = MemMin;
    if(x > pa)
        panic("kernel too big");
    mapfree(&rmapram, x, pa-x);
    memset(KADDR(x), 0, pa-x);      /* keep us honest */
}
@
% >>



<<function ramscan(x86)>>=
static void
ramscan(phys_addr maxmem)
{
    ulong *k0, kzero, map, *pte, *table, *va, vbase, x;
    phys_addr pa, maxpa, maxkpa;

    // hash<enum<memtype>, int> nb pages per memory type
    int nvalid[NMemType];

    /*
     * The bootstrap code has created a prototype page
     * table which maps the first MemMin of physical memory to KZERO.
     * The page directory is at cpu->pdproto and the first page of
     * free memory is after the per-processor MMU information.
     */
    pa = MemMin;

    /*
     * Check if the extended memory size can be obtained from the CMOS.
     * If it's 0 then it's either not known or >= 64MB. Always check
     * at least 24MB in case there's a memory gap (up to 8MB) below 16MB;
     * in this case the memory from the gap is remapped to the top of
     * memory.
     * The value in CMOS is supposed to be the number of KB above 1MB.
     */
    if(maxmem == 0){
        x = (nvramread(0x18)<<8)|nvramread(0x17);
        if(x == 0 || x >= (63*KB))
            maxpa = MemMax;
        else
            maxpa = MB+x*KB;
        if(maxpa < 24*MB)
            maxpa = 24*MB;
    }else
        maxpa = maxmem;

    maxkpa = MAXKPA; /* 2^32 - KZERO */

    /*
     * March up memory from MemMin to maxpa 1MB at a time,
     * mapping the first page and checking the page can
     * be written and read correctly. The page tables are created here
     * on the fly, allocating from low memory as necessary.
     */
    k0 = (kern_addr2)KADDR(0);
    kzero = *k0;
    map = 0;
    x = 0x12345678;
    memset(nvalid, 0, sizeof(nvalid));
    
    /*
     * Can't map memory to KADDR(pa) when we're walking because
     * can only use KADDR for relatively low addresses.
     * Instead, map each 4MB we scan to the virtual address range
     * MemMin->MemMin+4MB while we are scanning.
     */
    vbase = MemMin;
    while(pa < maxpa){
        /*
         * Map the page. Use mapalloc(&rmapram, ...) to make
         * the page table if necessary, it will be returned to the
         * pool later if it isn't needed.  Map in a fixed range (the second 4M)
         * because high physical addresses cannot be passed to KADDR.
         */
        va = (void*)(vbase + pa%(4*MB));
        table = &cpu->pdproto[PDX(va)];
        if(pa%(4*MB) == 0){
            if(map == 0 && (map = mapalloc(&rmapram, 0, BY2PG, BY2PG)) == 0)
                break;
            memset(KADDR(map), 0, BY2PG);
            *table = map|PTEWRITE|PTEVALID;
            memset(nvalid, 0, sizeof(nvalid));
        }
        table = KADDR(PPN(*table));
        pte = &table[PTX(va)];

        *pte = pa|PTEWRITE|PTEUNCACHED|PTEVALID;
        mmuflushtlb(PADDR(cpu->pdproto));
        /*
         * Write a pattern to the page and write a different
         * pattern to a possible mirror at KZERO. If the data
         * reads back correctly the chunk is some type of RAM (possibly
         * a linearly-mapped VGA framebuffer, for instance...) and
         * can be cleared and added to the memory pool. If not, the
         * chunk is marked uncached and added to the UMB pool if <16MB
         * or is marked invalid and added to the UPA pool.
         */
        *va = x;
        *k0 = ~x;
        if(*va == x){
            nvalid[MemRAM] += MB/BY2PG;
            mapfree(&rmapram, pa, MB);

            do{
                *pte++ = pa|PTEWRITE|PTEVALID;
                pa += BY2PG;
            }while(pa % MB);
            mmuflushtlb(PADDR(cpu->pdproto));
            /* memset(va, 0, MB); so damn slow to memset all of memory */
        }
        else if(pa < 16*MB){
            nvalid[MemUMB] += MB/BY2PG;
            mapfree(&rmapumb, pa, MB);

            do{
                *pte++ = pa|PTEWRITE|PTEUNCACHED|PTEVALID;
                pa += BY2PG;
            }while(pa % MB);
        }
        else{
            nvalid[MemUPA] += MB/BY2PG;
            mapfree(&rmapupa, pa, MB);
            *pte = 0;
            pa += MB;
        }

        /*
         * Done with this 4MB chunk, review the options:
         * 1) not physical memory and >=16MB - invalidate the PD entry;
         * 2) physical memory - use the 4MB page extension if possible;
         * 3) not physical memory and <16MB - use the 4MB page extension
         *    if possible;
         * 4) mixed or no 4MB page extension - commit the already
         *    initialised space for the page table.
         */
        if(pa%(4*MB) == 0 && pa >= 32*MB && nvalid[MemUPA] == (4*MB)/BY2PG){
            /*
             * If we encounter a 4MB chunk of missing memory
             * at a sufficiently high offset, call it the end of
             * memory.  Otherwise we run the risk of thinking
             * that video memory is real RAM.
             */
            break;
        }
        if(pa <= maxkpa && pa%(4*MB) == 0){
            table = &cpu->pdproto[PDX(KADDR(pa - 4*MB))];
            if(nvalid[MemUPA] == (4*MB)/BY2PG)
                *table = 0;
            else if(nvalid[MemRAM] == (4*MB)/BY2PG && (cpu->cpuiddx & 0x08))
                *table = (pa - 4*MB)|PTESIZE|PTEWRITE|PTEVALID;
            else if(nvalid[MemUMB] == (4*MB)/BY2PG && (cpu->cpuiddx & 0x08))
                *table = (pa - 4*MB)|PTESIZE|PTEWRITE|PTEUNCACHED|PTEVALID;
            else{
                *table = map|PTEWRITE|PTEVALID;
                map = 0;
            }
        }
        mmuflushtlb(PADDR(cpu->pdproto));
        x += 0x3141526;
    }
    /*
     * If we didn't reach the end of the 4MB chunk, that part won't
     * be mapped.  Commit the already initialised space for the page table.
     */
    if(pa % (4*MB) && pa <= maxkpa){
        cpu->pdproto[PDX(KADDR(pa))] = map|PTEWRITE|PTEVALID;
        map = 0;
    }
    if(map)
        mapfree(&rmapram, map, BY2PG);

    cpu->pdproto[PDX(vbase)] = 0;
    mmuflushtlb(PADDR(cpu->pdproto));

    mapfree(&rmapupa, pa, (u32int)(-pa));
    *k0 = kzero;
}
@




\subsection{[[conf]] initialization}

% already set conf.ncpu (but to 1), and conf.mem normally

<<[[Conf]] other fields>>=
ulong npage;    /* total physical pages of memory */

ulong upages;   /* user page pool */ 
// kpages = npage - upages

ulong nimage;   /* number of page cache image headers */
ulong ialloc;   /* max interrupt time allocation in bytes */
@

<<function confinit(x86)>>=
// precondition: meminit() have initialized Conf.mem
void
confinit(void)
{
    char *p;
    int i, userpcnt;
    ulong kpages;
    ulong kmem;

    if(p = getconf("*kernelpercent"))
        userpcnt = 100 - strtol(p, 0, 0);
    else
        userpcnt = 0;

    conf.npage = 0;
    for(i=0; i<nelem(conf.mem); i++)
        conf.npage += conf.mem[i].npage;

    // 1 process per 250Ko of available memory
    conf.nproc = 100 + ((conf.npage*BY2PG)/MB)*5;
    if(cpuserver)
        conf.nproc *= 3;
    if(conf.nproc > 2000)
        conf.nproc = 2000;

    conf.nimage = 200;

    conf.nswap = conf.nproc*80;
    conf.nswppo = 4096;

    if(cpuserver) {
        if(userpcnt < 10)
            userpcnt = 70;
        kpages = conf.npage - (conf.npage*userpcnt)/100;

        /*
         * Hack for the big boys. Only good while physmem < 4GB.
         * Give the kernel fixed max + enough to allocate the
         * page pool.
         * This is an overestimate as conf.upages < conf.npages.
         * The patch of nimage is a band-aid, scanning the whole
         * page list in imagereclaim just takes too long.
         */
        if(kpages > (128*MB + conf.npage*sizeof(Page))/BY2PG){
            kpages = (128*MB + conf.npage*sizeof(Page))/BY2PG;
            conf.nimage = 2000;
            kpages += (conf.nproc*KSTACK)/BY2PG;
        }
    } else {
        if(userpcnt < 10) {
            if(conf.npage*BY2PG < 16*MB)
                userpcnt = 40;
            else
                userpcnt = 80;
        }
        kpages = conf.npage - (conf.npage*userpcnt)/100;

        /*
         * Make sure terminals with low memory get at least
         * 4MB on the first Image chunk allocation.
         */
        if(conf.npage*BY2PG < 16*MB)
            imagmem->minarena = 4*MB;
    }

    /*
     * can't go past the end of virtual memory
     */
    if(kpages > MAXKPA/BY2PG)
        kpages = MAXKPA/BY2PG;

    conf.upages = conf.npage - kpages;
    conf.ialloc = (kpages/2)*BY2PG;

    /*
     * Guess how much is taken by the large permanent
     * datastructures. Mntcache and Mntrpc are not accounted for
     * (probably ~300KB).
     */
    kmem = kpages * BY2PG;
    kmem -= conf.upages*sizeof(Page)
            + conf.nproc*sizeof(Proc)
            + conf.nimage*sizeof(KImage)
            + conf.nswap
            + conf.nswppo*sizeof(Page*); // pad's second bugfix :)
    mainmem->maxsize = kmem;
    if(!cpuserver){
        /*
         * give terminals lots of image memory, too; the dynamic
         * allocation will balance the load properly, hopefully.
         * be careful with 32-bit overflow.
         */
        imagmem->maxsize = kmem;
    }
}
@
%bug: see pad's bugfix above

%references also mainmem, imagmem

% see also cat /dev/swap

\subsection{[[idt]] initialization}

<<function trapinit0(x86)>>=
/*
 * Minimal trap setup.  Just enough so that we can panic
 * on traps (bugs) during kernel initialization.
 * Called very early - malloc is not yet available.
 */
void
trapinit0(void)
{
    int d1, v;
    kern_addr vaddr;
    Segdesc *idt;

    idt = (Segdesc*)IDTADDR;
    vaddr = (kern_addr)vectortable;
    for(v = 0; v < 256; v++){
        d1 = (vaddr & 0xFFFF0000)|SEGP;
        switch(v){
        case VectorBPT:
            d1 |= SEGPL(3)|SEGIG;
            break;
        case VectorSYSCALL:
            d1 |= SEGPL(3)|SEGIG;
            break;
        default:
            d1 |= SEGPL(0)|SEGIG;
            break;
        }
        idt[v].d0 = (vaddr & 0xFFFF)|(KESEL<<16);
        idt[v].d1 = d1;
        vaddr += 6;
    }
}
@ 
% >>

<<function trapinit(x86)>>=
void
arch_trapinit(void)
{
    /*
     * Special traps.
     * Syscall() is called directly without going through trap().
     */
    trapenable(VectorBPT, debugbpt, 0, "debugpt");
    trapenable(VectorPF, fault386, 0, "fault386");

    trapenable(Vector2F, doublefault, 0, "doublefault");
    trapenable(Vector15, unexpected, 0, "unexpected");
    nmienable();

    addarchfile("irqalloc", 0444, irqallocread, nil);
    trapinited = true;
}
@ 
% LP split! put debugpt line in debugging section, VectorPF in Page fault?

<<global trapinited(x86)>>=
static bool trapinited;
@

% ??
<<function doublefault(x86)>>=
static void
doublefault(Ureg*, void*)
{
    panic("double fault");
}
@ 

% ??
<<function unexpected(x86)>>=
static void
unexpected(Ureg* ureg, void*)
{
    print("unexpected trap %lud; ignoring\n", ureg->trap);
}
@ 

\subsection{Virtual memory initialisation}

<<function mmuinit0(x86)>>=
void
mmuinit0(void)
{
    // cpu->gdt should point to CPU0GDT, see cpu0init
    memmove(cpu->gdt, gdt, sizeof gdt); 
}
@

% need xinit? cos mmuwalk possible call xspanalloc?
% todo simplify the code?
<<function mmuinit(x86)>>=
void
arch_mmuinit(void)
{
    ulong x, *p;
    ushort ptr[3];

    didmmuinit = true;

    memglobal();
    <<[[mmuinit()]] vpt adjusments(x86)>>
    
    cpu->tss = malloc(sizeof(Tss));
    if(cpu->tss == nil)
        panic("mmuinit: no memory");
    memset(cpu->tss, 0, sizeof(Tss));
    cpu->tss->iomap = 0xDFFF<<16;

    /*
     * We used to keep the GDT in the Cpu structure, but it
     * turns out that that slows down access to the rest of the
     * page.  Since the Cpu structure is accessed quite often,
     * it pays off anywhere from a factor of 1.25 to 2 on real
     * hardware to separate them (the AMDs are more sensitive
     * than Intels in this regard).  Under VMware it pays off
     * a factor of about 10 to 100.
     */
     // so now cpu->gdt is a pointer to another page (CPU0GDT <> CPUADDR)
     // but why it was slowing down things to have both data in same page?

    // we already did that in mmuinit0, but mmuinit is also called by
    // the other processors which don't call mmuinit0 and which have
    // a different cpu->gdt pointer.
    memmove(cpu->gdt, gdt, sizeof gdt); 
    x = (ulong)cpu->tss;
    cpu->gdt[TSSSEG].d0 = (x<<16)|sizeof(Tss);
    cpu->gdt[TSSSEG].d1 = (x&0xFF000000)|((x>>16)&0xFF)|SEGTSS|SEGPL(0)|SEGP;

    ptr[0] = sizeof(gdt)-1;
    x = (ulong)cpu->gdt;
    ptr[1] = x & 0xFFFF;
    ptr[2] = (x>>16) & 0xFFFF;
    lgdt(ptr);

    ptr[0] = sizeof(Segdesc)*256-1;
    x = IDTADDR;
    ptr[1] = x & 0xFFFF;
    ptr[2] = (x>>16) & 0xFFFF;
    lidt(ptr);

    /* make kernel text unwritable */
    for(x = KTZERO; x < (ulong)etext; x += BY2PG){
        p = mmuwalk(cpu->pdproto, x, 2, false);
        if(p == nil)
            panic("mmuinit");
        *p &= ~PTEWRITE;
    }

    taskswitch(PADDR(cpu->pdproto),  (ulong)cpu + BY2PG);
    ltr(TSSSEL);
}
@

<<global didmmuinit(x86)>>=
static bool didmmuinit;
@


<<[[Cpu]] [[Arch]] other fields(x86)>>=
int havepge;
@

<<function memglobal(x86)>>=
/* 
 * On processors that support it, we set the PTEGLOBAL bit in
 * page table and page directory entries that map kernel memory.
 * Doing this tells the processor not to bother flushing them
 * from the TLB when doing the TLB flush associated with a 
 * context switch (write to CR3).  Since kernel memory mappings
 * are never removed, this is safe.  (If we ever remove kernel memory
 * mappings, we can do a full flush by turning off the PGE bit in CR4,
 * writing to CR3, and then turning the PGE bit back on.) 
 *
 * See also mmukmap below.
 * 
 * Processor support for the PTEGLOBAL bit is enabled in devarch.c.
 */
static void
memglobal(void)
{
    int i, j;
    ulong *pd, *pt;

    /* only need to do this once, on bootstrap processor */
    if(cpu->cpuno != 0)
        return;

    if(!cpu->havepge)
        return;

    pd = cpu->pdproto;
    for(i=PDX(KZERO); i<1024; i++){
        if(pd[i] & PTEVALID){
            pd[i] |= PTEGLOBAL;
            if(!(pd[i] & PTESIZE)){
                pt = KADDR(pd[i]&~(BY2PG-1));
                for(j=0; j<1024; j++)
                    if(pt[j] & PTEVALID)
                        pt[j] |= PTEGLOBAL;
            }
        }
    }           
}
@

\subsection{Memory initialisation}

%setup kernel memory xlists and also palloc.mem which is all about user memory

<<function xinit>>=
void
xinit(void)
{
    int i;
    int nkpages;
    int kpages;
    ulong maxpages;
    Confmem *m;
    Pallocmem *pm;
    Hole *h, *eh;

    eh = &xlists.hole[Nhole-1];
    for(h = xlists.hole; h < eh; h++)
        h->next = h+1;

    xlists.unused_slots = xlists.hole;

    kpages = conf.npage - conf.upages;

    pm = palloc.mem;
    for(i=0; i<nelem(conf.mem); i++){
        m = &conf.mem[i];
        nkpages = m->npage;
        if(nkpages > kpages)
            nkpages = kpages; // will be zero once kpages has been filled
        /* don't try to use non-KADDR-able memory for kernel */
        maxpages = arch_cankaddr(m->base)/BY2PG;
        if(nkpages > maxpages)
            nkpages = maxpages;

        /* first give to kernel */
        if(nkpages > 0){
            xhole(m->base, nkpages*BY2PG);
            kpages -= nkpages;
            <<[[xinit()]] nkpages kernel memory in m>>
        }

        /* if anything left over, give to user */
        if(m->npage > nkpages){
            if(pm >= palloc.mem+nelem(palloc.mem)){
                print("xinit: losing %lud pages\n", m->npage-nkpages);
                continue;
            }
            pm->base = m->base+nkpages*BY2PG;
            pm->npage = m->npage - nkpages;
            pm++;
        }
    }
}
@


<<function procinit>>=
void
procinit(void)
{
    Proc *p;
    int i;

    procalloc.free = xalloc(conf.nproc*sizeof(Proc));
    if(procalloc.free == nil){
        xsummary();
        panic("cannot allocate %lud procs (%ludMB)\n", 
                      conf.nproc, conf.nproc*sizeof(Proc)/MB);
    }
    procalloc.arena = procalloc.free;

    p = procalloc.free;
    for(i=0; i<conf.nproc-1; i++,p++)
        p->qnext = p+1;
    p->qnext = nil;
}
@ 
%old: old was called procinit0 to not conflict with devproc.c procinit


<<function pageinit>>=
void
pageinit(void)
{
    int i, j;
    Page *p;
    Pallocmem *pm;
    ulong m, np, k, vkb, pkb;
    int color;

    np = 0;
    for(i=0; i<nelem(palloc.mem); i++){
        pm = &palloc.mem[i];
        np += pm->npage;
    }
    palloc.pages = xalloc(np*sizeof(Page));
    if(palloc.pages == nil)
        panic("pageinit");

 color = 0;
    palloc.head = palloc.pages;
    p = palloc.head;
    for(i=0; i<nelem(palloc.mem); i++){
        pm = &palloc.mem[i];
        for(j=0; j<pm->npage; j++){
            p->prev = p-1;
            p->next = p+1;
            p->pa = pm->base+j*BY2PG;
   p->color = color;
            palloc.freecount++;
   color = (color+1)%NCOLOR;
            p++;
        }
    }
    palloc.tail = p - 1;
    palloc.head->prev = nil;
    palloc.tail->next = nil;

    palloc.user = p - palloc.pages;
    assert(palloc.user == np);

    pkb = palloc.user*BY2PG/KB;
    vkb = pkb + (conf.nswap*BY2PG)/KB;

    /* Paging numbers */
    swapalloc.highwater = (palloc.user*5)/100;
    swapalloc.headroom = swapalloc.highwater + (swapalloc.highwater/4);

    // diagnostic
    m = 0;
    for(i=0; i<nelem(conf.mem); i++)
        if(conf.mem[i].npage)
            m += conf.mem[i].npage*BY2PG;
    k = PGROUND(end - (char*)KTZERO);
    print("%ldM memory: ", (m+k+1024*1024-1)/(1024*1024));
    print("%ldM kernel data, ", (m+k-pkb*1024+1024*1024-1)/(1024*1024));
    print("%ldM user, ", pkb/1024);
    print("%ldM swap\n", vkb/1024);
}
@


<<function swapinit>>=
void
swapinit(void)
{
    swapalloc.swmap = xalloc(conf.nswap);
    swapalloc.top = &swapalloc.swmap[conf.nswap];
    swapalloc.alloc = swapalloc.swmap;
    swapalloc.last = swapalloc.swmap;
    swapalloc.free = conf.nswap;
    iolist = xalloc(conf.nswppo*sizeof(Page*));
    if(swapalloc.swmap == nil || iolist == nil)
        panic("swapinit: not enough memory");

    swapimage.notext = true;
}
@

<<constant NFREECHAN>>=
#define NFREECHAN 64
@


<<function imageinit>>=
void
imageinit(void)
{
    KImage *i, *ie;

    imagealloc.free = xalloc(conf.nimage*sizeof(KImage));
    if (imagealloc.free == nil)
        panic("imageinit: no memory");
    ie = &imagealloc.free[conf.nimage-1];
    for(i = imagealloc.free; i < ie; i++)
        i->next = i+1;
    i->next = nil;
    imagealloc.freechan = malloc(NFREECHAN * sizeof(Chan*));
    imagealloc.szfreechan = NFREECHAN;
}
@
%old: was called initseg, not sure why



\subsection{Device initialisation}

<<function chandevreset>>=
void
chandevreset(void)
{
    int i;

    todinit();  /* avoid later reentry causing infinite recursion */
    for(i=0; devtab[i] != nil; i++) {
        print("reset %d, %s\n", i, devtab[i]->name);
        devtab[i]->reset();
    }
}
@
%    //debugstart = getconf("*debugstart") != nil;

<<[[Dev]] methods>>=
void  (*reset)(void); // done once at boot time
@

\section{The first process (x86)}

% kernel code part of first process: init0
% user code part of first process: initcode, which will then exec boot/boot!

<<function userinit(x86)>>=
void
userinit(void)
{
    void *v;
    Proc *p;
    Segment *s;
    Page *pg;

    p = newproc();

    p->pgrp = newpgrp();
    p->fgrp = dupfgrp(nil);
    p->egrp = smalloc(sizeof(Egrp)); //todo: newegrp()
    p->egrp->ref = 1;
    p->rgrp = newrgrp();

    p->procmode = 0640;

    kstrdup(&eve, "");
    kstrdup(&p->text, "*init*");
    kstrdup(&p->user, eve);

    <<[[userinit()]] fp setup(x86)>>

    /*
     * Kernel Stack
     *
     * N.B. make sure there's enough space for syscall to check
     *      for valid args and 
     *      4 bytes for arch_gotolabel's return PC
     */
    p->sched.pc = (kern_addr)init0;
    p->sched.sp = (kern_addr)p->kstack+KSTACK-(sizeof(Sargs)+BY2WD);

    /*
     * User Stack
     *
     * N.B. cannot call newpage() with clear=1, because PC arch_kmap()
     * requires up != nil.  use tmpmap() instead.
     */
    s = newseg(SG_STACK, USTKTOP-USTKSIZE, USTKSIZE/BY2PG);
    p->seg[SSEG] = s;
    pg = newpage(false, nil, USTKTOP-BY2PG);
    v = tmpmap(pg);
    memset(v, 0, BY2PG);
    segpage(s, pg);
    bootargs(v); // populate user stack for boot/boot program
    tmpunmap(v);

    /*
     * Text
     */
    s = newseg(SG_TEXT, UTZERO, 1); // 1 page
    s->flushme = true;
    p->seg[TSEG] = s;
    pg = newpage(false, nil, UTZERO);
    memset(pg->cachectl, PG_TXTFLUSH, sizeof(pg->cachectl));
    segpage(s, pg);
    v = tmpmap(pg);
    memset(v, 0, BY2PG);
    memmove(v, initcode, sizeof initcode); // must be < BY2PG!
    tmpunmap(v);

    ready(p);
}
@

%how setup user stack to be big? there is just brk() ... 
%what about the other side?
%every process after userinit comes from a fork or exec, and they
% inherit the same SG_STACK.
%so if want to implement ulimit? can't, have to modify the kernel
% and recompile. But note that it's currently pretty big, 16Mo,
% and that it's content is loaded on demand via page fault so it's ok
% to make it bigger.
% also maybe cause use segattach for a new seg and put the stack there?


% rename init_kernel_part? will be the code at the very top
% of the stack! that should eventually IRET to user code
<<function init0(x86)>>=
// set by userinit to sched.pc
void
init0(void)
{
    int i;
    char buf[2*KNAMELEN]; // has to be the same than in ksetenv?
    
    up->nerrlab = 0;

    arch_spllo();

    /*
     * These are o.k. because rootinit is null.
     * Then early kproc's will have a root and dot.
     */
    up->slash = namec("#/", Atodir, 0, 0);
    pathclose(up->slash->path);
    up->slash->path = newpath("/"); // prefer / to #/
    up->dot = cclone(up->slash);

    chandevinit();

    if(!waserror()){
        snprint(buf, sizeof(buf), "%s %s", arch->id, conffile);
        ksetenv("terminal", buf, false);
        ksetenv("cputype", "386", false); // used by mkfile! 
        if(cpuserver)
                ksetenv("service", "cpu", false);
        else
                ksetenv("service", "terminal", false);
        for(i = 0; i < nconf; i++){
                if(confname[i][0] != '*')
                        ksetenv(confname[i], confval[i], false);
                ksetenv(confname[i], confval[i], true);
        }
        poperror();
    }
    kproc("kalarm", alarmkproc, nil);
    cgapost(0x9);
    arch_touser(sp);
}
@
% sp, use of global sp, because of bootargs?

<<function chandevinit>>=
void
chandevinit(void)
{
    int i;
    for(i=0; devtab[i] != nil; i++) {
        devtab[i]->init();
    }
}
@

<<[[Dev]] methods>>=
void  (*init)(void);
@
% diff with reset? this is done in a context of the first process
% so maybe it can set some globals in up that will then be propagated
% when forking? maybe could remove


% UTZERO+32 because of a.out header of initcode binary generated by ld
<<function touser(x86)>>=
/*
 *  Used to get to the first process:
 *      set up an interrupt return frame and IRET to user level.
 */
TEXT arch_touser(SB), $0
        PUSHL   $(UDSEL)                        /* old ss */
        MOVL    sp+0(FP), AX                    /* old sp */
        PUSHL   AX
        MOVL    $0x200, AX                      /* interrupt enable flag */
        PUSHL   AX                              /* old flags */
        PUSHL   $(UESEL)                        /* old cs */
        PUSHL   $(UTZERO+32)                    /* old pc */
        MOVL    $(UDSEL), AX
        MOVW    AX, DS
        MOVW    AX, ES
        MOVW    AX, GS
        MOVW    AX, FS
        IRETL
@ 


% code of initcode here! generated by a trick in a .h! chicken and egg

% get rid of that? have just initcode.c that do the _main? why this extra
%  complexity? because of portability again, they have init9.c, 
% but also init9.s in other architecture, and so the common part 
% is having a startboot() but before you need to setup a few things
% like the proper stack registers (see bcm init9.s)
<<init9.c>>=
//@Scheck: def can actually be found initcode.c, but this file is in skip list
extern void startboot(char*, char**);

//@Scheck: entry point looked for by the linker 8l 
//For x86, no need for an init9.s; there is no special registers
//to set in assembly (for example for arm we need to set R12 and we can
//do that only from assembly).
void
_main(char *argv0)
{
    startboot(argv0, &argv0);
}
@
% see also initcode_dead.s

% _main? related to main9.s in libc/386/? it is
% because ld is using _main for the default entry point!
% (and this _main in libc usually setups a few things and then call main()
% (and also can maybe cleanup things after main()))

% TODO how is compiled char cons[] = "#c/cons";? not in data segment?
%	$LD -l -R1 -s -o init.out init9.$O initcode.$O /386/lib/libc.a
% so stripped? -s? -l ?

<<initcode.c>>=
/*
 * IMPORTANT!  DO NOT ADD LIBRARY CALLS TO THIS FILE.
 * The entire text image must fit on one page
 * (and there's no data segment, so any read/write data must be on the stack).
 */

#include <u.h>
#include <libc.h>

char cons[] = "#c/cons";
char boot[] = "/boot/boot";
char dev[] = "/dev";
char c[] = "#c";
char e[] = "#e";
char ec[] = "#ec";
char s[] = "#s";
char srv[] = "/srv";
char env[] = "/env";

void
startboot(char *argv0, char **argv)
{
    char buf[200];  /* keep this fairly large to capture error details */

    /* in case boot is a shell script */
    open(cons, OREAD);
    open(cons, OWRITE);
    open(cons, OWRITE);

    bind(c, dev, MAFTER);
    bind(ec, env, MAFTER);
    bind(e, env, MCREATE|MAFTER);
    bind(s, srv, MREPL|MCREATE);

    USED(argv0);
    exec(boot, argv);

    rerrstr(buf, sizeof buf);
    buf[sizeof buf - 1] = '\0';
    _exits(buf);
}
@

\section{Booting the user}

% see section on Userspace system programs
% when arrive here, we got the first process executing! and
% a working kernel!

% see boot.rc now! simpler than 9/boot/


%###############################################################################

%\part{Files and Directories}

\chapter{Files}
\minitoc

<<systab file syscalls>>=
    [OPEN]      sysopen,
    [CLOSE]     sysclose,
    [PREAD]     syspread,
    [PWRITE]    syspwrite,
    [SEEK]      sysseek,
@ 

\section{Overview}

% Chan, fds, Dev, devtab.
% complications: dirs, mount table, namespace, "..", union directories, devmnt

% fs is fundamental! see Principia/Bootstrapping, without fs you struggle!

%note that files are used for many things, including devices!!
% and actually in plan9 device drivers are really more file servers.
%pike: interface is not everything is a file, but everything is
% a file server interface!


\section{[[Chan]]nels}

% see chapter 3 to recall main fields of Chan (type, dev, qid,  path, etc)

<<enum channelflag>>=
/*
 * channel flags
 */
enum 
{
  COPEN = 0x0001,   /* for i/o */
  CFREE = 0x0010,   /* not in use */
  <<enum channelflag cases>>
};
@
%/*rsc CCREATE = 0x0004,   /* permits creation if c->mnt */
% COPEN is set in devopen() generic helper. why not done in sysopen 
%  generically?


<<[[Chan]] other fields>>=
// enum<channelflag>> (actually a bitset for certain properties)
ushort  flag;
@
% see also the 'mode' field of enum<open>




<<struct Chanalloc>>=
struct Chanalloc
{
    //list<ref<Chan>> (next = Chan.next), the free one
    Chan    *free;
    //list<ref<Chan>> (next = Chan.link), the used one
    Chan    *list;

    int fid; // could be a Counter, but already have a Lock anyway

    // extra
    Lock;
};
@
% not arena allocator, gradually allocated via malloc, but never freed.
% fid is for devmnt. When chan are free the fid seems to be reused as is


<<[[Chan]] extra fields>>=
// list<ref<Chan> of Chanalloc.free
Chan* next;     /* allocation */
// list<ref<Chan> of Chanalloc.list
Chan* link;
@ 

<<global chanalloc>>=
struct Chanalloc chanalloc;
@



% used by devattach(), devclone() (itself called from devwalk())
<<constructor newchan>>=
Chan*
newchan(void)
{
    Chan *c;

    lock(&chanalloc);
    c = chanalloc.free;
    if(c != nil)
        chanalloc.free = c->next;
    unlock(&chanalloc);

    if(c == nil){
        c = smalloc(sizeof(Chan));
        lock(&chanalloc);
        c->fid = ++chanalloc.fid;
        c->link = chanalloc.list;
        chanalloc.list = c;
        unlock(&chanalloc);
    }

    /* if you get an error before associating with a dev,
       close calls rootclose, a nop */
    c->type = 0;
    c->dev = 0;

    c->path = nil;

    c->offset = 0;
    c->devoffset = 0;
    // c->mode?

    c->flag = 0;
    c->ref = 1;

    c->ismtpt = false;
    c->umh = nil;
    // c->umc?
    c->uri = 0;

    c->mux = nil;
    c->mchan = nil;
    memset(&c->mqid, 0, sizeof(c->mqid));
    c->mcp = nil;
    c->iounit = 0;
    c->dri = 0;

    c->aux = nil;
    
    return c;
}
@
%dirrock = nil? umc = nil
% what about ->qid? could do a memset 0 like for mqid no? the caller
% of newchan will take care of that as he knows better the kind of qid
% one wants, QTDIR or QTFILE for instance

% but actually the real destructor managing references is cclose()
<<destructor chanfree>>=
void
chanfree(Chan *c)
{
    c->flag = CFREE;

    <<[[chanfree()]] optional free>>

    pathclose(c->path);
    c->path = nil;

    lock(&chanalloc);
    c->next = chanalloc.free;
    chanalloc.free = c;
    unlock(&chanalloc);
}
@
% see also cclose(), but complicated so will see later


% usually call via c = uniquechan(c); hence the cclose below
% less: mv closer to where it's used
<<function uniquechan>>=
/*
 * Make sure we have the only copy of c.  (Copy on write.)
 */
Chan*
uniquechan(Chan *c)
{
    Chan *nc;

    if(c->ref != 1){
        nc = cclone(c);
        cclose(c);
        return nc;
    }else{
      return c;
    }
}
@

\section{Devices table [[devtab]]}
% mv elsewhere? In Namespace? but we will use devtab below 

% see chapter 3 too, Dev and devtab global

% ex of attach? they call devattach no? namec('#/', ...) will call devattach
% of the root device
<<function devattach>>=
Chan*
devattach(Rune tc, char *spec)
{
    int n;
    Chan *c;
    char *buf;

    c = newchan();
    mkqid(&c->qid, 0, 0, QTDIR); // root of a device is a QTDIR
    c->type = devno(tc, false);

    if(spec == nil)
        spec = "";
    n = 1+UTFmax+strlen(spec)+1; // '#' + Rune + spec + '\0'
    buf = smalloc(n);
    snprint(buf, n, "#%C%s", tc, spec);
    c->path = newpath(buf);
    free(buf);

    return c;
}
@
% what about c->dev? the specific attach should handle that?

<<function devno>>=
int
devno(Rune c, bool user)
{
    int i;

    for(i = 0; devtab[i] != nil; i++) {
        if(devtab[i]->dc == c)
            return i;
    }
    if(!user)
        panic("devno %C %#ux", c, c);

    return -1;
}
@


\section{File descriptors}

% why fds? otherwise have to pass a string to each operations.
% also allow redirection trick with the fd0, fd1 convention

<<struct Fgrp>>=
struct Fgrp
{
    // array<option<ref_counted<Chan>>>
    Chan  **fd;
    // nelem(fd)
    int nfd;      /* number allocated */
    int maxfd;      /* highest fd in use */ // <= nfd
  
    <<[[Fgrp]] other fields>>
    // extra
    Ref;
};
@ 


<<[[Proc]] files fields>>=
// ref_counted<fgrp>
Fgrp  *fgrp;    /* File descriptor group */
@

% newfgrp? it's duppgrp with nil
% todo: could define such a function no?

% a kind of constructor when pass nil as parameter
<<function dupfgrp>>=
Fgrp*
dupfgrp(Fgrp *f)
{
    Fgrp *new;
    Chan *c;
    int i;

    new = smalloc(sizeof(Fgrp));
    if(f == nil){
        new->fd = smalloc(DELTAFD*sizeof(Chan*));
        new->nfd = DELTAFD;
        new->ref = 1;
        return new;
    }

    lock(f);
    /* Make new fd list shorter if possible, preserving quantization */
    new->nfd = f->maxfd+1;
    i = new->nfd%DELTAFD;
    if(i != 0)
        new->nfd += DELTAFD - i;
    new->fd = malloc(new->nfd*sizeof(Chan*));
    if(new->fd == nil){
        unlock(f);
        free(new);
        error("no memory for fgrp");
    }
    new->ref = 1;

    new->maxfd = f->maxfd;
    for(i = 0; i <= f->maxfd; i++) {
        if(c = f->fd[i]){
            incref(c);
            new->fd[i] = c;
        }
    }
    unlock(f);

    return new;
}
@ 

<<constant DELTAFD>>=
    DELTAFD = 20    /* incremental increase in Fgrp.fd's */
@
% another thing where allocate first more to amortize realloc cost
% define a growing_array type?

% called by pexit()
<<function closefgrp>>=
void
closefgrp(Fgrp *f)
{
    int i;
    Chan *c;

    if(f == nil)
        return;

    if(decref(f) != 0)
        return;

    /*
     * If we get into trouble, forceclosefgrp
     * will bail us out.
     */
    up->closingfgrp = f;
    for(i = 0; i <= f->maxfd; i++)
        if(c = f->fd[i]){
            f->fd[i] = nil;
            cclose(c);
        }
    up->closingfgrp = nil;

    free(f->fd);
    free(f);
}
@ 

% allocate new fd for freshly opened channel, e.g. in sysopen()
<<function newfd>>=
int
newfd(Chan *c)
{
    int fd;
    Fgrp *f;

    f = up->fgrp;
    lock(f);
    fd = findfreefd(f, 0);
    if(fd < 0){
        unlockfgrp(f);
        return -1;
    }
    if(fd > f->maxfd)
        f->maxfd = fd;
    f->fd[fd] = c;
    unlockfgrp(f);
    return fd;
}
@

<<function findfreefd>>=
/*
 *  this assumes that the fgrp is locked
 */
int
findfreefd(Fgrp *f, int start)
{
    int fd;

    for(fd=start; fd<f->nfd; fd++)
        if(f->fd[fd] == nil)
            break;
    if(fd >= f->nfd && growfd(f, fd) < 0)
        return -1;
    return fd;
}
@

% growing array
<<function growfd>>=
int
growfd(Fgrp *f, int fd) /* fd is always >= 0 */
{
    Chan **newfd, **oldfd;

    if(fd < f->nfd)
        return 0; // should never happen no?
    if(fd >= f->nfd+DELTAFD)
        return -1;  /* out of range */ // when can this happen? from sysdup?
    /*
     * Unbounded allocation is unwise
     */
    if(f->nfd >= 5000){
    Exhausted:
        print("no free file descriptors\n");
        return -1;
    }
    // realloc
    newfd = malloc((f->nfd+DELTAFD)*sizeof(Chan*));
    if(newfd == nil)
        goto Exhausted;
    oldfd = f->fd;
    memmove(newfd, oldfd, f->nfd*sizeof(Chan*));
    f->fd = newfd;
    free(oldfd);
    f->nfd += DELTAFD;
    if(fd > f->maxfd){
        if(fd/100 > f->maxfd/100)
            f->exceed = (fd/100)*100;
        f->maxfd = fd;
    }
    return 1;
}
@
% define constant instead of hardcoded 5000?

<<[[Fgrp]] other fields>>=
int exceed;     /* debugging */
@
% put in ifallcode and aspectize this debugging code?


% unlock wrapper
<<function unlockfgrp>>=
static void
unlockfgrp(Fgrp *f)
{
    int ex;

    ex = f->exceed;
    f->exceed = 0;
    unlock(f);
    if(ex)
        pprint("warning: process exceeds %d file descriptors\n", ex);
}
@
% when this happen?




\section{[[sysopen()]], [[sysclose()]]}

% this is also in libc.h
<<enum open>>=
enum open {
    OREAD = 0, /* open for read */
    OWRITE = 1, /* write */
    ORDWR = 2, /* read and write */
    <<enum open cases>>
};
@ 
% OWRITE will be checked later in syspwrite()

% Chan has a field mode, but for many of the remaining enum open cases
% the bit is actually put in the c->flag, not c->mode

<<syscall open>>=
// int open(char *file, int omode);
long
sysopen(ulong* arg)
{
    int fd;
    Chan *c;

    openmode(arg[1]);   /* error check only */
    validaddr(arg[0], 1, false);
    c = namec((char*)arg[0], Aopen, arg[1], 0);
    if(waserror()){
        cclose(c);
        nexterror();
    }
    fd = newfd(c);
    if(fd < 0)
        error(Enofd);
    poperror();
    return fd;
}
@
% namec() is very complex, will see later, related to Directories and mount
% as it needs to follow and find the appropriate device to
% ultimately do the device->open()
% (note that device is really a file server, so it's kinda a call to VFS)

<<function openmode>>=
int
openmode(ulong o)
{
    o &= ~(OTRUNC|OCEXEC|ORCLOSE);
    if(o > OEXEC)
        error(Ebadarg);
    if(o == OEXEC)
        return OREAD;
    return o;
}
@
% normalize, the OCEXEC ORCLOSE are actually put in c->flag, not c->mode
% could introduce another type?


<<syscall close>>=
// int close(int fd);
long
sysclose(ulong* arg)
{
    fdtochan(arg[0], -1, false, false); // for its error checking side effect
    fdclose(arg[0], 0);
    return 0;
}
@

% the mode parameter is either -1 or OREAD|OWRITE|ORDRW, or 
% openmode(omode) (in dupopen)
<<function fdtochan>>=
Chan*
fdtochan(int fd, int mode, bool chkmnt, bool iref)
{
    Chan *c;
    Fgrp *f;

    c = nil;
    f = up->fgrp;

    lock(f);
    if(fd<0 || f->nfd<=fd || (c = f->fd[fd])==nil) {
        unlock(f);
        error(Ebadfd);
    }
    // c = f->fd[fd] != nil

    if(iref)
        incref(c);
    unlock(f);

    if(chkmnt && (c->flag&CMSG)) {
        <<[[fdtochan()]] undo iref incref>>
        error(Ebadusefd);
    }

    if(mode<0 || c->mode==ORDWR) // mode < 0? mean no check?
        return c;

    if((mode&OTRUNC) && c->mode==OREAD) { // BUG impossible, dead code
        <<[[fdtochan()]] undo iref incref>>
        error(Ebadusefd);
    }
    // the access mode must match the opening mode
    if((mode&~OTRUNC) != c->mode) {
        <<[[fdtochan()]] undo iref incref>>
        error(Ebadusefd);
    }

    return c;
}
@
%BUG? mode&~OTRUNK enough? what about OEXEC, ... cover all the cases?
% why not just check that if ask for OREAD then check OREAD or ORWDR or OEXEC,
% and for OWRITE check for OWRITE or ORWDR or OTRUNC?
% why OTRUNK weird logic? LP split?
%actually I think OTRUNC can't be passed to fdtochan(), there is no place
% in the codebase passing OTRUNC I think
% LP split chkmnt

<<[[fdtochan()]] undo iref incref>>=
if(iref)
    cclose(c);
@

<<function fdclose>>=
void
fdclose(int fd, int flag)
{
    int i;
    Chan *c;
    Fgrp *f = up->fgrp;

    lock(f);
    c = f->fd[fd]; // bound checking??
    if(c == nil){
        /* can happen for users with shared fd tables */
        unlock(f);
        return;
    }
    if(flag){
        if(c==nil || !(c->flag&flag)){ // dead test c==nil? see above
            unlock(f);
            return;
        }
    }
    f->fd[fd] = nil;

    if(fd == f->maxfd)
        for(i=fd; --i>=0 && f->fd[i]==nil; )
            f->maxfd = i;

    unlock(f);
    cclose(c);
}
@

<<[[Dev]] methods>>=
void  (*close)(Chan*);
@

<<function cclose>>=
void
chan_cclose(Chan *c)
{
    if(c->flag&CFREE)
        panic("cclose %#p", getcallerpc(&c));

    DBG("cclose %p name=%s ref=%ld\n", c, c->path->s, c->ref);
    if(decref(c))
        return;

    if(!waserror()){
        devtab[c->type]->close(c);
        poperror();
    }
    chanfree(c);
}
@
% see also ccloseq


\section{[[namec()]]}
% big function ...
% not in Dir chapter cos don't need path, and LP splitted enough
% now that mainly expose the ->open() method so better closer to sysopen()

% have seen before:
%        up->slash = namec("#/", Atodir, 0, 0); in init0
% and
%    c = namec((char*)arg[0], Aopen, arg[1], 0); in sysopen
% LP aspectize different places where call namec()?

<<[[sysexec()]] call namec() to get a channel in tc from file>>=
tc = namec(file, Aopen, OEXEC, 0);
@


<<enum open cases>>=
OEXEC = 3, /* execute, == read but check execute permission */
@

<<enum accessnamec>>=
/*
 * Access types in namec
 */
enum
{
  Aopen,        /* for i/o */
  Acreate,      /* is to be created */
  Aremove,      /* will be removed by caller */
  Aaccess,      /* as in stat, wstat */
  Atodir,       /* as in chdir */
  <<enum accessnamec cases>>
};
@

% basic logical flow string -> Elemlist -> Chan
<<[[namec()]] locals>>=
char *name;
@

<<[[namec()]] locals>>=
Elemlist e;
@

<<[[namec()]] locals>>=
Chan *c;
@
% (that will also adjust c->path gradually)


% another big function ... calls dev->attach, dev->walk, dev->open, dev->create
<<function namec>>=
/*
 * Turn a name into a channel.
 * &name[0] is known to be a valid address.  It may be a kernel address.
 *
 * Opening with amode Aopen, Acreate, Aremove, or Aaccess guarantees
 * that the result will be the only reference to that particular fid.
 * This is necessary since we might pass the result to
 * devtab[]->remove().
 *
 * Opening Atodir or Amount does not guarantee this.
 *
 * Under certain circumstances, opening Aaccess will cause
 * an unnecessary clone in order to get a uniquechan Chan so it
 * can attach the correct name.  Sysstat and sys_stat need the
 * correct name so they can rewrite the stat info.
 */
Chan*
namec(char *aname, int amode, int omode, ulong perm)
{
    <<[[namec()]] locals>>

    if(aname[0] == '\0')
        error("empty file name");

    aname = validnamedup(aname, true);

    if(waserror()){
        free(aname);
        nexterror();
    }
    DBG("namec %s %d %d\n", aname, amode, omode);
    name = aname;

    sharppath = (name[0] == '#');

    /*
     * Find the starting off point (the current slash, the root of
     * a device tree, or the current dot) as well as the name to
     * evaluate starting there.
     */
    switch(name[0]){
    <<[[namec()]] if name[0] is a sharp>>
    case '/':
        c = up->slash;
        incref(c);
        break;
    
    default:
        c = up->dot;
        incref(c);
        break;
    }

    <<[[namec()]] initializes Elemlist e>>

    if(waserror()){
        cclose(c);
        <<[[namec()]] if waserror free Elemlist e and prepare nice error>>
    }

    /*
     * Build a list of elements in the name.
     */
    parsename(name, &e);

    /*
     * On create, ....
     */
    <<[[namec()]] adjust Elemlist e if Acreate>>

    if(walk(&c, e.elems, e.nelems, sharppath, &e.nerror) < 0){
        if(e.nerror < 0 || e.nerror > e.nelems){
            print("namec %s walk error nerror=%d\n", aname, e.nerror);
            e.nerror = 0;
        }
        nexterror();
    }

    <<[[namec()]] error if not a directory or cannot exec directory>>

    switch(amode){
    case Aopen:
    case Aremove:
    case Aaccess:
    Open:
        <<[[namec()]] case Aopen, Acreate, Aremove, Aaccess, handle mountpoint part1>>
    
        switch(amode){
        case Aopen:
        case Acreate:
            <<[[namec()]] print error if c->umh != nil>>
            <<[[namec()]] case Aopen, Acreate, handle mountpoint part2>>
   
            <<[[namec()]] set channel flag before open>>
            c = devtab[c->type]->open(c, omode&~OCEXEC);
            <<[[namec()]] set channel flag after open>>
            break;

        case Aaccess:
        case Aremove:
           <<[[namec()]] case Aremove, Aaccess, handle mountpoint part2>>
            break;
    
        }
        break;
    <<[[namec()]] other cases>>
    default:
        panic("unknown namec access %d\n", amode);
    }

    <<[[namec()]] set genbuf from Elemlist e>>

    <<[[namec()]] free Elemlist e>>
    poperror(); /* e c */
    free(aname);
    poperror(); /* aname */

    return c;
}
@
%        if(0 && chandebug)
%            print("showing %d+%d/%d (of %d) of %s (%d %d)\n", e.prefix, e.off[e.nerror], e.nerror, e.nelems, aname, e.off[0], e.off[1]);


<<[[Dev]] methods>>=
Chan* (*open)(Chan*, int);
@
% it's actually called like
%        c = devtab[c->type]->open(c, omode&~OCEXEC);
% weird no? open is just here to give a hint to the file server
% that this file was not only accessed but should now be open for business.
% walk() was the one who already returned the channel.

% actually can return another channel! for instance cat /proc/#/text
% is a redirect to the channel of the image of the binary! so open incref
% and return another channel (and close the one passed in)


<<[[namec()]] set genbuf from Elemlist e>>=
/* place final element in genbuf for e.g. exec */
if(e.nelems > 0)
    kstrcpy(up->genbuf, e.elems[e.nelems-1], sizeof up->genbuf);
else
    kstrcpy(up->genbuf, ".", sizeof up->genbuf);
@

<<[[Proc]] other fields>>=
char  genbuf[128];  /* buffer used e.g. for last name element from namec */
@
% for up->text. Could do cleaner and just use lastpath in sysexec no?


\ifallcode
<<[[namec()]] locals>>=
int len, n, t;
@
\fi

\subsection{Checking valid filename string}

% seems always called with slashok=true
<<function validnamedup>>=
char*
validnamedup(char *aname, bool slashok)
{
    return validname0(aname, slashok, true, getcallerpc(&aname));
}
@

<<function validname>>=
void
validname(char *aname, bool slashok)
{
    validname0(aname, slashok, false, getcallerpc(&aname));
}
@


<<function validname0>>=
/*
 * Check that the name
 *  a) is in valid memory.
 *  b) is shorter than 2^16 bytes, so it can fit in a 9P string field.
 *  c) contains no frogs.
 * The first byte is known to be addressible by the requester, so the
 * routine works for kernel and user memory both.
 * The parameter slashok flags whether a slash character is an error
 * or a valid character.
 *
 * The parameter dup flags whether the string should be copied
 * out of user space before being scanned the second time.
 * (Otherwise a malicious thread could remove the NUL, causing us
 * to access unchecked addresses.) 
 */
static char*
validname0(char *aname, bool slashok, bool dup, kern_addr pc)
{
    char *ename, *name, *s;
    int n;
    int c;
    Rune r;

    name = aname;

    if((virt_addr)name < KZERO){
        if(!dup)
            print("warning: validname called from %#p with user pointer", pc);
        ename = vmemchr(name, 0, (1<<16));
    }else
        ename = memchr(name, 0, (1<<16));

    if(ename==nil || ename-name>=(1<<16))
        error("name too long");

    s = nil;
    if(dup){
        n = ename-name;
        s = smalloc(n+1);
        memmove(s, name, n);
        s[n] = '\0';
        aname = s;
        name = s;
        setmalloctag(s, pc);
    }

    // checking validity of name    
    while(*name){
        /* all characters above '~' are ok */
        c = *(byte*)name;
        if(c >= Runeself)
            name += chartorune(&r, name);
        else{
            if(isfrog[c])
                if(!slashok || c!='/'){
                    snprint(up->genbuf, sizeof(up->genbuf), "%s: %q", Ebadchar, aname);
                    free(s);
                    error(up->genbuf);
            }
            name++;
        }
    }
    return s;
}
@
% >> >> >>



<<global isfrog>>=
char isfrog[256]={
    /*NUL*/ 1, 1, 1, 1, 1, 1, 1, 1,
    /*BKS*/ 1, 1, 1, 1, 1, 1, 1, 1,
    /*DLE*/ 1, 1, 1, 1, 1, 1, 1, 1,
    /*CAN*/ 1, 1, 1, 1, 1, 1, 1, 1,
    ['/']   1,
    [0x7f]  1,
};
@
% Size must be Runeself, s/0x7f/Runeself - 1/ ?

\subsection{Parsing filename}

% used internally by namec()
<<struct Elemlist>>=
struct Elemlist
{
    char    *aname; /* original name */
    char    *name;  /* copy of name, so '/' can be overwritten */

    //array<string> pointing to subparts of name
    char    **elems; // subparts
    // size(elems)
    int nelems;
    //array<int>, offset in name for the subparts of name in elems
    int *off;

    bool mustbedir; // if last part of filename is a '/'

    int nerror;
    int prefix;
};
@
% another growing array in elems

<<[[namec()]] initializes Elemlist e>>=
e.aname = aname;
e.prefix = name - aname;
e.name = nil;
e.elems = nil;
e.off = nil;
e.nelems = 0;
e.nerror = 0;
@

<<[[namec()]] free Elemlist e>>=
free(e.name);
free(e.elems);
free(e.off);
@


<<function parsename>>=
/*
 * The name is known to be valid.
 * Copy the name so slashes can be overwritten.
 * An empty string will set nelem=0.
 * A path ending in / or /. or /.//./ etc. will have
 * e.mustbedir = true, so that we correctly
 * reject, e.g., "/adm/users/." when /adm/users is a file
 * rather than a directory.
 */
static void
parsename(char *aname, Elemlist *e)
{
    char *name, *slash;

    kstrdup(&e->name, aname);
    name = e->name;
    e->nelems = 0;
    e->elems = nil;
    e->off = smalloc(sizeof(int));
    e->off[0] = skipslash(name) - name;
    for(;;){
        name = skipslash(name);
        if(*name == '\0'){
            e->off[e->nelems] = name+strlen(name) - e->name;
            e->mustbedir = true;
            break;
        }
        growparse(e);
        e->elems[e->nelems++] = name;
        slash = utfrune(name, '/');
        if(slash == nil){
            e->off[e->nelems] = name+strlen(name) - e->name;
            e->mustbedir = false;
            break;
        }
        e->off[e->nelems] = slash - e->name;
        *slash++ = '\0';
        name = slash;
    }
}
@
%    if(0 && chandebug){
%        int i;
%        
%        print("parsename %s:", e->name);
%        for(i=0; i<=e->nelems; i++)
%            print(" %d", e->off[i]);
%        print("\n");
%    }


<<function growparse>>=
static void
growparse(Elemlist *e)
{
    char **new;
    int *inew;
    enum { Delta = 8 };

    if(e->nelems % Delta == 0){
        new = smalloc((e->nelems+Delta) * sizeof(char*));
        memmove(new, e->elems, e->nelems*sizeof(char*));
        free(e->elems);
        e->elems = new;
        inew = smalloc((e->nelems+Delta+1) * sizeof(int));
        memmove(inew, e->off, (e->nelems+1)*sizeof(int));
        free(e->off);
        e->off = inew;
    }
}
@



<<function skipslash>>=
/*
 * name is valid. skip leading / and ./ as much as possible
 */
char*
skipslash(char *name)
{
    while(name[0]=='/' || (name[0]=='.' && (name[1]=='\0' || name[1]=='/')))
        name++;
    return name;
}
@

\subsection{Error management}

<<[[namec()]] locals>>=
char tmperrbuf[ERRMAX];
@

<<[[namec()]] if waserror free Elemlist e and prepare nice error>>=
free(e.name);
free(e.elems);
/*
 * Prepare nice error, showing first e.nerror elements of name.
 */
if(e.nerror == 0)
    nexterror();
strcpy(tmperrbuf, up->errstr);
if(e.off[e.nerror]==0)
    print("nerror=%d but off=%d\n",e.nerror, e.off[e.nerror]);
len = e.prefix+e.off[e.nerror];
free(e.off);
namelenerror(aname, len, tmperrbuf);
@

<<function namelenerror>>=
void
namelenerror(char *aname, int len, char *err)
{
    char *ename, *name, *next;
    int i, errlen;

    /*
     * If the name is short enough, just use the whole thing.
     */
    errlen = strlen(err);
    if(len < ERRMAX/3 || len+errlen < 2*ERRMAX/3)
        snprint(up->genbuf, sizeof up->genbuf, "%.*s", 
            utfnlen(aname, len), aname);
    else{
        /*
         * Print a suffix of the name, but try to get a little info.
         */
        ename = aname+len;
        next = ename;
        do{
            name = next;
            next = memrchr(aname, '/', name-aname);
            if(next == nil)
                next = aname;
            len = ename-next;
        }while(len < ERRMAX/3 || len + errlen < 2*ERRMAX/3);

        /*
         * If the name is ridiculously long, chop it.
         */
        if(name == ename){
            name = ename-ERRMAX/4;
            if(name <= aname)
                panic("bad math in namelenerror");
            /* walk out of current UTF sequence */
            for(i=0; (*name&0xC0)==0x80 && i<UTFmax; i++)
                name++;
        }
        snprint(up->genbuf, sizeof up->genbuf, "...%.*s",
            utfnlen(name, ename-name), name);
    }               
    snprint(up->errstr, ERRMAX, "%#q %s", up->genbuf, err);
    nexterror();
}
@

% used by wstat later
<<function nameerror>>=
void
nameerror(char *name, char *err)
{
    namelenerror(name, strlen(name), err);
}
@


\section{[[syspread()]], [[syspwrite()]]}

\t is there a copy involved between kernel and user process?
\t  when write(fd, x, 45), where x a pointer in memory
\t  does kernel copy this buffer first in his own memory?
\t NO I think, so important zero-copy principle here! kernel can look
\t  in the user process address space easily!

% put offset field here? 

<<syscall pread>>=
// long pread(int fd, void *buf, long nbytes, vlong offset);
long
syspread(ulong* arg)
{
    vlong v;
    va_list list;

    /* use varargs to guarantee alignment of vlong */
    va_start(list, arg[2]);
    v = va_arg(list, vlong);
    va_end(list);

    if(v == ~0ULL)
        return read(arg, nil);

    return read(arg, &v);
}
@
% vlong? because the ulong* arg sysargs trick does not like vlong?
% why pread? for backward compatible reasons?

<<[[Dev]] methods>>=
long  (*read)(Chan*, void*, long, vlong);
@

<<function read>>=
// long pread(int fd, void *buf, long nbytes, vlong offset);
static long
read(ulong *arg, vlong *offp)
{
    long n, nn, nnn;
    byte *p;
    Chan *c;
    vlong off;

    n = arg[2];
    validaddr(arg[1], n, true);
    p = (void*)arg[1];
    c = fdtochan(arg[0], OREAD, true, true);

    if(waserror()){
        cclose(c);
        nexterror();
    }

    if(offp == nil) /* use and maintain channel's offset */
        off = c->offset;
    else
        off = *offp;

    if(off < 0)
        error(Enegoff);

    if(off == 0){   /* rewind to the beginning of the directory */
        if(offp == nil){
            c->offset = 0;
            c->devoffset = 0;
        }
        <<[[read()]] rewind when off == 0>>
    }

    <<[[read()]] if c is a QTDIR>>
    else
        nnn = nn = devtab[c->type]->read(c, p, n, off);

    lock(c);
    c->offset += nnn;
    c->devoffset += nn;
    unlock(c);

    poperror();
    cclose(c);

    return nnn;
}
@
% this ->read() will call block related readers? who uses bread?

% note that pread actually takes an offset so it's a combined seek and read
% from read(2)
%  "By combining the operations in a single atomic call, they more closely
%   match the 9P protocol"


<<syscall pwrite>>=
// long pwrite(int fd, void *buf, long nbytes, vlong offset);
long
syspwrite(ulong* arg)
{
    vlong v;
    va_list list;

    /* use varargs to guarantee alignment of vlong */
    va_start(list, arg[2]);
    v = va_arg(list, vlong);
    va_end(list);

    if(v == ~0ULL)
        return write(arg, nil);

    return write(arg, &v);
}
@


<<[[Dev]] methods>>=
long  (*write)(Chan*, void*, long, vlong);
@

<<function write>>=
// long pwrite(int fd, void *buf, long nbytes, vlong offset);
static long
write(ulong *arg, vlong *offp)
{
    Chan *c;
    long m, n;
    vlong off;

    validaddr(arg[1], arg[2], false);
    n = 0;
    c = fdtochan(arg[0], OWRITE, true, true);
    if(waserror()) {
        if(offp == nil){
            lock(c);
            c->offset -= n;
            unlock(c);
        }
        cclose(c);
        nexterror();
    }

    if(c->qid.type & QTDIR)
        error(Eisdir);

    n = arg[2];

    if(offp == nil){    /* use and maintain channel's offset */
        lock(c);
        off = c->offset;
        c->offset += n;
        unlock(c);
    }else
        off = *offp;

    if(off < 0)
        error(Enegoff);

    m = devtab[c->type]->write(c, (void*)arg[1], n, off);

    if(offp == nil && m < n){
        lock(c);
        c->offset -= n - m;
        unlock(c);
    }

    poperror();
    cclose(c);

    return m;
}
@
% no devoffset thing here? because can't write in union dir?


\section{[[sysseek()]]}

% because return vlong and not just a long, arg[0] is a ref
% to write into the vlong (need probably look at cc to understand?)
% note that the mkfile in 9syscall/ has some special handling for seek
<<syscall seek>>=
// vlong seek(int fd, vlong n, int type);
long
sysseek(ulong* arg)
{
    validaddr(arg[0], BY2V, true);
    arch_validalign(arg[0], sizeof(vlong));
    sseek(arg);
    return 0;
}
@


<<function sseek>>=
union v_or_u2 {
  vlong v;
  ulong u[2];
};

// vlong seek(int fd, vlong n, int type);
static void
sseek(ulong *arg)
{
    Chan *c;
    byte buf[sizeof(DirEntry)+100];
    DirEntry dir;
    int n;
    vlong off;
    union v_or_u2 o;

    c = fdtochan(arg[1], -1, true, true);
    if(waserror()){
        cclose(c);
        nexterror();
    }
    <<[[sseek()]] and pipes>>

    off = 0;
    o.u[0] = arg[2];
    o.u[1] = arg[3];
    switch(arg[4]){
    case 0: // from the start
        off = o.v;
        <<[[sseek()]] ensures off is 0 for directories>>
        if(off < 0)
            error(Enegoff);
        c->offset = off; // just write, no need for lock
        break;

    case 1: // from the current location
        <<[[sseek()]] disallows seek type 1 or 2 for directories>>
        lock(c);    /* lock for read/write update */
        off = o.v + c->offset;
        if(off < 0){
            unlock(c);
            error(Enegoff);
        }
        c->offset = off;
        unlock(c);
        break;

    case 2: // from the end of the file
        <<[[sseek()]] disallows seek type 1 or 2 for directories>>
        n = devtab[c->type]->stat(c, buf, sizeof buf);
        if(convM2D(buf, n, &dir, nil) == 0)
            error("internal error: stat error in seek");
        off = dir.length + o.v;
        if(off < 0)
            error(Enegoff);
        c->offset = off;
        break;

    default:
        error(Ebadarg);
    }
    *(vlong*)arg[0] = off;
    c->uri = 0;
    c->dri = 0;
    cclose(c);
    poperror();
}
@
% uri? dri?
% note that no seek Dev method, see the comment next to Dev for why


\section{Collecting unclosed files}

<<[[Proc]] files fields>>=
Fgrp  *closingfgrp; /* used during teardown */
@
% this is set in closefgrp() while iterative over
% all the open fd and closing them (which can generate
% some error() I guess), so need to collect

<<[[sleep()]] forceclosefgrp>>=
if(up->procctl == Proc_exitme && up->closingfgrp)
    forceclosefgrp();
@

<<function forceclosefgrp>>=
/*
 * Called from sleep because up is in the middle
 * of closefgrp and just got a kill ctl message.
 * This usually means that up has wedged because
 * of some kind of deadly embrace with mntclose
 * trying to talk to itself.  To break free, hand the
 * unclosed channels to the close queue.  Once they
 * are finished, the blocked cclose that we've 
 * interrupted will finish by itself.
 */
void
forceclosefgrp(void)
{
    int i;
    Chan *c;
    Fgrp *f;

    if(up->procctl != Proc_exitme || up->closingfgrp == nil){
        print("bad forceclosefgrp call");
        return;
    }

    f = up->closingfgrp;
    for(i = 0; i <= f->maxfd; i++)
        if(c = f->fd[i]){
            f->fd[i] = nil;
            ccloseq(c);
        }
}
@ 



<<struct Clunkq>>=
/*
 * Queue a chan to be closed by one of the clunk procs.
 */
struct Clunkq {
    Chan *head;
    Chan *tail;
    int nqueued;
    int nclosed;
    Lock l;
    QLock q;
    Rendez r;
};
@


<<global clunkq>>=
struct Clunkq clunkq;
@


<<function ccloseq>>=
void
ccloseq(Chan *c)
{
    if(c->flag&CFREE)
        panic("cclose %#p", getcallerpc(&c));

    DBG("ccloseq %p name=%s ref=%ld\n", c, c->path->s, c->ref);

    if(decref(c))
        return;

    lock(&clunkq.l);
    clunkq.nqueued++;
    c->next = nil;
    if(clunkq.head)
        clunkq.tail->next = c;
    else
        clunkq.head = c;
    clunkq.tail = c;
    unlock(&clunkq.l);

    if(!wakeup(&clunkq.r))
        kproc("kcloseproc", closeproc, nil); 
}
@


<<function clunkwork>>=
static int
clunkwork(void*)
{
    return clunkq.head != nil;
}
@


<<function closeproc>>=
void
closeproc(void*)
{
    Chan *c;

    for(;;){
        qlock(&clunkq.q);
        if(clunkq.head == nil){
            if(!waserror()){
                tsleep(&clunkq.r, clunkwork, nil, 5000);
                poperror();
            }
            if(clunkq.head == nil){
                qunlock(&clunkq.q);
                pexit("no work", /*freemem*/true);
            }
        }
        lock(&clunkq.l);
        c = clunkq.head;
        clunkq.head = c->next;
        clunkq.nclosed++;
        unlock(&clunkq.l);
        qunlock(&clunkq.q);
        if(!waserror()){
            devtab[c->type]->close(c);
            poperror();
        }
        chanfree(c);
    }
}
@


\section{Special opening modes}

\subsection{Close on exec}

% useful for what?
% in mmm I have
%let extern dh ctype =
%  let (pin, pout) = pipe() in
%  (* children must not keep pout open *)
%  Unix.set_close_on_exec pout;
%  match Low.fork() with
%  | 0 ->
%      dup2 pin stdin; close pin;
%      Munix.execvp "metamail" [| "metamail"; "-b"; "-x"; "-c"; ctype |]
% close the pipe on exec because???


<<enum open cases>>=
OCEXEC = 32,  /* or'ed in, close on exec */
@
% usually negated before calling ->open()

<<enum channelflag cases>>=
CCEXEC  = 0x0008,   /* close on exec */
@

<<[[namec()]] set channel flag after open>>=
if(omode & OCEXEC)
    c->flag |= CCEXEC;
@

<<[[namec()]] set channel flag after create>>=
if(omode & OCEXEC)
    cnew->flag |= CCEXEC;
@

<<[[sysexec()]] locals>>=
Fgrp *f;
@

<<[[sysexec()]] close files marked as opened with close on exec>>=
/*
 * Close on exec
 */
f = up->fgrp;
for(i=0; i<=f->maxfd; i++)
    fdclose(i, CCEXEC);
@

\subsection{Remove on close}
% for temporary files? convenient?

<<enum open cases>>=
ORCLOSE = 64,  /* or'ed in, remove on close */
@

<<enum channelflag cases>>=
CRCLOSE = 0x0020,   /* remove on close */
@


<<[[namec()]] set channel flag after open>>=
if(omode & ORCLOSE)
    c->flag |= CRCLOSE;
@

<<[[namec()]] set channel flag after create>>=
if(omode & ORCLOSE)
    cnew->flag |= CRCLOSE;
@

% no generic code operating on CRCLOSE, each dev does differently
% but why? why not call ->remove() in sysclose()?





\chapter{Directories}

<<systab directory syscalls>>=
    [CREATE]    syscreate,
    [REMOVE]    sysremove,

    [CHDIR]     syschdir,
    [FD2PATH]   sysfd2path, // =~ pwd

    [STAT]      sysstat,
    [FSTAT]     sysfstat,
    [WSTAT]     syswstat,
    [FWSTAT]    sysfwstat,
@

\section{Overview}

% not that called often, but helps illustrate QTDIR introduced in chapter 3
<<function error_if_not_dir>>=
void
error_if_not_dir(Chan *c)
{
    if(c->qid.type & QTDIR)
        return;
    error(Enotdir);
}
@

% could put slash and dot Proc fields here

% a few diffs between generic File and Dir, do certain
% special things/checks for Dir


<<[[sseek()]] ensures off is 0 for directories>>=
if((c->qid.type & QTDIR) && off != 0)
    error(Eisdir);
@

<<[[sseek()]] disallows seek type 1 or 2 for directories>>=
if(c->qid.type & QTDIR)
    error(Eisdir);
@

<<[[namec()]] error if not a directory or cannot exec directory>>=
if(e.mustbedir && !(c->qid.type & QTDIR))
    error(Enotdir);

if((amode == Aopen) && (omode & OEXEC) && (c->qid.type & QTDIR))
    error("cannot exec directory");
@
% was (omode&OEXEC) == OEXEC but does not make sense

\section{[[Path]]}
% mv later?

% see Path *path; in Chan

<<struct Path>>=
struct Path
{
    char  *s;
    int len;      /* strlen(s) */
    int alen;     /* allocated length of s */

    <<[[Path]] mtpt fields>>
 
    // extra
    Ref;
};
@
% why need path? for fd2path for sure, but also for error messages on channel
%  in general. But then could do things lazily no? start from chan
%  and go '..' until slash then can compute full path? for full
%  explanation see lexnames.ps.





\ifallcode
% could delete, just used for statistics but never made accessible anywhere
<<global npath>>=
Ref npath;
@
\fi


<<constructor newpath>>=
Path*
newpath(char *s)
{
    int i;
    Path *p;

    p = smalloc(sizeof(Path));
    i = strlen(s);
    p->len = i;
    p->alen = i+PATHSLOP;
    p->s = smalloc(p->alen);
    memmove(p->s, s, i+1);
    p->ref = 1;
    incref(&npath);

    <<[[newpath()]] mtpt handling>>
    return p;
}
@

<<constant PATHSLOP>>=
PATHSLOP    = 20,
@


<<function copypath>>=
static Path*
copypath(Path *p)
{
    int i;
    Path *pp;
    
    pp = smalloc(sizeof(Path));
    pp->ref = 1;
    incref(&npath);
    DBG("copypath %s %p => %p\n", p->s, p, pp);
    
    pp->len = p->len;
    pp->alen = p->alen;
    pp->s = smalloc(p->alen);
    memmove(pp->s, p->s, p->len+1);
    
    <<[[copypath()]] mtpt handling>>
    return pp;
}
@


<<destructor pathclose>>=
void
pathclose(Path *p)
{
    int i;
    
    if(p == nil)
        return;
    <<[[pathclose()]] debugging>>
    if(decref(p))
        return;

    decref(&npath);
    free(p->s);

    <<[[pathclose()]] mtpt handling>>
    free(p);
}
@


% usually call via p = uniquepath(p) hence the pathclose() below
% because you are cloning yourself and removing yourself from
% the used refs.
<<function uniquepath>>=
static Path*
uniquepath(Path *p)
{
    Path *new;
    
    if(p->ref > 1){
        /* copy on write */
        new = copypath(p);
        pathclose(p);
        p = new;
    }
    return p;
}
@


% called from walk(), namec(), so maybe put after walk?
<<function addelem>>=
static Path*
addelem(Path *p, char *s, Chan *from)
{
    char *t;
    int a, i;
    Chan *c, **tt;

    if(s[0]=='.' && s[1]=='\0')
        return p;

    p = uniquepath(p);

    i = strlen(s);
    // +1 for the '\0'
    if(p->len+1+i+1 > p->alen){
        a = p->len+1+i+1 + PATHSLOP;
        t = smalloc(a);
        memmove(t, p->s, p->len+1);
        free(p->s);
        p->s = t;
        p->alen = a;
    }
    /* don't insert extra slash if one is present */
    if(p->len>0 && p->s[p->len-1]!='/' && s[0]!='/')
        p->s[p->len++] = '/';
    memmove(p->s+p->len, s, i+1);
    p->len += i;

    if(isdotdot(s)){
        fixdotdotname(p);
    }
    <<[[addelem()]] mtpt handling>>

    return p;
}
@


\section{[[..]]}
% mv later? not used in namec directly

<<function isdotdot>>=
int
isdotdot(char *p)
{
    return p[0]=='.' && p[1]=='.' && p[2]=='\0';
}
@

% essentially cleanname()
<<function fixdotdotname>>=
/*
 * In place, rewrite name to compress multiple /, eliminate ., and process ..
 * (Really only called to remove a trailing .. that has been added.
 * Otherwise would need to update n->mtpt as well.)
 */
static void
fixdotdotname(Path *p)
{
    char *r;

    if(p->s[0] == '#'){
        r = strchr(p->s, '/');
        if(r == nil)
            return;
        cleanname(r);

        /*
         * The correct name is #i rather than #i/,
         * but the correct name of #/ is #/.
         */
        if(strcmp(r, "/")==0 && p->s[1] != '/')
            *r = '\0';
    }else
        cleanname(p->s);
    p->len = strlen(p->s);
}
@
% cleanname() is in libc, and modify in place. it only shortens
% so no need to realloc there


\section{[[walk()]]}

%update:
% will need to get listing of a directory when want to
%  - list its content (read syscall)
%  - cd over it (walk syscall)
% and there are lots of commonalities between the 2 so
% they have this devdirread(..., qidgen), and devwalk(..., qidgen)
% helpers so can factorize code and have the developer of a new
% device to mostly write just the qidgen.

% overview: get a list of names, walk as far as possible towards
% next .. (cos handled generically here I think) or end.
% should return in walkqid the set of names went through that are
% in this mountpoint. Then go through this list of names and make
% sure there was no intermediate mountpoint on the way

% taking a list of names allows to do multiple walks at once, so avoid too
% many roundtrips to file server
<<[[Dev]] methods>>=
Walkqid*(*walk)(Chan*, Chan*, char**, int);
@
% what is second chan parameter?
% have to explain semantic of this method. take an array of names
% and its length (or sublength), and walk as much as possible it can?
% and return number of elements handled

<<struct Walkqid>>=
struct Walkqid
{
  Chan  *clone;
  int nqid;
  // variable array length, size = nqid
  Qid qid[1];
};
@

% logical flow?
<<[[walk()]] locals>>=
Chan *c;
Path *path;
Walkqid *wq;
Chan *nc;
@

<<[[walk()]] locals>>=
Mhead *mh;
Mhead *nmh;
int type, dev;
@
% more in later chapter, but hard to LP split more

<<[[walk()]] locals>>=
Chan *mtpt;
bool didmount;
@

<<[[walk()]] locals>>=
bool dotdot;
@

<<[[walk()]] locals>>=
int nhave, ntry;
@
% ntry is passed the last elt to process? so len+1?

\ifallcode
<<[[walk()]] locals>>=
int i, n;
@
\fi

<<[[namec()]] locals>>=
bool sharppath;
@
% remember:   sharppath = (name[0] == '#'); in namec()


% another big function ... namec() and walk() are complicated
% called by namec():  if(walk(&c, e.elems, e.nelems, mount, &e.nerror) < 0){
% s/ntry/next?
<<function walk>>=
/*
 * Either walks all the way or not at all.  No partial results in *cp.
 * *nerror is the number of names to display in an error message.
 */
int
walk(Chan **cp, char **names, int nnames, bool sharppath, int *nerror)
{
    <<[[walk()]] locals>>

    c = *cp;
    incref(c);
    path = c->path;
    incref(path);

    mh = nil;

    /*
     * While we haven't gotten all the way down the path:
     *    1. step through a mount point, if any
     *    2. send a walk request for initial dotdot or initial prefix without dotdot
     *    3. move to the first mountpoint along the way.
     *    4. repeat.
     *
     * Each time through the loop:
     *
     *  If didmount==false, c is on the undomount side of the mount point.
     *  If didmount==true, c is on the domount side of the mount point.
     *  Either way, c's full path is path.
     */
    didmount = false;
    for(nhave=0; nhave<nnames; nhave+=n){

        <<[[walk()]] return error if channel c is not a dir>>

        <<[[walk()]] set dotdot and ntry to index of next '..' or end>>

        if(!sharppath && !dotdot && !didmount)
            domount(&c, &mh, &path);
        
        type = c->type;
        dev = c->dev;

        if((wq = ewalk(c, names+nhave, ntry)) == nil){
            // didn't find the element, look in union mount
            <<[[walk()]] if c is a union mount, find and adjust type and dev>>
            <<[[walk()]] if wq is still nil, close and return>>
        }

        didmount = false;
        if(dotdot){
            assert(wq->nqid == 1);
            assert(wq->clone != nil);
            path = addelem(path, "..", nil);
            nc = undomount(wq->clone, path);
            nmh = nil;
            n = 1;
        }else{
            nc = nil;
            nmh = nil;
            if(!sharppath){
                // mount points along path?
                for(i=0; i<wq->nqid && i<ntry-1; i++){
                    if(findmount(&nc, &nmh, type, dev, wq->qid[i])){
                        didmount = true;
                        break;
                    }
                }
            }

            if(!didmount){  /* no mount points along path */
                <<[[walk()]] if nc == nil and wq->clone == nil return error>>
                n = wq->nqid;
                nc = wq->clone;
            }else{      /* stopped early, at a mount point */
                if(wq->clone != nil){
                    cclose(wq->clone);
                    wq->clone = nil;
                }
                n = i+1;
            }

            for(i=0; i<n; i++){
                mtpt = nil;
                if(i==n-1 && nmh)
                    mtpt = nmh->from;
                path = addelem(path, names[nhave+i], mtpt);
            }
        }
        cclose(c);
        c = nc;
        putmhead(mh);
        mh = nmh;
        free(wq);
    }

    putmhead(mh);

    c = uniquechan(c); // late? why now? we've modified in place c already

    <<[[walk()]] print error if c->umh != nil>>

    pathclose(c->path);
    c->path = path;

    cclose(*cp);
    *cp = c;
    if(nerror)
        *nerror = nhave;
    return 0;
}
@
% handle specially dotdot because of the mtpt and the getting dot dot right thing

<<function ewalk>>=
/*
 * Call dev walk but catch errors.
 */
static Walkqid*
ewalk(Chan *c, char **names, int nnames)
{
    Walkqid *wq;

    if(waserror())
        return nil;
    wq = devtab[c->type]->walk(c, nil, names, nnames);
    poperror();
    return wq;
}
@

<<[[walk()]] set dotdot and ntry to index of next '..' or end>>=
dotdot = false;
// remaining names
ntry = nnames - nhave;
if(ntry > MAXWELEM)
    ntry = MAXWELEM;

for(i=0; i<ntry; i++){
    if(isdotdot(names[nhave+i])){
        if(i==0){
            dotdot = true;
            ntry = 1;
        }else
            ntry = i;
        break;
    }
}
// ntry is now the index of the next '..' or the remaining names to walk
@

<<[[walk()]] return error if channel c is not a dir>>=
if(!(c->qid.type & QTDIR)){
    pathclose(path);
    cclose(c);
    if(nerror)
        *nerror = nhave;
    if(mh != nil)
        putmhead(mh);
    strcpy(up->errstr, Enotdir);
    return -1;
}
@

<<[[walk()]] if wq is still nil, close and return>>=
if(wq == nil){
    pathclose(path);
    cclose(c);
    if(nerror)
        *nerror = nhave+1;
    if(mh != nil)
        putmhead(mh);
    return -1;
}
@

<<[[walk()]] if nc == nil and wq->clone == nil return error>>=
if(wq->clone == nil){
    pathclose(path);
    cclose(c);
    if(wq->nqid==0 || (wq->qid[wq->nqid-1].type&QTDIR)){
        if(nerror)
            *nerror = nhave+wq->nqid+1;
        strcpy(up->errstr, Edoesnotexist);
    }else{
        if(nerror)
            *nerror = nhave+wq->nqid;
        strcpy(up->errstr, Enotdir);
    }
    free(wq);
    if(mh != nil)
        putmhead(mh);
    return -1;
}
@
% (wq->qid[wq->nqid-1].type&QTDIR) ??? what is this for?

<<function cclone>>=
Chan*
cclone(Chan *c)
{
    Chan *nc;
    Walkqid *wq;

    wq = devtab[c->type]->walk(c, nil, nil, 0);

    if(wq == nil)
        error("clone failed");
    nc = wq->clone;
    free(wq);
    nc->path = c->path;
    if(c->path)
        incref(c->path);
    return nc;
}
@


\section{[[syscreate()]]}


<<syscall create>>=
// int create(char *file, int omode, ulong perm);
long
syscreate(ulong* arg)
{
    int fd;
    Chan *c;

    openmode(arg[1]&~OEXCL);    /* error check only; OEXCL okay here */
    validaddr(arg[0], 1, false);
    c = namec((char*)arg[0], Acreate, arg[1], arg[2]);
    if(waserror()){
        cclose(c);
        nexterror();
    }
    fd = newfd(c);
    if(fd < 0)
        error(Enofd);
    poperror();
    return fd;
}
@
% very similar to sysopen, but with Acreate instead of Aopen


<<[[namec()]] adjust Elemlist e if Acreate>>=
if(amode == Acreate){
    /* perm must have DMDIR if last element is / or /. */
    if(e.mustbedir && !(perm&DMDIR)){
        e.nerror = e.nelems;
        error("create without DMDIR");
    }

    /* don't try to walk the last path element just yet. */
    if(e.nelems == 0)
        error(Eexist);
    e.nelems--;
}
@
% not e.nerrors-- ?

<<[[namec()]] locals>>=
Chan *cnew;
char *createerr;
@

<<[[Dev]] methods>>=
void  (*create)(Chan*, char*, int, ulong);
@

<<[[namec()]] other cases>>=
case Acreate:
    /*
     * We've already walked all but the last element.
     * If the last exists, try to open it OTRUNC.
     * If omode&OEXCL is set, just give up.
     */
    e.nelems++;
    e.nerror++;
    if(walk(&c, e.elems+e.nelems-1, 1, sharppath, nil) == 0){
        if(omode&OEXCL)
            error(Eexist);
        omode |= OTRUNC;
        goto Open;
    }

    /*
     * The semantics of the create(2) system call are that if the
     * file exists and can be written, it is to be opened with truncation.
     * On the other hand, the create(5) message fails if the file exists.
     * If we get two create(2) calls happening simultaneously, 
     * they might both get here and send create(5) messages, but only 
     * one of the messages will succeed.  To provide the expected create(2)
     * semantics, the call with the failed message needs to try the above
     * walk again, opening for truncation.  This correctly solves the 
     * create/create race, in the sense that any observable outcome can
     * be explained as one happening before the other.
     * The create/create race is quite common.  For example, it happens
     * when two rc subshells simultaneously update the same
     * environment variable.
     *
     * The implementation still admits a create/create/remove race:
     * (A) walk to file, fails
     * (B) walk to file, fails
     * (A) create file, succeeds, returns 
     * (B) create file, fails
     * (A) remove file, succeeds, returns
     * (B) walk to file, return failure.
     *
     * This is hardly as common as the create/create race, and is really
     * not too much worse than what might happen if (B) got a hold of a
     * file descriptor and then the file was removed -- either way (B) can't do
     * anything with the result of the create call.  So we don't care about this race.
     *
     * Applications that care about more fine-grained decision of the races
     * can use the OEXCL flag to get at the underlying create(5) semantics;
     * by default we provide the common case.
     *
     * We need to stay behind the mount point in case we
     * need to do the first walk again (should the create fail).
     *
     * We also need to cross the mount point and find the directory
     * in the union in which we should be creating.
     *
     * The channel staying behind is c, the one moving forward is cnew.
     */
    m = nil;
    cnew = nil; /* is this assignment necessary? */
    if(!waserror()){    /* try create */
        <<[[namec()]] Acreate case, if cnew is a mountpoint>>
        else{
            cnew = c;
            incref(cnew);
        }

        /*
         * We need our own copy of the Chan because we're
         * about to send a create, which will move it.  Once we have
         * our own copy, we can fix the name, which might be wrong
         * if findmount gave us a new Chan.
         */
        cnew = uniquechan(cnew);
        pathclose(cnew->path);
        cnew->path = c->path;
        incref(cnew->path);

        devtab[cnew->type]->create(cnew, e.elems[e.nelems-1], omode&~(OEXCL|OCEXEC), perm);
        poperror();
        <<[[namec()]] set channel flag after create>>
        if(m)
            putmhead(m);
        cclose(c);
        c = cnew;
        c->path = addelem(c->path, e.elems[e.nelems-1], nil);
        break; // switch
    }

    /* create failed */
    cclose(cnew);
    if(m)
        putmhead(m);
    if(omode & OEXCL)
        nexterror();

    /* save error */
    createerr = up->errstr;
    up->errstr = tmperrbuf;
    /* note: we depend that walk does not error */
    if(walk(&c, e.elems+e.nelems-1, 1, sharppath, nil) < 0){
        up->errstr = createerr;
        error(createerr);   /* report true error */
    }
    up->errstr = createerr;
    omode |= OTRUNC;
    goto Open;
@





% do a Special creation modes?

<<enum open cases>>=
OTRUNC = 16,  /* or'ed in (except for exec), truncate file first */
@
% lp split stuff using OTRUNC here?

<<enum open cases>>=
OEXCL = 0x1000,  /* or'ed in, exclusive create */
@





\section{[[sysremove()]]}

<<[[Dev]] methods>>=
void  (*remove)(Chan*);
@

<<syscall remove>>=
// int remove(char *file);
long
sysremove(ulong* arg)
{
    Chan *c;

    validaddr(arg[0], 1, false);
    c = namec((char*)arg[0], Aremove, 0, 0);
    /*
     * Removing mount points is disallowed to avoid surprises
     * (which should be removed: the mount point or the mounted Chan?).
     */
    if(c->ismtpt){
        cclose(c);
        error(Eismtpt);
    }
    if(waserror()){
        c->type = 0;    /* see below */
        cclose(c);
        nexterror();
    }
    devtab[c->type]->remove(c);
    /*
     * Remove clunks the fid, but we need to recover the Chan
     * so fake it up.  rootclose() is known to be a nop.
     */
    c->type = 0;
    poperror();
    cclose(c);
    return 0;
}
@
% comment about clunks??
% what about already opened files? can remove a used file?

\section{[[syschdir()]]}

% could put dot Proc field here and LP split its use before

<<syscall chdir>>=
// int chdir(char *dirname);
long
syschdir(ulong* arg)
{
    Chan *c;

    validaddr(arg[0], 1, false);
    c = namec((char*)arg[0], Atodir, 0, 0);
    cclose(up->dot);
    up->dot = c;
    return 0;
}
@

% after validated name, parsed name, walked name, got a ("unopened") channel
<<[[namec()]] other cases>>=
case Atodir:
    /*
     * Directories (e.g. for cd) are left before the mount point,
     * so one may mount on / or . and see the effect.
     */
    if(!(c->qid.type & QTDIR))
        error(Enotdir);
    break;
@
% comments can be understood only in relation to other cases and 
% the understanding of domount()

\section{[[sysfd2path()]] (a.k.a [[pwd()]])}
% does a realpath? plan9 has symlinks?

<<syscall fd2path>>=
// int fd2path(int fd, char *buf, int nbuf);
long
sysfd2path(ulong* arg)
{
    Chan *c;

    validaddr(arg[1], arg[2], true);
    c = fdtochan(arg[0], -1, false, true);
    snprint((char*)arg[1], arg[2], "%s", 
              chanpath(c));
    cclose(c);
    return 0;
}
@

% also used by nameerror
<<function chanpath>>=
char*
chanpath(Chan *c)
{
    if(c == nil)
        return "<nil chan>";
    if(c->path == nil)
        return "<nil path>";
    if(c->path->s == nil)
        return "<nil path.s>";
    return c->path->s;
}
@


\section{[[DirEntry]]}

% also in libc.h (but called Dir there)
% so if change fields here, need to change also in libc.h but
% there are code like direntry_setname that compute offsets so safer to not change
<<struct DirEntry>>=
struct DirEntry {
  /* system-modified data */
  ushort  type; /* server type */
  uint  dev;  /* server subtype */

  /* file data */
  Qid qid;  /* unique id from server */
  // bitset<enum<dirmode>>
  ulong mode; /* permissions */

  ulong atime;  /* last read time */
  ulong mtime;  /* last write time */

  vlong length; /* file length: see <u.h> */
  char  *name;  /* last element of path */

  char  *uid; /* owner name */
  char  *gid; /* group name */
  char  *muid;  /* last modifier name */
};
@ 
% rename mode perm? and have a typedef perm? (and typedef openmode)
% gid here! cool muid :)
% vs walkqid? vs Dirtab? reorder so look closer to Dirtab (DirEntryShort)

<<enum dirmode>>=
/* bits in DirEntry.mode */
enum dirmode {
    DMDIR = 0x80000000,  /* mode bit for directories */

    DMREAD = 0x4,   /* mode bit for read permission */
    DMWRITE = 0x2,   /* mode bit for write permission */
    DMEXEC = 0x1,   /* mode bit for execute permission */
    <<enum dirmode cases>>
};
@ 
% DMREAD, DMWRITE, DMEXEC are actually never used in the kernel.
% I think the kernel does not really care except just passing around
% and delegate. So those are defined in libc.h but do not need to
% be defined here I think.
%DMAPPEND = 0x40000000,  /* mode bit for append only files */

<<function direntry_setname>>=
static long
direntry_setname(char *name, int len, byte *p, long n, long maxn)
{
    char *oname;
    int olen;
    long nn;

    if(n == BIT16SZ)
        return BIT16SZ;

    oname = offsetof_name_direntry(p, &olen);

    nn = n+len-olen;
    PBIT16(p, nn-BIT16SZ);
    if(nn > maxn)
        return BIT16SZ;

    if(len != olen)
        memmove(oname+len, oname+olen, p+n-(byte*)(oname+olen));
    PBIT16((byte*)(oname-2), len);
    memmove(oname, name, len);
    return nn;
}
@

% find offset of name field in DirEntry?
<<function offsetof_name_direntry>>=
static char*
offsetof_name_direntry(byte *p, int *n)
{
    p += BIT16SZ+BIT16SZ+BIT32SZ +
          BIT8SZ+BIT32SZ+BIT64SZ +
          BIT32SZ+BIT32SZ+BIT32SZ + 
          BIT64SZ;
    *n = GBIT16(p);
    return (char*)p+BIT16SZ;
}
@



\section{[[sysstat()]]}

<<[[Dev]] methods>>=
int (*stat)(Chan*, byte*, int);
@

%byte* actually a buffer containing a DirEntry I think
% but platform independent?
<<syscall stat>>=
// int stat(char *name, byte *edir, int nedir);
long
sysstat(ulong* arg)
{
    char *name;
    Chan *c;
    uint l;

    l = arg[2];
    validaddr(arg[1], l, true);
    validaddr(arg[0], 1, false);
    c = namec((char*)arg[0], Aaccess, 0, 0);
    if(waserror()){
        cclose(c);
        nexterror();
    }
    l = devtab[c->type]->stat(c, (byte*)arg[1], l);

    name = pathlast(c->path);
    if(name)
        l = direntry_setname(name, strlen(name), (byte*)arg[1], l, arg[2]);

    poperror();
    cclose(c);
    return l;
}
@

% like stat but with a file descriptor instead of a filename
<<syscall fstat>>=
// int fstat(int fd, byte *edir, int nedir);
long
sysfstat(ulong* arg)
{
    Chan *c;
    uint l;

    l = arg[2];
    validaddr(arg[1], l, true);
    c = fdtochan(arg[0], -1, false, true);
    if(waserror()) {
        cclose(c);
        nexterror();
    }
    l = devtab[c->type]->stat(c, (byte*)arg[1], l);
    poperror();
    cclose(c);
    return l;
}
@
% why don't do the same direntry_setname thing?


<<function pathlast>>=
static char*
pathlast(Path *p)
{
    char *s;

    if(p == nil)
        return nil;
    if(p->len == 0)
        return nil;
    s = strrchr(p->s, '/');
    if(s)
        return s+1;
    return p->s;
}
@




<<[[Dev]] methods>>=
int (*wstat)(Chan*, byte*, int);
@



<<syscall wstat>>=
// int wstat(char *name, byte *edir, int nedir);
long
syswstat(ulong* arg)
{
    Chan *c;
    uint l;

    l = arg[2];
    validaddr(arg[1], l, false);
    validstat((byte*)arg[1], l);
    validaddr(arg[0], 1, false);
    c = namec((char*)arg[0], Aaccess, 0, 0);
    return wstat(c, (byte*)arg[1], l);
}
@

<<syscall fwstat>>=
// int fwstat(int fd, byte *edir, int nedir);
long
sysfwstat(ulong* arg)
{
    Chan *c;
    uint l;

    l = arg[2];
    validaddr(arg[1], l, false);
    validstat((byte*)arg[1], l);
    c = fdtochan(arg[0], -1, true, true);
    return wstat(c, (byte*)arg[1], l);
}
@



<<function validstat>>=
void
validstat(byte *s, int n)
{
    int m;
    char buf[64];

    if(statcheck(s, n) < 0)
        error(Ebadstat);
    /* verify that name entry is acceptable */
    s += STATFIXLEN - 4*BIT16SZ;    /* location of first string */
    /*
     * s now points at count for first string.
     * if it's too long, let the server decide; this is
     * only for his protection anyway. otherwise
     * we'd have to allocate and waserror.
     */
    m = GBIT16(s);
    s += BIT16SZ;
    if(m+1 > sizeof buf)
        return;
    memmove(buf, s, m);
    buf[m] = '\0';
    /* name could be '/' */
    if(strcmp(buf, "/") != 0)
        validname(buf, false);
}
@


<<function wstat>>=
static long
wstat(Chan *c, byte *d, int nd)
{
    long l;
    int namelen;

    if(waserror()){
        cclose(c);
        nexterror();
    }
    if(c->ismtpt){
        /*
         * Renaming mount points is disallowed to avoid surprises
         * (which should be renamed? the mount point or the mounted Chan?).
         */
        offsetof_name_direntry(d, &namelen);
        if(namelen)
            nameerror(chanpath(c), Eismtpt);
    }
    l = devtab[c->type]->wstat(c, d, nd);
    poperror();
    cclose(c);
    return l;
}
@








\chapter{Namespaces}
\minitoc

<<systab namespace syscalls>>=
    [BIND]      sysbind,
    [MOUNT]     sysmount,
    [UNMOUNT]   sysunmount,
@ 

\section{Overview}

% Mount point, Mount table, Namespace (per process mount table), Union mount
% (and union directories)

% before and after mount point, 'from', 'to'. you go through a mount point.
% "being on the left part, right part of a mount point".

% also in libc.h
<<enum mount>>=
enum mount {
    MREPL = 0x0000,  /* mount replaces object */
  
    MBEFORE = 0x0001,  /* mount goes before others in union directory */
    MAFTER = 0x0002,  /* mount goes after others in union directory */
  
    MCREATE = 0x0004,  /* permit creation in mounted directory */
    <<enum mount cases>>
  
    MORDERMASK =  0x0003,  /* mask for bits defining order of mounting */
    MMASK = 0x0017,  /* all bits on */
};
@ 

% see names.ps

% relation with PL namespace concept? module A = Xxx.Yyyy.Zzz similar?


\section{Mount point}

<<struct Mhead>>=
struct Mhead
{
    // ref<Chan>
    Chan* from;     /* channel mounted upon */
    // list<ref<Mount>> list because of union mount (ordered via MBEFORE|MAFTER)
    Mount*  mount;      /* what's mounted upon it */

    Ref;
    RWlock  lock;
    <<[[Mhead]] extra fields>>
};
@
% have Mhead and Mount instead of just Mount because of union mount
% but for now can just think as one structure: Mountpoint.
% it's not a list<ref_owned<Mount>> actually, see putmhead which does not
%  call mountfree(). The owner is the mhead in mnthash, but not any mhead.
%  (but maybe Mount could have a Ref so it will be simpler)

<<constructor newmhead>>=
Mhead*
newmhead(Chan *from)
{
    Mhead *mh;

    mh = smalloc(sizeof(Mhead));
    mh->ref = 1;
    mh->from = from;
    incref(from);
    return mh;
}
@

<<destructor putmhead>>=
/*
 * This is necessary because there are many
 * pointers to the top of a given mount list:
 *
 *  - the mhead in the namespace hash table
 *  - the mhead in chans returned from findmount:
 *    used in namec and then by unionread.
 *  - the mhead in chans returned from createdir:
 *    used in the open/create race protect, which is gone.
 *
 * The RWlock in the Mhead protects the mount list it contains.
 * The mount list is deleted when we cunmount.
 * The RWlock ensures that nothing is using the mount list at that time.
 *
 * It is okay to replace c->mh with whatever you want as 
 * long as you are sure you have a unique reference to it.
 *
 * This comment might belong somewhere else.
 */
void
putmhead(Mhead *m)
{
    if(m && decref(m) == 0){
        m->mount = (Mount*)0xCafeBeef;
        free(m);
    }
}
@
% cafebeef? for what? just to be sure if missed a ref then it will go haywire
% quickly.
% does not call mountfree(m->mount)? who owns the mount then? closepgrp()
% the main pb is that should put a counter on Mount ...


<<struct Mount>>=
struct Mount
{
    // ref<Chan>
    Chan* to;     /* channel replacing channel */

    // enum<mount>, but mainly for MCREATE, the MBEFORE|MAFTER is encoded via list
    int mflag;

    // option<string>
    char  *spec; // for mount(), nil for bind()
    <<[[Mount]] other fields>>

    <<[[Mount]] extra fields>>
};
@
% ex of spec? for special mount requests?
% they should put a Ref!

% does not insert in any mh. for this you need to put it at
% the right place, in the right order, and this is done by the caller
<<constructor newmount>>=
Mount*
newmount(Chan *to, int flag, char *spec)
{
    Mount *m;

    m = smalloc(sizeof(Mount));
    m->to = to;
    incref(to);
    m->mountid = incref(&mountid);
    m->mflag = flag;
    if(spec != nil)
        kstrdup(&m->spec, spec);

    return m;
}
@ 
% so have Mhead->from, and then Mhead->mount->to

<<[[Mount]] extra fields>>=
Mount*  next;
@
% union mount, but will see later. Can aspectize? maybe too hard.

<<destructor mountfree>>=
void
mountfree(Mount *m)
{
    Mount *f;

    while(m) {
        f = m->next;
        cclose(m->to);
        m->mountid = 0;
        free(m->spec);
        free(m);
        m = f;
    }
}
@ 
% no lock? owned by Mhead so the lock should be done on that?


\section{Mount table}

% rename?
<<struct Pgrp>>=
// Mount table, aka Namespace, aka process group
struct Pgrp
{
    // hash<qid.path, list<ref<Mhead> (next = Mhead.next)>
    Mhead *mnthash[MNTHASH];

    <<[[Pgrp]] other fields>>
  
    // extra
    Ref;        /* also used as a lock when mounting */

    // ORDER OF LOCK: first debug and then ns
    QLock debug;      /* single access via devproc.c */
    RWlock  ns;     /* Namespace n read/one write lock */
};
@ 
% but would really like actually a hash from gqid (type+dev+qid) to Mhead.

<<[[Proc]] files fields>>=
// ref_counted<pgrp>
Pgrp  *pgrp;    /* Process group for namespace */
@



<<function MOUNTH>>=
enum
{
    MNTLOG  = 5,
    MNTHASH = 1<<MNTLOG,  /* Hash to walk mount table */
};
#define MOUNTH(p,qid) ((p)->mnthash[(qid).path&((1<<MNTLOG)-1)])
@
% >> >>

<<[[Mhead]] extra fields>>=
// hash<qid.path, list<ref<Mhead>> of Pgrp.mnthash
Mhead*  hash;     /* Hash chain */
@





<<[[Pgrp]] other fields>>=
ulong pgrpid;
@
% use of pgrpid? does not seem super used, could maybe remove it or aspectize
% it with the code that actually uses it

<<global pgrpid>>=
static Counter pgrpid;
@ 
% LP aspectize? remove? at least explain ... code using /dev/pgrpid?



<<constructor newpgrp>>=
Pgrp*
newpgrp(void)
{
    Pgrp *p;

    p = smalloc(sizeof(Pgrp));
    p->ref = 1;
    p->pgrpid = incref(&pgrpid);
    return p;
}
@ 


<<destructor closepgrp>>=
void
closepgrp(Pgrp *p)
{
    Mhead **h, **e, *f, *next;

    if(decref(p) != 0)
        return;

    qlock(&p->debug);
    wlock(&p->ns);
    p->pgrpid = -1;

    e = &p->mnthash[MNTHASH];
    for(h = p->mnthash; h < e; h++) {
        for(f = *h; f; f = next) {
            wlock(&f->lock);
            cclose(f->from);
            mountfree(f->mount);
            f->mount = nil;
            next = f->hash;
            wunlock(&f->lock);
            putmhead(f);
        }
    }
    wunlock(&p->ns);
    qunlock(&p->debug);
    free(p);
}
@ 
% s/p/mt? p is for process ... or s/p/pg?
% s/f/head, s/h/heads/
% should really just do putmhead(f) that then handle itself mountfree(f->mount)



\section{Device path}

% kind of bootstrapping the whole thing.
% usually: bind #xxx /dev/, which will lead the the creation of a Mhead and Mount
%  and later if mentions /dev again then we will add in the Mhead

% alternative is hardcoded list of drivers and huge populated /dev/
% via major/minor special file as in Linux



<<[[namec()]] locals>>=
Rune r;
@
% devices use rune for codename of the device: e.g. '#c', '#I', etc
% (better than char where it would then limit to 256 possible drivers)

<<[[namec()]] if name[0] is a sharp>>=
case '#':
    up->genbuf[0] = '\0';
    n = 0;
    while(*name != '\0' && (*name != '/' || n < 2)){ // "#/" is ok hence n < 2
        if(n >= sizeof(up->genbuf)-1)
            error(Efilename);
        up->genbuf[n++] = *name++;
    }
    up->genbuf[n] = '\0';

    n = chartorune(&r, up->genbuf+1)+1; // +1 for the leading '#'

    <<[[namec()]] noattach checking>>

    t = devno(r, true);
    if(t == -1)
        error(Ebadsharp);

    c = devtab[t]->attach(up->genbuf+n);
    break;
@
% so c is the starting point (instead of up->slash, or up->dot)
% genbuf+n? for the deviceno. chartorune modify &r and returns number of bytes
% read to produce the rune, so genbuf+n = remaining chars in name

<<[[Dev]] methods>>=
Chan* (*attach)(char*);
@
% called in namec() and bindmount()
% the char is a special string, kinda minor number, e.g. #ec, #e, (more?)




\section{[[sysbind()]]}

% ex: bind("#c", "/dev", MREPL), kinda major/minor mode of Linux
% ex: bind("/root/386/bin", "/bin", MREPL), kinda symlinks


<<syscall bind>>=
// int bind(char *to, char *from, int flag);
long
sysbind(ulong* arg)
{
    return bindmount(false, -1, -1, (char*)arg[0], (char*)arg[1], arg[2], nil);
}
@
% was: // int bind(char *name, char *old, int flag);
% but why use name and old? would be better src and dest no? old in the sense
% that it's a channel that will be mount upon and so people mentioning
% the path of old will actually be redirected to the new chan.

% bind to from flag: find chan c0 of to, find chan c1 of from, and adjust
% up->pgrp adding in mnthash a new mhead (if none before) for gqid
% of c1 and add Mount 'to' to be c0, and 'from' of mhead to be 'c1'
<<[[bindmount()]] locals>>=
Chan *c0;
Chan *c1;
@


% return mountid? what for?
<<function bindmount>>=

long
bindmount(bool ismount, int fd, int afd, char* arg0, char* arg1, ulong flag, char* spec)
{
    <<[[bindmount()]] locals>>

    if((flag&~MMASK) || (flag&MORDERMASK)==(MBEFORE|MAFTER))
        error(Ebadarg);

    <<[[bindmount()]] if ismount>>
    else{
        spec = nil;
        validaddr((ulong)arg0, 1, false);
        c0 = namec(arg0, Abind, 0, 0);
    }

    if(waserror()){
        cclose(c0);
        nexterror();
    }

    validaddr((ulong)arg1, 1, false);
    c1 = namec(arg1, Amount, 0, 0);

    if(waserror()){
        cclose(c1);
        nexterror();
    }

    ret = cmount(c0, c1, flag, spec);

    poperror();
    cclose(c1);
    poperror();
    cclose(c0);
    <<[[bindmount()]] if ismount free>>
    return ret;
}
@

\ifallcode
<<[[bindmount()]] locals>>=
int ret;
@
\fi

<<enum accessnamec cases>>=
Abind,        /* for left-hand-side of bind */
Amount,       /* to be mounted or mounted upon */
@

<<[[namec()]] other cases>>=
case Abind:
    m = nil;
    if(!sharppath)
        /* no need to maintain path - cannot dotdot an Abind */ // so pass nil
        domount(&c, &m, nil);
    <<[[namec()]] set c->umh in Abind if mounted point>>
    break;
@


<<[[namec()]] other cases>>=
case Amount:
    /*
     * When mounting on an already mounted upon directory,
     * one wants subsequent mounts to be attached to the
     * original directory, not the replacement.  Don't domount.
     */
    break;
@


<<[[cmount()]] locals>>=
Pgrp *pg;
Mhead *mh;
Mount *m;
int order;
@

% big function again
<<function cmount>>=
int
cmount(Chan *new, Chan *old, int flag, char *spec)
{
    <<[[cmount()]] locals>>

    if((old->qid.type ^ new->qid.type) & QTDIR)
        error(Emount);
    <<[[cmount()]] print error if old->umh != nil>>

    order = flag&MORDERMASK;
    if(!(old->qid.type & QTDIR) && order != MREPL)
        error(Emount);

    <<[[cmount()]] if new is itself a mount point, error if cant create there>>

    pg = up->pgrp;
    wlock(&pg->ns);

    // mh = lookup(old->gdid, pg.mnthash)
    l = &MOUNTH(pg, old->qid);
    for(mh = *l; mh; mh = mh->hash){
        if(eqchan(mh->from, old, true))
            break;
        l = &mh->hash;
    }

    if(mh == nil){
        /*
         *  nothing mounted here yet.  create a mount
         *  head and add to the hash table.
         */
        mh = newmhead(old);
        *l = mh;

        /*
         *  if this is a union mount, add the old
         *  node to the mount chain.
         */
        if(order != MREPL)
            mh->mount = newmount(old, 0, nil);
    }

    wlock(&mh->lock);
    if(waserror()){
        wunlock(&mh->lock);
        nexterror();
    }
    wunlock(&pg->ns);

    m = newmount(new, flag, spec);

    <<[[cmount()]] if new is itself a mount point, copy mounts>>

    if(mh->mount && order == MREPL){
        mountfree(mh->mount);
        mh->mount = nil;
    }
    if(flag & MCREATE)
        m->mflag |= MCREATE;

    if(mh->mount && order == MAFTER){
        for(f = mh->mount; f->next; f = f->next)
            ;
        f->next = m;
    }else{ // MBEFORE or MREPL
        // when new was itself a mount point, can have union of mount again
        for(f = m; f->next; f = f->next)
            ;
        f->next = mh->mount; // =~ m->next = mh->mount for the most common case
        mh->mount = m;
    }

    wunlock(&mh->lock);
    poperror();
    return m->mountid;
}
@



\section{[[/proc/#/ns]]}

<<struct Mntwalk>>=
struct Mntwalk              /* state for /proc/#/ns */
{
    bool cddone;
    Mhead*  mh;
    Mount*  cm;
};
@

<<[[procread()]] locals>>=
Mntwalk *mw;
char flag[10];
@

% introduce union case for c->aux!
<<[[procopen()]] cases>>=
case Qns:
    if(omode != OREAD)
        error(Eperm);
    c->aux = malloc(sizeof(Mntwalk));
    break;
@

<<[[procclose()]] hooks>>=
if(QID(c->qid) == Qns && c->aux != nil)
    free(c->aux);
@

<<[[procread()]] cases>>=
case Qns:
    qlock(&p->debug);
    if(waserror()){
        qunlock(&p->debug);
        nexterror();
    }
    if(p->pgrp == nil || p->pid != PID(c->qid))
        error(Eprocdied);

    mw = c->aux;
    if(mw == nil)
        error(Enomem);
    if(mw->cddone){
        qunlock(&p->debug);
        poperror();
        return 0;
    }

    mntscan(mw, p);

    if(mw->mh == nil){
        mw->cddone = true;
        i = snprint(a, n, "cd %s\n", p->dot->path->s);
        qunlock(&p->debug);
        poperror();
        return i;
    }

    int2flag(mw->cm->mflag, flag);
    if(strcmp(mw->cm->to->path->s, "#M") == 0){
        srv = srvname(mw->cm->to->mchan);
        i = snprint(a, n, "mount %s %s %s %s\n", flag,
            srv==nil? mw->cm->to->mchan->path->s : srv,
            mw->mh->from->path->s, mw->cm->spec? mw->cm->spec : "");
        free(srv);
    }else
        i = snprint(a, n, "bind %s %s %s\n", flag,
            mw->cm->to->path->s, mw->mh->from->path->s);
    qunlock(&p->debug);
    poperror();
    return i;
@

<<function int2flag>>=
static void
int2flag(int flag, char *s)
{
    if(flag == 0){
        *s = '\0';
        return;
    }
    *s++ = '-';
    if(flag & MAFTER)
        *s++ = 'a';
    if(flag & MBEFORE)
        *s++ = 'b';
    if(flag & MCREATE)
        *s++ = 'c';
    if(flag & MCACHE)
        *s++ = 'C';
    *s = '\0';
}
@

<<function mntscan>>=
void
mntscan(Mntwalk *mw, Proc *p)
{
    Pgrp *pg;
    Mount *t;
    Mhead *f;
    int i;
    bool nxt;
    ulong last, bestmid;

    pg = p->pgrp;
    rlock(&pg->ns);

    nxt = false;
    bestmid = ~0;

    last = 0;
    if(mw->mh)
        last = mw->cm->mountid;

    for(i = 0; i < MNTHASH; i++) {
        for(f = pg->mnthash[i]; f; f = f->hash) {
            for(t = f->mount; t; t = t->next) {
                if(mw->mh == nil ||
                  (t->mountid > last && t->mountid < bestmid)) {
                    mw->cm = t;
                    mw->mh = f;
                    bestmid = mw->cm->mountid;
                    nxt = true;
                }
            }
        }
    }
    if(nxt == false)
        mw->mh = nil;

    runlock(&pg->ns);
}
@



\section{[[findmount()]], [[domount()]]}
% namec() and walk() part2

% have seen how to create mount point, and mount table, now
% see when access it: via namec()

<<[[namec()]] locals>>=
Mhead *m;
Path *path;
@
% s/m/mh? but it's called that way because probably at the beginning
% there was just Mount, and so they were using m


<<[[namec()]] case Aopen, Acreate, Aremove, Aaccess, handle mountpoint part1>>=
/* save&update the name; domount might change c */
path = c->path;
incref(path);

m = nil;
if(!sharppath)
    domount(&c, &m, &path);

/* our own copy to open or remove */
c = uniquechan(c);

/* now it's our copy anyway, we can put the name back */
pathclose(c->path);
c->path = path;

/* record whether c is on a mount point */
c->ismtpt = (m!=nil);
@
% could put ismtpt chan field here, but also used before so ....
% LP split the path related stuff?

<<[[namec()]] case Aremove, Aaccess, handle mountpoint part2>>=
putmhead(m);
@


<<function findmount>>=
/* also used by sysfile.c:/^mountfix */
bool
findmount(Chan **cp, Mhead **mp, int type, int dev, Qid qid)
{
    Pgrp *pg;
    Mhead *m;

    pg = up->pgrp;
    rlock(&pg->ns);

    // *mp = lookup(gqid, pg.mnthash); *cp = mp->mount->to
    for(m = MOUNTH(pg, qid); m; m = m->hash){
        rlock(&m->lock);
        if(m->from == nil){
            print("m %p m->from 0\n", m);
            runlock(&m->lock);
            continue;
        }
        if(eqchantdqid(m->from, type, dev, qid, true)){
            runlock(&pg->ns);
            if(mp != nil){
                if(*mp != nil)
                    putmhead(*mp);
                *mp = m;
                incref(m);
            }
            if(*cp != nil)
                cclose(*cp);
            *cp = m->mount->to;
            incref(m->mount->to);
            runlock(&m->lock);
            return true;
        }
        runlock(&m->lock);
    }

    runlock(&pg->ns);
    return false;
}
@
% could simplify the code if could do some assert cp != nil, mp != nil
% and then even *mp == nil

% rename mount_chan_from_to_if_mountpoint?
<<function domount>>=
/*
 * Calls findmount but also updates path.
 */
static void
domount(Chan **cp, Mhead **mp, Path **path)
{
    Chan **lc;
    Path *p;

    if(!findmount(cp, mp, (*cp)->type, (*cp)->dev, (*cp)->qid))
        return;

    if(path){
        p = *path;
        p = uniquepath(p);
        if(p->mlen <= 0)
            print("domount: path %s has mlen==%d\n", p->s, p->mlen);
        else{
            lc = &p->mtpt[p->mlen-1];
            DBG("domount %p %s => add %p (was %p)\n", p, p->s, (*mp)->from, p->mtpt[p->mlen-1]);
            if(*lc)
                cclose(*lc);
            *lc = (*mp)->from;
            incref((*mp)->from);
        }
        *path = p;
    }
    return;
}
@
% LP split the path thing. don't increment mlen?
% assert path != nil too? actually for Abind we pass nil



\section{Path mount points and [[..]]}

<<[[Path]] mtpt fields>>=
// array<option<ref_counted<Chan>>, nil for elements which are not mount point
Chan  **mtpt;     /* mtpt history */
int mlen;     /* number of path elements */
int malen;      /* allocated length of mtpt */
@
% mtpt is for the mounted points on the path
% so for /usr/pad/foo.c => path s = "/usr/pad/foo.c\0", ??
% mlen = 3; chan = [nil; from of /usr if /usr is a mntpoint; nil; nil ]

% why need this array of mtpt? for reference counting the
%  intermediate dirs so that you can't remove those intermediate dirs as
%  there are still referenced in opened files? hmm no. It's mainly
%  to get '..' right, 
% see lexnames.ps


<<constant PATHMSLOP>>=
    PATHMSLOP   = 20,
@


<<[[newpath()]] mtpt handling>>=
/*
 * Cannot use newpath for arbitrary names because the mtpt 
 * array will not be populated correctly.  The names #/ and / are
 * allowed, but other names with / in them draw warnings.
 */
if(strchr(s, '/') && strcmp(s, "#/") != 0 && strcmp(s, "/") != 0)
    print("newpath: %s from %#p\n", s, getcallerpc(&s));

p->mlen = 1;
p->malen = PATHMSLOP;
p->mtpt = smalloc(p->malen*sizeof p->mtpt[0]); // smalloc set p->mtpt[0] = nil
@
% todo: sizeof could be simplified

<<[[copypath()]] mtpt handling>>=
pp->mlen = p->mlen;
pp->malen = p->malen;
pp->mtpt = smalloc(p->malen*sizeof pp->mtpt[0]);
for(i=0; i<pp->mlen; i++){
    pp->mtpt[i] = p->mtpt[i];
    if(pp->mtpt[i])
        incref(pp->mtpt[i]);
}
@

<<[[pathclose()]] mtpt handling>>=
for(i=0; i<p->mlen; i++)
    if(p->mtpt[i])
        cclose(p->mtpt[i]);
free(p->mtpt);
@

\ifallcode
<<[[pathclose()]] debugging>>=
    DBG("pathclose %p %s ref=%ld =>", p, p->s, p->ref);
    for(i=0; i<p->mlen; i++)
        DBG(" %p", p->mtpt[i]);
    DBG("\n");
@
\fi




% in walk()
%            path = addelem(path, "..", nil);
%            nc = undomount(wq->clone, path);


<<[[addelem()]] mtpt handling>>=
if(isdotdot(s)){
    DBG("addelem %s .. => rm %p\n", p->s, p->mtpt[p->mlen-1]);
    if(p->mlen>1 && (c = p->mtpt[--p->mlen])){
        p->mtpt[p->mlen] = nil;
        cclose(c);
    }
}else{
    if(p->mlen >= p->malen){
        // realloc
        p->malen = p->mlen+1+PATHMSLOP;
        tt = smalloc(p->malen*sizeof tt[0]);
        memmove(tt, p->mtpt, p->mlen*sizeof tt[0]);
        free(p->mtpt);
        p->mtpt = tt;
    }
    DBG("addelem %s %s => add %p\n", p->s, s, from);
    p->mtpt[p->mlen++] = from;
    if(from)
        incref(from);
}
@


<<function undomount>>=
/*
 * If c is the right-hand-side of a mount point, returns the left hand side.
 * Changes name to reflect the fact that we've uncrossed the mountpoint,
 * so name had better be ours to change!
 */
static Chan*
undomount(Chan *c, Path *path)
{
    Chan *nc;

    if(path->ref != 1 || path->mlen == 0)
        print("undomount: path %s ref %ld mlen %d caller %#p\n",
            path->s, path->ref, path->mlen, getcallerpc(&c));

    if(path->mlen>0 && (nc=path->mtpt[path->mlen-1]) != nil){
        DBG("undomount %p %s => remove %p\n", path, path->s, nc);
        cclose(c);
        path->mtpt[path->mlen-1] = nil;
        // c = nc = mh->from
        c = nc;
    }
    return c;
}
@
% don't decrement path->mlen too?

\section{Union mount}

% seen already list of Mount in Mhead with next field in Mount and MBEFORE, MAFTER.

\subsection{Union walk}
<<[[walk()]] locals>>=
Mount *f;
@
% rename, bad name 'f'

<<[[walk()]] if c is a union mount, find and adjust type and dev>>=
/* try a union mount, if any */
if(mh && !sharppath){
    /*
     * mh->mount->to == c, so start at mh->mount->next
     */
    rlock(&mh->lock);
    f = mh->mount;
    for(f = (f? f->next: f); f; f = f->next)
        if((wq = ewalk(f->to, names+nhave, ntry)) != nil)
            break;
    runlock(&mh->lock);
    if(f != nil){
        type = f->to->type;
        dev = f->to->dev;
    }
}
@

\subsection{[[->umh]]}


<<[[namec()]] case Aopen, Acreate, handle mountpoint part2>>=
/* only save the mount head if it's a multiple element union */
if(m && m->mount && m->mount->next)
    c->umh = m;
else
    putmhead(m);
@
% LP split for umh again


<<[[Chan]] other fields>>=
Mhead*  umh;      /* mount point that derived Chan; used in unionread */
@
% "that derived Chan" =~

<<[[chanfree()]] optional free>>=
if(c->umh != nil){
    putmhead(c->umh);
    c->umh = nil;
}
@


% namec(), walk(), cmount()

% in Aopen|Acreate after walked, the walk should not set umh, need umh
% to read so only when actually open the chan and will call syspread later
<<[[namec()]] print error if c->umh != nil>>=
if(c->umh != nil){
    print("uniquechan umh Open\n");
    putmhead(c->umh);
    c->umh = nil;
}
@

<<[[walk()]] print error if c->umh != nil>>=
if(c->umh != nil){  //BUG
    print("walk umh\n");
    putmhead(c->umh);
    c->umh = nil;
}
@

<<[[cmount()]] print error if old->umh != nil>>=
if(old->umh)
    print("cmount: unexpected umh, caller %#p\n", getcallerpc(&new));
@
% old is accessed via namec(Amount), so should not do any domount()


\subsection{[[syspread()]] for directories}

<<[[Chan]] other fields>>=
vlong devoffset;    /* in underlying device; see read */
@
%why need offset and devoffset? because of union dirs?

<<[[read()]] if c is a QTDIR>>=
    if(c->qid.type & QTDIR){
        if(mountrockread(c, p, n, &nn)){
            /* do nothing: mountrockread filled buffer */
        }else if(c->umh){
            nn = unionread(c, p, n);
        }else{
            if(off != c->offset)
                error(Edirseek);
            nn = devtab[c->type]->read(c, p, n, c->devoffset);
        }
        nnn = mountfix(c, p, nn, n);
    }
@
% LP split more, mountrockread? mountfix? and mv the simple read of dir
%  before? or put in Directory chapter? with devoffeset?










<<[[Chan]] other fields>>=
Chan* umc;      /* channel in union; held for union read */
QLock umqlock;    /* serialize unionreads */
int uri;      /* union read index */
@
% uri is index in list of Mount of c->umh

<<[[chanfree()]] optional free>>=
if(c->umc != nil){
    cclose(c->umc);
    c->umc = nil;
}
@


<<function unionread>>=
long
unionread(Chan *c, virt_addr3 va, long n)
{
    int i;
    long nr;
    Mhead *m;
    Mount *mount;

    qlock(&c->umqlock);
    m = c->umh;
    rlock(&m->lock);
    mount = m->mount;

    /* bring mount in sync with c->uri and c->umc */
    for(i = 0; mount != nil && i < c->uri; i++)
        mount = mount->next;

    nr = 0;
    while(mount != nil){
        /* Error causes component of union to be skipped */
        if(mount->to && !waserror()){
            if(c->umc == nil){
                c->umc = cclone(mount->to);
                c->umc = devtab[c->umc->type]->open(c->umc, OREAD);
            }
    
            nr = devtab[c->umc->type]->read(c->umc, va, n, c->umc->offset);
            c->umc->offset += nr;
            poperror();
        }
        if(nr > 0)
            break;

        /* Advance to next element */
        c->uri++;
        if(c->umc){
            cclose(c->umc);
            c->umc = nil;
        }
        mount = mount->next;
    }
    runlock(&m->lock);
    qunlock(&c->umqlock);
    return nr;
}
@


<<[[read()]] rewind when off == 0>>=
/*
 * The offset is passed through on directories, normally.
 * Sysseek complains, but pread is used by servers like exportfs,
 * that shouldn't need to worry about this issue.
 *
 * Notice that c->devoffset is the offset that c's dev is seeing.
 * The number of bytes read on this fd (c->offset) may be different
 * due to rewritings in rockfix.
 */
    mountrewind(c);
    unionrewind(c);
@

% mountrewind? deal with nrock

<<function unionrewind>>=
static void
unionrewind(Chan *c)
{
    qlock(&c->umqlock);
    c->uri = 0;
    if(c->umc){
        cclose(c->umc);
        c->umc = nil;
    }
    qunlock(&c->umqlock);
}
@



\subsection{[[MCREATE]]}

<<[[namec()]] Acreate case, if cnew is a mountpoint>>=
if(!sharppath && findmount(&cnew, &m, c->type, c->dev, c->qid))
    cnew = createdir(cnew, m);
@

<<function createdir>>=
/*
 * c is a mounted non-creatable directory.  find a creatable one.
 */
Chan*
createdir(Chan *c, Mhead *m)
{
    Chan *nc;
    Mount *f;

    rlock(&m->lock);
    if(waserror()){
        runlock(&m->lock);
        nexterror();
    }
    for(f = m->mount; f; f = f->next){
        if(f->mflag&MCREATE){
            nc = cclone(f->to);
            runlock(&m->lock);
            poperror();
            cclose(c);
            return nc;
        }
    }
    error(Enocreate);
    panic("createdir: should not reach this point");
    return nil; // unreachable
}
@


\subsection{Union of union}

<<[[namec()]] set c->umh in Abind if mounted point>>=
    if(c->umh != nil)
        putmhead(c->umh);
    c->umh = m;
@
% set in Abind, other place where set?



<<[[cmount()]] locals>>=
int flg;
Mhead *umh, **l;
Mount *f, *um, **h;
@

<<[[cmount()]] if new is itself a mount point, error if cant create there>>=
umh = new->umh;
/*
 * Not allowed to bind when the old directory is itself a union. 
 * (Maybe it should be allowed, but I don't see what the semantics
 * would be.)
 *
 * We need to check umh->mount->next to tell unions apart from
 * simple mount points, so that things like
 *  mount -c fd /root
 *  bind -c /root /
 * work.  
 * 
 * The check of mount->mflag allows things like
 *  mount fd /root
 *  bind -c /root /
 * 
 * This is far more complicated than it should be, but I don't
 * see an easier way at the moment.
 */
if((flag&MCREATE) && umh && umh->mount
   && (umh->mount->next || !(umh->mount->mflag&MCREATE)))
    error(Emount);
@

<<[[cmount()]] if new is itself a mount point, copy mounts>>=
if(umh != nil && umh->mount != nil){
    /*
     *  copy a union when binding it onto a directory
     */
    flg = order;
    if(order == MREPL)
        flg = MAFTER;
    h = &m->next;
    um = umh->mount;
    for(um = um->next; um; um = um->next){
        f = newmount(um->to, flg, um->spec);
        *h = f;
        h = &f->next;
    }
}
@



\section{Sandboxing}
% can also do chroot with sysbind + noattach no?

<<[[Pgrp]] other fields>>=
bool noattach;
@

% this is in mount case. bind is allowed (but not bind to #path)
<<[[bindmount()]] error if noattach>>=
if(up->pgrp->noattach)
    error(Enoattach);
@

<<[[namec()]] noattach checking>>=
/*
 *  noattach is sandboxing.
 *
 *  the OK exceptions are:
 *  |  it only gives access to pipes you create
 *  d  this process's file descriptors
 *  e  this process's environment
 *  the iffy exceptions are:
 *  c  time and pid, but also cons and consctl
 *  p  control of your own processes (and unfortunately
 *     any others left unprotected)
 */
/* actually / is caught by parsing earlier */
if(utfrune("M", r))
    error(Enoattach);
if(up->pgrp->noattach && utfrune("|decp", r)==nil)
    error(Enoattach);
@


<<[[sysrfork()]] inherit noattach, RFPROC==0 case>>=
/* inherit noattach */
up->pgrp->noattach = opg->noattach;
@

<<[[sysrfork()]] inherit noattach, RFPROC==1 case>>=
/* inherit noattach */
p->pgrp->noattach = up->pgrp->noattach;
@

<<[[sysrfork()]] set noattach to true when RFNOMNT, RFPROC==0 case>>=
if(flag & RFNOMNT)
    up->pgrp->noattach = true;
@

<<[[sysrfork()]] set noattach to true when RFNOMNT, RFPROC==1 case>>=
if(flag & RFNOMNT)
    p->pgrp->noattach = true;
@

\section{[[sysmount()]]}

%ex of cmd? with spec?

<<syscall mount>>=
// int mount(int fd, int afd, char *old, int flag, char *aname);
long
sysmount(ulong* arg)
{
    return bindmount(true, arg[0], arg[1], nil, (char*)arg[2], arg[3], (char*)arg[4]);
}
@
%// int mount(int fd, int afd, char *from, int flag, ???);


<<[[bindmount()]] locals>>=
Chan *ac, *bc;

struct Bogus bogus;
@
% union for attach, attach should take a byte*, not char* really

<<[[bindmount()]] if ismount>>=
if(ismount){
    validaddr((ulong)spec, 1, false);
    spec = validnamedup(spec, true);
    if(waserror()){
        free(spec);
        nexterror();
    }
    <<[[bindmount()]] error if noattach>>

    ac = nil;
    bc = fdtochan(fd, ORDWR, false, true);
    if(waserror()) {
        if(ac)
            cclose(ac);
        cclose(bc);
        nexterror();
    }

    if(afd >= 0)
        ac = fdtochan(afd, ORDWR, false, true);

    bogus.flags = flag & MCACHE;
    bogus.chan = bc;
    bogus.authchan = ac;
    bogus.spec = spec;
    ret = devno('M', false);
    c0 = devtab[ret]->attach((char*)&bogus);
    poperror(); /* ac bc */
    if(ac)
        cclose(ac);
    cclose(bc);
}
@
% poperror of spec?

<<[[bindmount()]] if ismount free>>=
if(ismount){
    fdclose(fd, 0);
    poperror();
    free(spec);
}
@


<<enum mount cases>>=
MCACHE = 0x0010,  /* cache some data */
@


\section{[[sysumount()]]}

% ex of umount? can unbind #c from /dev for instance?

<<syscall unmount>>=
// int unmount(char *name, char *old);
long
sysunmount(ulong* arg)
{
    Chan *cmount, *cmounted;

    cmounted = nil;

    validaddr(arg[1], 1, false);
    cmount = namec((char *)arg[1], Amount, 0, 0);
    if(waserror()) {
        cclose(cmount);
        if(cmounted)
            cclose(cmounted);
        nexterror();
    }

    if(arg[0]) {
        /*
         * This has to be namec(..., Aopen, ...) because
         * if arg[0] is something like /srv/cs or /fd/0,
         * opening it is the only way to get at the real
         * Chan underneath.
         */
        validaddr(arg[0], 1, false);
        cmounted = namec((char*)arg[0], Aopen, OREAD, 0);
    }
    cunmount(cmount, cmounted);
    poperror();
    cclose(cmount);
    if(cmounted)
        cclose(cmounted);
    return 0;
}
@

<<[[Chan]] other fields>>=
Chan* mchan;      /* channel to mounted server */
@
% but who sets ->mchan? attach of 'M' device driver?


<<[[cunmount()]] print error if mnt->umh>>=
if(mnt->umh)    /* should not happen */
    print("cunmount newp extra umh %p has %p\n", mnt, mnt->umh);
@

<<function cunmount>>=
void
cunmount(Chan *mnt, Chan *mounted)
{
    Pgrp *pg;
    Mhead *m, **l;
    Mount *f, **p;

    <<[[cunmount()]] print error if mnt->umh>>

    /*
     * It _can_ happen that mounted->umh is non-nil, 
     * because mounted is the result of namec(Aopen)
     * (see sysfile.c:/^sysunmount).
     * If we open a union directory, it will have a umh.
     * Although surprising, this is okay, since the
     * cclose will take care of freeing the umh.
     */

    pg = up->pgrp;
    wlock(&pg->ns);

    l = &MOUNTH(pg, mnt->qid);
    for(m = *l; m; m = m->hash){
        if(eqchan(m->from, mnt, true))
            break;
        l = &m->hash;
    }

    if(m == nil){
        wunlock(&pg->ns);
        error(Eunmount);
    }

    wlock(&m->lock);
    if(mounted == nil){
        *l = m->hash;
        wunlock(&pg->ns);
        mountfree(m->mount);
        m->mount = nil;
        cclose(m->from);
        wunlock(&m->lock);
        putmhead(m);
        return;
    }

    p = &m->mount;
    for(f = *p; f; f = f->next){
        /* BUG: Needs to be 2 pass */
        if(eqchan(f->to, mounted, true) ||
          (f->to->mchan && eqchan(f->to->mchan, mounted, true))){
            *p = f->next;
            f->next = nil;
            mountfree(f);
            if(m->mount == nil){
                *l = m->hash;
                cclose(m->from);
                wunlock(&m->lock);
                wunlock(&pg->ns);
                putmhead(m);
                return;
            }
            wunlock(&m->lock);
            wunlock(&pg->ns);
            return;
        }
        p = &f->next;
    }
    wunlock(&m->lock);
    wunlock(&pg->ns);
    error(Eunion);
}
@

\section{XTODO}


% put in union mount section?
<<[[Mount]] other fields>>=
ulong mountid;
@

<<global mountid>>=
static Counter mountid;
@ 

% mountid? because have sorted list of mount? because mount on top of 
%  something else?

<<[[Mount]] other fields>>=
// list<ref<Mount>> sorted list by mount->mountid
Mount*  order;
@

<<[[Mount]] extra fields>>=
Mount*  copy;
@


% used by pgrpcpy
<<function pgrpinsert>>=
void
pgrpinsert(Mount **order, Mount *m)
{
    Mount *f;

    m->order = nil;
    if(*order == nil) {
        *order = m;
        return;
    }
    for(f = *order; f; f = f->order) {
        if(m->mountid < f->mountid) {
            m->order = f;
            *order = m;
            return;
        }
        order = &f->order;
    }
    *order = m;
}
@ 


% used by sysrfork
<<function pgrpcpy>>=
/*
 * pgrpcpy MUST preserve the mountid allocation order of the parent group
 */
void
pgrpcpy(Pgrp *to, Pgrp *from)
{
    int i;
    Mount *n, *m, **link, *order;
    Mhead *f, **tom, **l, *mh;

    wlock(&from->ns);
    order = nil;
    tom = to->mnthash;
    for(i = 0; i < MNTHASH; i++) {
        l = tom++;
        for(f = from->mnthash[i]; f; f = f->hash) {
            rlock(&f->lock);
            mh = newmhead(f->from);
            *l = mh;
            l = &mh->hash;
            link = &mh->mount;
            for(m = f->mount; m; m = m->next) {
                n = newmount(m->to, m->mflag, m->spec);

                m->copy = n;
                pgrpinsert(&order, m);

                *link = n;
                link = &n->next;
            }
            runlock(&f->lock);
        }
    }
    /*
     * Allocate mount ids in the same sequence as the parent group
     */
    lock(&mountid);
    for(m = order; m; m = m->order)
        m->copy->mountid = mountid.ref++;
    unlock(&mountid);
    wunlock(&from->ns);
}
@ 




\section{XTODO}

<<[[chanfree()]] optional free>>=
if(c->mux != nil){
    muxclose(c->mux);
    c->mux = nil;
}
if(c->mchan != nil){
    cclose(c->mchan);
    c->mchan = nil;
}
@





% ls -l /dev
%  and will see the different device driver owner of the files

<<[[chanfree()]] optional free>>=
if(c->dirrock != nil){
    free(c->dirrock);
    c->dirrock = nil;
    c->nrock = 0;
    c->mrock = 0;
}
@


<<[[Chan]] other fields>>=
byte*  dirrock;    /* directory entry rock for translations */
int nrock;
int mrock;
QLock rockqlock;
@

<<function mountrock>>=
/*
 * Mountfix might have caused the fixed results of the directory read
 * to overflow the buffer.  Catch the overflow in c->dirrock.
 */
static void
mountrock(Chan *c, byte *p, byte **pe)
{
    byte *e, *r;
    int len, n;

    e = *pe;

    /* find last directory entry */
    for(;;){
        len = BIT16SZ+GBIT16(p);
        if(p+len >= e)
            break;
        p += len;
    }

    /* save it away */
    qlock(&c->rockqlock);
    if(c->nrock+len > c->mrock){
        n = ROUND(c->nrock+len, 1024);
        r = smalloc(n);
        memmove(r, c->dirrock, c->nrock);
        free(c->dirrock);
        c->dirrock = r;
        c->mrock = n;
    }
    memmove(c->dirrock+c->nrock, p, len);
    c->nrock += len;
    qunlock(&c->rockqlock);

    /* drop it */
    *pe = p;
}
@


<<function mountrockread>>=
/*
 * Satisfy a directory read with the results saved in c->dirrock.
 */
static bool
mountrockread(Chan *c, byte *op, long n, long *nn)
{
    long dirlen;
    byte *rp, *erp, *ep, *p;

    /* common case */
    if(c->nrock == 0)
        return false;

    /* copy out what we can */
    qlock(&c->rockqlock);
    rp = c->dirrock;
    erp = rp+c->nrock;
    p = op;
    ep = p+n;
    while(rp+BIT16SZ <= erp){
        dirlen = BIT16SZ+GBIT16(rp);
        if(p+dirlen > ep)
            break;
        memmove(p, rp, dirlen);
        p += dirlen;
        rp += dirlen;
    }

    if(p == op){
        qunlock(&c->rockqlock);
        return false;
    }

    /* shift the rest */
    if(rp != erp)
        memmove(c->dirrock, rp, erp-rp);
    c->nrock = erp - rp;

    *nn = p - op;
    qunlock(&c->rockqlock);
    return true;
}
@



<<function mountrewind>>=
static void
mountrewind(Chan *c)
{
    c->nrock = 0;
}
@


<<function mountfix>>=
/*
 * Rewrite the results of a directory read to reflect current 
 * name space bindings and mounts.  Specifically, replace
 * directory entries for bind and mount points with the results
 * of statting what is mounted there.  Except leave the old names.
 */
static long
mountfix(Chan *c, byte *op, long n, long maxn)
{
    char *name;
    int nbuf, nname;
    Chan *nc;
    Mhead *mh;
    Mount *m;
    byte *p;
    int dirlen, rest;
    long l;
    byte *buf, *e;
    DirEntry d;

    p = op;
    buf = nil;
    nbuf = 0;
    for(e=&p[n]; p+BIT16SZ<e; p+=dirlen){
        dirlen = dirfixed(p, e, &d);
        if(dirlen < 0)
            break;
        nc = nil;
        mh = nil;
        if(findmount(&nc, &mh, d.type, d.dev, d.qid)){
            /*
             * If it's a union directory and the original is
             * in the union, don't rewrite anything.
             */
            for(m=mh->mount; m; m=m->next)
                if(eqchantdqid(m->to, d.type, d.dev, d.qid, true))
                    goto Norewrite;

            name = offsetof_name_direntry(p, &nname);
            /*
             * Do the stat but fix the name.  If it fails, leave old entry.
             * BUG: If it fails because there isn't room for the entry,
             * what can we do?  Nothing, really.  Might as well skip it.
             */
            if(buf == nil){
                buf = smalloc(4096);
                nbuf = 4096;
            }
            if(waserror())
                goto Norewrite;
            l = devtab[nc->type]->stat(nc, buf, nbuf);
            l = direntry_setname(name, nname, buf, l, nbuf);
            if(l == BIT16SZ)
                error("direntry_setname");
            poperror();

            /*
             * Shift data in buffer to accomodate new entry,
             * possibly overflowing into rock.
             */
            rest = e - (p+dirlen);
            if(l > dirlen){
                while(p+l+rest > op+maxn){
                    mountrock(c, p, &e);
                    if(e == p){
                        dirlen = 0;
                        goto Norewrite;
                    }
                    rest = e - (p+dirlen);
                }
            }
            if(l != dirlen){
                memmove(p+l, p+dirlen, rest);
                dirlen = l;
                e = p+dirlen+rest;
            }

            /*
             * Rewrite directory entry.
             */
            memmove(p, buf, l);

            Norewrite:
            cclose(nc);
            putmhead(mh);
        }
    }
    if(buf)
        free(buf);

    if(p != e)
        error("oops in rockfix");

    return e-op;
}
@

<<function dirfixed>>=
static int
dirfixed(byte *p, byte *e, DirEntry *d)
{
    int len;

    len = GBIT16(p)+BIT16SZ;
    if(p + len > e)
        return -1;

    p += BIT16SZ;   /* ignore size */
    d->type = devno(GBIT16(p), true);
    p += BIT16SZ;
    d->dev = GBIT32(p);
    p += BIT32SZ;
    d->qid.type = GBIT8(p);
    p += BIT8SZ;
    d->qid.vers = GBIT32(p);
    p += BIT32SZ;
    d->qid.path = GBIT64(p);
    p += BIT64SZ;
    d->mode = GBIT32(p);
    p += BIT32SZ;
    d->atime = GBIT32(p);
    p += BIT32SZ;
    d->mtime = GBIT32(p);
    p += BIT32SZ;
    d->length = GBIT64(p);

    return len;
}
@







\chapter{Devices}
\minitoc
%less: Keyboard/Screen sections before File/Dir/Namespace sections? hmmm hard.

\section{The keyboard (x86)}

\subsection{Overview}

% interrupt i8042intr 
% -> kbdputsc (accumulate, handle special keys) sc for scan code
% -> kbdputc (which adjust kbd circular buffer);

% interrupt kbdcclock 
% -> echo() 
% -> qproduce(kbdq) (and echoscreen()!)

\subsection{Scan code}

% Note that the main function here generates unicode characters (Rune=32bits)
% (but they are actually decomposed back in individual chars later)

% http://www.computer-engineering.org/ps2keyboard/

\t same than keyboard.h?
<<enum specialkey>>=
enum {
    KF=         0xF000,     /* function key (begin Unicode private space) */
    Spec=       0xF800,     /* Unicode private space */


    PF=         Spec|0x20,  /* num pad function key */
    View=       Spec|0x00,  /* view (shift window up) */

    Shift=      Spec|0x60,
    Break=      Spec|0x61,
    Ctrl=       Spec|0x62,
    Alt=        Spec|0x63,
    Caps=       Spec|0x64,
    Num=        Spec|0x65,
    Middle=     Spec|0x66,
    Altgr=      Spec|0x67,

    Kmouse=     Spec|0x100,

    No=         0x00,       /* peter */

    /* KF|1, KF|2, ..., KF|0xC is F1, F2, ..., F12 */

    Home=       KF|13,
    Up=         KF|14,
    Pgup=       KF|15,
    Print=      KF|16,
    Left=       KF|17,
    Right=      KF|18,
    End=        KF|24,
    Down=       View,
    Pgdown=     KF|19,
    Ins=        KF|20,
    Del=        0x7F,
    Scroll=     KF|21,

    Nscan=  128,
};
@
% Use unicode! hence the Spec| it will allow
% cool things like having C^P to be returned simply by looking in an array.
% how would do it otherwise? would need a complex enum anyway.
%less: who is the "begin private unicode space"

% according to http://en.wikipedia.org/wiki/Private_Use_Areas
% Kmouse which is Spec|0x100 is out of private space though

% Nscan = 128 because 1 bit is used for the pressed/release information

<<global kbtab>>=
Rune kbtab[Nscan] = 
{
[0x00]  No, 0x1b,   '1',    '2',    '3',    '4',    '5',    '6',
[0x08]  '7',    '8',    '9',    '0',    '-',    '=',    '\b',   '\t',
[0x10]  'q',    'w',    'e',    'r',    't',    'y',    'u',    'i',
[0x18]  'o',    'p',    '[',    ']',    '\n',   Ctrl,   'a',    's',
[0x20]  'd',    'f',    'g',    'h',    'j',    'k',    'l',    ';',
[0x28]  '\'',   '`',    Shift,  '\\',   'z',    'x',    'c',    'v',
[0x30]  'b',    'n',    'm',    ',',    '.',    '/',    Shift,  '*',
[0x38]  Alt,  ' ',    Ctrl,   KF|1,   KF|2,   KF|3,   KF|4,   KF|5,
[0x40]  KF|6,   KF|7,   KF|8,   KF|9,   KF|10,  Num,    Scroll, '7',
[0x48]  '8',    '9',    '-',    '4',    '5',    '6',    '+',    '1',
[0x50]  '2',    '3',    '0',    '.',    No, No, No, KF|11,
[0x58]  KF|12,  No, No, No, No, No, No, No,
[0x60]  No, No, No, No, No, No, No, No,
[0x68]  No, No, No, No, No, No, No, No,
[0x70]  No, No, No, No, No, No, No, No,
[0x78]  No, No, No, No, No, No, No, No,
};
@
% hash<scan_code, Rune>, 
% can see Ctrl, Shift, Alt here (but not Altgr? Altgr is in ktabesc1)

% See Compiler.nw to see how then a character is translated in an integer,
% and actually here as a Rune.

<<global kbtabshift>>=
Rune kbtabshift[Nscan] =
{
[0x00]  No, 0x1b,   '!',    '@',    '#',    '$',    '%',    '^',
[0x08]  '&',    '*',    '(',    ')',    '_',    '+',    '\b',   '\t',
[0x10]  'Q',    'W',    'E',    'R',    'T',    'Y',    'U',    'I',
[0x18]  'O',    'P',    '{',    '}',    '\n',   Ctrl,   'A',    'S',
[0x20]  'D',    'F',    'G',    'H',    'J',    'K',    'L',    ':',
[0x28]  '"',    '~',    Shift,  '|',    'Z',    'X',    'C',    'V',
[0x30]  'B',    'N',    'M',    '<',    '>',    '?',    Shift,  '*',
[0x38]  Alt,  ' ',    Ctrl,   KF|1,   KF|2,   KF|3,   KF|4,   KF|5,
[0x40]  KF|6,   KF|7,   KF|8,   KF|9,   KF|10,  Num,    Scroll, '7',
[0x48]  '8',    '9',    '-',    '4',    '5',    '6',    '+',    '1',
[0x50]  '2',    '3',    '0',    '.',    No, No, No, KF|11,
[0x58]  KF|12,  No, No, No, No, No, No, No,
[0x60]  No, No, No, No, No, No, No, No,
[0x68]  No, No, No, No, No, No, No, No,
[0x70]  No, No, No, No, No, No, No, No,
[0x78]  No, No, No, No, No, No, No, No,
};
@
%$

<<global kbtabctrl decl>>=
extern Rune kbtabctrl[];
@
% contain special ascii character like ^P so can't be included here


<<global kbtabaltgr>>=
Rune kbtabaltgr[Nscan] =
{
[0x00]  No, No, No, No, No, No, No, No,
[0x08]  No, No, No, No, No, No, No, No,
[0x10]  No, No, No, No, No, No, No, No,
[0x18]  No, No, No, No, '\n',   Ctrl,   No, No,
[0x20]  No, No, No, No, No, No, No, No,
[0x28]  No, No, Shift,  No, No, No, No, No,
[0x30]  No, No, No, No, No, '/',    No, Print,
[0x38]  Altgr,  No, No, No, No, No, No, No,
[0x40]  No, No, No, No, No, No, Break,  Home,
[0x48]  Up, Pgup,   No, Left,   No, Right,  No, End,
[0x50]  Down,   Pgdown, Ins,    Del,    No, No, No, No,
[0x58]  No, No, No, No, No, No, No, No,
[0x60]  No, No, No, No, No, No, No, No,
[0x68]  No, No, No, No, No, No, No, No,
[0x70]  No, No, No, No, No, No, No, No,
[0x78]  No, No, No, No, No, No, No, No,
};
@

% what about kbtabalt? Alt is managed in a special way to generate advanced
% latin or unicode characters.


<<struct Kbscan>>=
struct Kbscan {
    bool ctl;
    bool shift;
    bool caps;
    bool alt;
    bool altgr;
    bool num;
    <<[[Kbscan]] other fields>>
};
@


<<enum kbscan>>=
/* kbscans indices */
enum kbscan {
    KbInt=    0,          
    KbExt,

    KbNscans,
};
@
% always used Int actually. Ext is used only by devkbin.c so could simplify code
% but apparently devkbin is useful for usb keyboard

<<global kbscans>>=
// hash<enum<kbscan>, Kbscan>
Kbscan kbscans[KbNscans]; /* kernel and external scan code state */
@




<<function kbdenable(x86)>>=
void
kbdenable(void)
{
    ioalloc(Data, 1, 0, "kbd");
    ioalloc(Cmd, 1, 0, "kbd");

    arch_intrenable(IrqKBD, i8042intr, 0, BUSUNKNOWN, "kbd");

    kbscans[KbInt].num = false;
    arch_setleds(&kbscans[KbInt]);
}
@
% used to have kdbq init here, but better to separate

<<global i8042lock(x86)>>=
static Lock i8042lock;
@

<<interrupt callback i8042intr(x86)>>=
/*
 *  keyboard interrupt
 */
static void
i8042intr(Ureg*, void*)
{
    byte s, c;

    /*
     *  get status
     */
    ilock(&i8042lock);
    s = inb(Status);
    if(!(s&Inready)){
        iunlock(&i8042lock);
        return;
    }

    /*
     *  get the character
     */
    c = inb(Data);
    iunlock(&i8042lock);

    <<[[i8042intr()]] aux port handling(x86)>>
    // !!!
    kbdputsc(c, KbInt);
}
@


% i8042intr -> <> -> kbdputc
<<function kbdputsc>>=
/*
 * Scan code processing
 */
void
kbdputsc(byte k, int external)
{
    bool keyup;
    Kbscan *kbscan;
    // Rune is (uint) but actually 'c' can get the result of functions
    // like latin1() which can return negative numbers.
    long c = k; 

    if(external)
        kbscan = &kbscans[KbExt];
    else
        kbscan = &kbscans[KbInt];

    <<[[kbdputsc()]] debugging>>

    <<[[kbdputsc()]] esc key handling part1 and possible return>>

    keyup = c & 0x80; // key released (1 bit)
    c &= 0x7f; // 128

    <<[[kbdputsc()]] ensures c is in boundary>>

    <<[[kbdputsc()]] esc key handling part2 and possible return>>
    else if(kbscan->shift)
        c = kbtabshift[c];
    else if(kbscan->altgr)
        c = kbtabaltgr[c];
    else if(kbscan->ctl)
        c = kbtabctrl[c];
    else
        c = kbtab[c];

    if(kbscan->caps && c<='z' && c>='a')
        c += 'A' - 'a';

    /*
     *  keyup only important for shifts
     */
    if(keyup){
        switch(c){
        case Ctrl:
            kbscan->ctl = false;
            break;
        case Alt:
            kbscan->alt = false;
            break;
        case Altgr:
            kbscan->altgr = false;
            break;
        case Shift:
            kbscan->shift = false;
            <<[[kbdputsc()]] reset mouseshift>>
            <<[[kbdputsc()]] debugging up shift>>
            break;
        <<[[kbdputsc()]] mouse keyup cases>>
        }
        return;
    }

    /*
     *  normal character
     */
    if(!(c & (Spec|KF))){
        <<[[kbdputsc()]] reboot if ctl-alt-del>>
        <<[[kbdputsc()]] if collecting>>
        else {
            kbdputc(c); //!! adding the character in kbd staging area
        }
    }else{
        switch(c){
        case Ctrl:
            kbscan->ctl = true;
            break;
        case Alt:
            kbscan->alt = true;
            <<[[kbdputsc()]] start collecting>>
            break;
        case Altgr:
            kbscan->altgr = true;
            break;
        case Shift:
            kbscan->shift = true;
            <<[[kbdputsc()]] set mouseshift>>
            <<[[kbdputsc()]] debugging down shift>>
            break;
        case Caps:
            kbscan->caps ^= true;
            break;
        case Num:
            kbscan->num ^= true;
            if(!external)
                arch_setleds(kbscan);
            break;
        <<[[kbdputsc()]] mouse keydown cases>>
        <<[[kbdputsc()]] special keyboard debug keys cases>>
        // e.g. Left, Right or other special key
        default:
            kbdputc(c);
            break;
        }
    }
}
@
%old: was taking an int, but clearer I think to take a byte

% about keyup, when type 'a', get 1e, when release get 9e, so 1e+0x80
% do not put char instead of byte for 'k', otherwise will get weird
% behavior like Left generating a 2.
%note that it does not send the Ctr key event to the process (so different
% than gtk where can get notified when you just pressed a key, any key,
% and also when it's released. Here even in raw mode there are some
% processing done)

\ifallcode
<<[[kbdputsc()]] ensures c is in boundary>>=
if(c > sizeof kbtab){
    // how could reach that? kbtab has 0x80 elts and do c&=0x7f.
    c |= keyup;
    if(c != 0xFF)   /* these come fairly often: CAPSLOCK U Y */
        print("unknown key %ux\n", c);
    return;
}
@
\fi


\subsection{Esc}
% actually when type Left on keyboard, it generates e0 4b.
% The esc1 esc2 here are not related to the Esc key.
% The actual Esc key generates scan code 0x01

\l bcm/kbd.c was also defining a kbtabshiftesc1, not sure needed

<<global kbtabesc1>>=
Rune kbtabesc1[Nscan] =
{
[0x00]  No, No, No, No, No, No, No, No,
[0x08]  No, No, No, No, No, No, No, No,
[0x10]  No, No, No, No, No, No, No, No,
[0x18]  No, No, No, No, '\n',   Ctrl,   No, No,
[0x20]  No, No, No, No, No, No, No, No,
[0x28]  No, No, Shift,  No, No, No, No, No,
[0x30]  No, No, No, No, No, '/',    No, Print,
[0x38]  Altgr,  No, No, No, No, No, No, No,
[0x40]  No, No, No, No, No, No, Break,  Home,
[0x48]  Up, Pgup,   No, Left,   No, Right,  No, End,
[0x50]  Down,   Pgdown, Ins,    Del,    No, No, No, No,
[0x58]  No, No, No, No, No, No, No, No,
[0x60]  No, No, No, No, No, No, No, No,
[0x68]  No, No, No, No, No, No, No, No,
[0x70]  No, No, No, No, No, No, No, No,
[0x78]  No, No, No, No, No, No, No, No,
};
@

<<[[Kbscan]] other fields>>=
bool esc1;
int esc2;
@

<<[[kbdputsc()]] esc key handling part1 and possible return>>=
/*
 *  e0's is the first of a 2 character sequence, e1 the first
 *  of a 3 character sequence (on the safari)
 */
if(c == 0xe0){
    kbscan->esc1 = true;
    return;
} else if(c == 0xe1){
    kbscan->esc2 = 2;
    return;
}
@
% get rid of esc2? how can generate it?

<<[[kbdputsc()]] esc key handling part2 and possible return>>=
if(kbscan->esc1){
    c = kbtabesc1[c];
    kbscan->esc1 = false;
} else if(kbscan->esc2){
    kbscan->esc2--;
    return;
}
@


\subsection{[[kbd]]}

<<struct ConsKbd>>=
struct ConsKbd
{
    /* a place to save up characters at interrupt time before dumping them in the queue */
    char    istage[1024];
    // pointers into istage to implement a circular buffer
    char    *iw; // write
    char    *ir; // read
    char    *ie; // end
    ILock    lockputc;

    <<[[ConsKbd]] other fields>>
    // extra
    QLock;
};
@
% why not using Rune line[1024] and Rune istage[1024]? will simplify things
% and anyway kputsc already handles unicode and produce unicode characters?
% because plan9 manages queue of bytes, it's the code reading those bytes
% that have the job to possibly call the rune functions on it.


<<global kbd>>=
static struct ConsKbd kbd = 
{
    .iw = kbd.istage,
    .ir = kbd.istage,
    .ie = kbd.istage + sizeof(kbd.istage),
};
@ 

% called from raw kbd functions in previous section
<<function kbdputc>>=
/*
 *  Put character, possibly a rune, into kbd at interrupt time.
 *  Called at interrupt time to process a character.
 */
void
kbdputc(Rune ch)
{
    int i, n;
    char buf[UTFmax]; // pad's fourth bugfix :)
    Rune r;
    char *next;

    <<[[kbdputc()]] debugging>>

    if(kbd.ir == nil)
        return;       /* in case we're not inited yet */
    
    ilock(&kbd.lockputc);       /* just a mutex */
    r = ch;
    n = runetochar(buf, &r);
    for(i = 0; i < n; i++){
        next = kbd.iw+1;
        // circular buffer
        if(next >= kbd.ie)
            next = kbd.istage;
        if(next == kbd.ir) // full
            break;
        *kbd.iw = buf[i];
        kbd.iw = next;
    }
    iunlock(&kbd.lockputc);
    return;
}
@ 
%old: used to take a queue argument, but was not using it so I removed it
%bug: see pad's bugfix above
\l should rename kbdputr for rune

<<clock callback kbdputcclock>>=
/*
 *  we save up input characters till clock time to reduce
 *  per character interrupt overhead.
 */
static void
kbdputcclock(void)
{
    char *iw;

    /* this amortizes cost of qproduce */
    if(kbd.iw != kbd.ir){
        iw = kbd.iw;
        if(iw < kbd.ir){
            echo(kbd.ir, kbd.ie-kbd.ir);
            kbd.ir = kbd.istage;
        }
        if(kbd.ir != iw){
            echo(kbd.ir, iw-kbd.ir);
            kbd.ir = iw;
        }
    }
}
@ 
% no ilock??? because no race possible?
% actually echo will echo back on screen and add in kbdq !!

<<[[consinit()]] initializing things>>=
    /*
     * at 115200 baud, the 1024 char buffer takes 56 ms to process,
     * processing it every 22 ms should be fine
     */
    addclock0link(kbdputcclock, 22);
@
% todo: understand this comment ...


\subsection{[[echo()]]}

% double role! to add in kbdq and print on screen

<<function echo>>=
static void
echo(char *buf, int n)
{
    <<[[echo()]] locals>>

    if(n == 0)
        return;

    <<[[echo()]] special keys handler>>

    qproduce(kbdq, buf, n); //!! add in kbd queue to be read from /dev/cons

    <<[[echo()]] return before any echoscreen if raw mode>>

    <<[[echo()]] hooks>>
}
@ 
% kbdq!!!!
% another special key handler ...

<<[[echo()]] hooks>>=
if(screenputs != nil)
   echoscreen(buf, n);
@

<<hook screenputs>>=
void    (*screenputs)(char*, int) = nil;
@ 
% see later set to cgascreenputs

<<function echoscreen>>=
static void
echoscreen(char *buf, int n)
{
    char *e, *p;
    char ebuf[128];
    int x;

    p = ebuf;
    e = ebuf + sizeof(ebuf) - 4;
    while(n-- > 0){
        if(p >= e){
            screenputs(ebuf, p - ebuf);
            p = ebuf;
        }
        x = *buf++;
        if(x == 0x15){ // ??
            *p++ = '^';
            *p++ = 'U';
            *p++ = '\n';
        } else
            *p++ = x;
    }
    if(p != ebuf)
        screenputs(ebuf, p - ebuf);
}
@ 
% screenputs!


\ifallcode
\subsection{Controller IO (x86)}

<<global nokbd(x86)>>=
static bool nokbd = true;           /* flag: no PS/2 keyboard */
@
% set to false in kbdinit

<<global ccc(x86)>>=
static byte ccc;
@
% set by i8042auxenable for mouse on aux port?


<<function kbdinit(x86)>>=
void
kbdinit(void)
{
    int c, try;

    /* wait for a quiescent controller */
    try = 500;
    while(try-- > 0 && (c = inb(Status)) & (Outbusy | Inready)) {
        if(c & Inready)
            inb(Data);
        delay(1);
    }
    if (try <= 0) {
        print(initfailed);
        return;
    }

    /* get current controller command byte */
    outb(Cmd, 0x20);
    if(inready() < 0){
        print("i8042: kbdinit can't read ccc\n");
        ccc = 0;
    } else
        ccc = inb(Data);

    /* enable kbd xfers and interrupts */
    ccc &= ~Ckbddis;
    ccc |= Csf | Ckbdint | Cscs1;
    if(outready() < 0) {
        print(initfailed);
        return;
    }

    nokbd = false;

    /* disable mouse */
    if (outbyte(Cmd, 0x60) < 0 || outbyte(Data, ccc) < 0)
        print("i8042: kbdinit mouse disable failed\n");

    /* see http://www.computer-engineering.org/ps2keyboard for codes */
    if(getconf("*typematic") != nil)
        /* set typematic rate/delay (0 -> delay=250ms & rate=30cps) */
        if(outbyte(Data, 0xf3) < 0 || outbyte(Data, 0) < 0)
            print("i8042: kbdinit set typematic rate failed\n");
}
@


%TODO: return bool instead? those outread < 0 seems bad no?
<<function outbyte(x86)>>=
static int
outbyte(int port, int c)
{
    outb(port, c);
    if(outready() < 0) {
        print(initfailed);
        return -1;
    }
    return 0;
}
@

<<function outready(x86)>>=
/*
 *  wait for output no longer busy
 */
static int
outready(void)
{
    int tries;

    for(tries = 0; (inb(Status) & Outbusy); tries++){
        if(tries > 500)
            return -1;
        delay(2);
    }
    return 0;
}
@


<<function inready(x86)>>=
/*
 *  wait for input
 */
static int
inready(void)
{
    int tries;

    for(tries = 0; !(inb(Status) & Inready); tries++){
        if(tries > 500)
            return -1;
        delay(2);
    }
    return 0;
}
@

\subsection{Leds}

<<function setleds(x86)>>=
/*
 * set keyboard's leds for lock states (scroll, numeric, caps).
 *
 * at least one keyboard (from Qtronics) also sets its numeric-lock
 * behaviour to match the led state, though it has no numeric keypad,
 * and some BIOSes bring the system up with numeric-lock set and no
 * setting to change that.  this combination steals the keys for these
 * characters and makes it impossible to generate them: uiolkjm&*().
 * thus we'd like to be able to force the numeric-lock led (and behaviour) off.
 */
void
arch_setleds(Kbscan *kbscan)
{
    int leds;

    if(nokbd || kbscan != &kbscans[KbInt])
        return;
    leds = 0;
    if(kbscan->num)
        leds |= 1<<1;
    if(0 && kbscan->caps)       /* we don't implement caps lock */
        leds |= 1<<2;

    ilock(&i8042lock);
    outready();
    outb(Data, 0xed);       /* `reset keyboard lock states' */
    if(inready() == 0)
        inb(Data);

    outready();
    outb(Data, leds);
    if(inready() == 0)
        inb(Data);

    outready();
    iunlock(&i8042lock);
}
@
% >> >>


\subsection{Changing keyboard, [[/dev/kbmap]]}

% to change keyboard: kbdputmap, kbdgetmap with /dev/kbmap


<<function kbdgetmap>>=
int
kbdgetmap(uint offset, int *t, int *sc, Rune *r)
{
    if ((int)offset < 0)
        error(Ebadarg);
    *t = offset/Nscan;
    *sc = offset%Nscan;
    switch(*t) {
    default:
        return 0;
    case 0:
        *r = kbtab[*sc];
        return 1;
    case 1:
        *r = kbtabshift[*sc];
        return 1;
    case 2:
        *r = kbtabesc1[*sc];
        return 1;
    case 3:
        *r = kbtabaltgr[*sc];
        return 1;
    case 4:
        *r = kbtabctrl[*sc];
        return 1;
    }
}
@


<<function kbdputmap>>=
void
kbdputmap(ushort m, ushort scanc, Rune r)
{
    if(scanc >= Nscan)
        error(Ebadarg);
    switch(m) {
    default:
        error(Ebadarg);
    case 0:
        kbtab[scanc] = r;
        break;
    case 1:
        kbtabshift[scanc] = r;
        break;
    case 2:
        kbtabesc1[scanc] = r;
        break;
    case 3:
        kbtabaltgr[scanc] = r;
        break;
    case 4: 
        kbtabctrl[scanc] = r;
        break;
    }
}
@

\fi


\section{The screen (x86)}

% just cga.c here, see Graphics.nw for the advanced vga kernel support
% (and also for full operation of the mouse)

<<cga.c enum color(x86)>>=
enum color {
    Black,
    Blue,
    Green,
    Cyan,
    Red,
    Magenta,
    Brown,
    Grey,

    Bright = 0x08,
    Blinking = 0x80,

    Yellow = Bright|Brown,
    White = Bright|Grey,
};
@

<<cga.c enum misc(x86)>>=
enum {
    Width       = 80*2,
    Height      = 25,

    Attr        = (Black<<4)|Grey,  /* high nibble background
                         * low foreground
                         */

    Poststrlen  = 0,
    Postcodelen = 2,
    Postlen     = Poststrlen+Postcodelen,
};
@
%>>

<<constant CGASCREENBASE(x86)>>=
#define CGASCREENBASE   ((byte*)KADDR(0xB8000))
@


<<global cgapos(x86)>>=
static int cgapos;
@


<<global cgascreenlock(x86)>>=
static Lock cgascreenlock;
@

<<function screeninit(x86)>>=
void
arch_screeninit(void)
{

    cgapos = cgaregr(0x0E)<<8;
    cgapos |= cgaregr(0x0F);
    cgapos *= 2;

    screenputs = cgascreenputs;
}
@
% >>
% see hook screenputs later

<<function cgascreenputs(x86)>>=
static void
cgascreenputs(char* s, int n)
{
    if(!arch_islo()){
        /*
         * Don't deadlock trying to
         * print in an interrupt.
         */
        if(!canlock(&cgascreenlock))
            return;
    }
    else
        lock(&cgascreenlock);

    while(n-- > 0)
        cgascreenputc(*s++);

    unlock(&cgascreenlock);
}
@
% note that this does not handle unicode characters. For
% this you need a better screenputs() like the one maybe provided
% by devvga?


<<function cgascreenputc(x86)>>=
static void
cgascreenputc(char c)
{
    int i;
    byte *p;

    if(c == '\n'){
        cgapos = cgapos/Width;
        cgapos = (cgapos+1)*Width;
    }
    else if(c == '\t'){
        i = 8 - ((cgapos/2)&7);
        while(i-->0)
            cgascreenputc(' ');
    }
    else if(c == '\b'){
        if(cgapos >= 2)
            cgapos -= 2;
        cgascreenputc(' ');
        cgapos -= 2;
    }
    else{
        CGASCREENBASE[cgapos++] = c;
        CGASCREENBASE[cgapos++] = Attr;
    }
    if(cgapos >= Width*Height){
        memmove(CGASCREENBASE, &CGASCREENBASE[Width], Width*(Height-1));
        p = &CGASCREENBASE[Width*(Height-1)];
        for(i=0; i<Width/2; i++){
            *p++ = ' ';
            *p++ = Attr;
        }
        cgapos = Width*(Height-1);
    }
    movecursor();
}
@
% does not handle unicode characters


<<function movecursor(x86)>>=
static void
movecursor(void)
{
    cgaregw(0x0E, (cgapos/2>>8) & 0xFF);
    cgaregw(0x0F, cgapos/2 & 0xFF);
    CGASCREENBASE[cgapos+1] = Attr;
}
@

%-------------------------------------------------------------------------------
<<function cgaregr(x86)>>=
static byte
cgaregr(int index)
{
    outb(0x3D4, index);
    return inb(0x3D4+1) & 0xFF;
}
@

<<function cgaregw(x86)>>=
static void
cgaregw(int index, int data)
{
    outb(0x3D4, index);
    outb(0x3D4+1, data);
}
@



\section{The console device [[/dev/cons]]}

% should be able to answer the interview question: "what happens
% when you type 'ls' on the keyboard" :)

% far cleaner than /dev/tty on linux!


% What C-D actually do:
%https://utcc.utoronto.ca/~cks/space/blog/unix/TypingEOFEffects

\subsection{Overview}

<<devcons.c enum Qxxx>>=
enum{
    Qdir,

    Qcons,
    Qconsctl,

    <<devcons.c enum Qxxx cases>>
};
@ 
% often "one-level directory containing a single file", and union
% helps agglomerate all in /dev/


<<global consdir>>=
static Dirtab consdir[]={
    ".",    {Qdir, 0, QTDIR},   0,      DMDIR|0555,

    "cons",     {Qcons},    0,      0660,
    "consctl",  {Qconsctl}, 0,      0220,

    <<[[consdir]] fields>>
};
@ 
% less: rename to /dev/console


% when keyboard key => have to print it back (echo())
% when someone writes in /dev/cons => have to print it back (putstrn0)

% here interested only in the "cons"! see other sections
% for extra features of the "console"

\subsection{Buffered input}

% see chapter later for queue IO
<<global kbdq>>=
Queue*  kbdq;           /* unprocessed console input */
@ 

<<function kbdqinit>>=
void
kbdqinit(void)
{
    kbdq = qopen(4*1024, 0, 0, 0);
    if(kbdq == nil)
        panic("kbdinit");
    qnoblock(kbdq, true);
}
@


<<global lineq>>=
Queue*  lineq;          /* processed console input */
@ 

<<function lineqinit>>=
void
lineqinit(void)
{

    lineq = qopen(2*1024, 0, nil, nil);
    if(lineq == nil)
        panic("lineqinit");
    qnoblock(lineq, true);
}
@ 
%old: was called printinit

<<[[ConsKbd]] other fields>>=
    char    line[1024]; /* current input line */
    int x;      /* index into line */
@

%!!! this is an important one!
<<[[consread()]] Qcons case>>=
    case Qcons:
        qlock(&kbd);
        if(waserror()) {
            qunlock(&kbd);
            nexterror();
        }
        while(!qcanread(lineq)){
            if(qread(kbdq, &ch, 1) == 0)
                continue;
            send = false;
            if(ch == 0){
                /* flush output on rawoff -> rawon */
                if(kbd.x > 0)
                    send = !qcanread(kbdq);
            
            <<[[consread()]] else if raw mode>>
            }else{
                switch(ch){
                case '\b':
                    if(kbd.x > 0)
                        kbd.x--;
                    break;
                case 0x15:  /* ^U */
                    kbd.x = 0;
                    break;
                case '\n':
                    send = true;
                    kbd.line[kbd.x++] = ch;
                    break;
                case 0x04:  /* ^D */
                    send = true;
                    break;
                default:
                    kbd.line[kbd.x++] = ch;
                    break;
                }
            }
            if(send || kbd.x == sizeof kbd.line){
                qwrite(lineq, kbd.line, kbd.x);
                kbd.x = 0;
            }
        }
        n = qread(lineq, buf, n);
        qunlock(&kbd);
        poperror();
        return n;
@


\subsection{Output}

% what happens when do ls > file, how we do not call screenputs?
% because in this case /dev/cons is not binded to the console!??
% but then how can still read from it? because fd0 is binded to it,
% but fd1 no! 

% but then why  echo 'foo' > dev/cons from
% rio does the right thing? how does not call cgascreenputs?
% because screenputs has been redirected in rio! via vga controller?
% and because rio actually create a new /dev/cons I think!

%!!! this is an important one!
<<[[conswrite()]] Qcons case>>=
    case Qcons:
        /*
         * Can't page fault in putstrn, so copy the data locally.
         */
        l = n;
        while(l > 0){
            bp = l;
            if(bp > sizeof buf)
                bp = sizeof buf;
            memmove(buf, a, bp);
            putstrn0(buf, bp, 1);
            a += bp;
            l -= bp;
        }
        break;
@

<<function putstrn0>>=
/*
 *   Print a string on the console.
 */
static void
putstrn0(char *str, int n, bool usewrite)
{
    int m;
    char *t;

    if(!arch_islo())
        usewrite = false;

    <<[[putstrn0()]] kmesg handling>>
    <<[[putstrn0()]] if kprint>>
    else if(screenputs != nil)
        screenputs(str, n);

    <<[[putstrn0()]] serialoq handling>>
}
@ 


\subsection{[[print()]], [[iprint()]], [[pprint()]]}

\subsubsection{[[print()]]}

<<constant PRINTSIZE>>=
PRINTSIZE = 256,
@

<<function print>>=
bool noprint; // to debug?

int
devcons_print(char *fmt, ...)
{
    int n;
    va_list arg;
    char buf[PRINTSIZE];

    if(noprint)
        return -1;

    va_start(arg, fmt);
    n = vseprint(buf, buf+sizeof(buf), fmt, arg) - buf;
    va_end(arg);
    putstrn(buf, n);

    return n;
}
@ 

<<function putstrn>>=
void
putstrn(char *str, int n)
{
    putstrn0(str, n, false);
}
@ 
% false = usewrite = ??? related to interrupts?

\subsubsection{[[iprint()]]}

<<global iprintscreenputs>>=
bool iprintscreenputs = true;
@ 
%bool iprintkmesgputs = true; ?

<<function iprint>>=
int
devcons_iprint(char *fmt, ...)
{
    int n, s, locked;
    va_list arg;
    char buf[PRINTSIZE];

    s = arch_splhi();

    va_start(arg, fmt);
    n = vseprint(buf, buf+sizeof(buf), fmt, arg) - buf;
    va_end(arg);

    locked = iprintcanlock(&iprintlock);

    kmesgputs(buf, n); // addon
    if(screenputs != nil && iprintscreenputs)
        screenputs(buf, n);
    uartputs(buf, n);

    if(locked)
        unlock(&iprintlock);

    arch_splx(s);

    return n;
}
@

<<global iprintlock>>=
/*
 * Want to interlock iprints to avoid interlaced output on 
 * multiprocessor, but don't want to deadlock if one processor
 * dies during print and another has something important to say.
 * Make a good faith effort.
 */
static Lock iprintlock;
@

<<function iprintcanlock>>=
static bool
iprintcanlock(Lock *l)
{
    int i;
    
    for(i=0; i<1000; i++){
        if(canlock(l))
            return true;
        if(l->cpu == CPUS(cpu->cpuno))
            return false;
        microdelay(100);
    }
    return false;
}
@


\subsubsection{[[pprint()]]}

% put in debugging section? Often used to report error
% to user process. pprint is program print where 
% the process name and pid of the current process wil be displayed
% before the actual message. e.g. 'db 43: unknown qid in procwrite'

% todo: see balestero note,
% in distributed context we want to print process error at the right place
%  not just on machine console
<<function pprint>>=
int
devcons_pprint(char *fmt, ...)
{
    int n;
    Chan *c;
    va_list arg;
    char buf[2*PRINTSIZE];

    if(up == nil || up->fgrp == nil)
        return 0;

    c = up->fgrp->fd[2]; // stderr
    if(c==nil || (c->mode!=OWRITE && c->mode!=ORDWR))
        return 0;

    n = snprint(buf, sizeof buf, "%s %lud: ", up->text, up->pid);
    va_start(arg, fmt);
    n = vseprint(buf+n, buf+sizeof(buf), fmt, arg) - buf;
    va_end(arg);

    if(waserror())
        return 0;
    devtab[c->type]->write(c, buf, n, c->offset);
    poperror();

    lock(c);
    c->offset += n;
    unlock(c);

    return n;
}
@ 

\subsection{[[/dev/cons]]}

<<method consinit>>=
static void
consinit(void)
{
    <<[[consinit()]] initializing things>>
}
@ 


<<method consopen>>=
static Chan*
consopen(Chan *c, int omode)
{
    c->aux = nil;
    c = devopen(c, omode, consdir, nelem(consdir), devgen);

    switch((ulong)c->qid.path){
    <<[[consopen()]] cases>>
    }
    return c;
}
@ 


<<method consclose>>=
static void
consclose(Chan *c)
{
    switch((ulong)c->qid.path){
    <<[[consclose()]] cases>>
    }
}
@ 


<<method consread>>=
static long
consread(Chan *c, void *buf, long n, vlong off)
{
    ulong l;
    char ch;
    char tmp[256];      /* must be >= 18*NUMSIZE (Qswap) */
    int i, k, send;
    vlong offset = off;

    if(n <= 0)
        return n;

    switch((ulong)c->qid.path){
    case Qdir:
        return devdirread(c, buf, n, consdir, nelem(consdir), devgen);

    <<[[consread()]] Qcons case>>

    <<[[consread()]] cases>>

    case Qtime:
        return readtime((ulong)offset, buf, n);

    case Qbintime:
        return readbintime(buf, n);
        


    case Quser:
        return readstr((ulong)offset, buf, n, up->user);

    case Qpid:
        return readnum((ulong)offset, buf, n, up->pid, NUMSIZE);

    case Qppid:
        return readnum((ulong)offset, buf, n, up->parentpid, NUMSIZE);

    case Qpgrpid:
        return readnum((ulong)offset, buf, n, up->pgrp->pgrpid, NUMSIZE);


    case Qnull:
        return 0;

    case Qzero:
        memset(buf, 0, n);
        return n;

    default:
        print("consread %#llux\n", c->qid.path);
        error(Egreg);
    }
    panic("consread: should not reach this point");
    return -1;
}
@

<<method conswrite>>=
static long
conswrite(Chan *c, void *va, long n, vlong off)
{
    char *a;

    <<[[conswrite]] locals>>

    a = va;
    USED(off);

    switch((ulong)c->qid.path){

    <<[[conswrite()]] Qcons case>>

    <<[[conswrite()]] cases>>

    case Qtime:
        if(!iseve())
            error(Eperm);
        return writetime(a, n);

    case Qbintime:
        if(!iseve())
            error(Eperm);
        return writebintime(a, n);


    case Quser:
        return userwrite(a, n);


    // > /dev/null :)
    case Qnull:
        break;

    default:
        print("conswrite: %#llux\n", c->qid.path);
        error(Egreg);
    }
    return n;
}
@ 

<<[[conswrite]] locals>>=
    char buf[256], ch;
    long l, bp;
    int fd;
    Chan *swc;
@

<<global consdevtab>>=
Dev consdevtab = {
    .dc       =    'c',
    .name     =    "cons",
               
    .reset    =    devreset,
    .init     =    consinit,
    .shutdown =    devshutdown,
    .attach   =    consattach,
    .walk     =    conswalk,
    .stat     =    consstat,
    .open     =    consopen,
    .create   =    devcreate,
    .close    =    consclose,
    .read     =    consread,
    .bread    =    devbread,
    .write    =    conswrite,
    .bwrite   =    devbwrite,
    .remove   =    devremove,
    .wstat    =    devwstat,
};
@ 

\subsection{[[/dev/consctl]] and raw input}

% who needs raw input? well rio, efuns!

<<[[ConsKbd]] other fields>>=
bool raw;        /* true if we shouldn't process input */
Ref ctl;        /* number of opens to the control file */
@


<<[[consread()]] else if raw mode>>=
}else if(kbd.raw){
    kbd.line[kbd.x++] = ch;
    send = !qcanread(kbdq);
@
% no buffered input, no lineq, send as soon as possible, do not wait for \n to send

<<[[echo()]] return before any echoscreen if raw mode>>=
if(kbd.raw)
    return;
@




<<[[consopen()]] cases>>=
case Qconsctl:
    incref(&kbd.ctl);
    break;
@

<<[[consclose()]] cases>>=
/* last close of control file turns off raw */
case Qconsctl:
    if(c->flag&COPEN){
        if(decref(&kbd.ctl) == 0)
            kbd.raw = false;
    }
    break;
@

<<[[conswrite()]] cases>>=
case Qconsctl:
    if(n >= sizeof(buf))
        n = sizeof(buf)-1;
    strncpy(buf, a, n);
    buf[n] = 0;
    for(a = buf; a;){
        if(strncmp(a, "rawon", 5) == 0){
            kbd.raw = true;
            /* clumsy hack - wake up reader */
            ch = 0;
            qwrite(kbdq, &ch, 1);           
        } else if(strncmp(a, "rawoff", 6) == 0){
            kbd.raw = false;
        }
        <<[[conswrite()]] Qconsctl other ifs>>
        if(a = strchr(a, ' '))
            a++;
    }
    break;
@


\section{The mouse (x86)}

% devmouse.c! or put in Graphics.nw?

\subsection{Mouse and keyboard}

% when you type shift on keyboard, this could change
% behavior of a mouse click.
% and when you click on the mouse, sometimes it copy paste
% some text which are entered just like they were entered
% through the keyboard. So strong mouse<->keyboard interaction.

<<[[Kbscan]] other fields>>=
int buttons;
@

<<[[kbdputsc()]] reset mouseshift>>=
mouseshifted = false;
@

<<[[kbdputsc()]] set mouseshift>>=
mouseshifted = true;
@


<<[[kbdputsc()]] mouse keyup cases>>=
case Kmouse|1:
case Kmouse|2:
case Kmouse|3:
case Kmouse|4:
case Kmouse|5:
    kbscan->buttons &= ~(1<<(c-Kmouse-1));
    if(kbdmouse)
        kbdmouse(kbscan->buttons);
    break;
@
% this is why kbdmouse is a pointer, because if no mouse driver
% loaded, then kbdmouse is a nop.

<<[[kbdputsc()]] mouse keydown cases>>=
case Kmouse|1:
case Kmouse|2:
case Kmouse|3:
case Kmouse|4:
case Kmouse|5:
    kbscan->buttons |= 1<<(c-Kmouse-1);
    if(kbdmouse)
        kbdmouse(kbscan->buttons);
    break;
@


% used by mouse.c
<<function i8042auxenable(x86)>>=
void
i8042auxenable(void (*putc)(int, int))
{
    char *err = "i8042: aux init failed\n";

    /* enable kbd/aux xfers and interrupts */
    ccc &= ~Cauxdis;
    ccc |= Cauxint;

    ilock(&i8042lock);
    if(outready() < 0)
        print(err);
    outb(Cmd, 0x60);            /* write control register */
    if(outready() < 0)
        print(err);
    outb(Data, ccc);
    if(outready() < 0)
        print(err);
    outb(Cmd, 0xA8);            /* auxiliary device enable */
    if(outready() < 0){
        iunlock(&i8042lock);
        return;
    }
    auxputc = putc;
    arch_intrenable(IrqAUX, i8042intr, 0, BUSUNKNOWN, "kbdaux");
    iunlock(&i8042lock);
}
@

<<hook auxputc(x86)>>=
static void (*auxputc)(int, int);
@

<<[[i8042intr()]] aux port handling(x86)>>=
    /*
     *  if it's the aux port...
     */
    if(s & Minready){
        if(auxputc != nil)
            auxputc(c, kbscans[KbInt].shift);
        return;
    }
@



% used by mouse, could be moved?
<<function i8042auxcmd(x86)>>=
int
i8042auxcmd(int cmd)
{
    unsigned int c;
    int tries;
    static bool badkbd;

    if(badkbd)
        return -1;
    c = 0;
    tries = 0;

    ilock(&i8042lock);
    do{
        if(tries++ > 2)
            break;
        if(outready() < 0)
            break;
        outb(Cmd, 0xD4);
        if(outready() < 0)
            break;
        outb(Data, cmd);
        if(outready() < 0)
            break;
        if(inready() < 0)
            break;
        c = inb(Data);
    } while(c == 0xFE || c == 0);
    iunlock(&i8042lock);

    if(c != 0xFA){
        print("i8042: %2.2ux returned to the %2.2ux command\n", c, cmd);
        badkbd = true; /* don't keep trying; there might not be one */
        return -1;
    }
    return 0;
}
@



\section{The floppy (x86)}
% or The storage device?

\section{Other devices}
%optional, advanced concepts

% devaudio.c


% see also devpipe.c and devdup.c, devmnt.c, devsrv.c


\chapter{[[Queue]]}

% hmmm this is used by kbdq, so it's independent of fs actually
% could be in separater chapter?

<<enum queuestate>>=
/* queue state bits,  Qmsg, Qcoalesce, and Qkick can be set in qopen */
enum
{
  /* Queue.state */
  Qstarve   = (1<<0), /* consumer starved */
  Qmsg    = (1<<1), /* message stream */
  Qclosed   = (1<<2), /* queue has been closed/hungup */
  Qflow   = (1<<3), /* producer flow controlled */
  Qcoalesce = (1<<4), /* coalesce packets on read */
  Qkick   = (1<<5), /* always call the kick routine after qwrite */
};
@

<<struct Queue>>=
struct Queue
{
  Lock;

  Block*  bfirst;   /* buffer */
  Block*  blast;

  int len;    /* bytes allocated to queue */
  int dlen;   /* data bytes in queue */
  int limit;    /* max bytes in queue */
  int inilim;   /* initial limit */
  int state;
  int noblock;  /* true if writes return immediately when q full */
  int eof;    /* number of eofs read by user */

  void  (*kick)(void*); /* restart output */
  void  (*bypass)(void*, Block*); /* bypass queue altogether */
  void* arg;    /* argument to kick */

  QLock rlock;    /* mutex for reading processes */
  Rendez  rr;   /* process waiting to read */
  QLock wlock;    /* mutex for writing processes */
  Rendez  wr;   /* process waiting to write */

  char  err[ERRMAX];
};
@

<<function pullupqueue>>=
/*
 *  make sure the first block has at least n bytes
 */
Block*
pullupqueue(Queue *q, int n)
{
    Block *b;

    if(BLEN(q->bfirst) >= n)
        return q->bfirst;
    q->bfirst = pullupblock(q->bfirst, n);
    for(b = q->bfirst; b != nil && b->next != nil; b = b->next)
        ;
    q->blast = b;
    return q->bfirst;
}
@


<<function qwrite>>=
/*
 *  write to a queue.  only Maxatomic bytes at a time is atomic.
 */
int
qwrite(Queue *q, void *vp, int len)
{
    int n, sofar;
    Block *b;
    byte *p = vp;

//    QDEBUG if(!arch_islo())  print("qwrite hi %#p\n", getcallerpc(&q));

    sofar = 0;
    do {
        n = len-sofar;
        if(n > Maxatomic)
            n = Maxatomic;

        b = allocb(n);
        setmalloctag(b, (up->text[0]<<24)|(up->text[1]<<16)|(up->text[2]<<8)|up->text[3]);
        if(waserror()){
            freeb(b);
            nexterror();
        }
        memmove(b->wp, p+sofar, n);
        poperror();
        b->wp += n;

        qbwrite(q, b);

        sofar += n;
    } while(sofar < len && (q->state & Qmsg) == 0);

    return len;
}
@



<<function qget>>=
/*
 *  get next block from a queue, return null if nothing there
 */
Block*
qget(Queue *q)
{
    int dowakeup;
    Block *b;

    /* sync with qwrite */
    ilock(q);

    b = q->bfirst;
    if(b == nil){
        q->state |= Qstarve;
        iunlock(q);
        return nil;
    }
    q->bfirst = b->next;
    b->next = 0;
    q->len -= BALLOC(b);
    q->dlen -= BLEN(b);
//    QDEBUG checkb(b, "qget");

    /* if writer flow controlled, restart */
    if((q->state & Qflow) && q->len < q->limit/2){
        q->state &= ~Qflow;
        dowakeup = 1;
    } else
        dowakeup = 0;

    iunlock(q);

    if(dowakeup)
        wakeup(&q->wr);

    return b;
}
@


<<function qdiscard>>=
/*
 *  throw away the next 'len' bytes in the queue
 */
int
qdiscard(Queue *q, int len)
{
    Block *b;
    int dowakeup, n, sofar;

    ilock(q);
    for(sofar = 0; sofar < len; sofar += n){
        b = q->bfirst;
        if(b == nil)
            break;
//        QDEBUG checkb(b, "qdiscard");
        n = BLEN(b);
        if(n <= len - sofar){
            q->bfirst = b->next;
            b->next = 0;
            q->len -= BALLOC(b);
            q->dlen -= BLEN(b);
            freeb(b);
        } else {
            n = len - sofar;
            b->rp += n;
            q->dlen -= n;
        }
    }

    /*
     *  if writer flow controlled, restart
     *
     *  This used to be
     *  q->len < q->limit/2
     *  but it slows down tcp too much for certain write sizes.
     *  I really don't understand it completely.  It may be
     *  due to the queue draining so fast that the transmission
     *  stalls waiting for the app to produce more data.  - presotto
     */
    if((q->state & Qflow) && q->len < q->limit){
        q->state &= ~Qflow;
        dowakeup = 1;
    } else
        dowakeup = 0;

    iunlock(q);

    if(dowakeup)
        wakeup(&q->wr);

    return sofar;
}
@


<<function qconsume>>=
/*
 *  Interrupt level copy out of a queue, return # bytes copied.
 */
int
qconsume(Queue *q, void *vp, int len)
{
    Block *b;
    int n, dowakeup;
    byte *p = vp;
    Block *tofree = nil;

    /* sync with qwrite */
    ilock(q);

    for(;;) {
        b = q->bfirst;
        if(b == 0){
            q->state |= Qstarve;
            iunlock(q);
            return -1;
        }
//        QDEBUG checkb(b, "qconsume 1");

        n = BLEN(b);
        if(n > 0)
            break;
        q->bfirst = b->next;
        q->len -= BALLOC(b);

        /* remember to free this */
        b->next = tofree;
        tofree = b;
    };

    if(n < len)
        len = n;
    memmove(p, b->rp, len);
    consumecnt += n;
    b->rp += len;
    q->dlen -= len;

    /* discard the block if we're done with it */
    if((q->state & Qmsg) || len == n){
        q->bfirst = b->next;
        b->next = 0;
        q->len -= BALLOC(b);
        q->dlen -= BLEN(b);

        /* remember to free this */
        b->next = tofree;
        tofree = b;
    }

    /* if writer flow controlled, restart */
    if((q->state & Qflow) && q->len < q->limit/2){
        q->state &= ~Qflow;
        dowakeup = 1;
    } else
        dowakeup = 0;

    iunlock(q);

    if(dowakeup)
        wakeup(&q->wr);

    if(tofree != nil)
        freeblist(tofree);

    return len;
}
@


<<function qpass>>=
int
qpass(Queue *q, Block *b)
{
    int dlen, len, dowakeup;

    /* sync with qread */
    dowakeup = 0;
    ilock(q);
    if(q->len >= q->limit){
        freeblist(b);
        iunlock(q);
        return -1;
    }
    if(q->state & Qclosed){
        len = BALLOC(b);
        freeblist(b);
        iunlock(q);
        return len;
    }

    /* add buffer to queue */
    if(q->bfirst)
        q->blast->next = b;
    else
        q->bfirst = b;
    len = BALLOC(b);
    dlen = BLEN(b);
//    QDEBUG checkb(b, "qpass");
    while(b->next){
        b = b->next;
//        QDEBUG checkb(b, "qpass");
        len += BALLOC(b);
        dlen += BLEN(b);
    }
    q->blast = b;
    q->len += len;
    q->dlen += dlen;

    if(q->len >= q->limit/2)
        q->state |= Qflow;

    if(q->state & Qstarve){
        q->state &= ~Qstarve;
        dowakeup = 1;
    }
    iunlock(q);

    if(dowakeup)
        wakeup(&q->rr);

    return len;
}
@


<<function qpassnolim>>=
int
qpassnolim(Queue *q, Block *b)
{
    int dlen, len, dowakeup;

    /* sync with qread */
    dowakeup = 0;
    ilock(q);

    if(q->state & Qclosed){
        freeblist(b);
        iunlock(q);
        return BALLOC(b);
    }

    /* add buffer to queue */
    if(q->bfirst)
        q->blast->next = b;
    else
        q->bfirst = b;
    len = BALLOC(b);
    dlen = BLEN(b);
//    QDEBUG checkb(b, "qpass");
    while(b->next){
        b = b->next;
//        QDEBUG checkb(b, "qpass");
        len += BALLOC(b);
        dlen += BLEN(b);
    }
    q->blast = b;
    q->len += len;
    q->dlen += dlen;

    if(q->len >= q->limit/2)
        q->state |= Qflow;

    if(q->state & Qstarve){
        q->state &= ~Qstarve;
        dowakeup = 1;
    }
    iunlock(q);

    if(dowakeup)
        wakeup(&q->rr);

    return len;
}
@


<<function qproduce>>=
int
qproduce(Queue *q, void *vp, int len)
{
    Block *b;
    int dowakeup;
    byte *p = vp;

    /* sync with qread */
    dowakeup = 0;
    ilock(q);

    /* no waiting receivers, room in buffer? */
    if(q->len >= q->limit){
        q->state |= Qflow;
        iunlock(q);
        return -1;
    }

    /* save in buffer */
    b = iallocb(len);
    if(b == 0){
        iunlock(q);
        return 0;
    }
    memmove(b->wp, p, len);
    producecnt += len;
    b->wp += len;
    if(q->bfirst)
        q->blast->next = b;
    else
        q->bfirst = b;
    q->blast = b;
    /* b->next = 0; done by iallocb() */
    q->len += BALLOC(b);
    q->dlen += BLEN(b);
//    QDEBUG checkb(b, "qproduce");

    if(q->state & Qstarve){
        q->state &= ~Qstarve;
        dowakeup = 1;
    }

    if(q->len >= q->limit)
        q->state |= Qflow;
    iunlock(q);

    if(dowakeup)
        wakeup(&q->rr);

    return len;
}
@


<<function qcopy>>=
/*
 *  copy from offset in the queue
 */
Block*
qcopy(Queue *q, int len, ulong offset)
{
    int sofar;
    int n;
    Block *b, *nb;
    byte *p;

    nb = allocb(len);

    ilock(q);

    /* go to offset */
    b = q->bfirst;
    for(sofar = 0; ; sofar += n){
        if(b == nil){
            iunlock(q);
            return nb;
        }
        n = BLEN(b);
        if(sofar + n > offset){
            p = b->rp + offset - sofar;
            n -= offset - sofar;
            break;
        }
//        QDEBUG checkb(b, "qcopy");
        b = b->next;
    }

    /* copy bytes from there */
    for(sofar = 0; sofar < len;){
        if(n > len - sofar)
            n = len - sofar;
        memmove(nb->wp, p, n);
        qcopycnt += n;
        sofar += n;
        nb->wp += n;
        b = b->next;
        if(b == nil)
            break;
        n = BLEN(b);
        p = b->rp;
    }
    iunlock(q);

    return nb;
}
@


<<function qopen>>=
/*
 *  called by non-interrupt code
 */
Queue*
qopen(int limit, int msg, void (*kick)(void*), void *arg)
{
    Queue *q;

    q = malloc(sizeof(Queue));
    if(q == nil)
        return nil;

    q->limit = q->inilim = limit;
    q->kick = kick;
    q->arg = arg;
    q->state = msg;
    
    q->state |= Qstarve;
    q->eof = 0;
    q->noblock = 0;

    return q;
}
@


<<function qbypass>>=
/* open a queue to be bypassed */
Queue*
qbypass(void (*bypass)(void*, Block*), void *arg)
{
    Queue *q;

    q = malloc(sizeof(Queue));
    if(q == nil)
        return nil;

    q->limit = 0;
    q->arg = arg;
    q->bypass = bypass;
    q->state = 0;

    return q;
}
@


<<function notempty>>=
static int
notempty(void *a)
{
    Queue *q = a;

    return (q->state & Qclosed) || q->bfirst != 0;
}
@


<<function qwait>>=
/*
 *  wait for the queue to be non-empty or closed.
 *  called with q ilocked.
 */
static int
qwait(Queue *q)
{
    /* wait for data */
    for(;;){
        if(q->bfirst != nil)
            break;

        if(q->state & Qclosed){
            if(++q->eof > 3)
                return -1;
            if(*q->err && strcmp(q->err, Ehungup) != 0)
                return -1;
            return 0;
        }

        q->state |= Qstarve;    /* flag requesting producer to wake me */
        iunlock(q);
        sleep(&q->rr, notempty, q);
        ilock(q);
    }
    return 1;
}
@


<<function qaddlist>>=
/*
 * add a block list to a queue
 */
void
qaddlist(Queue *q, Block *b)
{
    /* queue the block */
    if(q->bfirst)
        q->blast->next = b;
    else
        q->bfirst = b;
    q->len += blockalloclen(b);
    q->dlen += blocklen(b);
    while(b->next)
        b = b->next;
    q->blast = b;
}
@


<<function qremove>>=
/*
 *  called with q ilocked
 */
Block*
qremove(Queue *q)
{
    Block *b;

    b = q->bfirst;
    if(b == nil)
        return nil;
    q->bfirst = b->next;
    b->next = nil;
    q->dlen -= BLEN(b);
    q->len -= BALLOC(b);
//    QDEBUG checkb(b, "qremove");
    return b;
}
@


<<function qputback>>=
/*
 *  put a block back to the front of the queue
 *  called with q ilocked
 */
void
qputback(Queue *q, Block *b)
{
    b->next = q->bfirst;
    if(q->bfirst == nil)
        q->blast = b;
    q->bfirst = b;
    q->len += BALLOC(b);
    q->dlen += BLEN(b);
}
@


<<function qwakeup_iunlock>>=
/*
 *  flow control, get producer going again
 *  called with q ilocked
 */
static void
qwakeup_iunlock(Queue *q)
{
    int dowakeup = 0;

    /* if writer flow controlled, restart */
    if((q->state & Qflow) && q->len < q->limit/2){
        q->state &= ~Qflow;
        dowakeup = 1;
    }

    iunlock(q);

    /* wakeup flow controlled writers */
    if(dowakeup){
        if(q->kick)
            q->kick(q->arg);
        wakeup(&q->wr);
    }
}
@


<<function qbread>>=
/*
 *  get next block from a queue (up to a limit)
 */
Block*
qbread(Queue *q, int len)
{
    Block *b, *nb;
    int n;

    qlock(&q->rlock);
    if(waserror()){
        qunlock(&q->rlock);
        nexterror();
    }

    ilock(q);
    switch(qwait(q)){
    case 0:
        /* queue closed */
        iunlock(q);
        qunlock(&q->rlock);
        poperror();
        return nil;
    case -1:
        /* multiple reads on a closed queue */
        iunlock(q);
        error(q->err);
    }

    /* if we get here, there's at least one block in the queue */
    b = qremove(q);
    n = BLEN(b);

    /* split block if it's too big and this is not a message queue */
    nb = b;
    if(n > len){
        if((q->state&Qmsg) == 0){
            n -= len;
            b = allocb(n);
            memmove(b->wp, nb->rp+len, n);
            b->wp += n;
            qputback(q, b);
        }
        nb->wp = nb->rp + len;
    }

    /* restart producer */
    qwakeup_iunlock(q);

    poperror();
    qunlock(&q->rlock);
    return nb;
}
@


<<function qread>>=
/*
 *  read a queue.  if no data is queued, post a Block
 *  and wait on its Rendez.
 */
long
qread(Queue *q, void *vp, int len)
{
    Block *b, *first, **l;
    int m, n;

    qlock(&q->rlock);
    if(waserror()){
        qunlock(&q->rlock);
        nexterror();
    }

    ilock(q);
again:
    switch(qwait(q)){
    case 0:
        /* queue closed */
        iunlock(q);
        qunlock(&q->rlock);
        poperror();
        return 0;
    case -1:
        /* multiple reads on a closed queue */
        iunlock(q);
        error(q->err);
    }

    /* if we get here, there's at least one block in the queue */
    if(q->state & Qcoalesce){
        /* when coalescing, 0 length blocks just go away */
        b = q->bfirst;
        if(BLEN(b) <= 0){
            freeb(qremove(q));
            goto again;
        }

        /*  grab the first block plus as many
         *  following blocks as will completely
         *  fit in the read.
         */
        n = 0;
        l = &first;
        m = BLEN(b);
        for(;;) {
            *l = qremove(q);
            l = &b->next;
            n += m;

            b = q->bfirst;
            if(b == nil)
                break;
            m = BLEN(b);
            if(n+m > len)
                break;
        }
    } else {
        first = qremove(q);
        n = BLEN(first);
    }

    /* copy to user space outside of the ilock */
    iunlock(q);
    b = bl2mem(vp, first, len);
    ilock(q);

    /* take care of any left over partial block */
    if(b != nil){
        n -= BLEN(b);
        if(q->state & Qmsg)
            freeb(b);
        else
            qputback(q, b);
    }

    /* restart producer */
    qwakeup_iunlock(q);

    poperror();
    qunlock(&q->rlock);
    return n;
}
@


<<function qnotfull>>=
static int
qnotfull(void *a)
{
    Queue *q = a;

    return q->len < q->limit || (q->state & Qclosed);
}
@


<<function qbwrite>>=
/*
 *  add a block to a queue obeying flow control
 */
long
qbwrite(Queue *q, Block *b)
{
    int n, dowakeup;
    Proc *p;

    n = BLEN(b);

    if(q->bypass){
        (*q->bypass)(q->arg, b);
        return n;
    }

    dowakeup = 0;
    qlock(&q->wlock);
    if(waserror()){
        if(b != nil)
            freeb(b);
        qunlock(&q->wlock);
        nexterror();
    }

    ilock(q);

    /* give up if the queue is closed */
    if(q->state & Qclosed){
        iunlock(q);
        error(q->err);
    }

    /* if nonblocking, don't queue over the limit */
    if(q->len >= q->limit){
        if(q->noblock){
            iunlock(q);
            freeb(b);
            noblockcnt += n;
            qunlock(&q->wlock);
            poperror();
            return n;
        }
    }

    /* queue the block */
    if(q->bfirst)
        q->blast->next = b;
    else
        q->bfirst = b;
    q->blast = b;
    b->next = 0;
    q->len += BALLOC(b);
    q->dlen += n;
//    QDEBUG checkb(b, "qbwrite");
    b = nil;

    /* make sure other end gets awakened */
    if(q->state & Qstarve){
        q->state &= ~Qstarve;
        dowakeup = 1;
    }
    iunlock(q);

    /*  get output going again */
    if(q->kick && (dowakeup || (q->state&Qkick)))
        q->kick(q->arg);

    /* wakeup anyone consuming at the other end */
    if(dowakeup){
        p = wakeup(&q->rr);

        /* if we just wokeup a higher priority process, let it run */
        if(p != nil && p->priority > up->priority)
            sched();
    }

    /*
     *  flow control, wait for queue to get below the limit
     *  before allowing the process to continue and queue
     *  more.  We do this here so that postnote can only
     *  interrupt us after the data has been queued.  This
     *  means that things like 9p flushes and ssl messages
     *  will not be disrupted by software interrupts.
     *
     *  Note - this is moderately dangerous since a process
     *  that keeps getting interrupted and rewriting will
     *  queue infinite crud.
     */
    for(;;){
        if(q->noblock || qnotfull(q))
            break;

        ilock(q);
        q->state |= Qflow;
        iunlock(q);
        sleep(&q->wr, qnotfull, q);
    }
    USED(b);

    qunlock(&q->wlock);
    poperror();
    return n;
}
@


<<function qiwrite>>=
/*
 *  used by print() to write to a queue.  Since we may be arch_splhi or not in
 *  a process, don't qlock.
 *
 *  this routine merges adjacent blocks if block n+1 will fit into
 *  the free space of block n.
 */
int
qiwrite(Queue *q, void *vp, int len)
{
    int n, sofar, dowakeup;
    Block *b;
    byte *p = vp;

    dowakeup = 0;

    sofar = 0;
    do {
        n = len-sofar;
        if(n > Maxatomic)
            n = Maxatomic;

        b = iallocb(n);
        if(b == nil)
            break;
        memmove(b->wp, p+sofar, n);
        b->wp += n;

        ilock(q);

        /* we use an artificially high limit for kernel prints since anything
         * over the limit gets dropped
         */
        if(q->dlen >= 16*1024){
            iunlock(q);
            freeb(b);
            break;
        }

//        QDEBUG checkb(b, "qiwrite");
        if(q->bfirst)
            q->blast->next = b;
        else
            q->bfirst = b;
        q->blast = b;
        q->len += BALLOC(b);
        q->dlen += n;

        if(q->state & Qstarve){
            q->state &= ~Qstarve;
            dowakeup = 1;
        }

        iunlock(q);

        if(dowakeup){
            if(q->kick)
                q->kick(q->arg);
            wakeup(&q->rr);
        }

        sofar += n;
    } while(sofar < len && (q->state & Qmsg) == 0);

    return sofar;
}
@


<<function qfree>>=
/*
 *  be extremely careful when calling this,
 *  as there is no reference accounting
 */
void
qfree(Queue *q)
{
    qclose(q);
    free(q);
}
@


<<function qclose>>=
/*
 *  Mark a queue as closed.  No further IO is permitted.
 *  All blocks are released.
 */
void
qclose(Queue *q)
{
    Block *bfirst;

    if(q == nil)
        return;

    /* mark it */
    ilock(q);
    q->state |= Qclosed;
    q->state &= ~(Qflow|Qstarve);
    strcpy(q->err, Ehungup);
    bfirst = q->bfirst;
    q->bfirst = 0;
    q->len = 0;
    q->dlen = 0;
    q->noblock = 0;
    iunlock(q);

    /* free queued blocks */
    freeblist(bfirst);

    /* wake up readers/writers */
    wakeup(&q->rr);
    wakeup(&q->wr);
}
@


<<function qhangup>>=
/*
 *  Mark a queue as closed.  Wakeup any readers.  Don't remove queued
 *  blocks.
 */
void
qhangup(Queue *q, char *msg)
{
    /* mark it */
    ilock(q);
    q->state |= Qclosed;
    if(msg == 0 || *msg == 0)
        strcpy(q->err, Ehungup);
    else
        strncpy(q->err, msg, ERRMAX-1);
    iunlock(q);

    /* wake up readers/writers */
    wakeup(&q->rr);
    wakeup(&q->wr);
}
@


<<function qiclosed>>=
/*
 *  return non-zero if the q is hungup
 */
int
qisclosed(Queue *q)
{
    return q->state & Qclosed;
}
@


<<function qreopen>>=
/*
 *  mark a queue as no longer hung up
 */
void
qreopen(Queue *q)
{
    ilock(q);
    q->state &= ~Qclosed;
    q->state |= Qstarve;
    q->eof = 0;
    q->limit = q->inilim;
    iunlock(q);
}
@


<<function qlen>>=
/*
 *  return bytes queued
 */
int
qlen(Queue *q)
{
    return q->dlen;
}
@


<<function qwindow>>=
/*
 * return space remaining before flow control
 */
int
qwindow(Queue *q)
{
    int l;

    l = q->limit - q->len;
    if(l < 0)
        l = 0;
    return l;
}
@


<<function qcanread>>=
/*
 *  return true if we can read without blocking
 */
int
qcanread(Queue *q)
{
    return q->bfirst!=0;
}
@


<<function qsetlimit>>=
/*
 *  change queue limit
 */
void
qsetlimit(Queue *q, int limit)
{
    q->limit = limit;
}
@


<<function qnoblock>>=
/*
 *  set blocking/nonblocking
 */
void
qnoblock(Queue *q, bool onoff)
{
    q->noblock = onoff;
}
@


<<function qflush>>=
/*
 *  flush the output queue
 */
void
qflush(Queue *q)
{
    Block *bfirst;

    /* mark it */
    ilock(q);
    bfirst = q->bfirst;
    q->bfirst = 0;
    q->len = 0;
    q->dlen = 0;
    iunlock(q);

    /* free queued blocks */
    freeblist(bfirst);

    /* wake up readers/writers */
    wakeup(&q->wr);
}
@


<<function qfull>>=
int
qfull(Queue *q)
{
    return q->state & Qflow;
}
@







\chapter{Filesystems}

% devices plan9 are actually file servers and so kinda filesystems.
% but even if the Dev interface encapsulate Devices, fs, vfs, better
% to separate in their usage. Devices are in general a restricted
% form of file servers and can have inkernel file servers which are
% really like filesystems in other OSes.


% used by devgenxxx helpers
<<struct Dirtab>>=
struct Dirtab
{
  char  name[KNAMELEN];
  Qid qid;
  vlong length;
  long  perm;
};
@
% rename DirEntryShort? we alread have a DirEntry

\section{The root filesystem}
% root device, root filesystem

%on why /bin/ /usr/bin is a relic of the past
%http://lists.busybox.net/pipermail/busybox/2010-December/074114.html

% devroot
%"to know how things get bootstrapped and having a
%small set of files in the kernel image is a handy technique
%for embedded applications." on 9fans

% just with that we can already have a working environment
% with a memory fs! where all binaries are processed via data2txt

% also see the trick with data2txt to get an initial rootfs
% that is not too bad, that allows for instance to have dossrv
% so can boostrap the whole thing :)
% nice trick! (data2txt or data2s?)

%#/

<<global rootdevtab>>=
Dev rootdevtab = {
    .dc       = '/',
    .name     = "root",
  
    .reset    = rootreset,
    .init     = devinit,
    .shutdown = devshutdown,
    .attach   = rootattach,
    .walk     = rootwalk,
    .stat     = rootstat,
    .open     = rootopen,
    .create   = devcreate,
    .close    = rootclose,
    .read     = rootread,
    .bread    = devbread,
    .write    = rootwrite,
    .bwrite   = devbwrite,
    .remove   = devremove,
    .wstat    = devwstat,
};
@

<<devroot enum Qxxx>>=
enum
{
    Qdir = 0,
    Qboot = 0x1000,

    Nrootfiles = 32,
    Nbootfiles = 32,
};
@


<<struct Dirlist>>=
struct Dirlist
{
    uint base; // for unique qids
    Dirtab *dir;
    byte **data;
    int ndir; // number of dir used
    int mdir; // max dir entries
};
@
% rename Dirlist to DirEntries ? or just Directory?

<<globals rootdir, rootdata, rootlist>>=
static Dirtab rootdir[Nrootfiles] = {
  {
    .name = "#/",
    .qid = {Qdir, 0, QTDIR},
    .length = 0,
    .perm = DMDIR|0555,
  },
  {    
    .name = "boot", 
    .qid = {Qboot, 0, QTDIR},
    .length = 0,
    .perm = DMDIR|0555,
  }
};
static byte *rootdata[Nrootfiles];
static Dirlist rootlist = 
{
  .base = 0,
  .dir = rootdir,
  .data = rootdata,
  .ndir = 2,
  .mdir = Nrootfiles
};
@



<<function addlist>>=
/*
 *  add a file to the list
 */
static void
addlist(Dirlist *l, char *name, byte *contents, ulong len, int perm)
{
    Dirtab *d;

    if(l->ndir >= l->mdir)
        panic("too many root files");
    l->data[l->ndir] = contents;
    d = &l->dir[l->ndir];
    strcpy(d->name, name);
    d->length = len;
    d->perm = perm;
    d->qid.type = 0;
    d->qid.vers = 0;
    d->qid.path = ++l->ndir + l->base;
    if(perm & DMDIR)
        d->qid.type |= QTDIR;
}
@




<<function addrootdir>>=
/*
 *  add a root directory
 */
static void
addrootdir(char *name)
{
    addlist(&rootlist, name, nil, 0, DMDIR|0555);
}
@


<<method rootreset>>=
static void
rootreset(void)
{
    addrootdir("bin");
    addrootdir("dev");
    addrootdir("env");
    addrootdir("fd");
    addrootdir("mnt");
    addrootdir("net");
    addrootdir("proc");
    addrootdir("root");
    addrootdir("srv");
    // can't use sys, would conflict with ROOT/sys
    addrootdir("ksys");
}
@


<<function rootgen>>=
static int
rootgen(Chan *c, char *name, Dirtab*, int, int s, DirEntry *dp)
{
    int t;
    Dirtab *d;
    Dirlist *l;

    switch((int)c->qid.path){
    case Qdir:
        if(s == DEVDOTDOT){
            devdir(c, (Qid){Qdir, 0, QTDIR}, "#/", 0, eve, 0555, dp);
            return 1;
        }
        return devgen(c, name, rootlist.dir, rootlist.ndir, s, dp);
    case Qboot:
        if(s == DEVDOTDOT){
            devdir(c, (Qid){Qdir, 0, QTDIR}, "#/", 0, eve, 0555, dp);
            return 1;
        }
        return devgen(c, name, bootlist.dir, bootlist.ndir, s, dp);
    default:
        if(s == DEVDOTDOT){
            if((int)c->qid.path < Qboot)
                devdir(c, (Qid){Qdir, 0, QTDIR}, "#/", 0, eve, 0555, dp);
            else
                devdir(c, (Qid){Qboot, 0, QTDIR}, "#/", 0, eve, 0555, dp);
            return 1;
        }
        if(s != 0)
            return -1;
        if((int)c->qid.path < Qboot){
            t = c->qid.path-1;
            l = &rootlist;
        }else{
            t = c->qid.path - Qboot - 1;
            l = &bootlist;
        }
        if(t >= l->ndir)
            return -1;
        d = &l->dir[t];
        devdir(c, d->qid, d->name, d->length, eve, d->perm, dp);
        return 1;
    }
}
@

%if(t < 0){
%print("rootgen %llud %d %d\n", c->qid.path, s, t);
%panic("whoops");
%}

<<method rootread>>=
static long
rootread(Chan *c, void *buf, long n, vlong off)
{
    ulong t;
    Dirtab *d;
    Dirlist *l;
    byte *data;
    ulong offset = off;

    t = c->qid.path;
    switch(t){
    case Qdir:
    case Qboot:
        return devdirread(c, buf, n, nil, 0, rootgen);
    }

    if(t<Qboot)
        l = &rootlist;
    else{
        t -= Qboot;
        l = &bootlist;
    }

    t--;
    if(t >= l->ndir)
        error(Egreg);

    d = &l->dir[t];
    data = l->data[t];
    if(offset >= d->length)
        return 0;
    if(offset+n > d->length)
        n = d->length - offset;
//#ifdef asdf
//        print("[%d] kaddr %.8ulx base %.8ulx offset %ld (%.8ulx), n %d %.8ulx %.8ulx %.8ulx\n", 
//        t, buf, data, offset, offset, n,
//        ((ulong*)(data+offset))[0],
//        ((ulong*)(data+offset))[1],
//        ((ulong*)(data+offset))[2]);
//#endif asdf
    memmove(buf, data+offset, n);
    return n;
}
@

\section{The /boot/ filesystem}

<<globals bootdir, bootdata, bootlist>>=
static Dirtab bootdir[Nbootfiles] = {
  {
    .name = "boot",
    .qid = {Qboot, 0, QTDIR},
    .length = 0,
    .perm = DMDIR|0555,
  }
};

static byte *bootdata[Nbootfiles];
static Dirlist bootlist =
{
    .base = Qboot,
    .dir = bootdir,
    .data = bootdata,
    .ndir = 1,
    .mdir = Nbootfiles
};
@



<<function addbootfile>>=
/*
 *  add a boot file
 */
void
addbootfile(char *name, byte *contents, ulong len)
{
    addlist(&bootlist, name, contents, len, 0555);
}
@

% very important for bootstrapping!
% will get boot program inside there, boot.rc, but also
% /bin/rc, /bin/ls, etc.


\section{Helpers}

<<enum qidtype cases>>=
QTMOUNT = 0x10,    /* type bit for mounted channel */
@

<<function devdir>>=
void
devdir(Chan *c, Qid qid, char *n, vlong length, char *user, long perm, DirEntry *db)
{
    db->name = n;
    if(c->flag&CMSG)
        qid.type |= QTMOUNT;
    db->qid = qid;
    db->type = devtab[c->type]->dc;
    db->dev = c->dev;
    db->mode = perm;
    db->mode |= qid.type << 24;
    db->atime = seconds();
    db->mtime = kerndate;
    db->length = length;
    db->uid = user;
    db->gid = eve;
    db->muid = user;
}
@



<<function devgen>>=
/*
 * (here, Devgen is the prototype; devgen is the function in dev.c.)
 * 
 * a Devgen is expected to return the directory entry for ".."
 * if you pass it s==DEVDOTDOT (-1).  otherwise...
 * 
 * there are two contradictory rules.
 * 
 * (i) if c is a directory, a Devgen is expected to list its children
 * as you iterate s.
 * 
 * (ii) whether or not c is a directory, a Devgen is expected to list
 * its siblings as you iterate s.
 * 
 * devgen always returns the list of children in the root
 * directory.  thus it follows (i) when c is the root and (ii) otherwise.
 * many other Devgens follow (i) when c is a directory and (ii) otherwise.
 * 
 * devwalk assumes (i).  it knows that devgen breaks (i)
 * for children that are themselves directories, and explicitly catches them.
 * 
 * devstat assumes (ii).  if the Devgen in question follows (i)
 * for this particular c, devstat will not find the necessary info.
 * with our particular Devgen functions, this happens only for
 * directories, so devstat makes something up, assuming
 * c->name, c->qid, eve, DMDIR|0555.
 * 
 * devdirread assumes (i).  the callers have to make sure
 * that the Devgen satisfies (i) for the chan being read.
 */
/*
 * the zeroth element of the table MUST be the directory itself for ..
*/
int
devgen(Chan *c, char *name, Dirtab *tab, int ntab, int i, DirEntry *dp)
{
    if(tab == 0)
        return -1;
    if(i == DEVDOTDOT){
        /* nothing */
    }else if(name){
        for(i=1; i<ntab; i++)
            if(strcmp(tab[i].name, name) == 0)
                break;
        if(i==ntab)
            return -1;
        tab += i;
    }else{
        /* skip over the first element, that for . itself */
        i++;
        if(i >= ntab)
            return -1;
        tab += i;
    }
    devdir(c, tab->qid, tab->name, tab->length, eve, tab->perm, dp);
    return 1;
}
@




<<function devclone>>=
Chan*
devclone(Chan *c)
{
    Chan *nc;

    if(c->flag & COPEN)
        panic("clone of open file type %C\n", devtab[c->type]->dc);

    nc = newchan();

    nc->type = c->type;
    nc->dev = c->dev;
    nc->mode = c->mode;
    nc->qid = c->qid;
    nc->offset = c->offset;
    nc->umh = nil;
    nc->aux = c->aux;
    nc->mqid = c->mqid;
    nc->mcp = c->mcp;
    return nc;
}
@


<<function devwalk>>=
Walkqid*
devwalk(Chan *c, Chan *nc, char **name, int nname, Dirtab *tab, int ntab, Devgen *gen)
{
    int i, j;
    bool alloc;
    Walkqid *wq;
    char *n;
    DirEntry dir;

    if(nname > 0)
        error_if_not_dir(c);

    alloc = false;
    wq = smalloc(sizeof(Walkqid)+(nname-1)*sizeof(Qid));
    if(waserror()){
        if(alloc && wq->clone!=nil)
            cclose(wq->clone);
        free(wq);
        return nil;
    }
    if(nc == nil){
        nc = devclone(c);
        nc->type = 0;   /* device doesn't know about this channel yet */
        alloc = true;
    }
    wq->clone = nc;

    for(j=0; j<nname; j++){
        if(!(nc->qid.type&QTDIR)){
            if(j==0)
                error(Enotdir);
            goto Done;
        }
        n = name[j];
        if(strcmp(n, ".") == 0){
    Accept:
            wq->qid[wq->nqid++] = nc->qid;
            continue;
        }
        if(strcmp(n, "..") == 0){
            if((*gen)(nc, nil, tab, ntab, DEVDOTDOT, &dir) != 1){
                print("devgen walk .. in dev%s %llux broken\n",
                    devtab[nc->type]->name, nc->qid.path);
                error("broken devgen");
            }
            nc->qid = dir.qid;
            goto Accept;
        }
        /*
         * Ugly problem: If we're using devgen, make sure we're
         * walking the directory itself, represented by the first
         * entry in the table, and not trying to step into a sub-
         * directory of the table, e.g. /net/net. Devgen itself
         * should take care of the problem, but it doesn't have
         * the necessary information (that we're doing a walk).
         */
        if(gen==devgen && nc->qid.path!=tab[0].qid.path)
            goto Notfound;
        for(i=0;; i++) {
            switch((*gen)(nc, n, tab, ntab, i, &dir)){
            case -1:
            Notfound:
                if(j == 0)
                    error(Enonexist);
                kstrcpy(up->errstr, Enonexist, ERRMAX);
                goto Done;
            case 0:
                continue;
            case 1:
                if(strcmp(n, dir.name) == 0){
                    nc->qid = dir.qid;
                    goto Accept;
                }
                continue;
            }
        }
    }
    /*
     * We processed at least one name, so will return some data.
     * If we didn't process all nname entries succesfully, we drop
     * the cloned channel and return just the Qids of the walks.
     */
Done:
    poperror();
    if(wq->nqid < nname){
        if(alloc)
            cclose(wq->clone);
        wq->clone = nil;
    }else if(wq->clone){
        /* attach cloned channel to same device */
        wq->clone->type = c->type;
    }
    return wq;
}
@


<<function devstat>>=
int
devstat(Chan *c, byte *db, int n, Dirtab *tab, int ntab, Devgen *gen)
{
    int i;
    DirEntry dir;
    char *p, *elem;

    for(i=0;; i++){
        switch((*gen)(c, nil, tab, ntab, i, &dir)){
        case -1:
            if(c->qid.type & QTDIR){
                if(c->path == nil)
                    elem = "???";
                else if(strcmp(c->path->s, "/") == 0)
                    elem = "/";
                else
                    for(elem=p=c->path->s; *p; p++)
                        if(*p == '/')
                            elem = p+1;
                devdir(c, c->qid, elem, 0, eve, DMDIR|0555, &dir);
                n = convD2M(&dir, db, n);
                if(n == 0)
                    error(Ebadarg);
                return n;
            }

            error(Enonexist);
        case 0:
            break;
        case 1:
            if(c->qid.path == dir.qid.path) {
                if(c->flag&CMSG)
                    dir.mode |= DMMOUNT;
                n = convD2M(&dir, db, n);
                if(n == 0)
                    error(Ebadarg);
                return n;
            }
            break;
        }
    }
    return -1; // unreachable
}
@

<<enum dirmode cases>>=
DMMOUNT = 0x10000000,  /* mode bit for mounted channel */
@


% could not be a local var of devdirread?
<<[[Chan]] other fields>>=
int dri;      /* devdirread index */
@

<<function devdirread>>=
long
devdirread(Chan *c, char *d, long n, Dirtab *tab, int ntab, Devgen *gen)
{
    long m, dsz;
    DirEntry dir;

    for(m=0; m<n; c->dri++) {
        switch((*gen)(c, nil, tab, ntab, c->dri, &dir)){
        case -1:
            return m;

        case 0:
            break;

        case 1:
            dsz = convD2M(&dir, (byte*)d, n-m);
            if(dsz <= BIT16SZ){ /* <= not < because this isn't stat; read is stuck */
                if(m == 0)
                    error(Eshort);
                return m;
            }
            m += dsz;
            d += dsz;
            break;
        }
    }

    return m;
}
@

<<function devpermcheck>>=
/*
 * error(Eperm) if open permission not granted for up->user.
 */
void
devpermcheck(char *fileuid, ulong perm, int omode)
{
    ulong t;
    static int access[] = { 0400, 0200, 0600, 0100 };

    if(strcmp(up->user, fileuid) == 0)
        perm <<= 0;
    else
    if(strcmp(up->user, eve) == 0)
        perm <<= 3;
    else
        perm <<= 6;

    t = access[omode&3];
    if((t&perm) != t)
        error(Eperm);
}
@

<<function devopen>>=
Chan*
devopen(Chan *c, int omode, Dirtab *tab, int ntab, Devgen *gen)
{
    int i;
    DirEntry dir;

    for(i=0;; i++) {
        switch((*gen)(c, nil, tab, ntab, i, &dir)){
        case -1:
            goto Return;
        case 0:
            break;
        case 1:
            if(c->qid.path == dir.qid.path) {
                devpermcheck(dir.uid, dir.mode, omode);
                goto Return;
            }
            break;
        }
    }
Return:
    c->offset = 0;
    if((c->qid.type&QTDIR) && omode!=OREAD)
        error(Eperm);
    c->mode = openmode(omode);
    c->flag |= COPEN;
    return c;
}
@


<<[[Dev]] methods>>=
Block* (*bread)(Chan*, long, ulong);
long  (*bwrite)(Chan*, Block*, ulong);
@
% bread is called from doread() in devmnt

<<function devbread>>=
Block*
devbread(Chan *c, long n, ulong offset)
{
    Block *bp;

    bp = allocb(n);
    if(bp == 0)
        error(Enomem);
    if(waserror()) {
        freeb(bp);
        nexterror();
    }
    bp->wp += devtab[c->type]->read(c, bp->wp, n, offset);
    poperror();
    return bp;
}
@


<<function devbrwrite>>=
long
devbwrite(Chan *c, Block *bp, ulong offset)
{
    long n;

    if(waserror()) {
        freeb(bp);
        nexterror();
    }
    n = devtab[c->type]->write(c, bp->rp, BLEN(bp), offset);
    poperror();
    freeb(bp);

    return n;
}
@

\section{SimpleFS}
% would be good to have a simplefs ...

% use ramfs? cheating a bit, and also it's an external fileserver
%  so more complicated
% use tinyfs? really too simple; no subdirectories for example.

%\section{[[devfs.c]]}
% not sure it's needed

\section{[[Block]]}

<<enum blockflag>>=
/* flag values */
enum
{
  BINTR = (1<<0),
  BFREE = (1<<1),
  Bipck = (1<<2),   /* ip checksum */
  Budpck  = (1<<3),   /* udp checksum */
  Btcpck  = (1<<4),   /* tcp checksum */
  Bpktck  = (1<<5),   /* packet checksum */
};
@

<<struct Block>>=
struct Block
{
  long  ref;
  Block*  next;
  Block*  list;
  byte*  rp;     /* first unconsumed byte */
  byte*  wp;     /* first empty byte */
  byte*  lim;      /* 1 past the end of the buffer */
  byte*  base;     /* start of the buffer */
  void  (*free)(Block*);
  ushort  flag;
  ushort  checksum;   /* IP checksum of complete packet (minus media header) */
};
@

<<function BLEN>>=
#define BLEN(s) ((s)->wp - (s)->rp)
@


<<function BALLOC>>=
#define BALLOC(s) ((s)->lim - (s)->base)
@


<<constant BLOCKALIGN(x86)>>=
#define BLOCKALIGN  8
@

<<function _allocb>>=
static Block*
_allocb(int size)
{
    Block *b;
    ulong addr;

    if((b = mallocz(sizeof(Block)+size+Hdrspc, false)) == nil)
        return nil;

    b->next = nil;
    b->list = nil;
    b->free = 0;
    b->flag = 0;
    b->ref = 0;
    arch_xinc(&b->ref);

    /* align start of data portion by rounding up */
    addr = (ulong)b;
    addr = ROUND(addr + sizeof(Block), BLOCKALIGN);
    b->base = (byte*)addr;

    /* align end of data portion by rounding down */
    b->lim = ((byte*)b) + msize(b);
    addr = (ulong)(b->lim);
    addr = addr & ~(BLOCKALIGN-1);
    b->lim = (byte*)addr;

    /* leave sluff at beginning for added headers */
    b->rp = b->lim - ROUND(size, BLOCKALIGN);
    if(b->rp < b->base)
        panic("_allocb");
    b->wp = b->rp;

    return b;
}
@

<<function msize>>=
ulong
msize(void *v)
{
    return poolmsize(mainmem, (ulong*)v-Npadlong)-Npadlong*sizeof(ulong);
}
@


<<function allocb>>=
Block*
allocb(int size)
{
    Block *b;

    /*
     * Check in a process and wait until successful.
     * Can still error out of here, though.
     */
    if(up == nil)
        panic("allocb without up: %#p", getcallerpc(&size));
    if((b = _allocb(size)) == nil){
        arch_splhi();
        xsummary();
        mallocsummary();
        delay(500);
        panic("allocb: no memory for %d bytes; caller %#p", size,
            getcallerpc(&size));
    }
    setmalloctag(b, getcallerpc(&size));

    return b;
}
@




<<struct Ialloc>>=
struct Ialloc
{
    Lock;
    ulong   bytes;
};
@


<<global ialloc>>=
struct Ialloc ialloc;
@

<<function iallocb>>=
Block*
iallocb(int size)
{
    Block *b;
    static int m1, m2, mp;

    if(ialloc.bytes > conf.ialloc){
        if((m1++%10000)==0){
            if(mp++ > 1000){
                active.exiting = true;
                exit(0);
            }
            iprint("iallocb: limited %lud/%lud\n",
                ialloc.bytes, conf.ialloc);
        }
        return nil;
    }

    if((b = _allocb(size)) == nil){
        if((m2++%10000)==0){
            if(mp++ > 1000){
                active.exiting = true;
                exit(0);
            }
            iprint("iallocb: no memory %lud/%lud\n",
                ialloc.bytes, conf.ialloc);
        }
        return nil;
    }
    setmalloctag(b, getcallerpc(&size));
    b->flag = BINTR;

    ilock(&ialloc);
    ialloc.bytes += b->lim - b->base;
    iunlock(&ialloc);

    return b;
}
@


<<function freeb>>=
void
freeb(Block *b)
{
    void *dead = (void*)Bdead;
    long ref;

    if(b == nil || (ref = arch_xdec(&b->ref)) > 0)
        return;

    if(ref < 0){
        dumpstack();
        panic("freeb: ref %ld; caller pc %#p", ref, getcallerpc(&b));
    }

    /*
     * drivers which perform non cache coherent DMA manage their own buffer
     * pool of uncached buffers and provide their own free routine.
     */
    if(b->free) {
        b->free(b);
        return;
    }
    if(b->flag & BINTR) {
        ilock(&ialloc);
        ialloc.bytes -= b->lim - b->base;
        iunlock(&ialloc);
    }

    /* poison the block in case someone is still holding onto it */
    b->next = dead;
    b->rp = dead;
    b->wp = dead;
    b->lim = dead;
    b->base = dead;

    free(b);
}
@


<<function checkb>>=
void
checkb(Block *b, char *msg)
{
    void *dead = (void*)Bdead;

    if(b == dead)
        panic("checkb b %s %#p", msg, b);
    if(b->base == dead || b->lim == dead || b->next == dead
      || b->rp == dead || b->wp == dead){
        print("checkb: base %#p lim %#p next %#p\n",
            b->base, b->lim, b->next);
        print("checkb: rp %#p wp %#p\n", b->rp, b->wp);
        panic("checkb dead: %s", msg);
    }

    if(b->base > b->lim)
        panic("checkb 0 %s %#p %#p", msg, b->base, b->lim);
    if(b->rp < b->base)
        panic("checkb 1 %s %#p %#p", msg, b->base, b->rp);
    if(b->wp < b->base)
        panic("checkb 2 %s %#p %#p", msg, b->base, b->wp);
    if(b->rp > b->lim)
        panic("checkb 3 %s %#p %#p", msg, b->rp, b->lim);
    if(b->wp > b->lim)
        panic("checkb 4 %s %#p %#p", msg, b->wp, b->lim);
}
@





<<function freeblist>>=
/*
 *  free a list of blocks
 */
void
freeblist(Block *b)
{
    Block *next;

    for(; b != 0; b = next){
        next = b->next;
        if(b->ref == 1)
            b->next = nil;
        freeb(b);
    }
}
@


<<function padblock>>=
/*
 *  pad a block to the front (or the back if size is negative)
 */
Block*
padblock(Block *bp, int size)
{
    int n;
    Block *nbp;

//    QDEBUG checkb(bp, "padblock 1");
    if(size >= 0){
        if(bp->rp - bp->base >= size){
            bp->rp -= size;
            return bp;
        }

        if(bp->next)
            panic("padblock %#p", getcallerpc(&bp));
        n = BLEN(bp);
        padblockcnt++;
        nbp = allocb(size+n);
        nbp->rp += size;
        nbp->wp = nbp->rp;
        memmove(nbp->wp, bp->rp, n);
        nbp->wp += n;
        freeb(bp);
        nbp->rp -= size;
    } else {
        size = -size;

        if(bp->next)
            panic("padblock %#p", getcallerpc(&bp));

        if(bp->lim - bp->wp >= size)
            return bp;

        n = BLEN(bp);
        padblockcnt++;
        nbp = allocb(size+n);
        memmove(nbp->wp, bp->rp, n);
        nbp->wp += n;
        freeb(bp);
    }
//    QDEBUG checkb(nbp, "padblock 1");
    return nbp;
}
@


<<function blocklen>>=
/*
 *  return count of bytes in a string of blocks
 */
int
blocklen(Block *bp)
{
    int len;

    len = 0;
    while(bp) {
        len += BLEN(bp);
        bp = bp->next;
    }
    return len;
}
@


<<function blockalloclen>>=
/*
 * return count of space in blocks
 */
int
blockalloclen(Block *bp)
{
    int len;

    len = 0;
    while(bp) {
        len += BALLOC(bp);
        bp = bp->next;
    }
    return len;
}
@


<<function concatblock>>=
/*
 *  copy the  string of blocks into
 *  a single block and free the string
 */
Block*
concatblock(Block *bp)
{
    int len;
    Block *nb, *f;

    if(bp->next == 0)
        return bp;

    nb = allocb(blocklen(bp));
    for(f = bp; f; f = f->next) {
        len = BLEN(f);
        memmove(nb->wp, f->rp, len);
        nb->wp += len;
    }
    concatblockcnt += BLEN(nb);
    freeblist(bp);
//    QDEBUG checkb(nb, "concatblock 1");
    return nb;
}
@


<<function pullupblock>>=
/*
 *  make sure the first block has at least n bytes
 */
Block*
pullupblock(Block *bp, int n)
{
    int i;
    Block *nbp;

    /*
     *  this should almost always be true, it's
     *  just to avoid every caller checking.
     */
    if(BLEN(bp) >= n)
        return bp;

    /*
     *  if not enough room in the first block,
     *  add another to the front of the list.
     */
    if(bp->lim - bp->rp < n){
        nbp = allocb(n);
        nbp->next = bp;
        bp = nbp;
    }

    /*
     *  copy bytes from the trailing blocks into the first
     */
    n -= BLEN(bp);
    while(nbp = bp->next){
        i = BLEN(nbp);
        if(i > n) {
            memmove(bp->wp, nbp->rp, n);
            pullupblockcnt++;
            bp->wp += n;
            nbp->rp += n;
//            QDEBUG checkb(bp, "pullupblock 1");
            return bp;
        } else {
            /* shouldn't happen but why crash if it does */
            if(i < 0){
                print("pullup negative length packet, called from %#p\n",
                    getcallerpc(&bp));
                i = 0;
            }
            memmove(bp->wp, nbp->rp, i);
            pullupblockcnt++;
            bp->wp += i;
            bp->next = nbp->next;
            nbp->next = 0;
            freeb(nbp);
            n -= i;
            if(n == 0){
//                QDEBUG checkb(bp, "pullupblock 2");
                return bp;
            }
        }
    }
    freeb(bp);
    return nil;
}
@


<<function packblock>>=
/*
 *  if the allocated space is way out of line with the used
 *  space, reallocate to a smaller block
 */
Block*
packblock(Block *bp)
{
    Block **l, *nbp;
    int n;

    for(l = &bp; *l; l = &(*l)->next){
        nbp = *l;
        n = BLEN(nbp);
        if((n<<2) < BALLOC(nbp)){
            *l = allocb(n);
            memmove((*l)->wp, nbp->rp, n);
            (*l)->wp += n;
            (*l)->next = nbp->next;
            freeb(nbp);
        }
    }

    return bp;
}
@


<<function trimblock>>=
/*
 *  trim to len bytes starting at offset
 */
Block *
trimblock(Block *bp, int offset, int len)
{
    ulong l;
    Block *nb, *startb;

//    QDEBUG checkb(bp, "trimblock 1");
    if(blocklen(bp) < offset+len) {
        freeblist(bp);
        return nil;
    }

    while((l = BLEN(bp)) < offset) {
        offset -= l;
        nb = bp->next;
        bp->next = nil;
        freeb(bp);
        bp = nb;
    }

    startb = bp;
    bp->rp += offset;

    while((l = BLEN(bp)) < len) {
        len -= l;
        bp = bp->next;
    }

    bp->wp -= (BLEN(bp) - len);

    if(bp->next) {
        freeblist(bp->next);
        bp->next = nil;
    }

    return startb;
}
@


<<function copyblock>>=
/*
 *  copy 'count' bytes into a new block
 */
Block*
copyblock(Block *bp, int count)
{
    int l;
    Block *nbp;

//    QDEBUG checkb(bp, "copyblock 0");
    nbp = allocb(count);
    for(; count > 0 && bp != 0; bp = bp->next){
        l = BLEN(bp);
        if(l > count)
            l = count;
        memmove(nbp->wp, bp->rp, l);
        nbp->wp += l;
        count -= l;
    }
    if(count > 0){
        memset(nbp->wp, 0, count);
        nbp->wp += count;
    }
    copyblockcnt++;
//    QDEBUG checkb(nbp, "copyblock 1");

    return nbp;
}
@


<<function adjustblock>>=
Block*
adjustblock(Block* bp, int len)
{
    int n;
    Block *nbp;

    if(len < 0){
        freeb(bp);
        return nil;
    }

    if(bp->rp+len > bp->lim){
        nbp = copyblock(bp, len);
        freeblist(bp);
//        QDEBUG checkb(nbp, "adjustblock 1");

        return nbp;
    }

    n = BLEN(bp);
    if(len > n)
        memset(bp->wp, 0, len-n);
    bp->wp = bp->rp+len;
//    QDEBUG checkb(bp, "adjustblock 2");

    return bp;
}
@


<<function pullblock>>=
/*
 *  throw away up to count bytes from a
 *  list of blocks.  Return count of bytes
 *  thrown away.
 */
int
pullblock(Block **bph, int count)
{
    Block *bp;
    int n, bytes;

    bytes = 0;
    if(bph == nil)
        return 0;

    while(*bph != nil && count != 0) {
        bp = *bph;
        n = BLEN(bp);
        if(count < n)
            n = count;
        bytes += n;
        count -= n;
        bp->rp += n;
//        QDEBUG checkb(bp, "pullblock ");
        if(BLEN(bp) == 0) {
            *bph = bp->next;
            bp->next = nil;
            freeb(bp);
        }
    }
    return bytes;
}
@

<<function bl2mem>>=
/*
 *  copy the contents of a string of blocks into
 *  memory.  emptied blocks are freed.  return
 *  pointer to first unconsumed block.
 */
Block*
bl2mem(byte *p, Block *b, int n)
{
    int i;
    Block *next;

    for(; b != nil; b = next){
        i = BLEN(b);
        if(i > n){
            memmove(p, b->rp, n);
            b->rp += n;
            return b;
        }
        memmove(p, b->rp, i);
        n -= i;
        p += i;
        b->rp += i;
        next = b->next;
        freeb(b);
    }
    return nil;
}
@


\section{Fileservers}

% put after Devices? after all Device and file servers
% are similar, they also implement the Dev interface
% it's just that they provide a Dev on top of another Dev

% see docs/man/3/ for references on all "devices/fileservers"


% intro to architecture? vs micro kernel?
% ref to FUSE?
% explain RPC? 9p

%Ramfs, dossrv

\section{XTODO}

<<enum qidtype cases>>=
QTAUTH = 0x08,    /* type bit for authentication file */
QTAPPEND = 0x40,    /* type bit for append only files */
QTEXCL = 0x20,    /* type bit for exclusive use files */
@


%###############################################################################

%\part{Extra}

\chapter{Time}
\minitoc

<<systab time syscalls>>=
    [SLEEP]     syssleep,
    [ALARM]     sysalarm,
@

<<[[Cpu]] [[Arch]] other fields(x86)>>=
// for arch_perfticks, tsc = time stamp counter
bool havetsc;
@

% what about delay() and microdelay()? but seems used only in panic path
% so maybe not that interesting

\section{Overview (x86)}

% we have one machine timer, but we want many processes to have
% different alarms.

% different capabilities? timer, clock, rtc, ??

<<[[PCArch]] time methods fields(x86)>>=
void  (*clockenable)(void);
uvlong  (*fastclock)(uvlong*);
void  (*timerset)(uvlong);
@

<<[[archgeneric]] time methods(x86)>>=
.clockenable=   i8253enable,
.fastclock= i8253read,
.timerset=  i8253timerset,
@


\section{Time units}

<<type Txxx>>=
typedef vlong   Tval; // ticks
typedef vlong   Tnano; // nanoseconds
typedef vlong   Tmicro; // microseconds
typedef int     Tms; // milliseconds
typedef vlong   Tsec; // seconds
@
%pad: Tval was there, but I added the other one I think


<<function tk2ms>>=
/*
 *  This tk2ms avoids overflows that the macro version is prone to.
 *  It is a LOT slower so shouldn't be used if you're just converting
 *  a delta.
 */
ulong
tk2ms(ulong ticks)
{
    uvlong t, hz;

    t = ticks;
    hz = HZ;
    t *= 1000L;
    t = t/hz;
    ticks = t;
    return ticks;
}
@ 


<<function ms2tk>>=
ulong
ms2tk(ulong ms)
{
    /* avoid overflows at the cost of precision */
    if(ms >= 1000000000/HZ)
        return (ms/1000)*HZ;
    return (ms*HZ+500)/1000;
}
@ 


% ?? -> <>
<<function us(x86)>>=
ulong
arch_us(void)
{
    return fastticks2us((*arch->fastclock)(nil));
}
@
%old: was called microsecond in unicode (Âµs)

<<function fastticks(x86)>>=
/*
 *  return value and speed of timer set in arch->clockenable
 */
uvlong
devarch_arch_fastticks(uvlong *hz)
{
    return (*arch->fastclock)(hz);
}
@


\section{Timers (x86)}

% capacity of machine is very low, just timer next point
%  but have many processes, many timer needs, so need map
%  all of that on very limited hardware power



\subsection{Programmable timer [[i8253]] (x86)}

\subsection{[[arch_timerset()]] (x86)}

<<function timerset(x86)>>=
// used to be static, but now shared between arch.c and devarch.c
int doi8253set = 1;
/*
 *  set next timer interrupt
 */
void
arch_timerset(Tval x)
{
    if(doi8253set)
        (*arch->timerset)(x);
}
@

<<function i8253timerset(x86)>>=
void
i8253timerset(uvlong next)
{
    long period;
    ulong want;
    ulong now;

    period = MaxPeriod;
    if(next != 0){
        want = next>>Tickshift;
        now = i8253.ticks;  /* assuming whomever called us just did arch_fastticks() */

        period = want - now;
        if(period < MinPeriod)
            period = MinPeriod;
        else if(period > MaxPeriod)
            period = MaxPeriod;
    }

    /* hysteresis */
    if(i8253.period != period){
        ilock(&i8253);
        /* load new value */
        outb(Tmode, Load0|Square);
        outb(T0cntr, period);       /* low byte */
        outb(T0cntr, period >> 8);      /* high byte */

        /* remember period */
        i8253.period = period;
        i8253.periodset++;
        iunlock(&i8253);
    }
}
@

\subsection{[[Timer]] and [[Timers]]}

<<struct Timer>>=
struct Timer
{
    /* Public interface */
    // enum<timermode>
    int tmode;    /* See above */
    Tnano tns;    /* meaning defined by mode */ //nanosecond
    void  (*tf)(Ureg*, Timer*);
    void  *ta;
  
    /* Internal */
    Lock;
    Tval  tticks;   /* tns converted to ticks */
    Tval  twhen;    /* ns represented in arch_fastticks */

    <<[[Timer extra fields>>
    };
@ 

<<enum timermode>>=
/*
 * fasttick timer interrupts
 */
enum timermode 
{
    Trelative,  /* timer programmed in ns from now */
    Tperiodic,  /* periodic timer, period in ns */
};
@ 

<<struct Timers>>=
struct Timers
{
    // list<Timer> (next = Timer.tnext)
    Timer *head;
    // extra
    Lock;
};
@ 

<<[[Timer extra fields>>=
// list<Timer> of Timers.head
Timer *tnext;
// ref<list<Timer>> Timers.head
Timers  *tt;    /* Timers queue this timer runs on */
@


<<function tadd>>=
static Tval
tadd(Timers *tt, Timer *nt)
{
    Timer *t, **last;

    /* Called with tt locked */
    assert(nt->tt == nil);
    switch(nt->tmode){
    case Trelative:
        if(nt->tns <= 0)
            nt->tns = 1;
        nt->twhen = arch_fastticks(nil) + ns2fastticks(nt->tns);
        break;
    case Tperiodic:
        assert(nt->tns >= 100000);  /* At least 100 Âµs period */
        if(nt->twhen == 0){
            /* look for another timer at same frequency for combining */
            for(t = tt->head; t; t = t->tnext){
                if(t->tmode == Tperiodic && t->tns == nt->tns)
                    break;
            }
            if (t)
                nt->twhen = t->twhen;
            else
                nt->twhen = arch_fastticks(nil);
        }
        nt->twhen += ns2fastticks(nt->tns);
        break;
    default:
        panic("timer: impossible");
        break;
    }

    for(last = &tt->head; t = *last; last = &t->tnext){
        if(t->twhen > nt->twhen)
            break;
    }
    nt->tnext = *last;
    *last = nt;
    nt->tt = tt;
    if(last == &tt->head)
        return nt->twhen;
    return 0;
}
@ 


<<function tdel>>=
static Tval
tdel(Timer *dt)
{
    Timer *t, **last;
    Timers *tt;

    tt = dt->tt;
    if (tt == nil)
        return 0; // possible? panic("impossible") would be better no?
    for(last = &tt->head; t = *last; last = &t->tnext){
        if(t == dt){
            assert(dt->tt);
            dt->tt = nil;
            *last = t->tnext;
            break;
        }
    }
    if(last == &tt->head && tt->head)
        return tt->head->twhen;
    return 0;
}
@ 

\subsection{[[timers]]}

<<global timers>>=
static Timers timers[MAXCPUS];
@ 

<<function timeradd>>=
/* add or modify a timer */
void
timeradd(Timer *nt)
{
    Timers *tt;
    Tval when;

    /* Must lock Timer struct before Timers struct */
    ilock(nt);

    if(tt = nt->tt){
        ilock(tt);
        tdel(nt);
        iunlock(tt);
    }

    tt = &timers[cpu->cpuno];
    ilock(tt);
    when = tadd(tt, nt);
    if(when)
        arch_timerset(when);
    iunlock(tt);
    iunlock(nt);
}
@ 

<<function timerdel>>=
void
timerdel(Timer *dt)
{
    Timers *tt;
    Tval when;

    ilock(dt);
    if(tt = dt->tt){
        ilock(tt);
        when = tdel(dt);
        if(when && tt == &timers[cpu->cpuno])
            arch_timerset(tt->head->twhen);
        iunlock(tt);
    }
    iunlock(dt);
}
@ 


\subsection{Initialisation}

<<global timersinited>>=
static bool timersinited;
@

<<function timersinit>>=
void
timersinit(void)
{
    Timer *t;

    timersinited = true;
    todinit();

    t = malloc(sizeof(Timer));
    if(t == nil)
        error(Enomem);
    t->tmode = Tperiodic;
    t->tt = nil;
    t->tns = 1000000000/HZ;
    /*
     * T->tf == nil means the HZ clock for this processor.
     */
    t->tf = nil;
    timeradd(t);
}
@ 

\subsection{[[timerintr()]]}

\ifallcode
<<clock.c statistics>>=
ulong intrcount[MAXCPUS];
ulong fcallcount[MAXCPUS];
@
\fi

<<interrupt callback timerintr>>=
// called via i8253clock
void
timerintr(Ureg *u, Tval)
{
    Timer *t;
    Timers *tt;
    uvlong when, now;
    int count, callhzclock;

    intrcount[cpu->cpuno]++;
    callhzclock = 0;
    tt = &timers[cpu->cpuno];
    now = arch_fastticks(nil);
    if(now == 0)
        panic("timerintr: zero arch_fastticks()");
    ilock(tt);
    count = Maxtimerloops;
    while((t = tt->head) != nil){
        /*
         * No need to ilock t here: any manipulation of t
         * requires tdel(t) and this must be done with a
         * lock to tt held.  We have tt, so the tdel will
         * wait until we're done
         */
        when = t->twhen;
        if(when > now){
            arch_timerset(when);
            iunlock(tt);
            if(callhzclock)
                hzclock(u);
            return;
        }
        tt->head = t->tnext;
        assert(t->tt == tt);
        t->tt = nil;
        fcallcount[cpu->cpuno]++;
        iunlock(tt);
        if(t->tf)
            (*t->tf)(u, t);
        else
            callhzclock++;
        ilock(tt);
        if(t->tmode == Tperiodic)
            tadd(tt, t);
        if (--count <= 0) {
            count = Maxtimerloops;
            iprint("timerintr: probably stuck in while loop; "
                "scrutinise clock.c or use faster cycle "
                "counter\n");
        }
    }
    iunlock(tt);
}
@ 

<<constant Maxtimerloops>>=
    Maxtimerloops = 20*1000,
@

\subsection{Clock callbacks, [[addclock0link()]]}
% very important! used a lot.

<<function addclock0link>>=
Timer*
addclock0link(void (*f)(void), Tms ms)
{
    Timer *nt;
    Tval when;

    if(!timersinited)
        panic("addclock0link: timersinit not called yet");

    /* Synchronize to hztimer if ms is 0 */
    nt = malloc(sizeof(Timer));
    if(nt == nil)
        error(Enomem);
    if(ms == 0)
        ms = 1000/HZ;

    nt->tns = (Tnano)ms*1000000LL;
    nt->tmode = Tperiodic;
    nt->tt = nil;
    nt->tf = (void (*)(Ureg*, Timer*))f;

    // those clock callbacks are all done on the bootstrap processor
    //dupe: timeradd() but with forced processor number
    ilock(&timers[0]);
    when = tadd(&timers[0], nt);
    if(when)
        arch_timerset(when);
    iunlock(&timers[0]);
    return nt;
}
@ 
\l why clock0? to say low-level?

\section{[[syssleep()]]}

<<[[Proc]] synchronization fields>>=
Rendez  sleepr;    /* place for syssleep/debug/tsleep */
@ 
%old: was sleep, but pb because of my #define sleep proc_sleep

<<syscall sleep>>=
// int sleep(long millisecs);
long
syssleep(ulong* arg)
{
    int n;
    n = arg[0];
    if(n <= 0) {
        <<[[syssleep()]] optional [[edfyield()]] for real-time scheduling>>
        yield();
        return 0;
    }
    if(n < TK2MS(1))
        n = TK2MS(1);
    tsleep(&up->sleepr, returnfalse, 0, n);
    return 0;
}
@ 

% time field?
<<[[Proc]] other fields>>=
Timer;      /* For tsleep and real-time */
Rendez  *trend;
int (*tfn)(void*);
@

<<function tsleep>>=
void
proc_tsleep(Rendez *r, int (*fn)(void*), void *arg, ulong ms)
{
    if (up->tt){
        print("tsleep: timer active: mode %d, tf %#p\n", up->tmode, up->tf);
        timerdel(up);
    }
    up->tns = MS2NS(ms);
    up->tf = twakeup;
    up->tmode = Trelative;
    up->ta = up;
    up->trend = r;
    up->tfn = fn;
    timeradd(up);

    if(waserror()){
        timerdel(up);
        nexterror();
    }
    sleep(r, tfn, arg);
    if(up->tt)
        timerdel(up);
    up->twhen = 0;
    poperror();
}
@ 

<<function tfn>>=
static int
tfn(void *arg)
{
    return up->trend == nil || up->tfn(arg);
}
@ 

<<function twakeup>>=
void
twakeup(Ureg*, Timer *t)
{
    Proc *p;
    Rendez *trend;

    p = t->ta;
    trend = p->trend;
    p->trend = nil;
    if(trend)
        wakeup(trend);
}
@ 


\section{[[sysalarm()]]}
%related? tsleep, tsemacquire

<<struct Alarms>>=
struct Alarms
{
    // list<ref<Proc> (next = Proc.palarm)
    Proc  *head;
    // extra
    QLock;
};
@ 

<<[[Proc]] extra fields>>=
// Alarms.head chain?
Proc  *palarm;  /* Next alarm time */
@

<<global alarms>>=
static Alarms   alarms;
@ 

<<syscall alarm>>=
// long alarm(unsigned long millisecs);
long
sysalarm(ulong* arg)
{
    return procalarm(arg[0]);
}
@ 

% have a [[Proc]] time field?
<<[[Proc]] other fields>>=
ulong alarm;    /* Time of call */
@

<<function procalarm>>=
ulong
procalarm(ulong time)
{
    Proc **l, *f;
    ulong when, old;

    if(up->alarm)
        old = tk2ms(up->alarm - CPUS(0)->ticks);
    else
        old = 0;
    if(time == 0) {
        up->alarm = 0;
        return old;
    }
    when = ms2tk(time)+CPUS(0)->ticks;
    if(when == 0)       /* ticks have wrapped to 0? */
        when = 1;   /* distinguish a wrapped alarm from no alarm */

    qlock(&alarms);
    l = &alarms.head;
    for(f = *l; f; f = f->palarm) {
        if(up == f){
            *l = f->palarm;
            break;
        }
        l = &f->palarm;
    }

    up->palarm = 0;
    if(alarms.head) {
        l = &alarms.head;
        for(f = *l; f; f = f->palarm) {
            if((long)(f->alarm - when) >= 0) {
                up->palarm = f;
                *l = up;
                goto done;
            }
            l = &f->palarm;
        }
        *l = up;
    }
    else
        alarms.head = up;
done:
    up->alarm = when;
    qunlock(&alarms);

    return old;
}
@ 





<<global alarmr>>=
static Rendez alarmr;
@ 

<<kernel process alarmkproc>>=
// Kernel Process for alarm managment
void
alarmkproc(void*)
{
    Proc *rp;
    ulong now;

    for(;;){
        now = CPUS(0)->ticks;
        qlock(&alarms);
        /*
         * the odd test of now vs. rp->alarm is to cope with
         * now wrapping around.
         */
        while((rp = alarms.head) && (long)(now - rp->alarm) >= 0){
            if(rp->alarm != 0L){
                if(canqlock(&rp->debug)){
                    if(!waserror()){
                        postnote(rp, 0, "alarm", NUser);
                        poperror();
                    }
                    qunlock(&rp->debug);
                    rp->alarm = 0L;
                }else
                    break;
            }
            alarms.head = rp->palarm;
        }
        qunlock(&alarms);

        sleep(&alarmr, returnfalse, 0);
    }
}
@ 


<<function checkalarms>>=
/*
 *  called every clock tick
 */
void
checkalarms(void)
{
    Proc *p;
    ulong now;

    p = alarms.head;
    now = CPUS(0)->ticks;

    if(p && (long)(now - p->alarm) >= 0)
        wakeup(&alarmr);
}
@ 


\section{Time of day}

% see big comment at beginning of tod.c, in kernel_extra

<<struct TOD>>=
struct TOD {
    int init;       /* true if initialized */
    ulong   cnt;
    Lock;
    uvlong  multiplier; /* ns = off + (multiplier*ticks)>>31 */
    uvlong  divider;    /* ticks = (divider*(ns-off))>>31 */
    uvlong  umultiplier;    /* Âµs = (Âµmultiplier*ticks)>>31 */
    uvlong  udivider;   /* ticks = (Âµdivider*Âµs)>>31 */
    vlong   hz;     /* frequency of fast clock */
    vlong   last;       /* last reading of fast clock */
    vlong   off;        /* offset from epoch to last */
    vlong   lasttime;   /* last return value from todget */
    vlong   delta;  /* add 'delta' each slow clock tick from sstart to send */
    ulong   sstart;     /* ... */
    ulong   send;       /* ... */
};
@ 


<<global tod>>=
struct TOD tod;
@ 


<<devcons.c Exxx errors>>=
char *Ebadtimectl = "bad time control";
@

<<constant VLNUMSIZE>>=
    VLNUMSIZE=  22,
@



<<function todinit>>=
void
todinit(void)
{
    if(tod.init)
        return;
    ilock(&tod);
    tod.init = 1;           /* prevent reentry via arch_fastticks */
    tod.last = arch_fastticks((uvlong *)&tod.hz);
    iunlock(&tod);
    todsetfreq(tod.hz);
    addclock0link(todfix, 100);
}
@ 


<<function todsetfreq>>=
/*
 *  calculate multiplier
 */
void
todsetfreq(vlong f)
{
    if (f <= 0)
        panic("todsetfreq: freq %lld <= 0", f);
    ilock(&tod);
    tod.hz = f;

    /* calculate multiplier for time conversion */
    tod.multiplier = mk64fract(TODFREQ, f);
    tod.divider = mk64fract(f, TODFREQ) + 1;
    tod.umultiplier = mk64fract(MicroFREQ, f);
    tod.udivider = mk64fract(f, MicroFREQ) + 1;
    iunlock(&tod);
}
@ 


<<function todset>>=
/*
 *  Set the time of day struct
 */
void
todset(vlong t, vlong delta, int n)
{
    if(!tod.init)
        todinit();

    ilock(&tod);
    if(t >= 0){
        tod.off = t;
        tod.last = arch_fastticks(nil);
        tod.lasttime = 0;
        tod.delta = 0;
        tod.sstart = tod.send;
    } else {
        if(n <= 0)
            n = 1;
        n *= HZ;
        if(delta < 0 && n > -delta)
            n = -delta;
        if(delta > 0 && n > delta)
            n = delta;
        if (n == 0) {
            iprint("todset: n == 0, delta == %lld\n", delta);
            delta = 0;
        } else
            delta /= n;
        tod.sstart = CPUS(0)->ticks;
        tod.send = tod.sstart + n;
        tod.delta = delta;
    }
    iunlock(&tod);
}
@ 


<<function todget>>=
/*
 *  get time of day
 */
vlong
todget(vlong *ticksp)
{
    uvlong x;
    vlong ticks, diff;
    ulong t;

    if(!tod.init)
        todinit();

    /*
     * we don't want time to pass twixt the measuring of arch_fastticks
     * and grabbing tod.last.  Also none of the vlongs are atomic so
     * we have to look at them inside the lock.
     */
    ilock(&tod);
    tod.cnt++;
    ticks = arch_fastticks(nil);

    /* add in correction */
    if(tod.sstart != tod.send){
        t = CPUS(0)->ticks;
        if(t >= tod.send)
            t = tod.send;
        tod.off = tod.off + tod.delta*(t - tod.sstart);
        tod.sstart = t;
    }

    /* convert to epoch */
    diff = ticks - tod.last;
    if(diff < 0)
        diff = 0;
    arch_mul64fract(&x, diff, tod.multiplier);
    x += tod.off;

    /* time can't go backwards */
    if(x < tod.lasttime)
        x = tod.lasttime;
    else
        tod.lasttime = x;

    iunlock(&tod);

    if(ticksp != nil)
        *ticksp = ticks;

    return x;
}
@ 


<<function todfix>>=
/*
 *  called regularly to avoid calculation overflows
 */
static void
todfix(void)
{
    vlong ticks, diff;
    uvlong x;

    ticks = arch_fastticks(nil);

    diff = ticks - tod.last;
    if(diff > tod.hz){
        ilock(&tod);

        /* convert to epoch */
        arch_mul64fract(&x, diff, tod.multiplier);
if(x > 30000000000ULL) iprint("todfix %llud\n", x);
        x += tod.off;

        /* protect against overflows */
        tod.last = ticks;
        tod.off = x;

        iunlock(&tod);
    }
}
@ 


<<function seconds>>=
long
seconds(void)
{
    return (vlong)todget(nil) / TODFREQ;
}
@ 


<<function fastticks2us>>=
uvlong
fastticks2us(uvlong ticks)
{
    uvlong res;

    if(!tod.init)
        todinit();
    arch_mul64fract(&res, ticks, tod.umultiplier);
    return res;
}
@ 


<<function ns2fastticks>>=
/*
 *  convert nanoseconds to fast ticks
 */
uvlong
ns2fastticks(uvlong ns)
{
    uvlong res;

    if(!tod.init)
        todinit();
    arch_mul64fract(&res, ns, tod.divider);
    return res;
}
@ 

<<function mk64fract>>=
/*
 * Make a 64 bit fixed point number that has a decimal point
 * to the left of the low order 32 bits.  This is used with
 * arch_mul64fract for converting twixt nanoseconds and arch_fastticks.
 *
 *  multiplier = (to<<32)/from
 */
uvlong
mk64fract(uvlong to, uvlong from)
{
    return (to<<32) / from;
}
@ 







<<global fasthz>>=
vlong   fasthz;
@ 


\section{[[/dev/time]]}
% for bin/date,
% but can also set the time if you write into it

<<function readtime>>=
/*
 *  like the old #c/time but with added info.  Return
 *
 *  secs    nanosecs    fastticks   fasthz
 */
static int
readtime(ulong off, char *buf, int n)
{
    vlong   nsec, ticks;
    long sec;
    char str[7*NUMSIZE];

    nsec = todget(&ticks);
    if(fasthz == 0LL)
        arch_fastticks((uvlong*)&fasthz);
    sec = nsec/1000000000ULL;
    snprint(str, sizeof(str), "%*lud %*llud %*llud %*llud ",
        NUMSIZE-1, sec,
        VLNUMSIZE-1, nsec,
        VLNUMSIZE-1, ticks,
        VLNUMSIZE-1, fasthz);
    return readstr(off, buf, n, str);
}
@

<<function writetime>>=
/*
 *  set the time in seconds
 */
static int
writetime(char *buf, int n)
{
    char b[13];
    long i;
    vlong now;

    if(n >= sizeof(b))
        error(Ebadtimectl);
    strncpy(b, buf, n);
    b[n] = 0;
    i = strtol(b, 0, 0);
    if(i <= 0)
        error(Ebadtimectl);
    now = i*1000000000LL;
    todset(now, 0, 0);
    return n;
}
@

%----------------------------------------------------------------

<<function readbintime>>=
/*
 *  read binary time info.  all numbers are little endian.
 *  ticks and nsec are syncronized.
 */
static int
readbintime(char *buf, int n)
{
    int i;
    vlong nsec, ticks;
    byte *b = (byte*)buf;

    i = 0;
    if(fasthz == 0LL)
        arch_fastticks((uvlong*)&fasthz);
    nsec = todget(&ticks);
    if(n >= 3*sizeof(uvlong)){
        vlong2le(b+2*sizeof(uvlong), fasthz);
        i += sizeof(uvlong);
    }
    if(n >= 2*sizeof(uvlong)){
        vlong2le(b+sizeof(uvlong), ticks);
        i += sizeof(uvlong);
    }
    if(n >= 8){
        vlong2le(b, nsec);
        i += sizeof(vlong);
    }
    return i;
}
@


<<function writebintime>>=
/*
 *  set any of the following
 *  - time in nsec
 *  - nsec trim applied over some seconds
 *  - clock frequency
 */
static int
writebintime(char *buf, int n)
{
    byte *p;
    vlong delta;
    long period;

    n--;
    p = (byte*)buf + 1;
    switch(*buf){
    case 'n':
        if(n < sizeof(vlong))
            error(Ebadtimectl);
        le2vlong(&delta, p);
        todset(delta, 0, 0);
        break;
    case 'd':
        if(n < sizeof(vlong)+sizeof(long))
            error(Ebadtimectl);
        p = le2vlong(&delta, p);
        le2long(&period, p);
        todset(-1, delta, period);
        break;
    case 'f':
        if(n < sizeof(uvlong))
            error(Ebadtimectl);
        le2vlong(&fasthz, p);
        if(fasthz <= 0)
            error(Ebadtimectl);
        todsetfreq(fasthz);
        break;
    }
    return n;
}
@

<<global uvorder>>=
static uvlong uvorder = 0x0001020304050607ULL;
@


<<function le2vlong>>=
static byte*
le2vlong(vlong *to, byte *f)
{
    byte *t, *o;
    int i;

    t = (byte*)to;
    o = (byte*)&uvorder;
    for(i = 0; i < sizeof(vlong); i++)
        t[o[i]] = f[i];
    return f+sizeof(vlong);
}
@


<<function vlong2le>>=
static byte*
vlong2le(byte *t, vlong from)
{
    byte *f, *o;
    int i;

    f = (byte*)&from;
    o = (byte*)&uvorder;
    for(i = 0; i < sizeof(vlong); i++)
        t[i] = f[o[i]];
    return t+sizeof(vlong);
}
@


<<global order>>=
static long order = 0x00010203;
@


<<function le2long>>=
static byte*
le2long(long *to, byte *f)
{
    byte *t, *o;
    int i;

    t = (byte*)to;
    o = (byte*)&order;
    for(i = 0; i < sizeof(long); i++)
        t[o[i]] = f[i];
    return f+sizeof(long);
}
@


\section{Real time clock, [[/dev/rtc]] (x86)}

% RTC

% needed? bcm/ works with fakertc and even without fakertc

<<struct Rtc(x86)>>=
struct Rtc
{
    int sec;
    int min;
    int hour;
    int mday;
    int mon;
    int year;
};
@


<<global rtcdevtab(x86)>>=
Dev rtcdevtab = {
    .dc       =    'r',
    .name     =    "rtc",
               
    .reset    =    devreset,
    .init     =    rtcinit,
    .shutdown =    devshutdown,
    .attach   =    rtcattach,
    .walk     =    rtcwalk,
    .stat     =    rtcstat,
    .open     =    rtcopen,
    .create   =    devcreate,
    .close    =    rtcclose,
    .read     =    rtcread,
    .bread    =    devbread,
    .write    =    rtcwrite,
    .bwrite   =    devbwrite,
    .remove   =    devremove,
    .wstat    =    devwstat,
};
@

<<constants SEC2XXX(x86)>>=
#define SEC2MIN 60L
#define SEC2HOUR (60L*SEC2MIN)
#define SEC2DAY (24L*SEC2HOUR)
@

<<globals dmsize ldmsize(x86)>>=
/*
 *  days per month plus days/year
 */
static  int dmsize[] =
{
    365, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31
};
static  int ldmsize[] =
{
    366, 31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31
};
@

<<function yrsize(x86)>>=
/*
 *  return the days/month for the given year
 */
static int*
yrsize(int y)
{
    if((y%4) == 0 && ((y%100) != 0 || (y%400) == 0))
        return ldmsize;
    else
        return dmsize;
}
@

<<function rtc2sec(x86)>>=
/*
 *  compute seconds since Jan 1 1970
 */
static ulong
rtc2sec(Rtc *rtc)
{
    ulong secs;
    int i;
    int *d2m;

    secs = 0;

    /*
     *  seconds per year
     */
    for(i = 1970; i < rtc->year; i++){
        d2m = yrsize(i);
        secs += d2m[0] * SEC2DAY;
    }

    /*
     *  seconds per month
     */
    d2m = yrsize(rtc->year);
    for(i = 1; i < rtc->mon; i++)
        secs += d2m[i] * SEC2DAY;

    secs += (rtc->mday-1) * SEC2DAY;
    secs += rtc->hour * SEC2HOUR;
    secs += rtc->min * SEC2MIN;
    secs += rtc->sec;

    return secs;
}
@

<<function sec2rtc(x86)>>=
/*
 *  compute rtc from seconds since Jan 1 1970
 */
static void
sec2rtc(ulong secs, Rtc *rtc)
{
    int d;
    long hms, day;
    int *d2m;

    /*
     * break initial number into days
     */
    hms = secs % SEC2DAY;
    day = secs / SEC2DAY;
    if(hms < 0) {
        hms += SEC2DAY;
        day -= 1;
    }

    /*
     * generate hours:minutes:seconds
     */
    rtc->sec = hms % 60;
    d = hms / 60;
    rtc->min = d % 60;
    d /= 60;
    rtc->hour = d;

    /*
     * year number
     */
    if(day >= 0)
        for(d = 1970; day >= *yrsize(d); d++)
            day -= *yrsize(d);
    else
        for (d = 1970; day < 0; d--)
            day += *yrsize(d-1);
    rtc->year = d;

    /*
     * generate month
     */
    d2m = yrsize(rtc->year);
    for(d = 1; day >= d2m[d]; d++)
        day -= d2m[d];
    rtc->mday = day + 1;
    rtc->mon = d;

    return;
}
@


\section{Watchdog}
% used in raspberry PI
% useful automatic reboot when something get completely stuck?

\chapter{IPC}
\minitoc

% of course can use fs to communicate between process :)
% also when fork child inherit fd and can share stuff there
% also child can communicate to parent fix exit code (if parent calls wait())
%  and this exit code is now even a string! as opposed to unix

% finally debugging is a form of IPC, the debugger communicate/control
% the debuggee process

<<systab ipc syscalls>>=
    [NOTIFY]    sysnotify,
    [NOTED]     sysnoted,

    [PIPE]      syspipe,

    [SEGATTACH] syssegattach,
    [SEGDETACH] syssegdetach,
    [SEGFREE]   syssegfree,
    [SEGFLUSH]  syssegflush,
    [SEGBRK]    syssegbrk,
@ 

<<systab concurrency syscalls>>=
    [RENDEZVOUS]    sysrendezvous,

    [SEMACQUIRE]    syssemacquire,
    [SEMRELEASE]    syssemrelease,
    [TSEMACQUIRE]   systsemacquire,
@ 

\section{Notes (signals)}

<<enum notekind>>=
enum notekind
{
    NUser,        /* note provided externally */
    NExit,        /* deliver note quietly */
    NDebug,       /* print debug message */
};
@ 

% also in libc.h?
<<enum note>>=
enum note {
  NCONT = 0, /* continue after note */
  NDFLT = 1, /* terminate after note */
  NSAVE = 2, /* clear note but hold state */
  NRSTR = 3, /* restore saved state */
};
@ 

<<global noteidalloc>>=
// also used by sysrfork()
Counter noteidalloc;
@ 



<<struct Note>>=
// a kind of unix signal
struct Note
{
    char  msg[ERRMAX];
    // enum<notekind>
    int flag;     /* whether system posted it */
};
@ 


<<[[Proc]] notes fields>>=
Note  note[NNOTE];
short nnote;

int (*notify)(void*, char*);
bool_ushort notified; /* sysnoted is due */

ulong noteid;   /* Equivalent of note group */

bool notepending;  /* note issued but not acted on */

Note  lastnote;

void  *ureg;    /* User registers for notes */
@ 

<<constant NNOTE>>=
    NNOTE = 5,
@

\subsection{[[sysnotify()]] (x86)}

<<syscall notify>>=
// int notify(void (*f)(void*, char*));
long
sysnotify(ulong* arg)
{
    if(arg[0] != 0)
        validaddr(arg[0], sizeof(ulong), false);
    up->notify = (int(*)(void*, char*))(arg[0]);
    return 0;
}
@ 

<<[[syscall()]] call notify()(x86)>>=
    if(scallnr!=RFORK && (up->procctl || up->nnote)){
        arch_splhi();
        notify(ureg);
    }
@

<<function notify(x86)>>=
/*
 *  Call user, if necessary, with note.
 *  Pass user the Ureg struct and the note on his stack.
 */
int
notify(Ureg* ureg)
{
    int l;
    ulong s, sp;
    Note *n;

    if(up->procctl)
        procctl(up); // a bit ugly to group procctl handling and note handling
    if(up->nnote == 0)
        return 0;

    <<[[notify()]] fp adjustments(x86)>>

    s = arch_spllo();
    qlock(&up->debug);
    up->notepending = false;
    n = &up->note[0];
    if(strncmp(n->msg, "sys:", 4) == 0){
        l = strlen(n->msg);
        if(l > ERRMAX-15)   /* " pc=0x12345678\0" */
            l = ERRMAX-15;
        seprint(n->msg+l, &n->msg[sizeof n->msg], " pc=0x%.8lux",
            ureg->pc);
    }

    if(n->flag!=NUser && (up->notified || up->notify==0)){
        if(n->flag == NDebug)
            pprint("suicide: %s\n", n->msg);
        qunlock(&up->debug);
        pexit(n->msg, n->flag!=NDebug);
    }

    if(up->notified){
        qunlock(&up->debug);
        arch_splhi();
        return 0;
    }

    if(!up->notify){
        qunlock(&up->debug);
        pexit(n->msg, n->flag!=NDebug);
    }
    sp = ureg->usp;
    sp -= 256;  /* debugging: preserve context causing problem */
    sp -= sizeof(Ureg);

    if(!okaddr((ulong)up->notify, 1, 0)
    || !okaddr(sp-ERRMAX-4*BY2WD, sizeof(Ureg)+ERRMAX+4*BY2WD, 1)){
        qunlock(&up->debug);
        pprint("suicide: bad address in notify\n");
        pexit("Suicide", false);
    }

    memmove((Ureg*)sp, ureg, sizeof(Ureg));
    *(Ureg**)(sp-BY2WD) = up->ureg; /* word under Ureg is old up->ureg */
    up->ureg = (void*)sp;
    sp -= BY2WD+ERRMAX;
    memmove((char*)sp, up->note[0].msg, ERRMAX);
    sp -= 3*BY2WD;
    *(ulong*)(sp+2*BY2WD) = sp+3*BY2WD;     /* arg 2 is string */
    *(ulong*)(sp+1*BY2WD) = (ulong)up->ureg;    /* arg 1 is ureg* */
    *(ulong*)(sp+0*BY2WD) = 0;          /* arg 0 is pc */
    ureg->usp = sp;
    ureg->pc = (ulong)up->notify;
    up->notified = true;
    up->nnote--;
    memmove(&up->lastnote, &up->note[0], sizeof(Note));
    memmove(&up->note[0], &up->note[1], up->nnote*sizeof(Note));

    qunlock(&up->debug);
    arch_splx(s);
    return 1;
}
@ 
%if(0) print("%s %lud: notify %.8lux %.8lux %.8lux %s\n",
%    up->text, up->pid, ureg->pc, ureg->usp, sp, n->msg);



\subsection{[[sysnoted()]]}

<<syscall noted>>=
// int noted(int v);
long
sysnoted(ulong* arg)
{
    if(arg[0]!=NRSTR && !up->notified)
        error(Egreg);
    return 0;
}
@ 

<<[[syscall()]] call noted()(x86)>>=
    if(scallnr == NOTED)
        noted(ureg, *(ulong*)(sp+BY2WD));
@

<<function noted(x86)>>=
/*
 *   Return user to state before notify()
 */
void
noted(Ureg* ureg, ulong arg0)
{
    Ureg *nureg;
    ulong oureg, sp;

    qlock(&up->debug);
    if(arg0!=NRSTR && !up->notified) {
        qunlock(&up->debug);
        pprint("call to noted() when not notified\n");
        pexit("Suicide", /*freemem*/false);
    }
    up->notified = false;

    nureg = up->ureg;   /* pointer to user returned Ureg struct */

    <<[[noted()]] fp adjustments(x86)>>

    /* sanity clause */
    oureg = (ulong)nureg;
    if(!okaddr((ulong)oureg-BY2WD, BY2WD+sizeof(Ureg), 0)){
        qunlock(&up->debug);
        pprint("bad ureg in noted or call to noted when not notified\n");
        pexit("Suicide", false);
    }

    /*
     * Check the segment selectors are all valid, otherwise
     * a fault will be taken on attempting to return to the
     * user process.
     * Take care with the comparisons as different processor
     * generations push segment descriptors in different ways.
     */
    if((nureg->cs & 0xFFFF) != UESEL || (nureg->ss & 0xFFFF) != UDSEL
      || (nureg->ds & 0xFFFF) != UDSEL || (nureg->es & 0xFFFF) != UDSEL
      || (nureg->fs & 0xFFFF) != UDSEL || (nureg->gs & 0xFFFF) != UDSEL){
        qunlock(&up->debug);
        pprint("bad segment selector in noted\n");
        pexit("Suicide", false);
    }

    /* don't let user change system flags */
    nureg->flags = (ureg->flags & ~0xCD5) | (nureg->flags & 0xCD5);

    memmove(ureg, nureg, sizeof(Ureg));

    switch(arg0){
    case NCONT:
    case NRSTR:
        if(!okaddr(nureg->pc, 1, 0) || !okaddr(nureg->usp, BY2WD, 0)){
            qunlock(&up->debug);
            pprint("suicide: trap in noted\n");
            pexit("Suicide", false);
        }
        up->ureg = (Ureg*)(*(ulong*)(oureg-BY2WD));
        qunlock(&up->debug);
        break;

    case NSAVE:
        if(!okaddr(nureg->pc, BY2WD, 0)
        || !okaddr(nureg->usp, BY2WD, 0)){
            qunlock(&up->debug);
            pprint("suicide: trap in noted\n");
            pexit("Suicide", false);
        }
        qunlock(&up->debug);
        sp = oureg-4*BY2WD-ERRMAX;
        arch_splhi();
        ureg->sp = sp;
        ((ulong*)sp)[1] = oureg;    /* arg 1 0(FP) is ureg* */
        ((ulong*)sp)[0] = 0;        /* arg 0 is pc */
        break;

    default:
        pprint("unknown noted arg 0x%lux\n", arg0);
        up->lastnote.flag = NDebug;
        /* fall through */

    case NDFLT:
        if(up->lastnote.flag == NDebug){
            qunlock(&up->debug);
            pprint("suicide: %s\n", up->lastnote.msg);
        } else
            qunlock(&up->debug);
        pexit(up->lastnote.msg, up->lastnote.flag!=NDebug);
    }
}
@ 
%if(0) print("%s %lud: noted %.8lux %.8lux\n",
%    up->text, up->pid, nureg->pc, nureg->usp);


\subsection{[[postnote()]]}

<<function postnote>>=
/*
 *  if waking a sleeping process, this routine must hold both
 *  p->rlock and r->lock.  However, it can't know them in
 *  the same order as wakeup causing a possible lock ordering
 *  deadlock.  We break the deadlock by giving up the p->rlock
 *  lock if we can't get the r->lock and retrying.
 */
int
proc_postnote(Proc *p, int dolock, char *n, int flag)
{
    int s, ret;
    Rendez *r;
    Proc *d, **l;

    if(dolock)
        qlock(&p->debug);

    if(flag != NUser && (p->notify == 0 || p->notified))
        p->nnote = 0;

    ret = 0;
    if(p->nnote < NNOTE) {
        strcpy(p->note[p->nnote].msg, n);
        p->note[p->nnote++].flag = flag;
        ret = 1;
    }
    p->notepending = true;
    if(dolock)
        qunlock(&p->debug);

    /* this loop is to avoid lock ordering problems. */
    for(;;){
        s = arch_splhi();
        lock(&p->rlock);
        r = p->r;

        /* waiting for a wakeup? */
        if(r == nil)
            break;  /* no */

        /* try for the second lock */
        if(canlock(r)){
            if(p->state != Wakeme || r->p != p)
                panic("postnote: state %d %d %d", r->p != p, p->r != r, p->state);
            p->r = nil;
            r->p = nil;
            ready(p);
            unlock(r);
            break;
        }

        /* give other process time to get out of critical section and try again */
        unlock(&p->rlock);
        arch_splx(s);
        sched();
    }
    unlock(&p->rlock);
    arch_splx(s);

    if(p->state != Rendezvous)
        return ret;

    /* Try and pull out of a rendezvous */
    lock(p->rgrp);
    if(p->state == Rendezvous) {
        p->rendval = ~0;
        l = &REND(p->rgrp, p->rendtag);
        for(d = *l; d; d = d->rendhash) {
            if(d == p) {
                *l = p->rendhash;
                break;
            }
            l = &d->rendhash;
        }
        ready(p);
    }
    unlock(p->rgrp);
    return ret;
}
@ 



\section{Pipes}

\subsection{[[syspipe()]]}

<<syscall pipe>>=
// int pipe(int fd[2]);
long
syspipe(ulong* arg)
{
    int fd[2];
    Chan *c[2];
    Dev *d;
    static char *datastr[] = {"data", "data1"};

    validaddr(arg[0], 2*BY2WD, true);
    arch_validalign(arg[0], sizeof(int));
    d = devtab[devno('|', false)];
    c[0] = namec("#|", Atodir, 0, 0);
    c[1] = nil;
    fd[0] = -1;
    fd[1] = -1;

    if(waserror()){
        cclose(c[0]);
        if(c[1])
            cclose(c[1]);
        nexterror();
    }
    c[1] = cclone(c[0]);
    if(walk(&c[0], datastr+0, 1, 1, nil) < 0)
        error(Egreg);
    if(walk(&c[1], datastr+1, 1, 1, nil) < 0)
        error(Egreg);
    c[0] = d->open(c[0], ORDWR);
    c[1] = d->open(c[1], ORDWR);
    if(newfd2(fd, c) < 0)
        error(Enofd);
    poperror();

    ((long*)arg[0])[0] = fd[0];
    ((long*)arg[0])[1] = fd[1];
    return 0;
}
@

<<function newfd2>>=
int
newfd2(int fd[2], Chan *c[2])
{
    Fgrp *f;

    f = up->fgrp;
    lock(f);
    fd[0] = findfreefd(f, 0);
    if(fd[0] < 0){
        unlockfgrp(f);
        return -1;
    }
    fd[1] = findfreefd(f, fd[0]+1);
    if(fd[1] < 0){
        unlockfgrp(f);
        return -1;
    }
    if(fd[1] > f->maxfd)
        f->maxfd = fd[1];
    f->fd[fd[0]] = c[0];
    f->fd[fd[1]] = c[1];
    unlockfgrp(f);

    return 0;
}
@

<<[[sseek()]] and pipes>>=
if(devtab[c->type]->dc == '|')
    error(Eisstream);
@
% seek is not in devtab?

\subsection{[[/dev/pipe]]}
% have pipe syscall and device, both useful? the syscall
% anyway calls the device, and named pipe
% can be done only via the device

<<struct Pipe>>=
struct Pipe
{
    int ref;
    ulong   path;
    long    perm;
    Queue   *q[2];
    int qref[2];

    // extra
    QLock;
    Pipe    *next;
};
@


<<struct Pipealloc>>=
struct Pipealloc
{
    ulong   path;

    // extra
    Lock;
};
@


<<global pipealloc>>=
struct Pipealloc pipealloc;
@


<<devpipe.c enum Qxxx>>=
enum
{
    Qdir,
    Qdata0,
    Qdata1,
};
@


<<global pipedir>>=
Dirtab pipedir[] =
{
    ".",        {Qdir,0,QTDIR}, 0,      DMDIR|0500,
    "data",     {Qdata0},   0,      0600,
    "data1",    {Qdata1},   0,      0600,
};
@

<<[[Conf]] other fields>>=
ulong pipeqsize;  /* size in bytes of pipe queues */
@ 

<<method pipeinit>>=
static void
pipeinit(void)
{
    if(conf.pipeqsize == 0){
        if(conf.ncpu > 1)
            conf.pipeqsize = 256*1024;
        else
            conf.pipeqsize = 32*1024;
    }
}
@

%TODO: use chanpipe below instead of chan
<<[[Chan]] union other fields>>=
/*Pipe*/void* chanpipe; // for pipes
@

<<method pipeattach>>=
/*
 *  create a pipe, no streams are created until an open
 */
static Chan*
pipeattach(char *spec)
{
    Pipe *p;
    Chan *c;

    c = devattach('|', spec);
    p = malloc(sizeof(Pipe));
    if(p == 0)
        exhausted("memory");
    p->ref = 1;

    p->q[0] = qopen(conf.pipeqsize, 0, 0, 0);
    if(p->q[0] == 0){
        free(p);
        exhausted("memory");
    }
    p->q[1] = qopen(conf.pipeqsize, 0, 0, 0);
    if(p->q[1] == 0){
        free(p->q[0]);
        free(p);
        exhausted("memory");
    }

    lock(&pipealloc);
    p->path = ++pipealloc.path;
    unlock(&pipealloc);
    p->perm = pipedir[Qdata0].perm;

    mkqid(&c->qid, NETQID(2*p->path, Qdir), 0, QTDIR);
    c->aux = p;
    c->dev = 0;
    return c;
}
@


<<function pipegen>>=
static int
pipegen(Chan *c, char*, Dirtab *tab, int ntab, int i, DirEntry *dp)
{
    Qid q;
    int len;
    Pipe *p;

    if(i == DEVDOTDOT){
        devdir(c, c->qid, "#|", 0, eve, DMDIR|0555, dp);
        return 1;
    }
    i++;    /* skip . */
    if(tab==0 || i>=ntab)
        return -1;

    tab += i;
    p = c->aux;
    switch((ulong)tab->qid.path){
    case Qdata0:
        len = qlen(p->q[0]);
        break;
    case Qdata1:
        len = qlen(p->q[1]);
        break;
    default:
        len = tab->length;
        break;
    }
    mkqid(&q, NETQID(NETID(c->qid.path), tab->qid.path), 0, QTFILE);
    devdir(c, q, tab->name, len, eve, p->perm, dp);
    return 1;
}
@


<<method pipewalk>>=
static Walkqid*
pipewalk(Chan *c, Chan *nc, char **name, int nname)
{
    Walkqid *wq;
    Pipe *p;

    wq = devwalk(c, nc, name, nname, pipedir, NPIPEDIR, pipegen);
    if(wq != nil && wq->clone != nil && wq->clone != c){
        p = c->aux;
        qlock(p);
        p->ref++;
        if(c->flag & COPEN){
            print("channel open in pipewalk\n");
            switch(NETTYPE(c->qid.path)){
            case Qdata0:
                p->qref[0]++;
                break;
            case Qdata1:
                p->qref[1]++;
                break;
            }
        }
        qunlock(p);
    }
    return wq;
}
@


<<method pipestat>>=
static int
pipestat(Chan *c, byte *db, int n)
{
    Pipe *p;
    DirEntry dir;

    p = c->aux;

    switch(NETTYPE(c->qid.path)){
    case Qdir:
        devdir(c, c->qid, ".", 0, eve, DMDIR|0555, &dir);
        break;
    case Qdata0:
        devdir(c, c->qid, "data", qlen(p->q[0]), eve, p->perm, &dir);
        break;
    case Qdata1:
        devdir(c, c->qid, "data1", qlen(p->q[1]), eve, p->perm, &dir);
        break;
    default:
        panic("pipestat");
    }
    n = convD2M(&dir, db, n);
    if(n < BIT16SZ)
        error(Eshortstat);
    return n;
}
@


<<method pipewstat>>=
static int
pipewstat(Chan* c, byte* db, int n)
{
    int m;
    DirEntry *dir;
    Pipe *p;

    p = c->aux;
    if(strcmp(up->user, eve) != 0)
        error(Eperm);
    if(NETTYPE(c->qid.path) == Qdir)
        error(Eisdir);

    dir = smalloc(sizeof(DirEntry)+n);
    if(waserror()){
        free(dir);
        nexterror();
    }
    m = convM2D(db, n, &dir[0], (char*)&dir[1]);
    if(m == 0)
        error(Eshortstat);
    if(!emptystr(dir[0].uid))
        error("can't change owner");
    if(dir[0].mode != ~0UL)
        p->perm = dir[0].mode;
    poperror();
    free(dir);
    return m;
}
@



<<method pipeopen>>=
/*
 *  if the stream doesn't exist, create it
 */
static Chan*
pipeopen(Chan *c, int omode)
{
    Pipe *p;

    if(c->qid.type & QTDIR){
        if(omode != OREAD)
            error(Ebadarg);
        c->mode = omode;
        c->flag |= COPEN;
        c->offset = 0;
        return c;
    }

    p = c->aux;
    qlock(p);
    switch(NETTYPE(c->qid.path)){
    case Qdata0:
        p->qref[0]++;
        break;
    case Qdata1:
        p->qref[1]++;
        break;
    }
    qunlock(p);

    c->mode = openmode(omode);
    c->flag |= COPEN;
    c->offset = 0;
    c->iounit = qiomaxatomic;
    return c;
}
@


<<method pipeclose>>=
static void
pipeclose(Chan *c)
{
    Pipe *p;

    p = c->aux;
    qlock(p);

    if(c->flag & COPEN){
        /*
         *  closing either side hangs up the stream
         */
        switch(NETTYPE(c->qid.path)){
        case Qdata0:
            p->qref[0]--;
            if(p->qref[0] == 0){
                qhangup(p->q[1], 0);
                qclose(p->q[0]);
            }
            break;
        case Qdata1:
            p->qref[1]--;
            if(p->qref[1] == 0){
                qhangup(p->q[0], 0);
                qclose(p->q[1]);
            }
            break;
        }
    }


    /*
     *  if both sides are closed, they are reusable
     */
    if(p->qref[0] == 0 && p->qref[1] == 0){
        qreopen(p->q[0]);
        qreopen(p->q[1]);
    }

    /*
     *  free the structure on last close
     */
    p->ref--;
    if(p->ref == 0){
        qunlock(p);
        free(p->q[0]);
        free(p->q[1]);
        free(p);
    } else
        qunlock(p);
}
@


<<method piperead>>=
static long
piperead(Chan *c, void *va, long n, vlong)
{
    Pipe *p;

    p = c->aux;

    switch(NETTYPE(c->qid.path)){
    case Qdir:
        return devdirread(c, va, n, pipedir, NPIPEDIR, pipegen);
    case Qdata0:
        return qread(p->q[0], va, n);
    case Qdata1:
        return qread(p->q[1], va, n);
    default:
        panic("piperead");
    }
    panic("piperead: should not reach this point");
    return -1; // unreachable
}
@


<<method pipebread>>=
static Block*
pipebread(Chan *c, long n, ulong offset)
{
    Pipe *p;

    p = c->aux;

    switch(NETTYPE(c->qid.path)){
    case Qdata0:
        return qbread(p->q[0], n);
    case Qdata1:
        return qbread(p->q[1], n);
    }

    return devbread(c, n, offset);
}
@


<<method pipewrite>>=
/*
 *  a write to a closed pipe causes a note to be sent to
 *  the process.
 */
static long
pipewrite(Chan *c, void *va, long n, vlong)
{
    Pipe *p;

    if(!arch_islo())
        print("pipewrite hi %#p\n", getcallerpc(&c));
    if(waserror()) {
        /* avoid notes when pipe is a mounted queue */
        if((c->flag & CMSG) == 0)
            postnote(up, 1, "sys: write on closed pipe", NUser);
        nexterror();
    }

    p = c->aux;

    switch(NETTYPE(c->qid.path)){
    case Qdata0:
        n = qwrite(p->q[1], va, n);
        break;

    case Qdata1:
        n = qwrite(p->q[0], va, n);
        break;

    default:
        panic("pipewrite");
    }

    poperror();
    return n;
}
@


<<method pipebwrite>>=
static long
pipebwrite(Chan *c, Block *bp, ulong)
{
    long n;
    Pipe *p;

    if(waserror()) {
        /* avoid notes when pipe is a mounted queue */
        if((c->flag & CMSG) == 0)
            postnote(up, 1, "sys: write on closed pipe", NUser);
        nexterror();
    }

    p = c->aux;
    switch(NETTYPE(c->qid.path)){
    case Qdata0:
        n = qbwrite(p->q[1], bp);
        break;

    case Qdata1:
        n = qbwrite(p->q[0], bp);
        break;

    default:
        n = 0;
        panic("pipebwrite");
    }

    poperror();
    return n;
}
@


<<global pipedevtab>>=
Dev pipedevtab = {
    .dc       =    '|',
    .name     =    "pipe",
               
    .reset    =    devreset,
    .init     =    pipeinit,
    .shutdown =    devshutdown,
    .attach   =    pipeattach,
    .walk     =    pipewalk,
    .stat     =    pipestat,
    .open     =    pipeopen,
    .create   =    devcreate,
    .close    =    pipeclose,
    .read     =    piperead,
    .bread    =    pipebread,
    .write    =    pipewrite,
    .bwrite   =    pipebwrite,
    .remove   =    devremove,
    .wstat    =    pipewstat,
};
@


\section{Shared segment and semaphore}
% shared segment? and so semaphore? libc_thread?
% can have semaphore without segments?

\subsection{Segment}

<<enum segtype other flags>>=
    SG_CEXEC  = 0100,   /* Detach at exec */
@
% not used at all in whole plan9, maybe could remove support for it

<<syscall segbrk>>=
// void* segbrk(void *saddr, void *addr);
long
syssegbrk(ulong* arg)
{
    int i;
    ulong addr;
    Segment *s;

    addr = arg[0];
    for(i = 0; i < NSEG; i++) {
        s = up->seg[i];
        if(s == nil || addr < s->base || addr >= s->top)
            continue;
        switch(s->type&SG_TYPE) {
        case SG_TEXT:
        case SG_DATA:
        case SG_STACK:
            error(Ebadarg);
        default:
            return ibrk(arg[1], i);
        }
    }

    error(Ebadarg);
    panic("syssegbrk: should not reach this point");
    return -1; // unreachable
}
@ 

% put here physseg thing?

<<syscall segattach>>=
// void* segattach(int attr, char *class, void *va, ulong len);
long
syssegattach(ulong* arg)
{
    return segattach(up, arg[0], (char*)arg[1], arg[2], arg[3]);
}
@ 

<<hook _globalsegattach>>=
Segment* (*_globalsegattach)(Proc*, char*);
@

<<function segattach>>=
ulong
segattach(Proc *p, ulong attr, char *name, ulong va, ulong len)
{
    int sno;
    Segment *s, *os;
    Physseg *ps;

    if(va != 0 && va >= USTKTOP)
        error(Ebadarg);

    validaddr((ulong)name, 1, false);
    vmemchr(name, 0, ~0);

    for(sno = 0; sno < NSEG; sno++)
        if(p->seg[sno] == nil && sno != ESEG)
            break;

    if(sno == NSEG)
        error(Enovmem);

    /*
     *  first look for a global segment with the
     *  same name
     */
    if(_globalsegattach != nil){
        s = (*_globalsegattach)(p, name);
        if(s != nil){
            p->seg[sno] = s;
            return s->base;
        }
    }

    len = PGROUND(len);
    if(len == 0)
        error(Ebadarg);

    /*
     * Find a hole in the address space.
     * Starting at the lowest possible stack address - len,
     * check for an overlapping segment, and repeat at the
     * base of that segment - len until either a hole is found
     * or the address space is exhausted.  Ensure that we don't
     * map the zero page.
     */
    if(va == 0) {
        for (os = p->seg[SSEG]; os != nil; os = isoverlap(p, va, len)) {
            va = os->base;
            if(len >= va)
                error(Enovmem);
            va -= len;
        }
        va &= ~(BY2PG-1);
    } else {
        va &= ~(BY2PG-1);
        if(va == 0 || va >= USTKTOP)
            error(Ebadarg);
    }

    if(isoverlap(p, va, len) != nil)
        error(Esoverlap);


    for(ps = physseg; ps->name; ps++)
        if(strcmp(name, ps->name) == 0)
            goto found;

    error(Ebadarg);
found:
    if(len > ps->size)
        error(Enovmem);

    attr &= ~SG_TYPE;       /* Turn off what is not allowed */
    attr |= ps->attr;       /* Copy in defaults */

    s = newseg(attr, va, len/BY2PG);
    s->pseg = ps;
    p->seg[sno] = s;

    return va;
}
@

<<function isoverlap>>=
Segment*
isoverlap(Proc *p, ulong va, int len)
{
    int i;
    Segment *ns;
    ulong newtop;

    newtop = va+len;
    for(i = 0; i < NSEG; i++) {
        ns = p->seg[i];
        if(ns == 0)
            continue;
        if((newtop > ns->base && newtop <= ns->top) ||
           (va >= ns->base && va < ns->top))
            return ns;
    }
    return nil;
}
@


<<syscall segdetach>>=
// int segdetach(void *addr);
long
syssegdetach(ulong* arg)
{
    int i;
    ulong addr;
    Segment *s;

    qlock(&up->seglock);
    if(waserror()){
        qunlock(&up->seglock);
        nexterror();
    }

    s = 0;
    addr = arg[0];
    for(i = 0; i < NSEG; i++)
        if(s = up->seg[i]) {
            qlock(&s->lk);
            if((addr >= s->base && addr < s->top) ||
               (s->top == s->base && addr == s->base))
                goto found;
            qunlock(&s->lk);
        }

    error(Ebadarg);

found:
    /*
     * Check we are not detaching the initial stack segment.
     */
    if(s == up->seg[SSEG]){
        qunlock(&s->lk);
        error(Ebadarg);
    }
    up->seg[i] = 0;
    qunlock(&s->lk);
    putseg(s);
    qunlock(&up->seglock);
    poperror();

    /* Ensure we flush any entries from the lost segment */
    arch_flushmmu();
    return 0;
}
@ 


<<syscall segfree>>=
// int segfree(void *va, ulong len);
long
syssegfree(ulong* arg)
{
    Segment *s;
    ulong from, to;

    from = arg[0];
    s = seg(up, from, 1);
    if(s == nil)
        error(Ebadarg);
    to = (from + arg[1]) & ~(BY2PG-1);
    from = PGROUND(from);

    if(to > s->top) {
        qunlock(&s->lk);
        error(Ebadarg);
    }

    mfreeseg(s, from, (to - from) / BY2PG);
    qunlock(&s->lk);
    arch_flushmmu();

    return 0;
}
@ 


% seems really expensive
<<function procflushseg>>=
/*
 *  wait till all processes have flushed their mmu
 *  state about segment s
 */
void
procflushseg(Segment *s)
{
    int i, ns, nm;
    bool wait;
    Proc *p;

    /*
     *  tell all processes with this
     *  segment to flush their mmu's
     */
    wait = false;
    for(i=0; i<conf.nproc; i++) {
        p = &procalloc.arena[i];
        if(p->state == Dead)
            continue;
        for(ns = 0; ns < NSEG; ns++)
            if(p->seg[ns] == s){
                p->newtlb = true;
                for(nm = 0; nm < conf.ncpu; nm++){
                    if(CPUS(nm)->proc == p){
                        CPUS(nm)->flushmmu = true;
                        wait = true;
                    }
                }
                break;
            }
    }
    if(!wait)
        return;

    /*
     *  wait for all processors to take a clock interrupt
     *  and flush their mmu's
     */
    for(nm = 0; nm < conf.ncpu; nm++)
        if(CPUS(nm) != cpu)
            while(CPUS(nm)->flushmmu)
                sched();
}
@ 
% but process could be allocated to different proc, so could loop forever
% or miss? when reallocated probably the tlb is flush anyway so safe?




<<syscall segflush>>=
long
syssegflush(ulong* arg)
{
    Segment *s;
    ulong addr, l;
    Pagetable *pt;
    int chunk, ps, pe, len;

    addr = arg[0];
    len = arg[1];

    while(len > 0) {
        s = seg(up, addr, 1);
        if(s == 0)
            error(Ebadarg);

    s->flushme = true;
    more:
        l = len;
        if(addr+l > s->top)
            l = s->top - addr;

        ps = addr-s->base;
        pt = s->pagedir[ps/PAGETABMAPMEM];
        ps &= PAGETABMAPMEM-1;
        pe = PAGETABMAPMEM;
        if(pe-ps > l){
            pe = ps + l;
            pe = ROUND(pe, BY2PG);
        }
        if(pe == ps) {
            qunlock(&s->lk);
            error(Ebadarg);
        }

        // when have cachectl
        if(pt)
            ptflush(pt, ps/BY2PG, pe/BY2PG);

        chunk = pe-ps;
        len -= chunk;
        addr += chunk;

        if(len > 0 && addr < s->top)
            goto more;

        qunlock(&s->lk);
    }
    arch_flushmmu();
    return 0;
}
@


\subsection{Semaphore}

% and show code of libcore/libc/port/lock.c! that uses that

<<struct Sema>>=
// user level semaphores, used to implement user-level lock, 
// see libc/port/lock.c
struct Sema
{
    long  *addr; // value stored in user space!
    bool waiting;
  
    //list<Sema> of Segment.sema
    Sema  *next;
    Sema  *prev;

    Rendez;
};
@ 

<<[[Segment]] other fields>>=
Sema sema;
@

<<[[newseg()]] sema initialization>>=
    // no list, just one sema
    s->sema.prev = &s->sema;
    s->sema.next = &s->sema;
@


\subsubsection{[[cmpswap()]] (x86)}

<<function cmpswap and default implementation(x86)>>=
/*
 * 386 has no compare-and-swap instruction.
 * Run it with interrupts turned off instead.
 */
// used to be static, but now shared between arch.c and devarch.c
int
cmpswap386(long *addr, long old, long new)
{
    int r, s;

    s = arch_splhi();
    if(r = (*addr == old))
        *addr = new;
    arch_splx(s);
    return r;
}

int (*arch_cmpswap)(long*, long, long) = cmpswap386;
@


<<function semqueue>>=
/* Add semaphore p with addr a to list in seg. */
static void
semqueue(Segment *s, long *a, Sema *p)
{
    memset(p, 0, sizeof *p);
    p->addr = a;
    lock(&s->sema); /* uses s->sema.Rendez.Lock, but no one else is */
    p->next = &s->sema;
    p->prev = s->sema.prev;
    p->next->prev = p;
    p->prev->next = p;
    unlock(&s->sema);
}
@ 


<<function semdequeue>>=
/* Remove semaphore p from list in seg. */
static void
semdequeue(Segment *s, Sema *p)
{
    lock(&s->sema);
    p->next->prev = p->prev;
    p->prev->next = p->next;
    unlock(&s->sema);
}
@ 


<<function semwakeup>>=
/* Wake up n waiters with addr a on list in seg. */
static void
semwakeup(Segment *s, long *a, long n)
{
    Sema *p;
    
    lock(&s->sema);
    for(p=s->sema.next; p!=&s->sema && n>0; p=p->next){
        if(p->addr == a && p->waiting){
            p->waiting = false;
            arch_coherence();
            wakeup(p);
            n--;
        }
    }
    unlock(&s->sema);
}
@ 


<<function semrelease>>=
/* Add delta to semaphore and wake up waiters as appropriate. */
static long
semrelease(Segment *s, long *addr, long delta)
{
    long value;

    do
        value = *addr;
    while(!arch_cmpswap(addr, value, value+delta));
    semwakeup(s, addr, delta);
    return value+delta;
}
@ 


<<function canacquire>>=
/* Try to acquire semaphore using compare-and-swap */
static bool
canacquire(long *addr)
{
    long value;
    
    while((value=*addr) > 0)
        if(arch_cmpswap(addr, value, value-1))
            return true;
    return false;
}       
@ 


<<function semawoke>>=
/* Should we wake up? */
static bool
semawoke(void *p)
{
    arch_coherence();
    return !((Sema*)p)->waiting;
}
@ 


<<function semacquire>>=
/* Acquire semaphore (subtract 1). */
static bool
semacquire(Segment *s, long *addr, bool block)
{
    int acquired;
    Sema phore;

    if(canacquire(addr))
        return true;
    if(!block)
        return false;

    acquired = false;
    semqueue(s, addr, &phore);
    for(;;){
        phore.waiting = true;
        arch_coherence();
        if(canacquire(addr)){
            acquired = true;
            break;
        }
        if(waserror())
            break;
        sleep(&phore, semawoke, &phore);
        poperror();
    }
    semdequeue(s, &phore);
    arch_coherence();    /* not strictly necessary due to lock in semdequeue */
    if(!phore.waiting)
        semwakeup(s, addr, 1);
    if(!acquired)
        nexterror();
    return false;
}
@ 


<<function tsemacquire>>=
/* Acquire semaphore or time-out */
static bool
tsemacquire(Segment *s, long *addr, ulong ms)
{
    int acquired, timedout;
    ulong t, elms;
    Sema phore;

    if(canacquire(addr))
        return true;
    if(ms == 0)
        return false;
    acquired = timedout = false;
    semqueue(s, addr, &phore);
    for(;;){
        phore.waiting = true;
        arch_coherence();
        if(canacquire(addr)){
            acquired = true;
            break;
        }
        if(waserror())
            break;
        t = cpu->ticks;
        tsleep(&phore, semawoke, &phore, ms);
        elms = TK2MS(cpu->ticks - t);
        poperror();
        if(elms >= ms){
            timedout = true;
            break;
        }
        ms -= elms;
    }
    semdequeue(s, &phore);
    arch_coherence();    /* not strictly necessary due to lock in semdequeue */
    if(!phore.waiting)
        semwakeup(s, addr, 1);
    if(timedout)
        return false;
    if(!acquired)
        nexterror();
    return false;
}
@ 


<<syscall semacquire>>=
// int semacquire(long *addr, int block);
long
syssemacquire(ulong* arg)
{
    int block;
    long *addr;
    Segment *s;

    validaddr(arg[0], sizeof(long), true);
    arch_validalign(arg[0], sizeof(long));
    addr = (long*)arg[0];
    block = arg[1];
    
    if((s = seg(up, (ulong)addr, 0)) == nil)
        error(Ebadarg);
    if(*addr < 0)
        error(Ebadarg);
    return semacquire(s, addr, block);
}
@ 


<<syscall tsemacquire>>=
// int tsemacquire(long *addr, ulong ms);
long
systsemacquire(ulong* arg)
{
    long *addr;
    ulong ms;
    Segment *s;

    validaddr(arg[0], sizeof(long), true);
    arch_validalign(arg[0], sizeof(long));
    addr = (long*)arg[0];
    ms = arg[1];

    if((s = seg(up, (ulong)addr, 0)) == nil)
        error(Ebadarg);
    if(*addr < 0)
        error(Ebadarg);
    return tsemacquire(s, addr, ms);
}
@ 


<<syscall semrelease>>=
// long semrelease(long *addr, long count);
long
syssemrelease(ulong* arg)
{
    long *addr, delta;
    Segment *s;

    validaddr(arg[0], sizeof(long), true);
    arch_validalign(arg[0], sizeof(long));
    addr = (long*)arg[0];
    delta = arg[1];

    if((s = seg(up, (ulong)addr, 0)) == nil)
        error(Ebadarg);
    /* delta == 0 is a no-op, not a release */
    if(delta < 0 || *addr < 0)
        error(Ebadarg);
    return semrelease(s, addr, delta);
}
@ 


\section{[[sysrendezvous()]]}

% it's more for synchro than for IPC but they
% actually exchange a value there!

<<function REND>>=
enum
{
    RENDLOG = 5,
    RENDHASH =  1<<RENDLOG, /* Hash to lookup rendezvous tags */
};
#define REND(p,s) ((p)->rendhash[(s)&((1<<RENDLOG)-1)])
@

% >> >>

<<struct Rgrp>>=
struct Rgrp
{
    // hash<??, list<ref<Proc>>>
    Proc  *rendhash[RENDHASH];  /* Rendezvous tag hash */
  
    // extra
    Ref;        /* the Ref's lock is also the Rgrp's lock */
};
@ 

% could be in other fields honestly, just like Egrp fields
<<[[Proc]] synchronization fields>>=
Rgrp  *rgrp;    /* Rendez group */

uintptr rendtag;  /* Tag for rendezvous */
uintptr rendval;  /* Value for rendezvous */
//??
Proc  *rendhash;  /* Hash list for tag values */
@


<<constructor newrgrp>>=
Rgrp*
newrgrp(void)
{
    Rgrp *r;

    r = smalloc(sizeof(Rgrp));
    r->ref = 1;
    return r;
}
@ 

<<destructor closergrp>>=
void
closergrp(Rgrp *r)
{
    if(decref(r) == 0)
        free(r);
}
@ 


<<enum procstate cases>>=
Rendezvous,
@

<<syscall rendezvous>>=
// void* rendezvous(void* tag, void* value);
long
sysrendezvous(ulong* arg)
{
    uintptr tag, val;
    Proc *p, **l;

    tag = arg[0];
    l = &REND(up->rgrp, tag);
    up->rendval = ~(uintptr)0;

    lock(up->rgrp);
    for(p = *l; p; p = p->rendhash) {
        if(p->rendtag == tag) {
            *l = p->rendhash;
            val = p->rendval;
            p->rendval = arg[1];

            while(p->cpu != 0) // ????
                ;

            ready(p);
            unlock(up->rgrp);
            return val;
        }
        l = &p->rendhash;
    }

    /* Going to sleep here */
    up->rendtag = tag;
    up->rendval = arg[1];
    up->rendhash = *l;
    *l = up;
    up->state = Rendezvous;
    unlock(up->rgrp);

    sched();

    return up->rendval;
}
@ 



\section{Network}
% and 9P

\chapter{Debugging Support}
%\section{Debugging user processes}

% Should cooperate with Debugger.nw at some point

% there are 2 processes involved: the debuggee/debugged, and the debugger.
% In the following, could call slave and master?

% If want to implement a debugger or strace, what do you need?
% Need a way to control and inspect another process. First for
% the control you need a way to stop him (if it does not stop by himself
% because of a suicide error in which case have core dumps(broken process))
% For instance before it gets to his second syscall you got a chance
% to print the trace of the first syscall. 


<<function debugbpt(x86)>>=
static void
debugbpt(Ureg* ureg, void*)
{
    char buf[ERRMAX];

    if(up == nil)
        panic("kernel bpt");
    /* restore pc to instruction that caused the trap */
    ureg->pc--;
    snprint(buf, sizeof buf, "sys: breakpoint");
    postnote(up, 1, buf, NDebug);
}
@ 


\section{XTODO (x86)}

<<[[Proc]] debugger fields>>=
void  *dbgreg;  /* User registers for devproc */
@
% also saved register in syscalls copied when forking

% old: int scallnr;  /* sys call number - known by db */
% put back? db will still work?

%TODO: Qreg section of /dev/proc
<<function setregisters(x86)>>=
/* This routine must save the values of registers the user is not permitted
 * to write from devproc and then restore the saved values before returning.
 */
void
arch_setregisters(Ureg* ureg, char* pureg, char* uva, int n)
{
    ulong cs, ds, es, flags, fs, gs, ss;

    ss = ureg->ss;
    flags = ureg->flags;
    cs = ureg->cs;
    ds = ureg->ds;
    es = ureg->es;
    fs = ureg->fs;
    gs = ureg->gs;
    memmove(pureg, uva, n);
    ureg->gs = gs;
    ureg->fs = fs;
    ureg->es = es;
    ureg->ds = ds;
    ureg->cs = cs;
    ureg->flags = (ureg->flags & 0x00FF) | (flags & 0xFF00);
    ureg->ss = ss;
}
@ 


\section{Core dumps and broken processes}
% When get a suicide, or a signal with NDEBUG, then put in a broken state.
% Also when have faulterror in pio().
% kinda of core dumps except don't pollute disk with it and keep everything
% intact for post mortem analysis.

% can then do 'db <pid>' and start debug!

<<enum procstate cases>>=
Broken,
@

<<struct Broken>>=
/*
 * weird thing: keep at most NBROKEN around
 */
#define NBROKEN 4
struct Broken
{
    // array<ref<Proc>>
    Proc    *p[NBROKEN];
    // number of entries used in p
    int n;

    // extra
    QLock;
};
@ 

<<global broken>>=
struct Broken broken;
@ 

% when call via pexit(exitstr, freemem=false)
<<function addbroken>>=
void
addbroken(Proc *p)
{
    qlock(&broken);
    if(broken.n == NBROKEN) {
        ready(broken.p[0]);
        memmove(&broken.p[0], &broken.p[1], sizeof(Proc*)*(NBROKEN-1));
        --broken.n;
    }
    broken.p[broken.n++] = p;
    qunlock(&broken);

    edfstop(up);
    p->state = Broken;
    p->psstate = nil;
    sched();
}
@ 


% usually unbreak will actually resume to pexit() ands and really finish the
% process
<<function unbreak>>=
void
unbreak(Proc *p)
{
    int b;

    qlock(&broken);
    for(b=0; b < broken.n; b++)
        if(broken.p[b] == p) {
            broken.n--;
            memmove(&broken.p[b], &broken.p[b+1],
                    sizeof(Proc*)*(NBROKEN-(b+1)));
            ready(p);
            break;
        }
    qunlock(&broken);
}
@ 

% call by the pager when we really really need memory
<<function freebroken>>=
int
freebroken(void)
{
    int i, n;

    qlock(&broken);
    n = broken.n;
    for(i=0; i<n; i++) {
        ready(broken.p[i]);
        broken.p[i] = nil;
    }
    broken.n = 0;
    qunlock(&broken);
    return n;
}
@ 

<<[[procctlreq()]] CMkill case, Broken case>>=
        case Broken:
            // will resume the broken process to finally die and free its mem
            unbreak(p); 
            break;
@


% http://backtrace.io/blog/blog/2015/10/03/whats-a-coredump/

\section{Stopping a process, [[/proc/x/ctl]]}

% multi usage: strace, debugger

<<enum procstate cases>>=
Stopped,
@
% Who can set this state? only when do procttl() where have a Proc_stopme.
% So who can set Proc_stopme for the procctl?


<<enum procctl>>=
enum procctl
{
    Proc_nothing = 0,
    Proc_stopme,
    <<enum procctl cases>>
};
@ 


<<[[Proc]] debugger fields>>=
// enum<procctl>
int procctl;  /* Control for /proc debugging */
@
% who can set to Proc_stopme? 
%  - when have up->hang (get stopped before anything run)
%  - when wrote stop to its ctl file (will be seen at next trap or syscall,
%    similar to notifications)
%  - when have Proc_tracesyscall
%    then at the entry the syscall sets the process to Stopme,
%    but actually Proc_tracesyscall needed a stopped process to begin with



<<function procctl>>=
/*
 *  called arch_splhi() by notify().  See comment in notify for the
 *  reasoning.
 */
void
procctl(Proc *p)
{
    char *oldstate;
    ulong s;

    switch(p->procctl) {
    <<[[procctl()]] Proc_traceme case (and fallthrough [[Proc_stopme]])>>
    case Proc_stopme:
        p->procctl = Proc_nothing;
        oldstate = p->psstate;
        p->psstate = "Stopped";
        s = arch_spllo();
        <<[[procctl()]] wakeup waiting debugger>>
        arch_splhi();
        p->state = Stopped;
        sched();
        // here when something (debugger, strace, user) ready(p) back
        p->psstate = oldstate;
        arch_splx(s);
        return;
    <<[[procctl()]] Proc_exitbig case>>
    <<[[procctl()]] Proc_exitme case>>
    }
}
@ 
% why pass p? it's always called via procctl(up), so why not using
% up directly? in the end we call sched()
% why set p->state = Stopped inside arch_splhi(), would make more sense
% actually to set it before wakeing up the debugger that is sleeping
% on the condition that the process was stopped!



% so how a process can cause procctl() for another process to
% be executed? can't just do  procctl(other_process)? sched()
% only sched up.
% but this other process is executing ... maybe at next trap
% it can look? Yes, notification mechanism


<<[[procctlreq()]] CMstop case>>=
    case CMstop:
        procstopwait(p, Proc_stopme);
        break;
@

<<[[procctlreq()]] CMstart case>>=
    case CMstart:
        if(p->state != Stopped)
            error(Ebadctl);
        ready(p);
        break;
@
% hmm but does not set to Proc_nothing?


% debug also (ab?)used in pexit when freeing memory
<<[[Proc]] debugger fields>>=
Proc  *pdbg;    /* the debugging process */
@

<<[[Proc]] debugger fields>>=
QLock debug;    /* to access debugging elements */ // used for many things
@
% used by strace, but also db, and also for notes, all related to
% one process communicating/controlling another process


<<function procstopwait>>=
// assumes p->debug is held
void
procstopwait(Proc *p, int ctl)
{
    int pid;

    if(p->pdbg)
        error(Einuse);
    if(procstopped(p) || p->state == Broken)
        return;

    if(ctl != Proc_nothing)
        p->procctl = ctl;

    p->pdbg = up;
    pid = p->pid;

    qunlock(&p->debug);
    up->psstate = "Stopwait";
    if(waserror()) {
        p->pdbg = nil;
        qlock(&p->debug);
        nexterror();
    }

    sleep(&up->sleepr, procstopped, p);

    poperror();
    qlock(&p->debug);
    if(p->pid != pid) // p was reallocated to a new process
        error(Eprocdied);
}
@

<<function procstopped>>=
bool
procstopped(void *a)
{
    Proc *p = a;
    return p->state == Stopped;
}
@

% so now we know how to stop another (your child or via /proc/x/ctl stop), but
% how tracer can wait? can't just call await(), we don't wait
% for the child to die...


<<[[procctl()]] wakeup waiting debugger>>=
        /* free a waiting debugger */
        qlock(&p->debug);
        if(p->pdbg) {
            wakeup(&p->pdbg->sleepr);
            p->pdbg = nil;
        }
        qunlock(&p->debug);
@




% overview steps on 'strace -c ls' or 'db ls':
% - strace: fork (to later exec ls)
% - child: before exec(), will 'echo hang > /proc/child/ctl'
%   (exec will use this info)
% - child: exec ls, because of hang will get his procctl to Proc_stopme,
%   which later when return from sysexec will get back to syscall() which
%   check if procctl, call notify() which then call procctl() which
%   will effectively stop ls!


<<[[Proc]] debugger fields>>=
bool hang;   /* hang at next exec for debug */
@

<<[[procctlreq()]] CMhang case>>=
    case CMhang:
        p->hang = true;
        break;
@
<<[[procctlreq()]] CMnohang case>>=
    case CMnohang:
        p->hang = false;
        break;
@


<<[[sysrfork()]] inherit hang>>=
    p->hang = up->hang;
@
% so strace can trace child of process! actually create one thread
% per child, see strace.c! but will it trace the syscall between
% fork and exec? yes because up->procctl get inherited!

<<[[sysexec()]] if hang>>=
    if(up->hang)
        up->procctl = Proc_stopme;
@
% why not do procctl(up) here? when the process will stop? because
% at return of sysexec there will be a call to notify and procctl(up),
% but looks a bit dirty, why they abused notify for that?
% because for the debugger they need more than just procctl? they need
% notes?

<<[[procctlreq()]] CMwaitstop case>>=
    case CMwaitstop:
        procstopwait(p, Proc_nothing);
        break;
@
% used by strace actually ... because did fork, but
% need to wait that it is actually created and scheduled
% to execute the exec and so on! it's not stopped yet!
% not that this one does not check for Stopped. It just sleep
% until reach the state Stopped (that we know it should eventually
% reach) 



\section{Inspecting process memory, [[/proc/x/mem]]}
% inspect and modify!

<<[[procread()]] cases>>=
case Qmem:
    if(offset < KZERO)
        return procctlmemio(p, offset, n, va, true);

    if(!iseve())
        error(Eperm);

    // why allowing read access to kernel code or kernel memory? 
    // who is using that?

    /* validate kernel addresses */
    if(offset < (kern_addr)end) {
        if(offset+n > (kern_addr)end)
            n = (kern_addr)end - offset;
        memmove(a, (char*)offset, n);
        return n;
    }
    for(i=0; i<nelem(conf.mem); i++){
        cm = &conf.mem[i];
        /* klimit-1 because klimit might be zero! */
        if(cm->kbase <= offset && offset <= cm->klimit-1){
            if(offset+n >= cm->klimit-1)
                n = cm->klimit - offset;
            memmove(a, (char*)offset, n);
            return n;
        }
    }
    error(Ebadarg);
@

<<[[xinit()]] nkpages kernel memory in m>>=
m->kbase = (ulong)KADDR(m->base);
m->klimit = (ulong)KADDR(m->base+nkpages*BY2PG);
@

<<[[Confmem]] other fields>>=
kern_addr kbase; // KADDR(Confmem.base)
kern_addr klimit; // KADDR(base+ x*BY2PG) where x <= Confmem.npage
@
% mostly used for /proc/#/mem, could probably be removed because
% I'm not sure why we want processes to read kernel memory



<<[[procwrite()]] cases>>=
case Qmem:
    if(p->state != Stopped)
        error(Ebadctl);

    n = procctlmemio(p, offset, n, va, false);
    break;
@

<<[[Segment]] other fields>>=
ushort  steal;    /* Page stealer lock */
@

<<function procctlmemio>>=
int
procctlmemio(Proc *p, ulong offset, int n, virt_addr3 va, bool read)
{
    Arch_KMap *k;
    Pagetable *pt;
    Page *pg;
    Segment *s;
    ulong soff, l;
    char *a = va, *b;

    for(;;) {
        s = seg(p, offset, 1);
        if(s == nil)
            error(Ebadarg);

        if(offset+n >= s->top)
            n = s->top-offset;

        if(!read && (s->type&SG_TYPE) == SG_TEXT)
            s = text2data(p, s);

        s->steal++;
        soff = offset-s->base;
        if(waserror()) {
            s->steal--;
            nexterror();
        }
        if(fixfault(s, offset, read, /*putmmu*/false) == 0)
            break;
        poperror();
        s->steal--;
    }
    poperror();
    pt = s->pagedir[soff/PAGETABMAPMEM];
    if(pt == nil)
        panic("procctlmemio");
    pg = pt->pagetab[(soff&(PAGETABMAPMEM-1))/BY2PG];
    if(pagedout(pg))
        panic("procctlmemio1");

    l = BY2PG - (offset&(BY2PG-1));
    if(n > l)
        n = l;

    k = arch_kmap(pg);
    if(waserror()) {
        s->steal--;
        arch_kunmap(k);
        nexterror();
    }
    b = (char*)VA(k);
    b += offset&(BY2PG-1);
    if(read == 1)
        memmove(a, b, n);   /* This can fault */
    else
        memmove(b, a, n);
    arch_kunmap(k);
    poperror();

 /* Ensure the process sees text page changes */
 if(s->flushme)
  memset(pg->cachectl, PG_TXTFLUSH, sizeof(pg->cachectl));

    s->steal--;

    if(read == 0)
        p->newtlb = false;

    return n;
}
@

% there is also data2txt
<<function text2data>>=
Segment*
text2data(Proc *p, Segment *s)
{
    int i;
    Segment *ps;

    ps = newseg(SG_DATA, s->base, s->size);
    ps->image = s->image;
    incref(ps->image);
    ps->fstart = s->fstart;
    ps->flen = s->flen;
    ps->flushme = true;

    qlock(&p->seglock);
    for(i = 0; i < NSEG; i++)
        if(p->seg[i] == s)
            break;
    if(i == NSEG)
        panic("segment gone");

    qunlock(&s->lk);
    putseg(s);
    qlock(&ps->lk);
    p->seg[i] = ps;
    qunlock(&p->seglock);

    return ps;
}
@



\section{[[/bin/strace]]}
% was actually called ratrace, but prefer strace

% overview steps on 'strace ls':
% - strace: echo 'startsyscall' > /proc/child/ctl
%   which should ready the child (ls) process and write Proc_tracesyscall
%   to procctl of child! (which was stopped so no race).
%   it will also trigger a sleep for strace until the other proc get
%   stopped again via procstopwait()

% loop:
% - ls could continue, and at first syscall entry will stop again
%   and wakeup tracer
% - strace: can read /proc/child/syscall content
% - strace: write back 'startsyscall' to /proc/child/ctl (and sleep)
% - ls continue and do actual syscall, and stop again
% - strace: can read /proc/child/syscall of return value of syscall
% - strace: write back 'startsyscall' to /proc/child/ctl (which will
%   make strace sleep at the same time)

% show sequence diagram? cos complex.
% why abuse notify()?

% alternative approach? 

<<enum procctl cases>>=
    Proc_tracesyscall,
@
% but who can set the procctl to Proc_tracesyscall?

% note that 'up' here is the process of the tracer! he is the one
% writing to /proc/x/ctl 
<<[[procctlreq()]] CMstartsyscall case>>=
    case CMstartsyscall:
        if(p->state != Stopped)
            error(Ebadctl);
        p->procctl = Proc_tracesyscall;
        ready(p);
        procstopwait(p, Proc_tracesyscall); // will sleep
        break;
@
% but how x was stopped in the first place? get hang to true
% but then it just leads to Proc_stopme, there was no call to procctl(up)
% in sysexec, so who stopped it? notify() ... call procctl(up)




<<[[syscall()]] Proc_tracesyscall if, syscall entry(x86)>>=
    if(up->procctl == Proc_tracesyscall){
        /*
         * Redundant validaddr.  Do we care?
         * Tracing syscalls is not exactly a fast path...
         * Beware, validaddr currently does a pexit rather
         * than an error if there's a problem; that might
         * change in the future.
         */
        if(sp < (USTKTOP-BY2PG) || sp > (USTKTOP-sizeof(Sargs)-BY2WD))
            validaddr(sp, sizeof(Sargs)+BY2WD, false);

        syscallfmt(scallnr, ureg->pc, (va_list)(sp+BY2WD));
        up->procctl = Proc_stopme;
        // this will call sched() and wakeup the tracer process
        procctl(up); 
        // back here when the tracer process readied us back and
        // should have set procctl back to Proc_tracesyscall
        if(up->syscalltrace)
            free(up->syscalltrace);
        up->syscalltrace = nil;
        startns = todget(nil);
    }
@

<<[[syscall()]] Proc_tracesyscall if, syscall exit(x86)>>=
    if(up->procctl == Proc_tracesyscall){
        stopns = todget(nil);
        up->procctl = Proc_stopme;
        sysretfmt(scallnr, (va_list)(sp+BY2WD), ret, startns, stopns);
        s = arch_splhi();
        procctl(up); // again, will call sched() and wakeup tracer process
        arch_splx(s);
        if(up->syscalltrace)
            free(up->syscalltrace);
        up->syscalltrace = nil;
    }
@
% why protect procctl(up) with arch_splhi here and not before?
% both the entry and exit are not perfectly symetric :( TOFIX?

<<[[sysrfork()]] inherit Proc_tracesyscall>>=
    if(up && up->procctl == Proc_tracesyscall)
        p->procctl = Proc_tracesyscall;
@
% used to be in newproc, but I mved it in sysrfork? it was the only thing
% in newproc() that propagate info from up; was not very consistent.


% communicate info via syscalltrace! accessible at /proc/x/syscall
% the 'inspect' mechanism needed
<<[[Proc]] debugger fields>>=
char  *syscalltrace;  /* syscall trace */
@


% /proc/x/syscall
<<[[procread()]] cases>>=
case Qsyscall:
    if(!p->syscalltrace)
        return 0;
    n = readstr(offset, a, n, p->syscalltrace);
    return n;
@









<<function syscallfmt>>=
void
syscallfmt(int syscallno, ulong pc, va_list list)
{
    long l;
    Fmt fmt;
    void *v;
    vlong vl;
    uintptr p;
    int i[2], len;
    char *a, **argv;

    fmtstrinit(&fmt);
    fmtprint(&fmt, "%uld %s ", up->pid, up->text);

    if(syscallno > nsyscall)
        fmtprint(&fmt, " %d ", syscallno);
    else
        fmtprint(&fmt, "%s ", sysctab[syscallno]?
            sysctab[syscallno]: "huh?");

    fmtprint(&fmt, "%ulx ", pc);
    if(up->syscalltrace != nil)
        free(up->syscalltrace);

    switch(syscallno){
    case NOP:
        p = va_arg(list, uintptr);
        fmtprint(&fmt, "%#p", p);
        break;
    case CHDIR:
    case EXITS:
    case REMOVE:
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, "");
        break;
    case BIND:
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        i[0] = va_arg(list, int);
        fmtprint(&fmt, "%#ux",  i[0]);
        break;
    case CLOSE:
    case NOTED:
        i[0] = va_arg(list, int);
        fmtprint(&fmt, "%d", i[0]);
        break;
    case DUP:
        i[0] = va_arg(list, int);
        i[1] = va_arg(list, int);
        fmtprint(&fmt, "%d %d", i[0], i[1]);
        break;
    case ALARM:
        l = va_arg(list, unsigned long);
        fmtprint(&fmt, "%#lud ", l);
        break;
    case EXEC:
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, "");
        argv = va_arg(list, char**);
        //validalign(PTR2UINT(argv), sizeof(char*)); ??
        for(;;){
            validaddr((ulong)argv, sizeof(char**), false);
            a = *(char **)argv;
            if(a == nil)
                break;
            fmtprint(&fmt, " ");
            fmtuserstring(&fmt, a, "");
            argv++;
        }
        break;
    case FAUTH:
        i[0] = va_arg(list, int);
        a = va_arg(list, char*);
        fmtprint(&fmt, "%d", i[0]);
        fmtuserstring(&fmt, a, "");
        break;
    case SEGBRK:
    case RENDEZVOUS:
        v = va_arg(list, void*);
        fmtprint(&fmt, "%#p ", v);
        v = va_arg(list, void*);
        fmtprint(&fmt, "%#p", v);
        break;
    case OPEN:
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        i[0] = va_arg(list, int);
        fmtprint(&fmt, "%#ux", i[0]);
        break;
    case SLEEP:
        l = va_arg(list, long);
        fmtprint(&fmt, "%ld", l);
        break;
    case RFORK:
        i[0] = va_arg(list, int);
        fmtprint(&fmt, "%#ux", i[0]);
        break;
    case PIPE:
    case BRK:
        v = va_arg(list, int*);
        fmtprint(&fmt, "%#p", v);
        break;
    case CREATE:
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        i[0] = va_arg(list, int);
        i[1] = va_arg(list, int);
        fmtprint(&fmt, "%#ux %#ux", i[0], i[1]);
        break;
    case FD2PATH:
    case FSTAT:
    case FWSTAT:
        i[0] = va_arg(list, int);
        a = va_arg(list, char*);
        l = va_arg(list, unsigned long);
        fmtprint(&fmt, "%d %#p %lud", i[0], a, l);
        break;
    case NOTIFY:
    case SEGDETACH:
        v = va_arg(list, void*);
        fmtprint(&fmt, "%#p", v);
        break;
    case SEGATTACH:
        i[0] = va_arg(list, int);
        fmtprint(&fmt, "%d ", i[0]);
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        /*FALLTHROUGH*/
    case SEGFREE:
    case SEGFLUSH:
        v = va_arg(list, void*);
        l = va_arg(list, unsigned long);
        fmtprint(&fmt, "%#p %lud", v, l);
        break;
    case UNMOUNT:
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, "");
        break;
    case SEMACQUIRE:
    case SEMRELEASE:
        v = va_arg(list, int*);
        i[0] = va_arg(list, int);
        fmtprint(&fmt, "%#p %d", v, i[0]);
        break;
    case TSEMACQUIRE:
        v = va_arg(list, long*);
        l = va_arg(list, ulong);
        fmtprint(&fmt, "%#p %ld", v, l);
        break;
    case SEEK:
        v = va_arg(list, vlong*);
        i[0] = va_arg(list, int);
        vl = va_arg(list, vlong);
        i[1] = va_arg(list, int);
        fmtprint(&fmt, "%#p %d %#llux %d", v, i[0], vl, i[1]);
        break;
    case FVERSION:
        i[0] = va_arg(list, int);
        i[1] = va_arg(list, int);
        fmtprint(&fmt, "%d %d ", i[0], i[1]);
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        l = va_arg(list, unsigned long);
        fmtprint(&fmt, "%lud", l);
        break;
    case WSTAT:
    case STAT:
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        /*FALLTHROUGH*/
    case ERRSTR:
    case AWAIT:
        a = va_arg(list, char*);
        l = va_arg(list, unsigned long);
        fmtprint(&fmt, "%#p %lud", a, l);
        break;
    case MOUNT:
        i[0] = va_arg(list, int);
        i[1] = va_arg(list, int);
        fmtprint(&fmt, "%d %d ", i[0], i[1]);
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, " ");
        i[0] = va_arg(list, int);
        fmtprint(&fmt, "%#ux ", i[0]);
        a = va_arg(list, char*);
        fmtuserstring(&fmt, a, "");
        break;
    case PREAD:
        i[0] = va_arg(list, int);
        v = va_arg(list, void*);
        l = va_arg(list, long);
        fmtprint(&fmt, "%d %#p %ld", i[0], v, l);
        if(syscallno == PREAD){
            vl = va_arg(list, vlong);
            fmtprint(&fmt, " %lld", vl);
        }
        break;
    case PWRITE:
        i[0] = va_arg(list, int);
        v = va_arg(list, void*);
        l = va_arg(list, long);
        fmtprint(&fmt, "%d ", i[0]);
        len = MIN(l, 64);
        fmtrwdata(&fmt, v, len, " ");
        fmtprint(&fmt, "%ld", l);
        if(syscallno == PWRITE){
            vl = va_arg(list, vlong);
            fmtprint(&fmt, " %lld", vl);
        }
        break;
    }

    up->syscalltrace = fmtstrflush(&fmt);
}
@ 


<<function sysretfmt>>=
void
sysretfmt(int syscallno, va_list list, long ret, uvlong start, uvlong stop)
{
    long l;
    void* v;
    Fmt fmt;
    vlong vl;
    int i, len;
    char *a, *errstr;

    fmtstrinit(&fmt);

    if(up->syscalltrace)
        free(up->syscalltrace);

    errstr = "\"\"";
    switch(syscallno){
    default:
    case ALARM:
    case PWRITE:
        if(ret == -1)
            errstr = up->syserrstr;
        fmtprint(&fmt, " = %ld", ret);
        break;
    case EXEC:
    case SEGBRK:
    case SEGATTACH:
    case RENDEZVOUS:
        if((void *)ret == (void*)-1)
            errstr = up->syserrstr;
        fmtprint(&fmt, " = %#p", (void *)ret);
        break;
    case AWAIT:
        a = va_arg(list, char*);
        l = va_arg(list, unsigned long);
        if(ret > 0){
            fmtuserstring(&fmt, a, " ");
            fmtprint(&fmt, "%lud = %ld", l, ret);
        }
        else{
            fmtprint(&fmt, "%#p/\"\" %lud = %ld", a, l, ret);
            errstr = up->syserrstr;
        }
        break;
    case ERRSTR:
        a = va_arg(list, char*);
        l = va_arg(list, unsigned long);
        if(ret > 0){
            fmtuserstring(&fmt, a, " ");
            fmtprint(&fmt, "%lud = %ld", l, ret);
        }
        else{
            fmtprint(&fmt, "\"\" %lud = %ld", l, ret);
            errstr = up->syserrstr;
        }
        break;
    case FD2PATH:
        i = va_arg(list, int);
        USED(i);
        a = va_arg(list, char*);
        l = va_arg(list, unsigned long);
        if(ret > 0){
            fmtuserstring(&fmt, a, " ");
            fmtprint(&fmt, "%lud = %ld", l, ret);
        }
        else{
            fmtprint(&fmt, "\"\" %lud = %ld", l, ret);
            errstr = up->syserrstr;
        }
        break;
    case PREAD:
        i = va_arg(list, int);
        USED(i);
        v = va_arg(list, void*);
        l = va_arg(list, long);
        if(ret > 0){
            len = MIN(ret, 64);
            fmtrwdata(&fmt, v, len, "");
        }
        else{
            fmtprint(&fmt, "/\"\"");
            errstr = up->syserrstr;
        }
        fmtprint(&fmt, " %ld", l);
        if(syscallno == PREAD){
            vl = va_arg(list, vlong);
            fmtprint(&fmt, " %lld", vl);
        }
        fmtprint(&fmt, " = %ld", ret);
        break;
    }
    fmtprint(&fmt, " %s %#llud %#llud\n", errstr, start, stop);
    up->syscalltrace = fmtstrflush(&fmt);
}
@ 

<<function fmtrwdata>>=
// WE ARE OVERRUNNING SOMEHOW
static void
fmtrwdata(Fmt* f, char* a, int n, char* suffix)
{
    int i;
    char *t;

    if(a == nil){
        fmtprint(f, "0x0%s", suffix);
        return;
    }
    validaddr((ulong)a, n, false);
    t = smalloc(n+1);
    for(i = 0; i < n; i++)
        if(a[i] > 0x20 && a[i] < 0x7f)  /* printable ascii? */
            t[i] = a[i];
        else
            t[i] = '.';

    fmtprint(f, " %#p/\"%s\"%s", a, t, suffix);
    free(t);
}
@ 


<<function fmtuserstring>>=
static void
fmtuserstring(Fmt* f, char* a, char* suffix)
{
    int n;
    char *t;

    if(a == nil){
        fmtprint(f, "0/\"\"%s", suffix);
        return;
    }
    validaddr((ulong)a, 1, false);
    n = ((char*)vmemchr(a, 0, 0x7fffffff) - a) + 1;
    t = smalloc(n+1);
    memmove(t, a, n);
    t[n] = 0;
    fmtprint(f, "%#p/\"%s\"%s", a, t, suffix);
    free(t);
}
@ 


\section{Scheduler events, [[/proc/trace]] and [[/bin/trace]]}
% /proc/trace contains events from the kernel scheduler
% I think it's useful to debug multi-process programs
% or to debug the scheduler itself.
% not sure it's that useful for general debugging. 

<<[[Proc]] debugger fields>>=
bool trace;    /* process being traced? */
@
% rename to schedtrace?

% echo 'trace 1' > proc/x/ctl

<<[[procctlreq()]] CMtrace case>>=
    case CMtrace:
        switch(cb->nf){
        case 1:
            p->trace ^= true;
            break;
        case 2:
            p->trace = (atoi(cb->f[1]) != 0);
            break;
        default:
            error("args");
        }
        break;
@


<<hook proctrace>>=
void (*proctrace)(Proc*, /*enum<tevent>*/int, vlong) = 0; // was in devproc.c
@ 

<<enum Tevent>>=
enum Tevent {
    SReady = 0,		/* runnable but not running  */
    SRun,		/* running best effort */
    SDead,		/* proc dies */
    SSleep,		/* blocked */
    SUser,		/* user event */

    /* real-time extensions */
    <<[[enum Tevent]] real-time scheduling events>>

    Nevent, // must be last
};
@

<<struct Traceevent>>=
struct Traceevent {
    ulong	pid;	
    // enum<tevent>
    ulong	etype;	/* Event type */
    vlong	time;	/* time stamp  */ // dimension?
};
@

%TODO: code of trace.h here

% Always code like:
%    pt = proctrace
%    if(pt) pt(...)
% Why not just if(proctrace) proctrace(...)? because of race!
% After the 'if' proctrace could be null!

% could draw automata :)

<<[[ready()]] hook proctrace>>=
    pt = proctrace;
    if(pt)
        pt(p, SReady, 0);
@

<<[[runproc()]] hook proctrace>>=
    pt = proctrace;
    if(pt)
        pt(p, SRun, 0);
@

<<[[pexit()]] hook proctrace>>=
    pt = proctrace;
    if(pt)
        pt(up, SDead, 0);
@


<<[[sleep()]] hook proctrace>>=
        pt = proctrace;
        if(pt)
            pt(up, SSleep, 0);
@

% this one is a little bit different
<<[[procctlreq()]] CMevent case>>=
    case CMevent:
        pt = proctrace;
        if(up->trace && pt)
            pt(up, SUser, 0);
        break;
@
%TODO: can remove the up->trace, pt does this internally

%TODO could put all of that in a struct, and a Lock, would be cleaner
<<global trace txxx>>=
// array<Traceevent>
static Traceevent *tevents;
static int topens;
static int tproduced, tconsumed;
static Lock tlock;
@
% topens can be > 1 ??? use a bool no?

<<function eventsavailable>>=
static int
eventsavailable(void *)
{
    return tproduced > tconsumed;
}
@



% no locks?
<<function _proctrace>>=
static void
_proctrace(Proc* p, Tevent etype, vlong ts)
{
    Traceevent *te;

    if (p->trace == false || topens == 0 ||
        tproduced - tconsumed >= Nevents)
        return;

    te = &tevents[tproduced&Emask];
    te->pid = p->pid;
    te->etype = etype;
    if (ts == 0)
        te->time = todget(nil);
    else
        te->time = ts;
    tproduced++;
}
@

<<constant Nevents>>=
    Nevents = 0x4000,
@

<<constant Emask>>=
    Emask = Nevents - 1,
@

<<[[procopen()]] Qtrace if>>=
    if(QID(c->qid) == Qtrace){
        if (omode != OREAD) 
            error(Eperm);
        lock(&tlock);
        if (waserror()){
            unlock(&tlock);
            nexterror();
        }
        if (topens > 0)
            error("already open");
        topens++;
        if (tevents == nil){
            tevents = (Traceevent*)malloc(Nevents * sizeof(Traceevent));
            if(tevents == nil)
                error(Enomem);
            tproduced = tconsumed = 0;
        }
        proctrace = _proctrace;
        unlock(&tlock);
        poperror();

        c->mode = openmode(omode);
        c->flag |= COPEN;
        c->offset = 0;
        return c;
    }
@

<<[[procclose()]] Qtrace if>>=
    if(QID(c->qid) == Qtrace){
        lock(&tlock);
        if(topens > 0)
            topens--;
        if(topens == 0)
            proctrace = nil;
        unlock(&tlock);
    }
@

<<[[procread()]] Qtrace if>>=
    if(QID(c->qid) == Qtrace){
        if(!eventsavailable(nil))
            return 0;

        rptr = (byte*)va;
        navail = tproduced - tconsumed;
        if(navail > n / sizeof(Traceevent))
            navail = n / sizeof(Traceevent);
        while(navail > 0) {
            ne = ((tconsumed & Emask) + navail > Nevents)? 
                    Nevents - (tconsumed & Emask): navail;
            memmove(rptr, &tevents[tconsumed & Emask], 
                    ne * sizeof(Traceevent));

            tconsumed += ne;
            rptr += ne * sizeof(Traceevent);
            navail -= ne;
        }
        return rptr - (byte*)va;
    }
@



\section{[[/bin/db]]}

% breakpoint?? via hardware exception? so trap? and in trap
% we look for procctl no?

% simple: modify the code in memory at the breakpoint address given
% by user to generate a fault => when execute and reach breakpoint
% we will be given back the hand. => efficient!


\section{Other}

% used? by what? acid? db? seems to stop until there is a note essentially
<<enum procctl cases>>=
    Proc_traceme,
@

<<[[procctl()]] Proc_traceme case (and fallthrough [[Proc_stopme]])>>=
    case Proc_traceme:
        if(p->nnote == 0)
            return;
        /* No break */
@

<<[[procctlreq()]] CMstartstop case>>=
    case CMstartstop:
        if(p->state != Stopped)
            error(Ebadctl);
        p->procctl = Proc_traceme;
        ready(p);
        procstopwait(p, Proc_traceme);
        break;
@





\chapter{Profiling Support}
%\section{Profiling user processes}

% should cooperate with Profiling.nw at some point

\section{[[/dev/cputime]] and [[/proc/#/status]]}

<<enum proctimer>>=
enum proctime 
{
    TUser = 0,    /* Proc.time */
    TSys,
    TReal,

    // to accumulate also the time of the children of the process
    TCUser,
    TCSys,
};
@ 

<<[[Proc]] stats and profiling fields>>=
// hash<enum<proctime>, ulong>
ulong time[5];  /* User, Sys, Real; child U, S */
@
% the ulong is number of ticks, so use Ttick? except for Real where it's
%  the tick number when the process was started
% used to be time[6] with a TCReal, but didn't make sense
% because time[TCREal] was never used because the real time
% is the full time of everything and we don't need to maintain
% that info; it's very easy to compute ... it's the rest that is hard
% to track.

<<[[sysrfork()]] setting time field>>=
memset(p->time, 0, sizeof(p->time));
p->time[TReal] = CPUS(0)->ticks;
@
% could factorize in newproc? but maybe to be the most precise
% they prefer to do that the closes to the point where they actually
% ready the process?

<<[[kproc()]] setting time field>>=
memset(p->time, 0, sizeof(p->time));
p->time[TReal] = CPUS(0)->ticks;
@

<<[[accountime()]] update time of current process>>=
p->time[p->insyscall ? TSys : TUser]++;
@
% this is called by hzclock so every tick


<<[[consread()]] cases>>=
case Qcputime:
    k = offset;
    if(k >= 5*NUMSIZE)
        return 0;
    if(k+n > 5*NUMSIZE)
        n = 5*NUMSIZE - k;
    /* easiest to format in a separate buffer and copy out */

    for(i=0; i<5 && NUMSIZE*i<k+n; i++){
        l = up->time[i];
        if(i == TReal)
            l = CPUS(0)->ticks - l;
        l = TK2MS(l);
        readnum(0, tmp+NUMSIZE*i, NUMSIZE, l, NUMSIZE);
    }
    memmove(buf, tmp+k, n);
    return n;
@
% this is /dev/ so only the current process can see it

<<[[procread()]] Qstatus case, time part>>=
for(i = 0; i < 5; i++) {
    l = p->time[i];
    if(i == TReal)
        l = CPUS(0)->ticks - l;
    l = TK2MS(l);
    readnum(0, statbuf+j+NUMSIZE*i, NUMSIZE, l, NUMSIZE);
}
@
% to see the time of other running processes

\section{[[/bin/time]]}


% actually waitmsg has time info, so /bin/time is pretty simple
<<[[Waitmsg]] time field>>=
  ulong time[3];  /* of loved one and descendants */
@
% 3 = user, sys, real

<<[[pexit()]] set wait msg time field>>=
utime = up->time[TUser] + up->time[TCUser];
stime = up->time[TSys] + up->time[TCSys];

wq->w.time[TUser] = tk2ms(utime);
wq->w.time[TSys] = tk2ms(stime);
wq->w.time[TReal] = tk2ms(CPUS(0)->ticks - up->time[TReal]);
@

<<[[pexit()]] update TC time of parent>>=
p->time[TCUser] += utime;
p->time[TCSys] += stime;
@


<<[[sysawait()]] snprint time field arguments>>=
w.time[TUser], w.time[TSys], w.time[TReal],
@

<<[[procread()]] Qwait case, snprint time field arguments>>=
wq->w.time[TUser], wq->w.time[TSys], wq->w.time[TReal],
@


\section{[[/bin/tprof]]}
% oprofile, frequency count, sampling based
% tprof? why t? tickprof? meh

% coverage data for Text segment! 
% profile[0] will be total time in ms.
% profile[xxx] where xxx corresponds to parts of the program 
% that has been executed, also in ms
<<[[Segment]] other fields>>=
kern_addr2  profile;  /* Tick profile area */ // for TSEG only
@
% why not put that in Proc instead? it's true it speaks about
% elements of text segment. Also because then it can be used
% for multiprocess (or multithreads) programs that share the same text!

<<[[putseg()]] free profile>>=
    if(s->profile != nil)
        free(s->profile);
@


% often used as (q->top-q->base)>>LRESPROF
<<constant LRESPROF>>=
LRESPROF  = 3,
@
% we don't count exactly each pc, anyway we are sampling,
% so we >>3 the pc


<<[[proc_init()]] other init>>=
addclock0link((void (*)(void))profclock, 113);  /* Relative prime to HZ */
@

<<clock callback profclock>>=
static void
profclock(Ureg *ur, Timer *)
{
    if(up == nil || up->state != Running)
        return;

    /* user profiling clock */
    if(arch_userureg(ur)){
        <<[[profclock]] tos adjustments when user>>
        segclock(ur->pc);
    }
}
@ 
% so this is sampling based profiling, a la oprofile?

<<clock callback segclock>>=
// called via profclock
void
segclock(ulong pc)
{
    Segment *s;

    s = up->seg[TSEG];
    if(s == nil || s->profile == nil)
        return;

    s->profile[0] += TK2MS(1);
    if(pc >= s->base && pc < s->top) {
        pc -= s->base;
        s->profile[pc>>LRESPROF] += TK2MS(1);
    }
}
@
% coverage!! super nice!


% to activate
<<[[procctlreq()]] CMprofile case>>=
    case CMprofile:
        s = p->seg[TSEG];
        if(s == nil || (s->type&SG_TYPE) != SG_TEXT)
            error(Ebadctl);
        if(s->profile != nil)
            free(s->profile);
        npc = (s->top-s->base)>>LRESPROF;
        s->profile = malloc(npc*sizeof(*s->profile));
        if(s->profile == nil)
            error(Enomem);
        break;
@

% to read
<<[[procread()]] cases>>=
case Qprofile:
    s = p->seg[TSEG];
    if(s == nil || s->profile == nil)
        error("profile is off");
    i = (s->top-s->base)>>LRESPROF;
    i *= sizeof(*s->profile);
    if(offset >= i)
        return 0;
    if(offset+n > i)
        n = i - offset;
    memmove(a, ((char*)s->profile)+offset, n);
    return n;
@

% size of profile data, for ls -l /proc/#/profile
<<[[procgen()]] Qprofile case>>=
    case Qprofile:
        q = p->seg[TSEG];
        if(q && q->profile) {
            len = (q->top-q->base)>>LRESPROF;
            len *= sizeof(*q->profile);
        }
        break;
@

\section{[[/bin/prof]]}

% cooperation between compiler, loader, kernel, and then /bin/prof that interprets
% data.
% /include/tos.h, lib_core/libc/port/profile.c, linker/??, compilers/??
% see also lib_core/libc/386/main9p.s?

% can't have a compiled program do things like I do in Common.profile_code and
% do a syscall to each funcall to get the time ... would be far too slow.
% so need fast access to time in userspace! enter tos
% note: other stuff we would like to put in tos to optimize kernel<->user comm?

<<struct Tos>>=
struct Tos {
    <<[[Tos]] prof field>>
    uvlong cyclefreq;	/* cycle clock frequency if there is one, 0 otherwise */

    vlong kcycles;	/* cycles spent in kernel */
    vlong pcycles;	/* cycles spent in process (kernel + user) */
    ulong clock; // in ms

    ulong pid;		/* might as well put the pid here */
    <<[[Tos]] other fields>>
    /* top of stack is here */
};
@
% tos? time os?

% idea is that Tos sits at the very top of user stack
% Tos then sysexec args then regular process stack frames
%    tos = (Tos*)(USTKTOP-sizeof(Tos));

<<[[Cpu]] other fields>>=
    // cyclefreq == cpuhz if havetsc, 0 otherwise
    uvlong  cyclefreq;    /* Frequency of user readable cycle counter */
@

<<[[Proc]] stats and profiling fields>>=
uvlong  kentry;   /* Kernel entry time stamp (for profiling) */
/*
 * pcycles: cycles spent in this process (updated on procsave/restore)
 * when this is the current proc and we're in the kernel
 * (procrestores outnumber procsaves by one)
 * the number of cycles spent in the proc is pcycles + cycles()
 * when this is not the current process or we're in user mode
 * (procrestores and procsaves balance), it is pcycles.
 */
vlong pcycles;
@ 

<<function cycles and default implementation(x86)>>=
static void
simplecycles(uvlong *x)
{
    *x = cpu->ticks;
}

void    (*arch_cycles)(uvlong*) = simplecycles;
@ 




\ifallcode
<<[[Tos]] prof field>>=
struct			/* Per process profiling */
{
    Plink	*pp;	/* known to be 0(ptr) */
    Plink	*next;	/* known to be 4(ptr) */
    Plink	*last;
    Plink	*first;
    ulong	pid;
    ulong	what;
} prof;
@
% this is actually used by lib_core/port/profile.c
\fi

\ifallcode
<<[[Tos]] other fields>>=
/* scratch space for kernel use (e.g., mips fp delay-slot execution) */
ulong	kscr[4];
@
\fi



<<[[sysexec()]] locals>>=
Tos *tos;
@

<<[[sysexec()]] tos settings>>=
    tos = (Tos*)(TSTKTOP - sizeof(Tos));

    tos->cyclefreq = cpu->cyclefreq;
    arch_cycles((uvlong*)&tos->pcycles);
    tos->pcycles = -tos->pcycles; // see comment above on Proc->pcycle
    tos->kcycles = tos->pcycles;
    tos->clock = 0;
    // what about other fields? like pid? will be set in kexit! but could be
    // done here? what about sysrfork? call kexit?
@

<<[[kexit()]] tos adjustments(x86)>>=
    uvlong t;
    Tos *tos;

    /* precise time accounting, kernel exit */
    tos = (Tos*)(USTKTOP-sizeof(Tos));
    arch_cycles(&t);
    tos->kcycles += t - up->kentry;
    tos->pcycles = up->pcycles;
    tos->pid = up->pid;
@

<<[[profclock]] tos adjustments when user>>=
Tos *tos;
tos = (Tos*)(USTKTOP-sizeof(Tos));
tos->clock += TK2MS(1);
@



<<[[syscall()]] adjust kentry(x86)>>=
    arch_cycles(&up->kentry);
@

<<[[trap()]] adjust kentry when interrupt user(x86)>>=
        arch_cycles(&up->kentry);
@


<<[[procsave()]] cycles adjustments(x86)>>=
    uvlong t;

    arch_cycles(&t);
    p->pcycles += t;
@


<<[[procrestore]] cycles adjustments(x86)>>=
    arch_cycles(&t);
    p->pcycles -= t;
@




<<[[sysexec()]] nbytes tos adjustments>>=
nbytes += sizeof(Tos); /* hole for profiling clock at top of stack (and more) */
@
<<[[execregs()]] return adjustments(x86)>>=
      -sizeof(Tos)
@





\chapter{Userspace System Programs}
\minitoc

% can execute them because they are in rootfs, via addrootfile,
% see mkrootall in mkfile via data2txt

\section{[[/boot/boot]]}

% boot.rc now!! no need complex boot.c

%history of standard error channel:
%http://www.spinellis.gr/blog/20131211/index.html

<<boot.c>>=
#include <u.h>
#include <libc.h>
#include "../boot/boot.h"

// Note that most of this code is now superseded by $objtype/boot.rc

/*
 * we should inherit the standard fds referring to /dev/cons,
 * but we're being paranoid.
 */
static void
opencons(void)
{
  close(STDIN);
  close(STDOUT);
  close(STDERR);
  open("/dev/cons", OREAD);
  open("/dev/cons", OWRITE);
  open("/dev/cons", OWRITE);
}

/*
 * init will reinitialize its namespace.
 * #ec gets us plan9.ini settings (*var variables).
 */
static void
bindenvsrv(void)
{
  bind("#ec", "/env", MREPL); // ec? 2 chars? #e and pass 'c' to device?
  bind("#e", "/env", MBEFORE|MCREATE); // devenv
  bind("#s", "/srv/", MREPL|MCREATE); // devsrv
}

//TODO: use open_safe, write_safe
static void
swapproc(void)
{
    int fd;

    fd = open("#c/swap", OWRITE);
    if(fd < 0){
        warning("opening #c/swap");
        return;
    }
    if(write(fd, "start", 5) <= 0)
        warning("starting swap kproc");
    close(fd);
}

static void
execinit(void)
{
  fdt fd;

  // basics

  bind_safe("#p", "/proc", MREPL); //devproc
  // used by rc and many programs, e.g. via open("#d/0")
  bind_safe("#d", "/fd", MREPL); //devdup
  // can't use sys, because too much code assumes /sys/ have an include/, src/
  bind_safe("#k", "/ksys", MREPL); //devsys

  bind_safe("/root", "/", MAFTER|MCREATE);

  bind_safe("/386/bin", "/bin", MREPL); // X86

  bind_safe("/rc/bin", "/bin", MAFTER);

  bind_safe("#P", "/dev", MAFTER); //devarch

  bind_safe("#m", "/dev", MAFTER); //devmouse
  run("/bin/mouse", "ps2", nil);


  // for draw

  bind_safe("#v", "/dev", MAFTER); //devvga
  //this just need a regular vga driver
  run("/bin/vga", "-l", "640x480x8", nil);
  //this need special drivers, such as the clgd424x.c in the kernel
  //run("/bin/vga", "-l", "1024x768x8", nil); // can add -V to debug vga
  bind_safe("#i", "/dev", MAFTER); // devdraw

  // for rio

  run("/bin/ramfs", "-m", "/mnt", nil);
  run("/bin/mkdir", "/mnt/temp", nil); // see thread(2), used to create pipes
  run("/bin/mkdir", "/mnt/wsys", nil);
  fd = open_safe("#k/hostowner", OWRITE);
  print_safe(fd, "pad");
  close(fd);

  // network

  bind_safe("#I", "/net", MREPL); // devip
  bind_safe("#l0", "/net", MAFTER); // ether (and dev 0)

  // for 8c, 8a, 8l

  putenv("objtype", "386");

  // I have a bug in the kernel where I can't get the current
  // date from qemu. At boot time there is some lapic clock error.
  // So then the date is set to 0sec since epoch which is 1970
  // which is bad for tools like mk because many files are in the futur.
  // So here I set the date to 2033 so mk should be happy
  fd = open_safe("#c/time", OWRITE);
  print_safe(fd, "2000000000");
  close(fd);

  // should normally run /root/init, but prefer to simply run rc for now
  run("/bin/rc", nil);
}


// called from boot$CONF.c:main()
void
boot(int argc, char *argv[])
{
  USED(argc);
  USED(argv);

  fmtinstall('r', errfmt);

  // at this point we should have #/ and #c setup by the kernel init0

  opencons();
  bindenvsrv();

  print("booooooooting...\n");

  rfork(RFNAMEG);

  connectlocal();

  swapproc();
  execinit();

  exits("failed to exec init");
}
@
%$

<<function run>>=
void
run(char *file, ...)
{
  runv(&file);
}
@

<<function runv>>=
void
runv(char **argv)
{
  int i, pid;
  
  switch(pid = fork()){
  case -1:
    fatal("fork");
  case 0:
    exec(argv[0], argv);
    fatal(smprint("can't exec %s: %r", argv[0]));
  default:
    while ((i = waitpid()) != pid && i != -1)
      ;
    if(i == -1)
      fatal(smprint("wait failed running %s", argv[0]));
  }
}
@


<<local.c>>=
#include <u.h>
#include <libc.h>
#include "../boot/boot.h"

// Note that most of this code is now superseded by $objtype/boot.rc

void
connectlocal(void)
{
  int fd;
  
  bind_safe("#S", "/dev", MAFTER);

  fd = open_safe("/dev/sdC0/ctl", ORDWR);
  //TODO: use fdisk -p /dev/sdC1/data > /dev/sdC1/ctl
  //for sdC0: #prep -p /dev/sdC1/plan9 > /dev/sdC1/ctl
  print_safe(fd, "part dos 1 1000063");
  close_safe(fd);

  run("/boot/dossrv", nil);
  run("/boot/mount", "-c", "/srv/dos", "/root", "/dev/sdC0/dos", nil);
  
  return;
}
@
%$


\section{[[/root/init]]}

% user init, != kernel init
% but actually not that needed, boot.rc can simply execute rc at the end.

\section{The shell}


\subsection{[[#!]]}
% hmm not sure right section. Maybe should be put
% in advanced topics?
% but now that I use boot.rc, we need it more!

<<[[sysexec()]] locals>>=
char line[sizeof(Exec)];
char *progarg[sizeof(Exec)/2+1];
char progelem[64];

bool indir = false;
@

<<[[sysexec()]] process sharpbang>>=
/*
 * Process #! /bin/sh args ...
 */
memmove(line, &exec, sizeof(Exec));
if(indir || line[0]!='#' || line[1]!='!')
    error(Ebadexec);
n = shargs(line, n, progarg);
if(n == 0)
    error(Ebadexec);
indir = true;
/*
 * First arg becomes complete file name
 */
progarg[n++] = file;
progarg[n] = 0;
validaddr(arg[1], BY2WD, true);
arg[1] += BY2WD;
file = progarg[0];
if(strlen(elem) >= sizeof progelem)
    error(Ebadexec);
strcpy(progelem, elem);
progarg[0] = progelem;
poperror();
cclose(tc);
@

<<function shargs>>=
int
shargs(char *s, int n, char **ap)
{
    int i;

    s += 2;
    n -= 2;     /* skip #! */
    for(i=0; s[i]!='\n'; i++)
        if(i == n-1)
            return 0;
    s[i] = 0;
    *ap = 0;
    i = 0;
    for(;;) {
        while(*s==' ' || *s=='\t')
            s++;
        if(*s == 0)
            break;
        i++;
        *ap++ = s;
        *ap = 0;
        while(*s && *s!=' ' && *s!='\t')
            s++;
        if(*s == 0)
            break;
        else
            *s++ = 0;
    }
    return i;
}
@ 


<<[[sysexec()]] if indir arg adjustments>>=
if(indir){
    argp = progarg;
    while(*argp){
        a = *argp++;
        nbytes += strlen(a) + 1;
        nargs++;
    }
}
@
<<[[sysexec()]] if indir argp adjustments>>=
if(indir)
    argp = progarg;
@

<<[[sysexec()]] if indir argp adjustments again>>=
if(indir && *argp==nil) {
    indir = false;
    argp = (char**)arg[1];
}
@











\chapter{Advanced Topics}
% put in Kernel_extra.nw for now

% [[select()]]? [[alt()]]?

% other: Serial line, Scsi, see Kernel_extra.nw

\section{Floating point (x86)}
% pretty important
% for ARM, simplified a lot by relying on VFP3 instructions
% generated by 5l -f. No need for coprocessor and fpiarm.c/fpi.c/fpimem.c.


%{FP}

% related co-processors: GPU

% apparently on 386 we have IrqIRQ13 for coprocessor, meaning the copro
% is really outside and need to communicate with him?
% simpler with 486?

\subsection{[[Arch_FPsave]]}

<<enum fpsavestatus>>=
/*
 * FPsave.status
 */
enum fpsavestatus
{
    /* this is a state */
    FPinit=   0,
    FPactive= 1,
    FPinactive= 2,

    FPemu = 3, // used by bcm/ only
  
    /* the following is a bit that can be or'd into the state */
    FPillegal=  0x100,
};
@ 

<<[[Proc]] other fields>>=
// enum<fpsavestatus>
int fpstate;
Arch_FPsave  fpsave;   /* address of this is known by db */
@

\subsection{[[Arch_FPsave]] (x86)}

<<union ArchFPSave(x86)>>=
/*
 * the FP regs must be stored here, not somewhere pointed to from here.
 * port code assumes this.
 */
// could be renamed Arch_ProcFPSave (used both in Proc and Cpu though)
union Arch_FPsave {
    FPstate;
    SFPssestate;
};
@
%old: FPsave

<<struct FPstate(x86)>>=
struct  FPstate     /* x87 fpu state */
{
  ushort  control;
  ushort  r1;
  // enum<fpsavestatus>
  ushort  status;
  ushort  r2;
  ushort  tag;
  ushort  r3;
  ulong pc;
  ushort  selector;
  ushort  r4;
  ulong operand;
  ushort  oselector;
  ushort  r5;
  uchar regs[80]; /* floating point registers */
};
@

\subsection{SSE}

<<struct  SFPssestate(x86)>>=
struct  SFPssestate   /* SSE fp state with alignment slop */
{
  FPssestate;
  uchar alignpad[FPalign]; /* slop to allow copying to aligned addr */
  ulong magic;    /* debugging: check for overrun */
};
@

<<constant FPalign(x86)>>=
#define FPalign   16      /* required for FXSAVE */
@


<<struct FPssestate(x86)>>=
struct  FPssestate    /* SSE fp state */
{
  ushort  fcw;    /* control */
  ushort  fsw;    /* status */
  ushort  ftw;    /* tag */
  ushort  fop;    /* opcode */
  ulong fpuip;    /* pc */
  ushort  cs;   /* pc segment */
  ushort  r1;   /* reserved */
  ulong fpudp;    /* data pointer */
  ushort  ds;   /* data pointer segment */
  ushort  r2;
  ulong mxcsr;    /* MXCSR register state */
  ulong mxcsr_mask; /* MXCSR mask register */
  uchar xregs[480]; /* extended registers */
};
@

\subsection{XXX}

<<[[Cpu]] [[Arch]] other fields(x86)>>=
Arch_FPsave *fpsavalign;
@


<<[[newproc()]] fb init>>=
    p->fpstate = FPinit;
@

<<[[sysrfork()]] propagate fpsave>>=
    p->fpsave = up->fpsave;
@

<<[[sysrfork()]] propagate fpstate>>=
    /* don't penalize the child, it hasn't done FP in a note handler. */
    p->fpstate = up->fpstate & ~FPillegal;
@

<<function fpsavealloc(x86)>>=
void
fpsavealloc(void)
{
    cpu->fpsavalign = mallocalign(sizeof(FPssestate), FPalign, 0, 0);
    if (cpu->fpsavalign == nil)
        panic("cpu%d: can't allocate fpsavalign", cpu->cpuno);
}
@ 


<<hook fprestore and fpsave(x86)>>=
void    (*fprestore)(Arch_FPsave*);
void    (*fpsave)(Arch_FPsave*);
@

<<function fpssesave(x86)>>=
/*
 * sse fp save and restore buffers have to be 16-byte (FPalign) aligned,
 * so we shuffle the data down as needed or make copies.
 */

void
fpssesave(Arch_FPsave *fps)
{
    Arch_FPsave *afps;

    fps->magic = 0x1234;
    afps = (Arch_FPsave *)ROUND(((uintptr)fps), FPalign);
    fpssesave0(afps);
    if (fps != afps)  /* not aligned? shuffle down from aligned buffer */
        memmove(fps, afps, sizeof(FPssestate));
    if (fps->magic != 0x1234)
        print("fpssesave: magic corrupted\n");
}
@ 


<<function fpsserestore(x86)>>=
void
fpsserestore(Arch_FPsave *fps)
{
    Arch_FPsave *afps;

    fps->magic = 0x4321;
    afps = (Arch_FPsave *)ROUND(((uintptr)fps), FPalign);
    if (fps != afps) {
        afps = cpu->fpsavalign;
        memmove(afps, fps, sizeof(FPssestate)); /* make aligned copy */
    }
    fpsserestore0(afps);
    if (fps->magic != 0x4321)
        print("fpsserestore: magic corrupted\n");
}
@ 





<<[[procsetup()]] fp setup(x86)>>=
/*
 *  set up floating point for a new process
 */
    p->fpstate = FPinit;
    fpoff();
@

<<[[userinit()]] fp setup(x86)>>=
    p->fpstate = FPinit;
    fpoff();
@

<<[[execregs()]] fp adjustments(x86)>>=
    //arch_procsetup(up), redundant?
    up->fpstate = FPinit;
    fpoff();
@

<<[[syscall()]] fp adjustments if fork(x86)>>=
    if(scallnr == RFORK && up->fpstate == FPactive){
        fpsave(&up->fpsave);
        up->fpstate = FPinactive;
    }
@

<<[[notify()]] fp adjustments(x86)>>=
    if(up->fpstate == FPactive){
        fpsave(&up->fpsave);
        up->fpstate = FPinactive;
    }
    up->fpstate |= FPillegal;
@

<<[[noted()]] fp adjustments(x86)>>=
    up->fpstate &= ~FPillegal;
@

<<[[procsave()]] fp adjustments(x86)>>=
    if(p->fpstate == FPactive){
        if(p->state == Moribund)
            fpclear();
        else{
            /*
             * Fpsave() stores without handling pending
             * unmasked exeptions. Postnote() can't be called
             * here as sleep() already has up->rlock, so
             * the handling of pending exceptions is delayed
             * until the process runs again and generates an
             * emulation fault to activate the FPU.
             */
            fpsave(&p->fpsave);
        }
        p->fpstate = FPinactive;
    }
@



<<[[procread()]] Qfpregs case>>=
    case Qfpregs:
        rptr = (uchar*)&p->fpsave;
        rsize = sizeof(Arch_FPsave);
        goto regread;
@

<<[[procwrite]] Qfpregs case>>=
    case Qfpregs:
        if(offset >= sizeof(Arch_FPsave))
            n = 0;
        else if(offset+n > sizeof(Arch_FPsave))
            n = sizeof(Arch_FPsave) - offset;
        memmove((uchar*)&p->fpsave+offset, va, n);
        break;
@




<<function mathstate(x86)>>=
static void
mathstate(ulong *stsp, ulong *pcp, ulong *ctlp)
{
        ulong sts, fpc, ctl;
        Arch_FPsave *f = &up->fpsave;

        if(fpsave == fpx87save){
                sts = f->status;
                fpc = f->pc;
                ctl = f->control;
        } else {
                sts = f->fsw;
                fpc = f->fpuip;
                ctl = f->fcw;
        }
        if(stsp)
                *stsp = sts;
        if(pcp)
                *pcp = fpc;
        if(ctlp)
                *ctlp = ctl;
}
@

<<function mathnote(x86)>>=
static void
mathnote(void)
{
        int i;
        ulong status, pc;
        char *msg, note[ERRMAX];

        mathstate(&status, &pc, nil);

        /*
         * Some attention should probably be paid here to the
         * exception masks and error summary.
         */
        msg = "unknown exception";
        for(i = 1; i <= 5; i++){
                if(!((1<<i) & status))
                        continue;
                msg = mathmsg[i];
                break;
        }
        if(status & 0x01){
                if(status & 0x40){
                        if(status & 0x200)
                                msg = "stack overflow";
                        else
                                msg = "stack underflow";
                }else
                        msg = "invalid operation";
        }
        snprint(note, sizeof note, "sys: fp: %s fppc=%#lux status=%#lux",
                msg, pc, status);
        postnote(up, 1, note, NDebug);
}
@
% >>

<<function matherror(x86)>>=
/*
 *  math coprocessor error
 */
static void
matherror(Ureg *ur, void*)
{
        ulong status, pc;

        /*
         *  a write cycle to port 0xF0 clears the interrupt latch attached
         *  to the error# line from the 387
         */
        if(!(cpu->cpuiddx & Fpuonchip))
                outb(0xF0, 0xFF);

        /*
         *  save floating point state to check out error
         */
        fpenv(&up->fpsave);     /* result ignored, but masks fp exceptions */
        fpsave(&up->fpsave);            /* also turns fpu off */
        fpon();
        mathnote();

        if((ur->pc & 0xf0000000) == KZERO){
                mathstate(&status, &pc, nil);
                panic("fp: status %#lux fppc=%#lux pc=%#lux", status, pc, ur->pc);
        }
}
@


<<function mathemu(x86)>>=
/*
 *  math coprocessor emulation fault
 */
static void
mathemu(Ureg *ureg, void*)
{
        ulong status, control;

        if(up->fpstate & FPillegal){
                /* someone did floating point in a note handler */
                postnote(up, 1, "sys: floating point in note handler", NDebug);
                return;
        }
        switch(up->fpstate){
        case FPinit:
                fpinit();
                up->fpstate = FPactive;
                break;
        case FPinactive:
                /*
                 * Before restoring the state, check for any pending
                 * exceptions, there's no way to restore the state without
                 * generating an unmasked exception.
                 * More attention should probably be paid here to the
                 * exception masks and error summary.
                 */
                mathstate(&status, nil, &control);
                if((status & ~control) & 0x07F){
                        mathnote();
                        break;
                }
                fprestore(&up->fpsave);
                up->fpstate = FPactive;
                break;
        case FPactive:
                panic("math emu pid %ld %s pc %#lux",
                        up->pid, up->text, ureg->pc);
                break;
        }
}
@


<<function mathover(x86)>>=
/*
 *  math coprocessor segment overrun
 */
static void
mathover(Ureg*, void*)
{
        pexit("math overrun", false);
}
@


<<function mathinit(x86)>>=
void
mathinit(void)
{
        trapenable(VectorCERR, matherror, 0, "matherror");
        if(X86FAMILY(cpu->cpuidax) == 3)
                arch_intrenable(IrqIRQ13, matherror, 0, BUSUNKNOWN, "matherror");
        trapenable(VectorCNA, mathemu, 0, "mathemu");
        trapenable(VectorCSO, mathover, 0, "mathover");
}
@



<<l_fp.s>>=
/*
 * Some machine instructions not handled by 8[al].
 */
#define FXSAVE          BYTE $0x0f; BYTE $0xae; BYTE $0x00  /* SSE FP save */
#define FXRSTOR         BYTE $0x0f; BYTE $0xae; BYTE $0x08  /* SSE FP restore */

        
/*
 * Floating point.
 * Note: the encodings for the FCLEX, FINIT, FSAVE, FSTCW, FSENV and FSTSW
 * instructions do NOT have the WAIT prefix byte (i.e. they act like their
 * FNxxx variations) so WAIT instructions must be explicitly placed in the
 * code as necessary.
 */
#define FPOFF(l)                                                 ;\
        MOVL    CR0, AX                                          ;\
        ANDL    $0xC, AX                        /* EM, TS */     ;\
        CMPL    AX, $0x8                                         ;\
        JEQ     l                                                ;\
        WAIT                                                     ;\
l:                                                               ;\
        MOVL    CR0, AX                                          ;\
        ANDL    $~0x4, AX                       /* EM=0 */       ;\
        ORL     $0x28, AX                       /* NE=1, TS=1 */ ;\
        MOVL    AX, CR0

#define FPON                                                     ;\
        MOVL    CR0, AX                                          ;\
        ANDL    $~0xC, AX                       /* EM=0, TS=0 */ ;\
        MOVL    AX, CR0

TEXT fpon(SB), $0                               /* enable */
        FPON
        RET

TEXT fpoff(SB), $0                              /* disable */
        FPOFF(l1)
        RET

TEXT fpinit(SB), $0                             /* enable and init */
        FPON
        FINIT
        WAIT
        /* setfcr(FPPDBL|FPRNR|FPINVAL|FPZDIV|FPOVFL) */
        /* note that low 6 bits are masks, not enables, on this chip */
        PUSHW   $0x0232
        FLDCW   0(SP)
        POPW    AX
        WAIT
        RET

TEXT fpx87save(SB), $0                          /* save state and disable */
        MOVL    p+0(FP), AX
        FSAVE   0(AX)                           /* no WAIT */
        FPOFF(l2)
        RET

TEXT fpx87restore(SB), $0                       /* enable and restore state */
        FPON
        MOVL    p+0(FP), AX
        FRSTOR  0(AX)
        WAIT
        RET

//TEXT fpstatus(SB), $0                         /* get floating point status */
//      FSTSW   AX
//      RET

TEXT fpenv(SB), $0                              /* save state without waiting */
        MOVL    p+0(FP), AX
        FSTENV  0(AX)                           /* also masks FP exceptions */
        RET

TEXT fpclear(SB), $0                            /* clear pending exceptions */
        FPON
        FCLEX                                   /* no WAIT */
        FPOFF(l3)
        RET

TEXT fpssesave0(SB), $0                         /* save state and disable */
        MOVL    p+0(FP), AX
        FXSAVE                                  /* no WAIT */
        FPOFF(l4)
        RET

TEXT fpsserestore0(SB), $0                      /* enable and restore state */
        FPON
        MOVL    p+0(FP), AX
        FXRSTOR
        WAIT
        RET
        
@



\section{SMP (x86)}

\section{Advanced virtual memory (x86)}

% large memory system: vpt/vpd, tmpmap, arch_kmap
% other: vmap? for devices? framebuffer related?
% 9atom also provides patches for PAE support and amd64 support

\subsection{Page coloring}
% page coloring, getpgcolor, cachectl, etc
% but I've removed the code actually
%update: put back because of bcm/ ?

%old? in newpage
%	for(i = 0; i < MAXMACH; i++)
%		p->cachectl[i] = ct;

\subsection{Cache line}

%#define CACHELINESZ 32      /* pentium & later */

\subsection{Extra segment types}

<<enum segtype other cases>>=
    SG_SHARED = 04,
@


<<enum segtype other cases>>=
    SG_PHYSICAL = 05,
@
% SG_PHYSICAL used only for vga/vesa apparently


<<struct Physseg>>=
struct Physseg
{
    ulong attr;     /* Segment attributes */
    char  *name;      /* Attach name */
    phys_addr pa;     /* Physical address */
    ulong size;     /* Maximum segment size in pages */
};
@
%    // seems dead, not even used by vga.c
%    Page  *(*pgalloc)(Segment*, ulong); /* Allocation if we need it */
%    void  (*pgfree)(Page*);


<<[[Segment]] other fields>>=
Physseg *pseg;
@


<<global physseg>>=
/*
 * Attachable segment types
 */
static Physseg physseg[10] = {
    { .attr= SG_SHARED, 
      .name= "shared", 
      .pa= 0,
      .size= SEGMAXSIZE, 
    },
    { .attr= SG_BSS, 
      .name= "memory", 
      .pa = 0,
      .size = SEGMAXSIZE, 
    },
    { 0, 0, 0, 0},
};
@

<<global physseglock>>=
static Lock physseglock;
@

% used by vga.c
<<function addphysseg>>=
int
addphysseg(Physseg* new)
{
    Physseg *ps;

    /*
     * Check not already entered and there is room
     * for a new entry and the terminating null entry.
     */
    lock(&physseglock);
    for(ps = physseg; ps->name; ps++){
        if(strcmp(ps->name, new->name) == 0){
            unlock(&physseglock);
            return -1;
        }
    }
    if(ps-physseg >= nelem(physseg)-2){
        unlock(&physseglock);
        return -1;
    }

    *ps = *new;
    unlock(&physseglock);

    return 0;
}
@



<<[[freept()]] SG_PHYSICAL case>>=
    case SG_PHYSICAL:
        ptop = &p->pagetab[PAGETABSIZE];
        for(pte = p->pagetab; pte < ptop; pte++) {
            pt = *pte;
            if(pt == nil)
                continue;
            lock(pt);
            ref = --pt->ref;
            unlock(pt);
            if(ref == 0)
                free(pt); // because was smalloc'ed in fixfault
        }
        break;
@

<<[[fixfault()]] SG_PHYSICAL case>>=
    case SG_PHYSICAL:
        if(*pte == nil) {
            new = smalloc(sizeof(Page));
            new->va = addr;
            new->pa = s->pseg->pa+(addr-s->base);
            new->ref = 1;
            *pte = new;
        }

        if (checkaddr && addr == addr2check)
            (*checkaddr)(addr, s, *pte);
        mmupte = PPN((*pte)->pa) |PTEWRITE|PTEUNCACHED|PTEVALID;
        (*pte)->modref = PG_MOD|PG_REF;
        break;
@

\subsection{[[vpt]], [[vpd]]}

% tricks apparently borrowed from exokernel code.
% see the toplevel comment in mmu.c
% essentially just tricks abusing the long page feature of x86 to make
% it easy to map and then edit physical content of page tables or
% page directory per process.

<<constant VPTSIZE(x86)>>=
#define VPTSIZE 0
@

<<constant VPT(x86)>>=
@

<<global vpt and vpd(x86)>>=
@

<<[[mmuinit()]] vpt adjusments(x86)>>=
@


<<[[mmupdalloc()]] vpt adjustments(x86)>>=
@
% the page->va used to be just after newpage() in mmupdalloc, not sure it matters




<<[[checkmmu()]] pd at pt check(x86)>>=
//    if(!(vpd[PDX(va)]&PTEVALID) || !(vpt[VPTX(va)]&PTEVALID))
//        return;
//    if(PPN(vpt[VPTX(va)]) != pa)
//        print("%ld %s: va=%#08lux pa=%#08lux pte=%#08lux\n",
//            up->pid, up->text,
//            va, pa, vpt[VPTX(va)]);
@

<<[[vmapsync()]] va set to entry(x86)>>=
// pad's code for simplified virtual memory, no VPT
if(up == nil) {
    return 0;
} else {
   if(up->mmupd == nil)
       upallocmmupd();
    mmupd = KADDR(up->mmupd->pa);
    mmupd[PDX(va)] = pde;
}
@

%-------------------------------------------------------------------------

<<constant VPTSIZETODO>>=
#define VPTSIZE   BY2XPG
@
% 4Mo because potentially a full page dir + page tables for 4Go
% can take 4Mo (1pagedir + 1024 page table = 1025 * 4Ko = 4Mo


<<constant VPTTODO>>=
#define VPT   (KZERO-VPTSIZE)
@


<<global vpt and vpdTODO>>=
#define vpt ((ulong*)VPT)
#define VPTX(va)        (((ulong)(va))>>12)
#define vpd (vpt+VPTX(VPT))
@

<<[[mmuinit()]] vpt adjusmentsTODO>>=
    cpu->pdproto[PDX(VPT)] = PADDR(cpu->pdproto)|PTEWRITE|PTEVALID; // setup VPT
@


<<[[mmupdalloc()]] vpt adjustmentsTODO>>=
        page->va = (ulong)vpd; // needed? not part of a segment anyway no?
        mmupd[PDX(VPT)] = page->pa|PTEWRITE|PTEVALID; /* set up VPT */
@
% the page->va used to be just after newpage() in mmupdalloc, not sure it matters


<<[[putmmu()]] adjustmentsTODO>>=
    /*
     * We should be able to get through this with interrupts
     * turned on (if we get interrupted we'll just pick up 
     * where we left off) but we get many faults accessing
     * vpt[] near the end of this function, and they always happen
     * after the process has been switched out and then 
     * switched back, usually many times in a row (perhaps
     * it cannot switch back successfully for some reason).
     * 
     * In any event, I'm tired of searching for this bug.  
     * Turn off interrupts during putmmu even though
     * we shouldn't need to.        - rsc
     */
    
    s = arch_splhi();
    if(!(vpd[PDX(va)]&PTEVALID)){
        if(up->mmufree == nil){
            arch_spllo();
            page = newpage(false, nil, nilptr);
            arch_splhi();
        }
        else{
            page = up->mmufree;
            up->mmufree = page->next;
        }
        vpd[PDX(va)] = PPN(page->pa)|PTEUSER|PTEWRITE|PTEVALID;
        /* page is now mapped into the VPT - clear it */
        memset((void*)(VPT+PDX(va)*BY2PG), 0, BY2PG);
        page->daddr = PDX(va); // ???
        page->next = up->mmuused;
        up->mmuused = page;
    }

    old = vpt[VPTX(va)];
    vpt[VPTX(va)] = pa|PTEUSER|PTEVALID;

    if(old&PTEVALID)
        flushpg(va);
    if(getcr3() != up->mmupd->pa)
        print("bad cr3 %#.8lux %#.8lux\n", getcr3(), up->mmupd->pa);
    arch_splx(s);
@


<<[[checkmmu()]] pd at pt checkTODO>>=
    if(!(vpd[PDX(va)]&PTEVALID) || !(vpt[VPTX(va)]&PTEVALID))
        return;
    if(PPN(vpt[VPTX(va)]) != pa)
        print("%ld %s: va=%#08lux pa=%#08lux pte=%#08lux\n",
            up->pid, up->text,
            va, pa, vpt[VPTX(va)]);
@


<<[[vmapsync()]] va set to entryTODO>>=
    vpd[PDX(va)] = entry;
@

% in mmuinit
%    //if(0) print("vpt=%#.8ux vpd=%#p kmap=%#.8ux\n", VPT, vpd, KMAP);




\subsection{[[tmpmap()]]}

<<constant TMPADDR(x86)>>=
@

<<function tmpmap(x86)>>=
virt_addr3
tmpmap(Page *p)
{
    if(arch_islo())
        panic("tmpmap: arch_islo");
    if(p->pa < MAXKPA)
        return KADDR(p->pa);
    else
      panic("tmpmap: physical address too high");
   return nil; // unreachable
}
@

<<function tmpunmap(x86)>>=
void
tmpunmap(virt_addr3 v)
{
    if(arch_islo())
        panic("tmpmap: arch_islo");
    if((ulong)v >= KZERO)
        return;
    panic("tmpmap: physical address too high");
}
@


%-------------------------------------------------------------

<<constant TMPADDRTODO>>=
#define TMPADDR   (KZERO+0x2000)    /* used for temporary mappings */
@

<<function tmpmapTODO>>=
virt_addr3
tmpmap(Page *p)
{
    ulong i;
    ulong *entry;
    
    if(arch_islo())
        panic("tmpaddr: arch_islo");

    if(p->pa < MAXKPA)
        return KADDR(p->pa);



    /*
     * PDX(TMPADDR) == PDX(CPUADDR), so this
     * entry is private to the processor and shared 
     * between up->mmupd (if any) and cpu->pd.
     */
    entry = &vpt[VPTX(TMPADDR)];
    if(!(*entry&PTEVALID)){
        for(i=KZERO; i<=CPU0CPU; i+=BY2PG)
            print("%#p: *%#p=%#p (vpt=%#p index=%#p)\n", i, &vpt[VPTX(i)], vpt[VPTX(i)], vpt, VPTX(i));
        panic("tmpmap: no entry");
    }
    if(PPN(*entry) != PPN(TMPADDR-KZERO))
        panic("tmpmap: already mapped entry=%#.8lux", *entry);
    *entry = p->pa|PTEWRITE|PTEVALID;
    flushpg(TMPADDR);
    return (virt_addr3)TMPADDR;
}
@
%PPN = pure page number

<<function tmpunmapTODO>>=
void
tmpunmap(virt_addr3 v)
{
    ulong *entry;
    
    if(arch_islo())
        panic("tmpaddr: arch_islo");
    if((ulong)v >= KZERO && v != (void*)TMPADDR)
        return;

    if(v != (void*)TMPADDR)
        panic("tmpunmap: bad address");

    entry = &vpt[VPTX(TMPADDR)];
    if(!(*entry&PTEVALID) || PPN(*entry) == PPN(PADDR(TMPADDR)))
        panic("tmpmap: not mapped entry=%#.8lux", *entry);
    *entry = PPN(TMPADDR-KZERO)|PTEWRITE|PTEVALID;
    flushpg(TMPADDR);
}
@



\subsection{[[arch_kmap()]]}

<<struct KMap(x86)>>=
/*
 * KMap the structure doesn't exist, but the functions do.
 */
typedef struct Arch_KMap   Arch_KMap;
@
% why not void like in bcm?

<<macro VA(x86)>>=
#define VA(k)   ((virt_addr3)(k))
@



<<constant KMAPSIZE(x86)>>=
#define KMAPSIZE 0
@
<<constant KMAP(x86)>>=
#define KMAP KZERO
@

<<global kpt(x86)>>=
@

<<constant NKPT(x86)>>=
@


% start of differences and simplificiations
<<function kmap(x86)>>=
Arch_KMap*
arch_kmap(Page *p)
{
    if(up == nil)
        panic("arch_kmap: up=0 pc=%#.8lux", getcallerpc(&p));
    if(p->pa < MAXKPA)
        return KADDR(p->pa);
    else
      panic("arch_kmap: physical address too high");
    return nil; // unreachable
}
@

<<function kunmap(x86)>>=
void
arch_kunmap(Arch_KMap *k)
{
    ulong va;
    va = (ulong)k;
    flushpg(va); // not sure we need that

    if((ulong)va >= KZERO)
        return;
    panic("arch_kunmap: physical address too high");
}
@

%ulong *mmupd;
%
<<[[mmurelease()]] handle kmaptable(x86)>>=
@
%old: ???

<<[[countpagerefs()]] handle kmaptable(x86)>>=
@
%old: ???

%dead:
%<<function kmapinval(x86)>>=
%#define kmapinval()
%@
%note: if '#define kmapinval() nil' then get warning with 8c
% when do 'kmapinval();' as it expands to 'nil;'
% but if you do not put value then codegraph complains

% -----------------------------------------------------------------------

<<constant KMAPSIZETODO>>=
#define KMAPSIZE  BY2XPG
@

<<constant KMAPTODO>>=
#define KMAP    (VPT-KMAPSIZE)
@

<<global kptTODO>>=
#define kpt (vpt+VPTX(KMAP))
@
<<constant NKPTTODO>>=
#define NKPT (KMAPSIZE/BY2PG)
@


<<[[Proc]] [[Arch]] memory fieldsTODO>>=
Page* kmaptable;    /* page table used by arch_kmap */
uint  lastkmap;   /* last entry used by arch_kmap */
int nkmap;      /* number of current kmaps */
@

<<[[countpagerefs()]] handle kmaptableTODO>>=
        if(p->kmaptable){
            if(print){
                if(ref[pagenumber(p->kmaptable)])
                    iprint("page %#.8lux is proc %d (pid %lud) kmaptable\n",
                        p->kmaptable->pa, i, p->pid);
                continue;
            }
            if(ref[pagenumber(p->kmaptable)]++ == 0)
                n++;
            else
                iprint("page %#.8lux is proc %d (pid %lud) kmaptable but has other refs!\n",
                    p->kmaptable->pa, i, p->pid);
        }

@

<<[[mmurelease()]] handle kmaptableTODO>>=
    if(proc->kmaptable){
        if(proc->mmupd == nil)
            panic("arch_mmurelease: no mmupd");
        if(--proc->kmaptable->ref)
            panic("arch_mmurelease: arch_kmap ref %d", proc->kmaptable->ref);
        if(proc->nkmap)
            panic("arch_mmurelease: nkmap %d", proc->nkmap);
        /*
         * remove kmaptable from pd before putting pd up for reuse.
         */
        mmupd = tmpmap(proc->mmupd);
        if(PPN(mmupd[PDX(KMAP)]) != proc->kmaptable->pa)
            panic("arch_mmurelease: bad kmap pde %#.8lux kmap %#.8lux",
                mmupd[PDX(KMAP)], proc->kmaptable->pa);
        mmupd[PDX(KMAP)] = 0;
        tmpunmap(mmupd);
        /*
         * move kmaptable to free list.
         */
        pagechainhead(proc->kmaptable);
        proc->kmaptable = nil;
    }
@


<<function kmapTODO>>=
Arch_KMap*
arch_kmap(Page *page)
{
    int i, o, s;

    if(up == nil)
        panic("arch_kmap: up=0 pc=%#.8lux", getcallerpc(&page));
    if(up->mmupd == nil)
        upallocmmupd();
    if(up->nkmap < 0)
        panic("arch_kmap %lud %s: nkmap=%d", up->pid, up->text, up->nkmap);
    
    /*
     * Arch_Splhi shouldn't be necessary here, but paranoia reigns.
     * See comment in putmmu above.
     */
    s = arch_splhi();
    up->nkmap++;
    if(!(vpd[PDX(KMAP)]&PTEVALID)){
        /* allocate page directory */
        if(KMAPSIZE > BY2XPG)
            panic("bad kmapsize");
        if(up->kmaptable != nil)
            panic("kmaptable");
        arch_spllo();
        up->kmaptable = newpage(0, 0, 0);
        arch_splhi();
        vpd[PDX(KMAP)] = up->kmaptable->pa|PTEWRITE|PTEVALID;
        flushpg((ulong)kpt);
        memset(kpt, 0, BY2PG);
        kpt[0] = page->pa|PTEWRITE|PTEVALID;
        up->lastkmap = 0;
        arch_splx(s);
        return (Arch_KMap*)KMAP;
    }
    if(up->kmaptable == nil)
        panic("no kmaptable");
    o = up->lastkmap+1;
    for(i=0; i<NKPT; i++){
        if(kpt[(i+o)%NKPT] == 0){
            o = (i+o)%NKPT;
            kpt[o] = page->pa|PTEWRITE|PTEVALID;
            up->lastkmap = o;
            arch_splx(s);
            return (Arch_KMap*)(KMAP+o*BY2PG);
        }
    }
    panic("out of arch_kmap");
    return nil;
}
@


<<function kunmapTODO>>=
void
arch_kunmap(Arch_KMap *k)
{
    ulong va;

    va = (ulong)k;
    if(up->mmupd == nil || !(vpd[PDX(KMAP)]&PTEVALID))
        panic("arch_kunmap: no kmaps");
    if(va < KMAP || va >= KMAP+KMAPSIZE)
        panic("arch_kunmap: bad address %#.8lux pc=%#p", va, getcallerpc(&k));
    if(!(vpt[VPTX(va)]&PTEVALID))
        panic("arch_kunmap: not mapped %#.8lux pc=%#p", va, getcallerpc(&k));
    up->nkmap--;
    if(up->nkmap < 0)
        panic("arch_kunmap %lud %s: nkmap=%d", up->pid, up->text, up->nkmap);
    vpt[VPTX(va)] = 0;
    flushpg(va);
}
@


\subsection{[[vmap()]]}

% used to map framebuffer for instance. the vga driver uses it!

<<constant VMAP(x86)>>=
#define VMAP    (KMAP-VMAPSIZE)
@

<<constant VMAPSIZE(x86)>>=
#define VMAPSIZE  (0x10000000-VPTSIZE-KMAPSIZE)
@
% 256Mo, enough for big framebuffers!

% actually this is independent of vpt, tmpmap, arch_kmap

<<global vmaplock(x86)>>=
static Lock vmaplock;
@


<<function vmap(x86)>>=
/*
 * Add a device mapping to the vmap range.
 */
virt_addr3
vmap(phys_addr pa, int size)
{
    int osize;
    virt_addr va;
    ulong o;
    
    /*
     * might be asking for less than a page.
     */
    osize = size;
    o = pa & (BY2PG-1);
    pa -= o;
    size += o;

    size = ROUND(size, BY2PG);
    if(pa == 0){
        print("vmap pa=0 pc=%#p\n", getcallerpc(&pa));
        return nil;
    }
    ilock(&vmaplock);
    if((va = vmapalloc(size)) == 0 
    || pdmap(CPUS(0)->pdproto, pa|PTEUNCACHED|PTEWRITE, va, size) < 0){
        iunlock(&vmaplock);
        return nil;
    }
    iunlock(&vmaplock);
    /* avoid trap on local processor
    for(i=0; i<size; i+=4*MB)
        vmapsync(va+i);
    */
    USED(osize);
//  print("  vmap %#.8lux %d => %#.8lux\n", pa+o, osize, va+o);
    return (void*)(va + o);
}
@

<<function pdmap(x86)>>=
/*
 * Add kernel mappings for pa -> va for a section of size bytes.
 */
int
pdmap(kern_addr2 mmupd, ulong pa, virt_addr va, int size)
{
    bool pse;
    ulong pgsz;
    kern_addr2 pte, pde;
    ulong flag, off;
    
    flag = pa&0xFFF;
    pa &= ~0xFFF;

    if((CPUS(0)->cpuiddx & Pse) && (getcr4() & 0x10))
        pse = true;
    else
        pse = false;

    for(off=0; off<size; off+=pgsz){
        pde = &mmupd[PDX(va+off)];
        if((*pde&PTEVALID) && (*pde&PTESIZE))
            panic("vmap: va=%#.8lux pa=%#.8lux pde=%#.8lux",
                va+off, pa+off, *pde);

        /*
         * Check if it can be mapped using a 4MB page:
         * va, pa aligned and size >= 4MB and processor can do it.
         */
        if(pse && (pa+off)%(4*MB) == 0 && (va+off)%(4*MB) == 0 && (size-off) >= 4*MB){
            *pde = (pa+off)|flag|PTESIZE|PTEVALID;
            pgsz = 4*MB;
        }else{
            pte = mmuwalk(mmupd, va+off, 2, true);
            if(*pte&PTEVALID)
                panic("vmap: va=%#.8lux pa=%#.8lux pte=%#.8lux",
                    va+off, pa+off, *pte);
            *pte = (pa+off)|flag|PTEVALID;
            pgsz = BY2PG;
        }
    }
    return 0;
}
@



<<function findhole(x86)>>=
static int
findhole(ulong *a, int n, int count)
{
    int have, i;
    
    have = 0;
    for(i=0; i<n; i++){
        if(a[i] == 0)
            have++;
        else
            have = 0;
        if(have >= count)
            return i+1 - have;
    }
    return -1;
}
@



<<function vmapalloc(x86)>>=
/*
 * Look for free space in the vmap.
 */
static virt_addr
vmapalloc(ulong size)
{
    int i, n, o;
    // this is really a page directory base, that spans a range of pdes
    // starting to map from VMAP to VMAP+VMAPSIZE
    kern_addr2 vpdb;
    int vpdsize;
    
    vpdb = &CPUS(0)->pdproto[PDX(VMAP)];
    vpdsize = VMAPSIZE/(4*MB);

    if(size >= 4*MB){
        n = (size+4*MB-1) / (4*MB);
        if((o = findhole(vpdb, vpdsize, n)) != -1)
            return VMAP + o*4*MB;
        return nilptr;
    }

    // size <= 4MB
    n = (size+BY2PG-1) / BY2PG;
    for(i=0; i<vpdsize; i++)
        if((vpdb[i]&PTEVALID) && !(vpdb[i]&PTESIZE))
            if((o = findhole(KADDR(PPN(vpdb[i])), WD2PG, n)) != -1)
                return VMAP + i*4*MB + o*BY2PG;

    if((o = findhole(vpdb, vpdsize, 1)) != -1)
        return VMAP + o*4*MB;
        
    /*
     * could span page directory entries, but not worth the trouble.
     * not going to be very much contention.
     */
    return nilptr;
}
@

<<function vunmap(x86)>>=
/*
 * Remove a device mapping from the vmap range.
 * Since pdunmap does not remove page tables, just entries,
 * the call need not be interlocked with vmap.
 */
void
vunmap(virt_addr3 v, int size)
{
    int i;
    virt_addr va;
    ulong o;
    Cpu *nm;
    Proc *p;
    
    /*
     * might not be aligned
     */
    va = (virt_addr)v;
    o = va&(BY2PG-1);
    va -= o;
    size += o;
    size = ROUND(size, BY2PG);
    
    if(size < 0 || va < VMAP || va+size > VMAP+VMAPSIZE)
        panic("vunmap va=%#.8lux size=%#x pc=%#.8lux",
            va, size, getcallerpc(&v));

    pdunmap(CPUS(0)->pdproto, va, size);
    
    /*
     * Flush mapping from all the tlbs and copied pds.
     * This can be (and is) slow, since it is called only rarely.
     * It is possible for vunmap to be called with up == nil,
     * e.g. from the reset/init driver routines during system
     * boot. In that case it suffices to flush the CPUS(0) TLB
     * and return.
     */
    if(!active.main_reached_sched){
        putcr3(PADDR(CPUS(0)->pdproto));
        return;
    }
    for(i=0; i<conf.nproc; i++){
        p = proctab(i);
        if(p->state == Dead)
            continue;
        if(p != up)
            p->newtlb = true;
    }
    for(i=0; i<conf.ncpu; i++){
        nm = CPUS(i);
        if(nm != cpu)
            nm->flushmmu = true;
    }
    arch_flushmmu();
    for(i=0; i<conf.ncpu; i++){
        nm = CPUS(i);
        if(nm != cpu)
            while((active.cpus&(1<<nm->cpuno)) && nm->flushmmu)
                ;
    }
}
@
% >>

<<function pdunmap(x86)>>=
/*
 * Remove mappings.  Must already exist, for sanity.
 * Only used for kernel mappings, so okay to use KADDR.
 */
static void
pdunmap(kern_addr2 mmupd, virt_addr va, int size)
{
    virt_addr vae;
    kern_addr2 pde, pte;
    
    vae = va+size;
    while(va < vae){
        pde = &mmupd[PDX(va)];
        if(!(*pde & PTEVALID)){
            panic("vunmap: not mapped");
            /* 
            va = (va+4*MB-1) & ~(4*MB-1);
            continue;
            */
        }
        if(*pde & PTESIZE){
            *pde = 0;
            va = (va+4*MB-1) & ~(4*MB-1);
            continue;
        }
        pte = KADDR(PPN(*pde));
        if(!(pte[PTX(va)] & PTEVALID))
            panic("vunmap: not mapped");
        pte[PTX(va)] = 0;
        va += BY2PG;
    }
}
@

<<function vmapsync(x86)>>=
/*
 * Handle a fault by bringing vmap up to date.
 * Only copy pd entries and they never go away,
 * so no locking needed.
 */
int
vmapsync(virt_addr va)
{
    ulong pde;
    kern_addr2 mmupt;
    kern_addr2 mmupd;

    if(va < VMAP || va >= VMAP+VMAPSIZE)
        return 0;

    pde = CPUS(0)->pdproto[PDX(va)];
    if(!(pde&PTEVALID))
        return 0;
    if(!(pde&PTESIZE)){
        /* make sure entry will help the fault */
        mmupt = KADDR(PPN(pde));
        if(!(mmupt[PTX(va)]&PTEVALID))
            return 0;
    }
    <<[[vmapsync()]] va set to entry(x86)>>
    /*
     * TLB doesn't cache negative results, so no flush needed.
     */
    return 1;
}
@

\subsection{Big pages }

% pse? see code in vmap, could aspectize things
% also does vpt/vpd uses this feature? I don't think so.



\section{Real-time scheduling}

<<constants for real-time priority>>=
    PriRelease  = Npriq,  /* released edf processes */
    PriEdf    = Npriq+1,  /* active edf processes */
    PriExtra  = Npriq-1,  /* edf processes at high best-effort pri */
@

<<[[runproc()]] test for empty real-time scheduling queue>>=
runq[Nrq-1].head == nil && runq[Nrq-2].head == nil
@

<<[[runproc()]] test if p is a real-time process>>=
    if(edflock(p)){
        edfrun(p, rq == &runq[PriEdf]); /* start deadline timer and do admin */
        edfunlock();
    }
@

<<[[schedinit()]] optional real-time [[edfrecord()]]>>=
        if((e = up->edf) && (e->flags & Admitted))
            edfrecord(up);
@

<<[[schedinit()]] optional real-time [[edfstop()]]>>=
            edfstop(up);
            if (up->edf)
                free(up->edf);
            up->edf = nil;
@

<<[[ready()]] optional [[edfready()]] for real-time scheduling>>=
    if(edfready(p)){
        arch_splx(s);
        return;
    }
@


<<[[syssleep()]] optional [[edfyield()]] for real-time scheduling>>=
        if (up->edf && (up->edf->flags & Admitted))
            edfyield();
        else
@

<<[[procctlreq()]] optional real-time commands>>=
    /* real time */
    case CMperiod:
        if(p->edf == nil)
            edfinit(p);
        if(e=parsetime(&time, cb->f[1]))    /* time in ns */
            error(e);
        edfstop(p);
        p->edf->T = time/1000;  /* Edf times are in microseconds */
        break;
    case CMdeadline:
        if(p->edf == nil)
            edfinit(p);
        if(e=parsetime(&time, cb->f[1]))
            error(e);
        edfstop(p);
        p->edf->D = time/1000;
        break;
    case CMcost:
        if(p->edf == nil)
            edfinit(p);
        if(e=parsetime(&time, cb->f[1]))
            error(e);
        edfstop(p);
        p->edf->C = time/1000;
        break;
    case CMsporadic:
        if(p->edf == nil)
            edfinit(p);
        p->edf->flags |= Sporadic;
        break;
    case CMdeadlinenotes:
        if(p->edf == nil)
            edfinit(p);
        p->edf->flags |= Sendnotes;
        break;
    case CMadmit:
        if(p->edf == 0)
            error("edf params");
        if(e = edfadmit(p))
            error(e);
        break;
    case CMextra:
        if(p->edf == nil)
            edfinit(p);
        p->edf->flags |= Extratime;
        break;
    case CMexpel:
        if(p->edf)
            edfstop(p);
        break;

@

<<[[sched()]] optional guard for real-time process>>=
    if(!p->edf)
@

<<[[pexit()]] optional [[edfstop()]] for real-time scheduling>>=
    edfstop(up);
@


<<[[Proc]] scheduling fields>>=
<<[[Proc]] optional [[edf]] field for real-time scheduling>>
@ 

% seems dead field
<<[[Proc]] scheduling fields>>=
ulong readytime;  /* time process came ready */
@
%dead? uchar yield;    /* non-zero if the process just did a sleep(0) */
%dead? ulong movetime; /* last time process switched processors */



<<[[Proc]] optional [[edf]] field for real-time scheduling>>=
// option<ref_own?<edf>>
Edf *edf; /* if non-null, real-time proc, edf contains scheduling params */
@

<<[[lock()]] optional priority-inversion for real-time process>>=
            if(conf.ncpu < 2 && up && up->edf && (up->edf->flags & Admitted)){
                /*
                 * Priority inversion, yield on a uniprocessor; on a
                 * multiprocessor, the other processor will unlock
                 */
                print("inversion %#p pc %#lux proc %lud held by pc %#lux proc %lud\n",
                    l, pc, up ? up->pid : 0, l->pc, l->p ? l->p->pid : 0);
                up->edf->d = todget(nil);   /* yield to process with lock */
            }
@




<<enum edfflags>>=
enum edfflags 
{
    /* Edf.flags field */
    Admitted    = 0x01,
    Sporadic    = 0x02,
    Yieldonblock    = 0x04,
    Sendnotes   = 0x08,
    Deadline    = 0x10,
    Yield     = 0x20,
    Extratime   = 0x40,
};
@ 


<<struct Edf>>=
struct Edf {
    /* All times in µs */
    /* time intervals */
    long    D;    /* Deadline */
    long    Delta;    /* Inherited deadline */
    long    T;    /* period */
    long    C;    /* Cost */
    long    S;    /* Slice: time remaining in this period */
    /* times (only low-order bits of absolute time) */
    long    r;    /* (this) release time */
    long    d;    /* (this) deadline */
    long    t;    /* Start of next period, t += T at release */
    long    s;    /* Time at which this proc was last scheduled */
  
    /* for schedulability testing */
    long    testDelta;
    int   testtype; /* Release or Deadline */
    long    testtime;
    Proc    *testnext;
  
    /* other */
    // set<enum<edfflags>>
    ushort    flags;
  
    Timer;
  
    /* Stats */
    long    edfused;
    long    extraused;
    long    aged;
    ulong   periods;
    ulong   missed;
};
@ 


\subsection*{[[processes/edf.c]]}

\ifallcode
<<edf.c debugging macro>>=
enum {
    Dontprint = true,
};
#define DPRINT  if(!Dontprint) print
@ 
\fi



<<edf.c statistics>>=
/* Statistics stuff */
ulong       edfnrun;
//ulong     nilcount;
//ulong     scheds;
//int       misseddeadlines;
@ 

<<enum procstate cases>>=
Waitrelease, // for real-time scheduling
@ 

<<edf.c>>=
/* EDF scheduling */
<<kernel basic includes>>

#include    <trace.h>

// in proc.c
extern Schedq   runq[Nrq];
extern ulong    delayedscheds;
extern int  nrdy;
extern ulong    runvec;
// in devcons.c
extern int panicking; 
// used to be in edf.h
//unused: extern Lock edftestlock;  /* for atomic admitting/expelling */

<<edf.c debugging macro>>

enum 
{
    Maxsteps = 200 * 100 * 2, /* 100 periods of 200 procs */
};


static long now;    /* Low order 32 bits of time in µs */


<<edf.c statistics>>

int     edfinited;

/* Edfschedlock protects modification of admission params */
QLock       edfschedlock;
static Lock thelock;

enum{
    Dl, /* Invariant for schedulability test: Dl < Rl */
    Rl,
};

static char *testschedulability(Proc*);
static Proc *qschedulability;

enum {
    Onemicrosecond =    1,
    Onemillisecond =    1000,
    Onesecond =     1000000,
    OneRound =      Onemillisecond/2,
};

static int
timeconv(Fmt *f)
{
    char buf[128], *sign;
    vlong t;

    buf[0] = 0;
    switch(f->r) {
    case 'U':
        t = va_arg(f->args, uvlong);
        break;
    case 't':           /* vlong in nanoseconds */
        t = va_arg(f->args, long);
        break;
    default:
        return fmtstrcpy(f, "(timeconv)");
    }
    if (t < 0) {
        sign = "-";
        t = -t;
    }
    else
        sign = "";
    if (t > Onesecond){
        t += OneRound;
        snprint(buf, sizeof buf, "%s%d.%.3ds", sign,
            (int)(t / Onesecond),
            (int)(t % Onesecond)/Onemillisecond);
    }else if (t > Onemillisecond)
        snprint(buf, sizeof buf, "%s%d.%.3dms", sign,
            (int)(t / Onemillisecond), (int)(t % Onemillisecond));
    else
        snprint(buf, sizeof buf, "%s%dµs", sign, (int)t);
    return fmtstrcpy(f, buf);
}

#ifdef EDFCYCLES
long edfcycles;
#endif

Edf*
edflock(Proc *p)
{
    Edf *e;

    if (p->edf == nil)
        return nil;
    ilock(&thelock);
    if((e = p->edf) && (e->flags & Admitted)){
        thelock.pc = getcallerpc(&p);
#ifdef EDFCYCLES
        edfcycles -= lcycles();
#endif
        now = arch_us();
        return e;
    }
    iunlock(&thelock);
    return nil;
}

void
edfunlock(void)
{

#ifdef EDFCYCLES
    edfcycles += lcycles();
#endif
    edfnrun++;
    iunlock(&thelock);
}

void
edfinit(Proc* p)
{
    if(!edfinited){
        fmtinstall('t', timeconv);
        edfinited++;
    }
    now = arch_us();
    DPRINT("%lud edfinit %lud[%s]\n", now, p->pid, statename[p->state]);
    p->edf = malloc(sizeof(Edf));
    if(p->edf == nil)
        error(Enomem);
    return;
}

static void
deadlineintr(Ureg*, Timer *t)
{
    /* Proc reached deadline */
    Proc *p;
    void (*pt)(Proc*, int, vlong);

    if(panicking || active.exiting)
        return;

    p = t->ta;
    now = arch_us();
    DPRINT("%lud deadlineintr %lud[%s]\n", now, p->pid, statename[p->state]);
    /* If we're interrupting something other than the proc pointed to by t->a,
     * we've already achieved recheduling, so we need not do anything
     * Otherwise, we must cause a reschedule, but if we call sched()
     * here directly, the timer interrupt routine will not finish its business
     * Instead, we cause the resched to happen when the interrupted proc
     * returns to user space
     */
    if(p == up){
        if(up->trace && (pt = proctrace))
            pt(up, SInts, 0);
        up->delaysched++;
        delayedscheds++;
    }
}

static void
release(Proc *p)
{
    /* Called with edflock held */
    Edf *e;
    void (*pt)(Proc*, int, vlong);
    long n;
    vlong nowns;

    e = p->edf;
    e->flags &= ~Yield;
    if(e->d - now < 0){
        e->periods++;
        e->r = now;
        if((e->flags & Sporadic) == 0){
            /*
             * Non sporadic processes stay true to their period;
             * calculate next release time.
             * Second test limits duration of while loop.
             */
            if((n = now - e->t) > 0){
                if(n < e->T)
                    e->t += e->T;
                else
                    e->t = now + e->T - (n % e->T);
            }
        }else{
            /* Sporadic processes may not be released earlier than
             * one period after this release
             */
            e->t = e->r + e->T;
        }
        e->d = e->r + e->D;
        e->S = e->C;
        DPRINT("%lud release %lud[%s], r=%lud, d=%lud, t=%lud, S=%lud\n",
            now, p->pid, statename[p->state], e->r, e->d, e->t, e->S);
        if(pt = proctrace){
            nowns = todget(nil);
            pt(p, SRelease, nowns);
            pt(p, SDeadline, nowns + 1000LL*e->D);
        }
    }else{
        DPRINT("%lud release %lud[%s], too late t=%lud, called from %#p\n",
            now, p->pid, statename[p->state], e->t, getcallerpc(&p));
    }
}

static void
releaseintr(Ureg*, Timer *t)
{
    Proc *p;
    Schedq *rq;

    if(panicking || active.exiting)
        return;

    p = t->ta;
    if((edflock(p)) == nil)
        return;
    DPRINT("%lud releaseintr %lud[%s]\n", now, p->pid, statename[p->state]);
    switch(p->state){
    default:
        edfunlock();
        return;
    case Ready:
        /* remove proc from current runq */
        rq = &runq[p->priority];
        if(dequeueproc(rq, p) != p){
            DPRINT("releaseintr: can't find proc or lock race\n");
            release(p); /* It'll start best effort */
            edfunlock();
            return;
        }
        p->state = Waitrelease;
        /* fall through */
    case Waitrelease:
        release(p);
        edfunlock();
        if(p->state == Wakeme){
            iprint("releaseintr: wakeme\n");
        }
        ready(p);
        if(up){
            up->delaysched++;
            delayedscheds++;
        }
        return;
    case Running:
        release(p);
        edfrun(p, 1);
        break;
    case Wakeme:
        release(p);
        edfunlock();
        if(p->trend)
            wakeup(p->trend);
        p->trend = nil;
        if(up){
            up->delaysched++;
            delayedscheds++;
        }
        return;
    }
    edfunlock();
}

void
edfrecord(Proc *p)
{
    long used;
    Edf *e;
    void (*pt)(Proc*, int, vlong);

    if((e = edflock(p)) == nil)
        return;
    used = now - e->s;
    if(e->d - now <= 0)
        e->edfused += used;
    else
        e->extraused += used;
    if(e->S > 0){
        if(e->S <= used){
            if(pt = proctrace)
                pt(p, SSlice, 0);
            DPRINT("%lud edfrecord slice used up\n", now);
            e->d = now;
            e->S = 0;
        }else
            e->S -= used;
    }
    e->s = now;
    edfunlock();
}

void
edfrun(Proc *p, int edfpri)
{
    Edf *e;
    void (*pt)(Proc*, int, vlong);
    long tns;

    e = p->edf;
    /* Called with edflock held */
    if(edfpri){
        tns = e->d - now;
        if(tns <= 0 || e->S == 0){
            /* Deadline reached or resources exhausted,
             * deschedule forthwith
             */
            p->delaysched++;
            delayedscheds++;
            e->s = now;
            return;
        }
        if(e->S < tns)
            tns = e->S;
        if(tns < 20)
            tns = 20;
        e->tns = 1000LL * tns;  /* µs to ns */
        if(e->tt == nil || e->tf != deadlineintr){
            DPRINT("%lud edfrun, deadline=%lud\n", now, tns);
        }else{
            DPRINT("v");
        }
        if(p->trace && (pt = proctrace))
            pt(p, SInte, todget(nil) + e->tns);
        e->tmode = Trelative;
        e->tf = deadlineintr;
        e->ta = p;
        timeradd(e);
    }else{
        DPRINT("<");
    }
    e->s = now;
}

char *
edfadmit(Proc *p)
{
    char *err;
    Edf *e;
    int i;
    Proc *r;
    void (*pt)(Proc*, int, vlong);
    long tns;

    e = p->edf;
    if (e->flags & Admitted)
        return "task state";    /* should never happen */

    /* simple sanity checks */
    if (e->T == 0)
        return "T not set";
    if (e->C == 0)
        return "C not set";
    if (e->D > e->T)
        return "D > T";
    if (e->D == 0)  /* if D is not set, set it to T */
        e->D = e->T;
    if (e->C > e->D)
        return "C > D";

    qlock(&edfschedlock);
    if (err = testschedulability(p)){
        qunlock(&edfschedlock);
        return err;
    }
    e->flags |= Admitted;

    edflock(p);

    if(p->trace && (pt = proctrace))
        pt(p, SAdmit, 0);

    /* Look for another proc with the same period to synchronize to */
    SET(r);
    for(i=0; i<conf.nproc; i++) {
        r = proctab(i);
        if(r->state == Dead || r == p)
            continue;
        if (r->edf == nil || (r->edf->flags & Admitted) == 0)
            continue;
        if (r->edf->T == e->T)
                break;
    }
    if (i == conf.nproc){
        /* Can't synchronize to another proc, release now */
        e->t = now;
        e->d = 0;
        release(p);
        if (p == up){
            DPRINT("%lud edfadmit self %lud[%s], release now: r=%lud d=%lud t=%lud\n",
                now, p->pid, statename[p->state], e->r, e->d, e->t);
            /* We're already running */
            edfrun(p, 1);
        }else{
            /* We're releasing another proc */
            DPRINT("%lud edfadmit other %lud[%s], release now: r=%lud d=%lud t=%lud\n",
                now, p->pid, statename[p->state], e->r, e->d, e->t);
            p->ta = p;
            edfunlock();
            qunlock(&edfschedlock);
            releaseintr(nil, p);
            return nil;
        }
    }else{
        /* Release in synch to something else */
        e->t = r->edf->t;
        if (p == up){
            DPRINT("%lud edfadmit self %lud[%s], release at %lud\n",
                now, p->pid, statename[p->state], e->t);
            edfunlock();
            qunlock(&edfschedlock);
            return nil;
        }else{
            DPRINT("%lud edfadmit other %lud[%s], release at %lud\n",
                now, p->pid, statename[p->state], e->t);
            if(e->tt == nil){
                e->tf = releaseintr;
                e->ta = p;
                tns = e->t - now;
                if(tns < 20)
                    tns = 20;
                e->tns = 1000LL * tns;
                e->tmode = Trelative;
                timeradd(e);
            }
        }
    }
    edfunlock();
    qunlock(&edfschedlock);
    return nil;
}

void
edfstop(Proc *p)
{
    Edf *e;
    void (*pt)(Proc*, int, vlong);

    if(e = edflock(p)){
        DPRINT("%lud edfstop %lud[%s]\n", now, p->pid, statename[p->state]);
        if(p->trace && (pt = proctrace))
            pt(p, SExpel, 0);
        e->flags &= ~Admitted;
        if(e->tt)
            timerdel(e);
        edfunlock();
    }
}

static int
yfn(void *)
{
    now = arch_us();
    return up->trend == nil || now - up->edf->r >= 0;
}

void
edfyield(void)
{
    /* sleep until next release */
    Edf *e;
    void (*pt)(Proc*, int, vlong);
    long n;

    if((e = edflock(up)) == nil)
        return;
    if(up->trace && (pt = proctrace))
        pt(up, SYield, 0);
    if((n = now - e->t) > 0){
        if(n < e->T)
            e->t += e->T;
        else
            e->t = now + e->T - (n % e->T);
    }
    e->r = e->t;
    e->flags |= Yield;
    e->d = now;
    if (up->tt == nil){
        n = e->t - now;
        if(n < 20)
            n = 20;
        up->tns = 1000LL * n;
        up->tf = releaseintr;
        up->tmode = Trelative;
        up->ta = up;
        up->trend = &up->sleepr;
        timeradd(up);
    }else if(up->tf != releaseintr)
        print("edfyield: surprise! %#p\n", up->tf);
    edfunlock();
    sleep(&up->sleepr, yfn, nil);
}

int
edfready(Proc *p)
{
    Edf *e;
    Schedq *rq;
    Proc *l, *pp;
    void (*pt)(Proc*, int, vlong);
    long n;

    if((e = edflock(p)) == nil)
        return 0;

    if(p->state == Wakeme && p->r){
        iprint("edfready: wakeme\n");
    }
    if(e->d - now <= 0){
        /* past deadline, arrange for next release */
        if((e->flags & Sporadic) == 0){
            /*
             * Non sporadic processes stay true to their period;
             * calculate next release time.
             */
            if((n = now - e->t) > 0){
                if(n < e->T)
                    e->t += e->T;
                else
                    e->t = now + e->T - (n % e->T);
            }
        }
        if(now - e->t < 0){
            /* Next release is in the future, schedule it */
            if(e->tt == nil || e->tf != releaseintr){
                n = e->t - now;
                if(n < 20)
                    n = 20;
                e->tns = 1000LL * n;
                e->tmode = Trelative;
                e->tf = releaseintr;
                e->ta = p;
                timeradd(e);
                DPRINT("%lud edfready %lud[%s], release=%lud\n",
                    now, p->pid, statename[p->state], e->t);
            }
            if(p->state == Running && (e->flags & (Yield|Yieldonblock)) == 0 && (e->flags & Extratime)){
                /* If we were running, we've overrun our CPU allocation
                 * or missed the deadline, continue running best-effort at low priority
                 * Otherwise we were blocked.  If we don't yield on block, we continue
                 * best effort
                 */
                DPRINT(">");
                p->basepri = PriExtra;
                p->fixedpri = 1;
                edfunlock();
                return 0;   /* Stick on runq[PriExtra] */
            }
            DPRINT("%lud edfready %lud[%s] wait release at %lud\n",
                now, p->pid, statename[p->state], e->t);
            p->state = Waitrelease;
            edfunlock();
            return 1;   /* Make runnable later */
        }
        DPRINT("%lud edfready %lud %s release now\n", now, p->pid, statename[p->state]);
        /* release now */
        release(p);
    }
    edfunlock();
    DPRINT("^");
    rq = &runq[PriEdf];
    /* insert in queue in earliest deadline order */
    lock(runq);
    l = nil;
    for(pp = rq->head; pp; pp = pp->rnext){
        if(pp->edf->d > e->d)
            break;
        l = pp;
    }
    p->rnext = pp;
    if (l == nil)
        rq->head = p;
    else
        l->rnext = p;
    if(pp == nil)
        rq->tail = p;
    rq->n++;
    nrdy++;
    runvec |= 1 << PriEdf;
    p->priority = PriEdf;
    p->readytime = cpu->ticks;
    p->state = Ready;
    unlock(runq);
    if(p->trace && (pt = proctrace))
        pt(p, SReady, 0);
    return 1;
}


static void
testenq(Proc *p)
{
    Proc *xp, **xpp;
    Edf *e;

    e = p->edf;
    e->testnext = nil;
    if (qschedulability == nil) {
        qschedulability = p;
        return;
    }
    SET(xp);
    for (xpp = &qschedulability; *xpp; xpp = &xp->edf->testnext) {
        xp = *xpp;
        if (e->testtime - xp->edf->testtime < 0
        || (e->testtime == xp->edf->testtime && e->testtype < xp->edf->testtype)){
            e->testnext = xp;
            *xpp = p;
            return;
        }
    }
    assert(xp->edf->testnext == nil);
    xp->edf->testnext = p;
}

static char *
testschedulability(Proc *theproc)
{
    Proc *p;
    long H, G, Cb, ticks;
    int steps, i;

    /* initialize */
    DPRINT("schedulability test %lud\n", theproc->pid);
    qschedulability = nil;
    for(i=0; i<conf.nproc; i++) {
        p = proctab(i);
        if(p->state == Dead)
            continue;
        if ((p->edf == nil || (p->edf->flags & Admitted) == 0) && p != theproc)
            continue;
        p->edf->testtype = Rl;
        p->edf->testtime = 0;
        DPRINT("\tInit: edfenqueue %lud\n", p->pid);
        testenq(p);
    }
    H=0;
    G=0;
    for(steps = 0; steps < Maxsteps; steps++){
        p = qschedulability;
        qschedulability = p->edf->testnext;
        ticks = p->edf->testtime;
        switch (p->edf->testtype){
        case Dl:
            H += p->edf->C;
            Cb = 0;
            DPRINT("\tStep %3d, Ticks %lud, pid %lud, deadline, H += %lud → %lud, Cb = %lud\n",
                steps, ticks, p->pid, p->edf->C, H, Cb);
            if (H+Cb>ticks){
                DPRINT("not schedulable\n");
                return "not schedulable";
            }
            p->edf->testtime += p->edf->T - p->edf->D;
            p->edf->testtype = Rl;
            testenq(p);
            break;
        case Rl:
            DPRINT("\tStep %3d, Ticks %lud, pid %lud, release, G  %lud, C%lud\n",
                steps, ticks, p->pid, p->edf->C, G);
            if(ticks && G <= ticks){
                DPRINT("schedulable\n");
                return nil;
            }
            G += p->edf->C;
            p->edf->testtime += p->edf->D;
            p->edf->testtype = Dl;
            testenq(p);
            break;
        default:
            assert(0);
        }
    }
    DPRINT("probably not schedulable\n");
    return "probably not schedulable";
}
@

% >>


\section{Power management (x86)}

%<<[[Dev]] methods>>=
%void  (*power)(bool);  /* power mgt: power(1) => on, power (0) => off */
%@
% but does not seem called by anything
% dead?

% used by apm.c
<<constant x86 other segments>>=
//#define APMCSEG   6 /* APM code segment */
//#define APMCSEG16 7 /* APM 16-bit code segment */
//#define APMDSEG   8 /* APM data segment */
/* #define  APM40SEG  8 /* APM segment 0x40 */
@


<<constant x86 other segment selectors>>=
//#define APMCSEL   SELECTOR(APMCSEG, SELGDT, 0)
//#define APMCSEL16 SELECTOR(APMCSEG16, SELGDT, 0)
//#define APMDSEL   SELECTOR(APMDSEG, SELGDT, 0)
/* #define  APM40SEL  SELECTOR(APM40SEG, SELGDT, 0) */
@


<<[[PCArch]] power methods fields(x86)>>=
int (*serialpower)(int);  /* 1 == on, 0 == off */
int (*modempower)(int); /* 1 == on, 0 == off */
@

<<[[archgeneric]] power methods(x86)>>=
    .serialpower=   unimplemented,
    .modempower=    unimplemented,
@

<<function unimplemented(x86)>>=
static int
unimplemented(int)
{
    return 0;
}
@


\section{Security}

<<global eve>>=
char    *eve;
@


<<function iseve>>=
bool iseve(void) { 
  return strcmp(eve, up->user) == 0; 
}
@

<<systab security syscalls>>=
[FAUTH]     sysfauth,
[FVERSION]  sysfversion,
@ 


<<global hostdomain>>=
char    hostdomain[DOMLEN];
@ 


<<syscall fversion>>=
long
sysfversion(ulong *arg)
{
    char *vers;
    uint arglen, m, msize;
    Chan *c;

    msize = arg[1];
    vers = (char*)arg[2];
    arglen = arg[3];
    validaddr(arg[2], arglen, true);
    /* check there's a NUL in the version string */
    if(arglen==0 || memchr(vers, 0, arglen)==0)
        error(Ebadarg);
    c = fdtochan(arg[0], ORDWR, false, true);
    if(waserror()){
        cclose(c);
        nexterror();
    }

    m = mntversion(c, vers, msize, arglen);

    cclose(c);
    poperror();
    return m;
}
@ 


<<syscall fauth>>=
long
sysfauth(ulong *arg)
{
    Chan *c, *ac;
    char *aname;
    int fd;

    validaddr(arg[1], 1, false);
    aname = validnamedup((char*)arg[1], true);
    if(waserror()){
        free(aname);
        nexterror();
    }
    c = fdtochan(arg[0], ORDWR, false, true);
    if(waserror()){
        cclose(c);
        nexterror();
    }

    ac = mntauth(c, aname);
    /* at this point ac is responsible for keeping c alive */
    poperror(); /* c */
    cclose(c);
    poperror(); /* aname */
    free(aname);

    if(waserror()){
        cclose(ac);
        nexterror();
    }

    fd = newfd(ac);
    if(fd < 0)
        error(Enofd);
    poperror(); /* ac */

    /* always mark it close on exec */
    ac->flag |= CCEXEC;

    return fd;
}
@ 


<<function userwrite>>=
/*
 *  called by devcons() for user device
 *
 *  anyone can become none
 */
long
userwrite(char *a, int n)
{
    if(n!=4 || strncmp(a, "none", 4)!=0)
        error(Eperm);
    kstrdup(&up->user, "none");
    up->basepri = PriNormal;
    return n;
}
@ 




<<function hostdomainwrite>>=
long
hostdomainwrite(char *a, int n)
{
    char buf[DOMLEN];

    if(!iseve())
        error(Eperm);
    if(n >= DOMLEN)
        error(Ebadarg);
    memset(buf, 0, DOMLEN);
    strncpy(buf, a, n);
    if(buf[0] == 0)
        error(Ebadarg);
    memmove(hostdomain, buf, DOMLEN);
    return n;
}
@ 

\section{Network}
% put also RPC and devmnt here?
% \book{Network}


\section{Fileservers}

% devmnt.c, devsrv.c

\subsection{[[Mnt]]}

<<struct Mnt>>=
struct Mnt
{
  Lock;
  /* references are counted using c->ref; channels on this mount point incref(c->mchan) == Mnt.c */
  Chan  *c;   /* Channel to file service */
  Proc  *rip;   /* Reader in progress */
  Mntrpc  *queue;   /* Queue of pending requests on this channel */
  ulong id;   /* Multiplexer id for channel check */
  Mnt *list;    /* Free list */
  int flags;    /* cache */
  int msize;    /* data + IOHDRSZ */
  char  *version; /* 9P version */
  Queue *q;   /* input queue */
};
@

<<struct Mntalloc>>=
/*
 * References are managed as follows:
 * The channel to the server - a network connection or pipe - has one
 * reference for every Chan open on the server.  The server channel has
 * c->mux set to the Mnt used for muxing control to that server.  Mnts
 * have no reference count; they go away when c goes away.
 * Each channel derived from the mount point has mchan set to c,
 * and increfs/decrefs mchan to manage references on the server
 * connection.
 */
struct Mntalloc
{
    Mnt*    list;       /* Mount devices in use */
    Mnt*    mntfree;    /* Free list */
    Mntrpc* rpcfree;
    int nrpcfree;
    int nrpcused;
    ulong   id;
    ulong   tagmask[NMASK];

    // extra
    Lock;

};
@

<<global mntalloc>>=
struct Mntalloc mntalloc;
@

<<constants tags>>=
enum
{
    TAGSHIFT = 5,           /* ulong has to be 32 bits */
    TAGMASK = (1<<TAGSHIFT)-1,
    NMASK = (64*1024)>>TAGSHIFT,
};
@

<<function freetag>>=
void
freetag(int t)
{
    mntalloc.tagmask[t>>TAGSHIFT] &= ~(1<<(t&TAGMASK));
}
@

% >>

<<function mntfree>>=
void
mntfree(Mntrpc *r)
{
    if(r->b != nil)
        freeblist(r->b);
    lock(&mntalloc);
    if(mntalloc.nrpcfree >= 10){
        free(r->rpc);
        freetag(r->request.tag);
        free(r);
    }
    else{
        r->list = mntalloc.rpcfree;
        mntalloc.rpcfree = r;
        mntalloc.nrpcfree++;
    }
    mntalloc.nrpcused--;
    unlock(&mntalloc);
}
@

<<function mntpntfree>>=
void
mntpntfree(Mnt *m)
{
    Mnt *f, **l;
    Queue *q;

    lock(&mntalloc);
    l = &mntalloc.list;
    for(f = *l; f; f = f->list) {
        if(f == m) {
            *l = m->list;
            break;
        }
        l = &f->list;
    }
    m->list = mntalloc.mntfree;
    mntalloc.mntfree = m;
    q = m->q;
    unlock(&mntalloc);

    qfree(q);
}
@


<<function muxclose>>=
void
muxclose(Mnt *m)
{
    Mntrpc *q, *r;

    for(q = m->queue; q; q = r) {
        r = q->list;
        mntfree(q);
    }
    m->id = 0;
    free(m->version);
    m->version = nil;
    mntpntfree(m);
}
@






\subsection{[[MntRpc]]}

<<struct Mntrpc>>=
struct Mntrpc
{
  Chan* c;    /* Channel for whom we are working */
  Mntrpc* list;   /* Free/pending list */
  Fcall request;  /* Outgoing file system protocol message */
  Fcall   reply;    /* Incoming reply */
  Mnt*  m;    /* Mount device during rpc */
  Rendez  r;    /* Place to hang out */
  byte*  rpc;    /* I/O Data buffer */
  uint  rpclen;   /* len of buffer */
  Block *b;   /* reply blocks */
  char  done;   /* Rpc completed */
  uvlong  stime;    /* start time for mnt statistics */
  ulong reqlen;   /* request length for mnt statistics */
  ulong replen;   /* reply length for mnt statistics */
  Mntrpc* flushed;  /* message this one flushes */
};
@


\section{Graphics}
% \book{Graphics}


\chapter{Special Fileservers}

\section{[[Cmdtab]]}

% kind of replacment for ioctl

<<struct Cmdtab>>=
struct Cmdtab
{
  int index;  /* used by client to switch on result */
  char  *cmd; /* command name */
  int narg; /* expected #args; 0 ==> variadic */
};
@

<<struct Cmdbuf>>=
struct Cmdbuf
{
  char  *buf;
  char  **f;
  int nf;
};
@

<<function parsecmd>>=
/*
 *  parse a command written to a device
 */
Cmdbuf*
parsecmd(char *p, int n)
{
    Cmdbuf *volatile cb;
    int nf;
    char *sp;

    nf = ncmdfield(p, n);

    /* allocate Cmdbuf plus string pointers plus copy of string including \0 */
    sp = smalloc(sizeof(*cb) + nf * sizeof(char*) + n + 1);
    cb = (Cmdbuf*)sp;
    cb->f = (char**)(&cb[1]);
    cb->buf = (char*)(&cb->f[nf]);

    if(up!=nil && waserror()){
        free(cb);
        nexterror();
    }
    memmove(cb->buf, p, n);
    if(up != nil)
        poperror();

    /* dump new line and null terminate */
    if(n > 0 && cb->buf[n-1] == '\n')
        n--;
    cb->buf[n] = '\0';

    cb->nf = tokenize(cb->buf, cb->f, nf-1);
    cb->f[cb->nf] = nil;

    return cb;
}
@


<<function cmderror>>=
/*
 * Reconstruct original message, for error diagnostic
 */
void
cmderror(Cmdbuf *cb, char *s)
{
    int i;
    char *p, *e;

    p = up->genbuf;
    e = p+ERRMAX-10;
    p = seprint(p, e, "%s \"", s);
    for(i=0; i<cb->nf; i++){
        if(i > 0)
            p = seprint(p, e, " ");
        p = seprint(p, e, "%q", cb->f[i]);
    }
    strcpy(p, "\"");
    error(up->genbuf);
}
@


<<function lookupcmd>>=
/*
 * Look up entry in table
 */
Cmdtab*
lookupcmd(Cmdbuf *cb, Cmdtab *ctab, int nctab)
{
    int i;
    Cmdtab *ct;

    if(cb->nf == 0)
        error("empty control message");

    for(ct = ctab, i=0; i<nctab; i++, ct++){
        if(strcmp(ct->cmd, "*") !=0)    /* wildcard always matches */
        if(strcmp(ct->cmd, cb->f[0]) != 0)
            continue;
        if(ct->narg != 0 && ct->narg != cb->nf)
            cmderror(cb, Ecmdargs);
        return ct;
    }

    cmderror(cb, "unknown control message");
    return nil;
}
@

<<ncmdfield>>=
/*
 * Generous estimate of number of fields, including terminal nil pointer
 */
static int
ncmdfield(char *p, int n)
{
    int white, nwhite;
    char *ep;
    int nf;

    if(p == nil)
        return 1;

    nf = 0;
    ep = p+n;
    white = 1;  /* first text will start field */
    while(p < ep){
        nwhite = (strchr(" \t\r\n", *p++ & 0xFF) != 0); /* UTF is irrelevant */
        if(white && !nwhite)    /* beginning of field */
            nf++;
        white = nwhite;
    }
    return nf+1;    /* +1 for nil */
}
@



\section{[[/env/]]}
%kind of an IPC? at least can communicate info from parent to child

% in every langage globals are a convenient way to transmit info
% from function down the line. Same here. except done in a universal
% way.

\subsection{[[Egrp]]}

<<struct Evalue>>=
struct Evalue
{
  // string
  char  *name;
  // option<array<byte>, usually a string but can be something else
  byte  *value;
  // nelem(Evalue.value), 
  int len;

  Qid qid;
};
@


<<struct Egrp>>=
struct Egrp
{
  // array<ref_counted<Evalue>>
  Evalue  **ent;
  // used entries, <= ment
  int nent;
  // nelem(Egrp.ent), malloc'ed entries
  int ment; 

  ulong path; /* qid.path of next Evalue to be allocated */
  ulong vers; /* of Egrp */

  // extra
  Ref;
  RWlock;
};
@

<<[[Proc]] other fields>>=
// ref_counted<Egrp>
Egrp  *egrp;    /* Environment group */
@

<<function closeegrp>>=
void
closeegrp(Egrp *eg)
{
    int i;
    Evalue *e;

    if(decref(eg) == 0){
        for(i=0; i<eg->nent; i++){
            e = eg->ent[i];
            free(e->name);
            if(e->value)
                free(e->value);
            free(e);
        }
        free(eg->ent);
        free(eg);
    }
}
@

<<function envcpy>>=
void
envcpy(Egrp *to, Egrp *from)
{
    int i;
    Evalue *ne, *e;

    rlock(from);
    to->ment = (from->nent+31)&~31;
    to->ent = smalloc(to->ment*sizeof(to->ent[0]));
    for(i=0; i<from->nent; i++){
        e = from->ent[i];
        ne = smalloc(sizeof(Evalue));
        ne->name = smalloc(strlen(e->name)+1);
        strcpy(ne->name, e->name);
        if(e->value){
            ne->value = smalloc(e->len);
            memmove(ne->value, e->value, e->len);
            ne->len = e->len;
        }
        ne->qid.path = ++to->path;
        to->ent[i] = ne;
    }
    to->nent = from->nent;
    runlock(from);
}
@

% could <<[[Chan]] union other fields>>=
%  Egrp *egrp; // for chan of devenv
%

% /env/pid vs /dev/pid?

\subsection{[[/env/]]}

%#e
<<function ksetenv>>=
/*
 *  to let the kernel set environment variables
 */
void
ksetenv(char *ename, char *eval, bool conf)
{
    Chan *c;
    char buf[2*KNAMELEN];
    
    snprint(buf, sizeof(buf), "#e%s/%s", conf?"c":"", ename);
    c = namec(buf, Acreate, OWRITE, 0600);
    devtab[c->type]->write(c, eval, strlen(eval), 0);
    cclose(c);
}
@
% no waserror?


<<global envdevtab>>=
Dev envdevtab = {
    .dc       =    'e',
    .name     =    "env",
               
    .reset    =    devreset,
    .init     =    devinit,
    .shutdown =    devshutdown,
    .attach   =    envattach,
    .walk     =    envwalk,
    .stat     =    envstat,
    .open     =    envopen,
    .create   =    envcreate,
    .close    =    envclose,
    .read     =    envread,
    .bread    =    devbread,
    .write    =    envwrite,
    .bwrite   =    devbwrite,
    .remove   =    envremove,
    .wstat    =    devwstat,
};
@

% put LP split of devenv.c here

\section{[[/proc/]]}
%#p

\subsection{[[/proc/x/ctl]]}

\subsection{[[/proc/x/mem]]}

\subsection{[[/proc/x/status]]}

\subsection{[[/proc/x/args]]}

\subsection{Other [[/proc/x/xxx]]}

\subsection{XXX}

<<[[Proc]] other fields>>=
ulong procmode; /* proc device default file mode */
@
% typedef openmode? perm?


<<[[Proc]] other fields>>=
bool privatemem; /* proc does not let anyone read mem */
@

<<[[procctlreq()]] CMprivate case>>=
case CMprivate:
    p->privatemem = true;
    break;
@

% apparently can also be used by the debugger acid
%  chmod +w /proc/96/mem and then acid 96

<<devproc.c enum Qxxx>>=
enum
{
    Qdir,
    Qtrace,

    Qargs,
    Qctl,
    Qfd,
    Qfpregs,
    Qkregs,
    Qmem,
    Qnote,
    Qnoteid,
    Qnotepg,
    Qns,
    Qproc,
    Qregs,
    Qsegment,
    Qstatus,
    Qtext,
    Qwait,
    Qprofile,
    Qsyscall,
};
@


<<devproc enum CMxxx>>=
enum
{
    CMclose,
    CMclosefiles,
    CMhang,
    CMkill,
    CMnohang,
    CMnoswap,
    CMprivate,
    CMprofile,

    CMpri,
    CMfixedpri,
    CMwired,

    CMstart,
    CMstartstop,
    CMstartsyscall,
    CMstop,
    CMwaitstop,
    CMtrace,

    /* real time */
    CMperiod,
    CMdeadline,
    CMcost,
    CMsporadic,
    CMdeadlinenotes,
    CMadmit,
    CMextra,
    CMexpel,
    CMevent,
};
@

<<global procdir>>=
/*
 * Status, fd, and ns are left fully readable (0444) because of their use in debugging,
 * particularly on shared servers.
 * Arguably, ns and fd shouldn't be readable; if you'd prefer, change them to 0000
 */
Dirtab procdir[] =
{
    "args",     {Qargs},    0,          0660,
    "ctl",      {Qctl},     0,          0000,
    "fd",       {Qfd},      0,          0444,
    "fpregs",   {Qfpregs},  sizeof(Arch_FPsave),     0000,
    "kregs",    {Qkregs},   sizeof(Ureg),       0400,
    "mem",      {Qmem},     0,          0000,
    "note",     {Qnote},    0,          0000,
    "noteid",   {Qnoteid},  0,          0664,
    "notepg",   {Qnotepg},  0,          0000,
    "ns",       {Qns},      0,          0444,
    "proc",     {Qproc},    0,          0400,
    "regs",     {Qregs},    sizeof(Ureg),       0000,
    "segment",  {Qsegment}, 0,          0444,
    "status",   {Qstatus},  STATSIZE,       0444,
    "text",     {Qtext},    0,          0000,
    "wait",     {Qwait},    0,          0400,
    "profile",  {Qprofile}, 0,          0400,
    "syscall",  {Qsyscall}, 0,          0400,   
};
@

<<global proccmd>>=
static
Cmdtab proccmd[] = {
    CMclose,        "close",        2,
    CMclosefiles,       "closefiles",       1,
    CMfixedpri,     "fixedpri",     2,
    CMhang,         "hang",         1,
    CMnohang,       "nohang",       1,
    CMnoswap,       "noswap",       1,
    CMkill,         "kill",         1,
    CMpri,          "pri",          2,
    CMprivate,      "private",      1,
    CMprofile,      "profile",      1,
    CMstart,        "start",        1,
    CMstartstop,        "startstop",        1,
    CMstartsyscall,     "startsyscall",     1,
    CMstop,         "stop",         1,
    CMwaitstop,     "waitstop",     1,
    CMwired,        "wired",        2,
    CMtrace,        "trace",        0,
    CMperiod,       "period",       2,
    CMdeadline,     "deadline",     2,
    CMcost,         "cost",         2,
    CMsporadic,     "sporadic",     1,
    CMdeadlinenotes,    "deadlinenotes",    1,
    CMadmit,        "admit",        1,
    CMextra,        "extra",        1,
    CMexpel,        "expel",        1,
    CMevent,        "event",        1,
};
@

<<devproc QXXX macros>>=
/*
 * Qids are, in path:
 *   5 bits of file type (qids above)
 *  26 bits of process slot number + 1
 *       in vers,
 *  32 bits of pid, for consistency checking
 * If notepg, c->pgrpid.path is pgrp slot, .vers is noteid.
 */
#define QSHIFT  5   /* location in qid of proc slot # */

#define QID(q)      ((((ulong)(q).path) & ((1<<QSHIFT)-1)) >> 0)
#define SLOT(q)     (((((ulong)(q).path) & ~(1UL<<31)) >> QSHIFT) - 1)
#define PID(q)      ((q).vers)
#define NOTEID(q)   ((q).vers)
@

<<function proctab>>=
Proc*
proc_proctab(int i)
{
    return &procalloc.arena[i];
}
@ 

<<[[Chan]] union other fields>>=
Qid pgrpid;   /* for #p/notepg */
@
% ???


<<method procinit>>=
static void
proc_init(void)
{
    if(conf.nproc >= (1<<(31-QSHIFT))-1)
        print("warning: too many procs for devproc\n");

    <<[[proc_init()]] other init>>
}
@
% >>
% was called procinit but conflict with procalloc procinit() function

<<global procdevtab>>=
Dev procdevtab = {
    .dc       =    'p',
    .name     =    "proc",
               
    .reset    =    devreset,
    .init     =    proc_init,
    .shutdown =    devshutdown,
    .attach   =    procattach,
    .walk     =    procwalk,
    .stat     =    procstat,
    .open     =    procopen,
    .create   =    devcreate,
    .close    =    procclose,
    .read     =    procread,
    .bread    =    devbread,
    .write    =    procwrite,
    .bwrite   =    devbwrite,
    .remove   =    devremove,
    .wstat    =    procwstat,
};
@

%TODO: use mid below instead of ->aux
<<[[Chan]] union other fields>>=
ulong mid;    /* for ns in devproc */
@


% ??? -> <>
% todo LP split
<<function setkernur(x86)>>=
/* Give enough context in the ureg to produce a kernel stack for
 * a sleeping process
 */
void
arch_setkernur(Ureg* ureg, Proc* p)
{
    ureg->pc = p->sched.pc;
    ureg->sp = p->sched.sp+4;
}
@ 
%??

<<[[procread()]] locals>>=
/* NSEG*32 was too small for worst cases */
char *a, *sps, *srv, statbuf[NSEG*64];
int i, j, m, navail, ne, pid, rsize;
long l;
byte *rptr;
ulong offset;
Confmem *cm;
Proc *p;
Segment *sg, *s;
Ureg kur;
Waitq *wq;
@
% LP distribute

<<method procread>>=
static long
procread(Chan *c, void *va, long n, vlong off)
{
    <<[[procread()]] locals>>
    
    a = va;
    offset = off;

    if(c->qid.type & QTDIR)
        return devdirread(c, a, n, 0, 0, procgen);

    <<[[procread()]] Qtrace if>>

    p = proctab(SLOT(c->qid));
    if(p->pid != PID(c->qid))
        error(Eprocdied);

    switch(QID(c->qid)){

    <<[[procread()]] cases>>

    case Qargs:
        qlock(&p->debug);
        j = procargs(p, up->genbuf, sizeof up->genbuf);
        qunlock(&p->debug);
        if(offset >= j)
            return 0;
        if(offset+n > j)
            n = j-offset;
        memmove(a, &up->genbuf[offset], n);
        return n;


    case Qnote:
        qlock(&p->debug);
        if(waserror()){
            qunlock(&p->debug);
            nexterror();
        }
        if(p->pid != PID(c->qid))
            error(Eprocdied);
        if(n < 1)   /* must accept at least the '\0' */
            error(Etoosmall);
        if(p->nnote == 0)
            n = 0;
        else {
            m = strlen(p->note[0].msg) + 1;
            if(m > n)
                m = n;
            memmove(va, p->note[0].msg, m);
            ((char*)va)[m-1] = '\0';
            p->nnote--;
            memmove(p->note, p->note+1, p->nnote*sizeof(Note));
            n = m;
        }
        if(p->nnote == 0)
            p->notepending = false;
        poperror();
        qunlock(&p->debug);
        return n;

    case Qproc:
        if(offset >= sizeof(Proc))
            return 0;
        if(offset+n > sizeof(Proc))
            n = sizeof(Proc) - offset;
        memmove(a, ((char*)p)+offset, n);
        return n;


    case Qregs:
        rptr = (byte*)p->dbgreg;
        rsize = sizeof(Ureg);
        goto regread;

    case Qkregs:
        memset(&kur, 0, sizeof(Ureg));
        arch_setkernur(&kur, p);
        rptr = (byte*)&kur;
        rsize = sizeof(Ureg);
        goto regread;

    <<[[procread()]] Qfpregs case>>

    regread:
        if(rptr == nil)
            error(Enoreg);
        if(offset >= rsize)
            return 0;
        if(offset+n > rsize)
            n = rsize - offset;
        memmove(a, rptr+offset, n);
        return n;


    // coupling with ps.c
 /*
  * 0  text
  * 1  user
  * 2  state
  * 3  cputime[5]
  * 8  memory
  * 9 basepri
  * 10 pri
  */
    case Qstatus:
        if(offset >= STATSIZE)
            return 0;
        if(offset+n > STATSIZE)
            n = STATSIZE - offset;

        memset(statbuf, ' ', sizeof statbuf);
        readstr(0, statbuf+0*KNAMELEN, KNAMELEN-1, p->text);
        readstr(0, statbuf+1*KNAMELEN, KNAMELEN-1, p->user);
        sps = p->psstate;
        if(sps == nil)
            sps = statename[p->state];
        readstr(0, statbuf+2*KNAMELEN, 11, sps);

        j = 2*KNAMELEN + 12;
        <<[[procread()]] Qstatus case, time part>>

        /* ignore stack, which is mostly non-existent */
        l = 0;
        for(i=1; i<NSEG; i++){
            s = p->seg[i];
            if(s)
                l += s->top - s->base;
        }
        readnum(0, statbuf+j+NUMSIZE*5, NUMSIZE, l>>10, NUMSIZE);
        readnum(0, statbuf+j+NUMSIZE*6, NUMSIZE, p->basepri, NUMSIZE);
        readnum(0, statbuf+j+NUMSIZE*7, NUMSIZE, p->priority, NUMSIZE);
        memmove(a, statbuf+offset, n);
        return n;

    case Qwait:
        if(!canqlock(&p->qwaitr))
            error(Einuse);

        if(waserror()) {
            qunlock(&p->qwaitr);
            nexterror();
        }

        lock(&p->exl);
        if(up == p && p->nchild == 0 && p->waitq == 0) {
            unlock(&p->exl);
            error(Enochild);
        }
        pid = p->pid;
        while(p->waitq == 0) {
            unlock(&p->exl);
            sleep(&p->waitr, haswaitq, p);
            if(p->pid != pid)
                error(Eprocdied);
            lock(&p->exl);
        }
        wq = p->waitq;
        p->waitq = wq->next;
        p->nwait--;
        unlock(&p->exl);

        qunlock(&p->qwaitr);
        poperror();
        n = snprint(a, n, "%d %lud %lud %lud %q",
            wq->w.pid,
            <<[[procread()]] Qwait case, snprint time field arguments>>
            wq->w.msg);
        free(wq);
        return n;


    case Qnoteid:
        return readnum(offset, va, n, p->noteid, NUMSIZE);
    case Qfd:
        return procfds(p, va, n, offset);
    }
    error(Egreg);
    panic("procread: should not reach this point");
    return -1; // unreachable
}
@

<<method procwrite>>=
static long
procwrite(Chan *c, void *va, long n, vlong off)
{
    int id, m;
    Proc *p, *t, *et;
    char *a, *arg, buf[ERRMAX];
    ulong offset = off;

    a = va;
    if(c->qid.type & QTDIR)
        error(Eisdir);

    p = proctab(SLOT(c->qid));

    /* Use the remembered noteid in the channel rather
     * than the process pgrpid
     */
    if(QID(c->qid) == Qnotepg) {
        pgrpnote(NOTEID(c->pgrpid), va, n, NUser);
        return n;
    }

    qlock(&p->debug);
    if(waserror()){
        qunlock(&p->debug);
        nexterror();
    }
    if(p->pid != PID(c->qid))
        error(Eprocdied);

    switch(QID(c->qid)){

    <<[[procwrite()]] cases>>

    case Qctl:
        procctlreq(p, va, n);
        break;

    case Qargs:
        if(n == 0)
            error(Eshort);
        if(n >= ERRMAX)
            error(Etoobig);
        arg = malloc(n+1);
        if(arg == nil)
            error(Enomem);
        memmove(arg, va, n);
        m = n;
        if(arg[m-1] != 0)
            arg[m++] = 0;
        free(p->args);
        p->nargs = m;
        p->args = arg;
        p->setargs = true;
        break;


    case Qregs:
        if(offset >= sizeof(Ureg))
            n = 0;
        else if(offset+n > sizeof(Ureg))
            n = sizeof(Ureg) - offset;
        if(p->dbgreg == nil)
            error(Enoreg);
        arch_setregisters(p->dbgreg, (char*)(p->dbgreg)+offset, va, n);
        break;

    <<[[procwrite]] Qfpregs case>>

    case Qnote:
        if(p->kp)
            error(Eperm);
        if(n >= ERRMAX-1)
            error(Etoobig);
        memmove(buf, va, n);
        buf[n] = 0;
        if(!postnote(p, 0, buf, NUser))
            error("note not posted");
        break;
    case Qnoteid:
        id = atoi(a);
        if(id == p->pid) {
            p->noteid = id;
            break;
        }
        t = proctab(0);
        for(et = t+conf.nproc; t < et; t++) {
            if(t->state == Dead)
                continue;
            if(id == t->noteid) {
                if(strcmp(p->user, t->user) != 0)
                    error(Eperm);
                p->noteid = id;
                break;
            }
        }
        if(p->noteid != id)
            error(Ebadarg);
        break;

    default:
        pprint("unknown qid in procwrite\n");
        error(Egreg);
    }
    poperror();
    qunlock(&p->debug);
    return n;
}
@

<<function pgrpnote>>=
void
pgrpnote(ulong noteid, char *a, long n, int flag)
{
    Proc *p, *ep;
    char buf[ERRMAX];

    if(n >= ERRMAX-1)
        error(Etoobig);

    memmove(buf, a, n);
    buf[n] = 0;
    p = proctab(0);
    ep = p+conf.nproc;
    for(; p < ep; p++) {
        if(p->state == Dead)
            continue;
        if(up != p && p->noteid == noteid && p->kp == 0) {
            qlock(&p->debug);
            if(p->pid == 0 || p->noteid != noteid){
                qunlock(&p->debug);
                continue;
            }
            if(!waserror()) {
                postnote(p, 0, buf, flag);
                poperror();
            }
            qunlock(&p->debug);
        }
    }
}
@ 


<<method procopen>>=
static Chan*
procopen(Chan *c, int omode)
{
    Proc *p;
    Pgrp *pg;
    Chan *tc;
    int pid;

    if(c->qid.type & QTDIR)
        return devopen(c, omode, 0, 0, procgen);

    <<[[procopen()]] Qtrace if>>
        
    p = proctab(SLOT(c->qid));
    qlock(&p->debug);
    if(waserror()){
        qunlock(&p->debug);
        nexterror();
    }
    pid = PID(c->qid);
    if(p->pid != pid)
        error(Eprocdied);

    omode = openmode(omode);

    switch(QID(c->qid)){

    <<[[procopen()]] cases>>
    case Qtext:
        if(omode != OREAD)
            error(Eperm);
        tc = proctext(c, p);
        tc->offset = 0;
        qunlock(&p->debug);
        poperror();
        cclose(c);
        return tc;

    case Qproc:
    case Qkregs:
    case Qsegment:
    case Qprofile:
    case Qfd:
        if(omode != OREAD)
            error(Eperm);
        break;

    case Qnote:
        if(p->privatemem)
            error(Eperm);
        break;

    case Qmem:
    case Qctl:
        if(p->privatemem)
            error(Eperm);
        nonone(p);
        break;

    case Qargs:
    case Qnoteid:
    case Qstatus:
    case Qwait:
    case Qregs:
    case Qfpregs:
    case Qsyscall:  
        nonone(p);
        break;


    case Qnotepg:
        nonone(p);
        pg = p->pgrp;
        if(pg == nil)
            error(Eprocdied);
        if(omode!=OWRITE || pg->pgrpid == 1)
            error(Eperm);
        c->pgrpid.path = pg->pgrpid+1;
        c->pgrpid.vers = p->noteid;
        break;

    default:
        pprint("procopen %#lux\n", QID(c->qid));
        error(Egreg);
    }

    /* Affix pid to qid */
    if(p->state != Dead)
        c->qid.vers = p->pid;

    /* make sure the process slot didn't get reallocated while we were playing */
    arch_coherence();
    if(p->pid != pid)
        error(Eprocdied);

    tc = devopen(c, omode, 0, 0, procgen);
    qunlock(&p->debug);
    poperror();

    return tc;
}
@


<<method procwstat>>=
static int
procwstat(Chan *c, byte *db, int n)
{
    Proc *p;
    DirEntry *d;

    if(c->qid.type&QTDIR)
        error(Eperm);

    if(QID(c->qid) == Qtrace)
        return devwstat(c, db, n);
        
    p = proctab(SLOT(c->qid));
    nonone(p);
    d = nil;
    if(waserror()){
        free(d);
        qunlock(&p->debug);
        nexterror();
    }
    qlock(&p->debug);

    if(p->pid != PID(c->qid))
        error(Eprocdied);

    if(strcmp(up->user, p->user) != 0 && strcmp(up->user, eve) != 0)
        error(Eperm);

    d = smalloc(sizeof(DirEntry)+n);
    n = convM2D(db, n, &d[0], (char*)&d[1]);
    if(n == 0)
        error(Eshortstat);
    if(!emptystr(d->uid) && strcmp(d->uid, p->user) != 0){
        if(strcmp(up->user, eve) != 0)
            error(Eperm);
        else
            kstrdup(&p->user, d->uid);
    }
    /* p->procmode determines default mode for files in /proc */
    if(d->mode != ~0UL)
        p->procmode = d->mode&0777;

    poperror();
    free(d);
    qunlock(&p->debug);
    return n;
}
@

% helpers for procread

<<function procoffset>>=
static long
procoffset(long offset, char *va, int *np)
{
    if(offset > 0) {
        offset -= *np;
        if(offset < 0) {
            memmove(va, va+*np+offset, -offset);
            *np = -offset;
        }
        else
            *np = 0;
    }
    return offset;
}
@


<<function procqidwidth>>=
static int
procqidwidth(Chan *c)
{
    char buf[32];

    return snprint(buf, sizeof buf, "%lud", c->qid.vers);
}
@

<<function procfdprint>>=
int
procfdprint(Chan *c, int fd, int w, char *s, int ns)
{
    int n;

    if(w == 0)
        w = procqidwidth(c);
    n = snprint(s, ns, "%3d %.2s %C %4ld (%.16llux %*lud %.2ux) %5ld %8lld %s\n",
        fd,
        &"r w rw"[(c->mode&3)<<1],
        devtab[c->type]->dc, c->dev,
        c->qid.path, w, c->qid.vers, c->qid.type,
        c->iounit, c->offset, c->path->s);
    return n;
}
@

<<function procgen>>=
static int
procgen(Chan *c, char *name, Dirtab *tab, int, int s, DirEntry *dp)
{
    Qid qid;
    Proc *p;
    char *ename;
    Segment *q;
    ulong pid, path, perm, len;

    if(s == DEVDOTDOT){
        mkqid(&qid, Qdir, 0, QTDIR);
        devdir(c, qid, "#p", 0, eve, 0555, dp);
        return 1;
    }

    if(c->qid.path == Qdir){
        if(s == 0){
            strcpy(up->genbuf, "trace");
            mkqid(&qid, Qtrace, -1, QTFILE);
            devdir(c, qid, up->genbuf, 0, eve, 0444, dp);
            return 1;
        }

        if(name != nil){
            /* ignore s and use name to find pid */
            pid = strtol(name, &ename, 10);
            if(pid==0 || ename[0]!='\0')
                return -1;
            s = procindex(pid);
            if(s < 0)
                return -1;
        }
        else if(--s >= conf.nproc)
            return -1;

        p = proctab(s);
        pid = p->pid;
        if(pid == 0)
            return 0;
        snprint(up->genbuf, sizeof up->genbuf, "%lud", pid);
        /*
         * String comparison is done in devwalk so name must match its formatted pid
        */
        if(name != nil && strcmp(name, up->genbuf) != 0)
            return -1;
        mkqid(&qid, (s+1)<<QSHIFT, pid, QTDIR);
        devdir(c, qid, up->genbuf, 0, p->user, DMDIR|0555, dp);
        return 1;
    }
    if(c->qid.path == Qtrace){
        strcpy(up->genbuf, "trace");
        mkqid(&qid, Qtrace, -1, QTFILE);
        devdir(c, qid, up->genbuf, 0, eve, 0444, dp);
        return 1;
    }
    if(s >= nelem(procdir))
        return -1;
    if(tab)
        panic("procgen");

    tab = &procdir[s];
    path = c->qid.path&~(((1<<QSHIFT)-1));  /* slot component */

    /* p->procmode determines default mode for files in /proc */
    p = proctab(SLOT(c->qid));
    perm = tab->perm;
    if(perm == 0)
        perm = p->procmode;
    else    /* just copy read bits */
        perm |= p->procmode & 0444;

    len = tab->length;
    switch(QID(c->qid)) {
    case Qwait:
        len = p->nwait; /* incorrect size, but >0 means there's something to read */
        break;

    <<[[procgen()]] Qprofile case>>
    }

    mkqid(&qid, path|tab->qid.path, c->qid.vers, QTFILE);
    devdir(c, qid, tab->name, len, p->user, perm, dp);
    return 1;
}
@



<<function nonone>>=
/*
 *  none can't read or write state on other
 *  processes.  This is to contain access of
 *  servers running as none should they be
 *  subverted by, for example, a stack attack.
 */
static void
nonone(Proc *p)
{
    if(p == up)
        return;
    if(strcmp(up->user, "none") != 0)
        return;
    if(iseve())
        return;
    error(Eperm);
}
@
% security!!

<<function procfds>>=
static int
procfds(Proc *p, char *va, int count, long offset)
{
    Fgrp *f;
    Chan *c;
    char buf[256];
    int n, i, w, ww;
    char *a;

    /* print to buf to avoid holding fgrp lock while writing to user space */
    if(count > sizeof buf)
        count = sizeof buf;
    a = buf;

    qlock(&p->debug);
    f = p->fgrp;
    if(f == nil){
        qunlock(&p->debug);
        return 0;
    }
    lock(f);
    if(waserror()){
        unlock(f);
        qunlock(&p->debug);
        nexterror();
    }

    n = readstr(0, a, count, p->dot->path->s);
    n += snprint(a+n, count-n, "\n");
    offset = procoffset(offset, a, &n);
    /* compute width of qid.path */
    w = 0;
    for(i = 0; i <= f->maxfd; i++) {
        c = f->fd[i];
        if(c == nil)
            continue;
        ww = procqidwidth(c);
        if(ww > w)
            w = ww;
    }
    for(i = 0; i <= f->maxfd; i++) {
        c = f->fd[i];
        if(c == nil)
            continue;
        n += procfdprint(c, i, w, a+n, count-n);
        offset = procoffset(offset, a, &n);
    }
    unlock(f);
    qunlock(&p->debug);
    poperror();

    /* copy result to user space, now that locks are released */
    memmove(va, buf, n);

    return n;
}
@


<<method procclose>>=
static void
procclose(Chan* c)
{
    <<[[procclose()]] Qtrace if>>
    <<[[procclose()]] hooks>>
}
@



<<[[Proc]] debugger fields>>=
bool setargs;
@ 



<<function procargs>>=
static int
procargs(Proc *p, char *buf, int nbuf)
{
    int j, k, m;
    char *a;
    int n;

    a = p->args;
    if(p->setargs){
        snprint(buf, nbuf, "%s [%s]", p->text, p->args);
        return strlen(buf);
    }
    n = p->nargs;
    for(j = 0; j < nbuf - 1; j += m){
        if(n <= 0)
            break;
        if(j != 0)
            buf[j++] = ' ';
        m = snprint(buf+j, nbuf-j, "%q",  a);
        k = strlen(a) + 1;
        a += k;
        n -= k;
    }
    return j;
}
@






<<function proctext>>=
Chan*
proctext(Chan *c, Proc *p)
{
    Chan *tc;
    KImage *i;
    Segment *s;

    s = p->seg[TSEG];
    if(s == 0)
        error(Enonexist);
    if(p->state==Dead)
        error(Eprocdied);

    lock(s);
    i = s->image;
    if(i == 0) {
        unlock(s);
        error(Eprocdied);
    }
    unlock(s);

    lock(i);
    if(waserror()) {
        unlock(i);
        nexterror();
    }

    tc = i->c;
    if(tc == 0)
        error(Eprocdied);

    if(incref(tc) == 1 || (tc->flag&COPEN) == 0 || tc->mode!=OREAD) {
        cclose(tc);
        error(Eprocdied);
    }

    if(p->pid != PID(c->qid)){
        cclose(tc);
        error(Eprocdied);
    }

    unlock(i);
    poperror();

    return tc;
}
@


<<function procctlcloseone>>=
static void
procctlcloseone(Proc *p, Fgrp *f, int fd)
{
    Chan *c;

    c = f->fd[fd];
    if(c == nil)
        return;
    f->fd[fd] = nil;
    unlock(f);
    qunlock(&p->debug);
    cclose(c);
    qlock(&p->debug);
    lock(f);
}
@
% bug, f->fd[fd] not bound check! (found on plan9 mailing list)


<<function procctlclosefiles>>=
void
procctlclosefiles(Proc *p, bool all, int fd)
{
    int i;
    Fgrp *f;

    f = p->fgrp;
    if(f == nil)
        error(Eprocdied);

    lock(f);
    f->ref++;
    if(all)
        for(i = 0; i < f->maxfd; i++)
            procctlcloseone(p, f, i);
    else
        procctlcloseone(p, f, fd);
    unlock(f);
    closefgrp(f);
}
@
% should be f->maxfd - 1?


<<function parsetime>>=
static char *
parsetime(vlong *rt, char *s)
{
    uvlong ticks;
    ulong l;
    char *e, *p;
    static int p10[] = {100000000, 10000000, 1000000, 100000, 10000, 1000, 100, 10, 1};

    if (s == nil)
        return "missing value";
    ticks=strtoul(s, &e, 10);
    if (*e == '.'){
        p = e+1;
        l = strtoul(p, &e, 10);
        if(e-p > nelem(p10))
            return "too many digits after decimal point";
        if(e-p == 0)
            return "ill-formed number";
        l *= p10[e-p-1];
    }else
        l = 0;
    if (*e == '\0' || strcmp(e, "s") == 0){
        ticks = 1000000000 * ticks + l;
    }else if (strcmp(e, "ms") == 0){
        ticks = 1000000 * ticks + l/1000;
    }else if (strcmp(e, "Âµs") == 0 || strcmp(e, "us") == 0){
        ticks = 1000 * ticks + l/1000000;
    }else if (strcmp(e, "ns") != 0)
        return "unrecognized unit";
    *rt = ticks;
    return nil;
}
@


<<function procctlreq>>=
// assumes p->debug is held
void
procctlreq(Proc *p, char *va, int n)
{
    Segment *s;
    int npc, pri;
    Cmdbuf *cb;
    Cmdtab *ct;
    vlong time;
    char *e;
    void (*pt)(Proc*, int, vlong);

    if(p->kp)   /* no ctl requests to kprocs */
        error(Eperm);

    cb = parsecmd(va, n);
    if(waserror()){
        free(cb);
        nexterror();
    }

    ct = lookupcmd(cb, proccmd, nelem(proccmd));

    switch(ct->index){

    <<[[procctlreq()]] CMpri case>>
    <<[[procctlreq()]] CMfixedpri case>>
    <<[[procctlreq()]] CMwired case>>
    <<[[procctlreq()]] CMnoswap case>>

    <<[[procctlreq()]] CMprivate case>>

    <<[[procctlreq()]] CMhang case>>
    <<[[procctlreq()]] CMnohang case>>

    <<[[procctlreq()]] CMstop case>>
    <<[[procctlreq()]] CMstart case>>
    <<[[procctlreq()]] CMwaitstop case>>

    <<[[procctlreq()]] CMstartsyscall case>>
    <<[[procctlreq()]] CMstartstop case>>

    <<[[procctlreq()]] CMtrace case>>
    <<[[procctlreq()]] CMevent case>>

    <<[[procctlreq()]] CMprofile case>>


    <<[[procctlreq()]] CMkill case>>

    case CMclose:
        procctlclosefiles(p, false, atoi(cb->f[1]));
        break;
    case CMclosefiles:
        procctlclosefiles(p, true, 0);
        break;


    <<[[procctlreq()]] optional real-time commands>>

    }

    poperror();
    free(cb);
}
@





\section{[[/fd/]]}

% this is actually used more than I thought. I think during
% booting it's used. todo: why?

\subsection{[[sysdup()]]}

<<systab special file syscalls>>=
[DUP]       sysdup,
@ 

<<syscall dup>>=
// int dup(int oldfd, int newfd);
long
sysdup(ulong* arg)
{
    int fd;
    Chan *c, *oc;
    Fgrp *f = up->fgrp;

    /*
     * Close after dup'ing, so date > #d/1 works
     */
    c = fdtochan(arg[0], -1, false, true);
    fd = arg[1];
    if(fd != -1){
        lock(f);
        if(fd<0 || growfd(f, fd)<0) {
            unlockfgrp(f);
            cclose(c);
            error(Ebadfd);
        }
        if(fd > f->maxfd)
            f->maxfd = fd;

        oc = f->fd[fd];
        f->fd[fd] = c;
        unlockfgrp(f);
        if(oc)
            cclose(oc);
    }else{
        if(waserror()) {
            cclose(c);
            nexterror();
        }
        fd = newfd(c);
        if(fd < 0)
            error(Enofd);
        poperror();
    }

    return fd;
}
@

\subsection{[[/fd/]]}

% devdup.c in Kernel_extra.nw

\section{[[/ksys/]]}
%pad: I created devsys.c,
% was originally in devcons.c, but better to not abuse so much devcons and /dev.
%pad: Note that conflict with use of /sys in plan9 e.g. /sys/src but nevermind,
% I think I agree with Linux way on this one.
%update: too annoying, so it is actually /ksys for now

% see also /sys/sysstat in profiling

% when /sys/ vs /dev/?
% if can't write into it, then for sure should go for /sys/
% if can write into it but it's hard to relate to a device notion then go for /sys/
% if it depends on up then /dev; /sys should be for global system settings

% hmm should maybe use sys_ to not confuse with syscalls

<<devsys.c enum Qxxx>>=
enum{
    Qdir,

    <<devsys.c enum Qxxx cases>>
};
@

<<global sysdir>>=
static Dirtab sysdir[]={
    ".",    {Qdir, 0, QTDIR},   0,      DMDIR|0555,

    <<[[sysdir]] fields>>
};
@

<<method sysinit>>=
static void
sysinit(void)
{
}
@


<<method sysattach>>=
static Chan*
sysattach(char *spec)
{
    return devattach('k', spec);
}
@

<<method sysread>>=
static long
sysread(Chan *c, void *buf, long n, vlong off)
{
    vlong offset = off;
    char tmp[256];
    <<[[sysread()]] locals>>

    if(n <= 0)
        return n;

    switch((ulong)c->qid.path){
    case Qdir:
        return devdirread(c, buf, n, sysdir, nelem(sysdir), devgen);

    <<[[sysread()]] cases>>

    default:
        print("sysread %#llux\n", c->qid.path);
        error(Egreg);
    }
    return -1;      /* never reached */
}
@

<<[[sysread()]] locals>>=
    char *b, *bp;
    int i, k;
    Cpu *mp;
    int id;
@


<<method syswrite>>=
static long
syswrite(Chan *c, void *va, long n, vlong off)
{
    ulong offset;
    char *a;
    <<[[syswrite()]] locals>>

    offset = off;
    a = va;

    switch((ulong)c->qid.path){

    <<[[syswrite()]] cases>>

    default:
        print("syswrite: %#llux\n", c->qid.path);
        error(Egreg);
    }
    return n;
}
@

<<[[syswrite()]] locals>>=
    char buf[256];
    Cpu *mp;
    int id;
@


<<global sysdevtab>>=
Dev sysdevtab = {
    .dc       =    'k',
    .name     =    "sys",
               
    .reset    =    devreset,
    .init     =    sysinit,
    .shutdown =    devshutdown,
    .attach   =    sysattach,
    .walk     =    syswalk,
    .stat     =    sysstat,
    .open     =    sysopen,
    .create   =    devcreate,
    .close    =    sysclose,
    .read     =    sysread,
    .bread    =    devbread,
    .write    =    syswrite,
    .bwrite   =    devbwrite,
    .remove   =    devremove,
    .wstat    =    devwstat,
};
@


\subsection{[[/ksys/osversion]]}

<<devsys.c enum Qxxx cases>>=
    Qosversion,
@

<<[[sysdir]] fields>>=
    "osversion",    {Qosversion},   0,      0444,
@

<<[[sysread()]] cases>>=
    case Qosversion:
        snprint(tmp, sizeof tmp, "pad's version");
        n = readstr((ulong)offset, buf, n, tmp);
        return n;
@
% pad version :)
%old: "2000"

\subsection{[[/ksys/config]]}

<<devsys.c decls and globals>>=
extern byte configfile[]; // in $CONF.c
@
%$


<<devsys.c enum Qxxx cases>>=
    Qconfig,
@

<<[[sysdir]] fields>>=
    "config",   {Qconfig},  0,      0444,
@

<<[[sysread()]] cases>>=
    case Qconfig:
        return readstr((ulong)offset, buf, n, (char*) configfile);
@

\subsection{[[/sys/hosthowner]], [[/sys/hostdomain]]}

<<devsys.c enum Qxxx cases>>=
    Qhostowner,
    Qhostdomain,
@

<<[[sysdir]] fields>>=
    "hostowner",    {Qhostowner},   0,      0664,
    "hostdomain",   {Qhostdomain},  DOMLEN,     0664,
@

<<[[sysread()]] cases>>=
    case Qhostowner:
        return readstr((ulong)offset, buf, n, eve);

    case Qhostdomain:
        return readstr((ulong)offset, buf, n, hostdomain);
@

<<[[syswrite()]] cases>>=
    case Qhostowner:
        return hostownerwrite(a, n);

    case Qhostdomain:
        return hostdomainwrite(a, n);
@


\subsection{[[/sys/sysname]]}

<<global sysname>>=
char    *sysname;
@ 

<<devsys.c enum Qxxx cases>>=
    Qsysname,
@

<<[[sysdir]] fields>>=
    "sysname",  {Qsysname}, 0,      0664,
@

<<[[sysread()]] cases>>=
    case Qsysname:
        if(sysname == nil)
            return 0;
        return readstr((ulong)offset, buf, n, sysname);
@

<<[[syswrite()]] cases>>=
    case Qsysname:
        if(offset != 0)
            error(Ebadarg);
        if(n <= 0 || n >= sizeof buf)
            error(Ebadarg);
        strncpy(buf, a, n);
        buf[n] = 0;
        if(buf[n-1] == '\n')
            buf[n-1] = 0;
        kstrdup(&sysname, buf);
        break;
@

\subsection{[[/sys/drivers]]}

<<devsys.c enum Qxxx cases>>=
    Qdrivers,
@

<<[[sysdir]] fields>>=
    "drivers",  {Qdrivers}, 0,      0444,
@

<<[[sysread()]] cases>>=
    case Qdrivers:
        b = malloc(READSTR);
        if(b == nil)
            error(Enomem);
        k = 0;
        for(i = 0; devtab[i] != nil; i++)
            k += snprint(b+k, READSTR-k, "#%C %s\n",
                devtab[i]->dc, devtab[i]->name);
        if(waserror()){
            free(b);
            nexterror();
        }
        n = readstr((ulong)offset, buf, n, b);
        free(b);
        poperror();
        return n;
@


\subsection{[[/sys/reboot]] (x86)}

<<function exit(x86)>>=
void
main_exit(bool ispanic)
{
        shutdown(ispanic);
        arch->reset();
}
@

<<[[kbdputsc()]] reboot if ctl-alt-del>>=
if(kbscan->ctl)
    if(kbscan->alt && c == Del) // Ctl-Alt-Del
        exit(0);
@

<<[[ConsKbd]] other fields>>=
bool ctlpoff; // ^P will not reboot if true
@

<<[[conswrite()]] Qconsctl other ifs>>=
else if(strncmp(a, "ctlpon", 6) == 0){
    kbd.ctlpoff = false;
} else if(strncmp(a, "ctlpoff", 7) == 0){
    kbd.ctlpoff = true;
}
@

<<[[echo()]] special key C-p>>=
case 0x10:  /* ^P */
    if(cpuserver && !kbd.ctlpoff){
        active.exiting = true;
        return;
    }
    break;
@

<<[[Active]] other fields>>=
bool ispanic;    /* shutdown in response to a panic */
@

<<function shutdown(x86)>>=
static void
shutdown(bool ispanic)
{
    int ms, once;

    lock(&active);
    if(ispanic)
        active.ispanic = ispanic;
    else if(cpu->cpuno == 0 && (active.cpus & (1<<cpu->cpuno)) == 0)
        active.ispanic = false;
    once = active.cpus & (1<<cpu->cpuno);
    /*
     * setting exiting will make hzclock() on each processor call exit(0),
     * which calls shutdown(0) and arch->reset(), which on mp systems is
     * mpshutdown, which idles non-bootstrap cpus and returns on bootstrap
     * processors (to permit a reboot).  clearing our bit in cpus avoids
     * calling exit(0) from hzclock() on this processor.
     */
    active.cpus &= ~(1<<cpu->cpuno);
    active.exiting = true;
    unlock(&active);

    if(once)
        iprint("cpu%d: exiting\n", cpu->cpuno);

    /* wait for any other processors to shutdown */
    arch_spllo();
    for(ms = 5*1000; ms > 0; ms -= TK2MS(2)){
        delay(TK2MS(2));
        if(active.cpus == 0 && consactive() == 0)
            break;
    }

    if(active.ispanic){
        if(!cpuserver)
            for(;;)
               halt();
        if(getconf("*debug"))
            delay(5*60*1000);
        else
            delay(10000);
    }else
        delay(1000);
}
@
% >>


<<function idle(x86)>>=
/*
 * Park a processor. Should never fall through a return from main to here,
 * should only be called by application processors when shutting down.
 */
TEXT idle(SB), $0
_idle:
        STI
        HLT
        JMP     _idle
@
%$

<<function archreset(x86)>>=
static void
archreset(void)
{
    i8042reset();

    /*
     * Often the BIOS hangs during restart if a conventional 8042
     * warm-boot sequence is tried. The following is Intel specific and
     * seems to perform a cold-boot, but at least it comes back.
     * And sometimes there is no keyboard...
     *
     * The reset register (0xcf9) is usually in one of the bridge
     * chips. The actual location and sequence could be extracted from
     * ACPI but why bother, this is the end of the line anyway.
     */
    print("Takes a licking and keeps on ticking...\n");
    *(ushort*)KADDR(0x472) = 0x1234;    /* BIOS warm-boot flag */
    outb(0xcf9, 0x02);
    outb(0xcf9, 0x06);

    for(;;)
        idle();
}
@

<<[[Active]] other fields>>=
bool rebooting;    /* just idle cpus > 0 */
@


<<function reboot(x86)>>=
void
arch_reboot(kern_addr3 entry, kern_addr3 code, ulong size)
{
    void (*f)(ulong, ulong, ulong);
    kern_addr2 mmupd;

    writeconf();

    /*
     * the boot processor is cpu0.  execute this function on it
     * so that the new kernel has the same cpu0.  this only matters
     * because the hardware has a notion of which processor was the
     * boot processor and we look at it at start up.
     */
    if (cpu->cpuno != 0) {
        procwired(up, 0);
        sched();
    }

    if(conf.ncpu > 1) {
        /*
         * the other cpus could be holding locks that will never get
         * released (e.g., in the print path) if we put them into
         * reset now, so force them to shutdown gracefully first.
         */
        lock(&active);
        active.rebooting = true;
        unlock(&active);
        shutdown(0);
        if(arch->resetothers)
            arch->resetothers();
        delay(20);
    }

    /*
     * should be the only processor running now
     */
    active.cpus = 0;
    if (cpu->cpuno != 0)
        print("on cpu%d (not 0)!\n", cpu->cpuno);

    print("shutting down...\n");
    delay(200);

    arch_splhi();

    <<[[reboot()]] reset serialoq(x86)>>

    /* shutdown devices */
    chandevshutdown();
    arch->introff();

    /*
     * Modify the processor page table to directly map the low 4MB of memory
     * This allows the reboot code to turn off the page mapping
     */
    mmupd = cpu->pdproto;
    mmupd[PDX(0)] = mmupd[PDX(KZERO)];
    mmuflushtlb(PADDR(mmupd));

    /* setup reboot trampoline function */
    f = (void*)REBOOTADDR;
    memmove(f, rebootcode, sizeof(rebootcode));

    print("rebooting...\n");

    /* off we go - never to return */
    arch_coherence();
    (*f)(PADDR(entry), PADDR(code), size);
}
@


<<function chandevshutdown>>=
void
chandevshutdown(void)
{
    int i;
    
    /* shutdown in reverse order */
    for(i=0; devtab[i] != nil; i++)
        ;
    for(i--; i >= 0; i--)
        devtab[i]->shutdown();
}
@

<<[[Dev]] methods>>=
void  (*shutdown)(void);
@
% opposite of reset() and init()?

<<function i8042reset(x86)>>=
/*
 *  ask 8042 to reset the machine
 */
void
i8042reset(void)
{
    int i, x;

    if(nokbd)
        return;

    *((ushort*)KADDR(0x472)) = 0x1234;  /* BIOS warm-boot flag */

    /*
     *  newer reset the machine command
     */
    outready();
    outb(Cmd, 0xFE);
    outready();

    /*
     *  Pulse it by hand (old somewhat reliable)
     */
    x = 0xDF;
    for(i = 0; i < 5; i++){
        x ^= 1;
        outready();
        outb(Cmd, 0xD1);
        outready();
        outb(Data, x);  /* toggle reset */
        delay(100);
    }
}
@

<<devsys.c enum Qxxx cases>>=
    Qreboot,
@

<<[[sysdir]] fields>>=
    "reboot",   {Qreboot},  0,      0660,
@

<<devsys.c decls and globals>>=
enum
{
    CMhalt,
    CMreboot,
    CMpanic,
};

Cmdtab rebootmsg[] =
{
    CMhalt,     "halt",     1,
    CMreboot,   "reboot",   0,
    CMpanic,    "panic",    0,
};
@


<<[[syswrite()]] locals>>=
    Cmdbuf *cb;
    Cmdtab *ct;
@

<<[[syswrite()]] cases>>=
    case Qreboot:
        if(!iseve())
            error(Eperm);
        cb = parsecmd(a, n);

        if(waserror()) {
            free(cb);
            nexterror();
        }
        ct = lookupcmd(cb, rebootmsg, nelem(rebootmsg));
        switch(ct->index) {
        case CMhalt:
            arch_reboot(nil, 0, 0);
            break;
        case CMreboot:
            rebootcmd(cb->nf-1, cb->f+1);
            break;
        case CMpanic:
            *(ulong*)0=0;
            panic("/dev/reboot");
        }
        poperror();
        free(cb);
        break;
@



%\subsection{[[/sys/xxx]]}
%% template
%
%<<devsys.c enum Qxxx cases>>=
%@
%
%<<[[sysdir]] fields>>=
%@
%
%<<[[sysread()]] cases>>=
%@
%
%<<[[syswrite()]] cases>>=
%@


\section{[[/dev/]]}

% saw /dev/cons, /dev/rtc, /dev/pipe??
% see /dev/kmesg, /dev/kprint in Debugging section
% see /dev/kprof in Profiling section
% (see also lots of /ksys that used to be under /dev)


<<devcons.c enum Qxxx cases>>=
    Qbintime,
    Qcputime,
    Qnull,
    Qpgrpid,
    Qpid,
    Qppid,
    Qrandom,
    Qswap,
    Qtime,
    Quser,
    Qzero,
@

<<[[consdir]] fields>>=
    "bintime",  {Qbintime}, 24,     0664,
    "cputime",  {Qcputime}, 6*NUMSIZE,  0444,
    "null",     {Qnull},    0,      0666,
    "pgrpid",   {Qpgrpid},  NUMSIZE,    0444,
    "pid",      {Qpid},     NUMSIZE,    0444,
    "ppid",     {Qppid},    NUMSIZE,    0444,
    "random",   {Qrandom},  0,      0444,
    "swap",     {Qswap},    0,      0664,
    "time",     {Qtime},    NUMSIZE+3*VLNUMSIZE,    0664,
    "user",     {Quser},    0,      0666,
    "zero",     {Qzero},    0,      0444,
@
% /dev/pid vs /env/pid?
% maybe could move those one elsewhere? abuse of #c a bit,
% un peu foutoire just to factorize things

<<[[consinit()]] initializing things>>=
    todinit();
    randominit();
@


\subsection{[[/dev/random]]}

<<global randn>>=
static  ulong   randn;
@


<<function seedrand>>=
static void
seedrand(void)
{
    if(!waserror()){
        randomread((void*)&randn, sizeof(randn));
        poperror();
    }
}
@


<<function nrand>>=
int
nrand(int n)
{
    if(randn == 0)
        seedrand();
    randn = randn*1103515245 + 12345 + CPUS(0)->ticks;
    return (randn>>16) % n;
}
@


<<struct Rb>>=
struct Rb
{
    QLock;
    Rendez  producer;
    Rendez  consumer;
    ulong   randomcount;
    byte   buf[1024];
    byte   *ep;
    byte   *rp;
    byte   *wp;
    byte   next;
    byte   wakeme;
    ushort  bits;
    ulong   randn;
};
@


<<global rb>>=
struct Rb rb;
@


<<struct rbnotfull>>=
static int
rbnotfull(void*)
{
    int i;

    i = rb.rp - rb.wp;
    return i != 1 && i != (1 - sizeof(rb.buf));
}
@


<<struct rbnotempty>>=
static int
rbnotempty(void*)
{
    return rb.wp != rb.rp;
}
@


<<function genrandom>>=
static void
genrandom(void*)
{
    up->basepri = PriNormal;
    up->priority = up->basepri;

    for(;;){
        for(;;)
            if(++rb.randomcount > 100000)
                break;
        if(anyhigher())
            sched();
        if(!rbnotfull(0))
            sleep(&rb.producer, rbnotfull, 0);
    }
}
@

<<clock callback randomclock>>=
/*
 *  produce random bits in a circular buffer
 */
static void
randomclock(void)
{
    if(rb.randomcount == 0 || !rbnotfull(0))
        return;

    rb.bits = (rb.bits<<2) ^ rb.randomcount;
    rb.randomcount = 0;

    rb.next++;
    if(rb.next != 8/2)
        return;
    rb.next = 0;

    *rb.wp ^= rb.bits;
    if(rb.wp+1 == rb.ep)
        rb.wp = rb.buf;
    else
        rb.wp = rb.wp+1;

    if(rb.wakeme)
        wakeup(&rb.consumer);
}
@
% >>

% called from consinit
<<function randominit>>=
void
randominit(void)
{
    /* Frequency close but not equal to HZ */
    addclock0link(randomclock, 13);
    rb.ep = rb.buf + sizeof(rb.buf);
    rb.rp = rb.wp = rb.buf;
    kproc("kgenrandom", genrandom, 0);
}
@


<<function randomread>>=
/*
 *  consume random bytes from a circular buffer
 */
ulong
randomread(void *xp, ulong n)
{
    byte *e, *p;
    ulong x;

    p = xp;

    if(waserror()){
        qunlock(&rb);
        nexterror();
    }

    qlock(&rb);
    for(e = p + n; p < e; ){
        if(rb.wp == rb.rp){
            rb.wakeme = 1;
            wakeup(&rb.producer);
            sleep(&rb.consumer, rbnotempty, 0);
            rb.wakeme = 0;
            continue;
        }

        /*
         *  beating clocks will be predictable if
         *  they are synchronized.  Use a cheap pseudo-
         *  random number generator to obscure any cycles.
         */
        x = rb.randn*1103515245 ^ *rb.rp;
        *p++ = rb.randn = x;

        if(rb.rp+1 == rb.ep)
            rb.rp = rb.buf;
        else
            rb.rp = rb.rp+1;
    }
    qunlock(&rb);
    poperror();

    wakeup(&rb.producer);

    return n;
}
@

<<[[consread()]] cases>>=
    case Qrandom:
        return randomread(buf, n);
@


%//int
%//rand(void)
%//{
%//  nrand(1);
%//  return randn;
%//}



\chapter{Conclusion}

% already lots of pages ... so network, graphics, security, etc in another volume
% actually even fs in other volume, and advanced subjects like:
%  SMP, storage (scsi, ata, floppy, ...) real time scheculing EDF, 


% From Chris McGee on 9fans:
%I like the idea of focusing on the functionality, not specific
%software, that could go into a 5th edition. It seems that stepping
%back and rethinking popular industry trends led to some of the unique
%and interesting decisions that gave us plan9 in the first place.

%Here is what I'd like to see
%-3D graphics (something akin to /dev/draw except for graphics pipelines)
%-Location capabilities (gps, map drawing, routing)
%-Mobile interface (clean, simple, optimized for small and touch screens)
%-2D graphics editing (edit photographs or make raster art from scratch, layers, antialiasing, filesystem for scripting)
%-3D printing (manipulate 3D model data, output one of the standard formats for printers)
%-Knowledge/AI system (plug in statements, make inferences)
%-Notifications (deliver events, alerts and reminders to my attention in a consistent manner)
%-Search quickly for files based on content (indices, also accessible via 9P, there's a paper floating around about this)
%-Easily find disk space statistics (free disk space for each file system)
%-Single Instruction Multiple Data (language and compiler for writing programs that can use these special instructions)
%-Video playback and recording (support for most popular 3 codecs, including one of the free ones, syncing of audio stream, record from camera and/or screen)
%-Clean HTML (not fully featured web browser, instead render existing HTML in a clean, readable way, not unlike the various reader modes in popular web browsers, convert to PDF/PS)

%I think that each of these can be done in the plan9 way with simple,
% consistent and elegant implementations that integrate well with the
% rest of the system. The focus is to enable capability and not
% necessarily to just port existing software, repeating existing
% complexity and bloat.

%###############################################################################

\appendix

\chapter{Debugging}

% see also printf section all this fmt stuff

% use of getconf("*debugstart*") to setup some global tracing stuff

\section{[[cgapost()]] (x86)}
%first line of "defense" (using sound could be nice too, like linus
% printf style debugging, except when can't even printf :) have to access
% directly the screen device :)

<<function cgapost(x86)>>=
char hex[] = "0123456789ABCDEF";

void
cgapost(int code)
{
    byte *cga;

    cga = CGASCREENBASE;
    cga[Width*Height-Postcodelen*2] = hex[(code>>4) & 0x0F];
    cga[Width*Height-Postcodelen*2+1] = Attr;
    cga[Width*Height-Postcodelen*2+2] = hex[code & 0x0F];
    cga[Width*Height-Postcodelen*2+3] = Attr;
}
@

% print() is also useful once has setup the screen.

\section{[[sysnop()]]}

% use sysnop to show example of debugging session?
%(was called sysr1) 


\section{Special keys and dumpers}

<<global kdebug>>=
bool kdebug;
@
%old: was a static, but now used outside kbd() in kbdputc in devcons.c


<<[[kbdputsc()]] special keyboard debug keys cases>>=
case KF|11:
    print("kbd debug on, F12 turns it off\n");
    kdebug = true;
    kbdputc(c);
    break;
case KF|12:
    kdebug = false;
    kbdputc(c);
    break;
@

<<[[kbdputsc()]] debugging>>=
if(kdebug)
    print("sc %x (ms %d)\n", k, mouseshifted);
@

<<[[kbdputsc()]] debugging up shift>>=
if(kdebug)
    print("shiftclr\n");
@

<<[[kbdputsc()]] debugging down shift>>=
if(kdebug)
    print("shift\n");
@

<<[[kbdputc()]] debugging>>=
extern bool kdebug;

if(kdebug)
    print("kbdputc(0x%x)\n", ch);
@


<<[[echo()]] locals>>=
static int ctrlt;
void* tmp;
int x;
char *e, *p;
@

<<[[echo()]] special keys handler>>=
    e = buf+n;
    for(p = buf; p < e; p++){
        switch(*p){

       <<[[echo()]] special key C-p>>
 
        case 0x14:  /* ^T */
            ctrlt++;
            if(ctrlt > 2)
                ctrlt = 2;
            continue;
        }
        if(ctrlt != 2)
            continue;

        /* ^T escapes */
        ctrlt = 0;
        switch(*p){
        case 's':
            dumpstack();
            return;
        case 'S':
            x = arch_splhi();
            dumpstack();
            procdump();
            arch_splx(x);
            return;
        case 'x':
            xsummary();
            tmp = xalloc(1000);
            xalloc(1000);
            xfree(tmp);
            xsummary();
            return;
        case 'X':
            xsummary();
            ixsummary();
            mallocsummary();
            arch_memorysummary();
            pagersummary();
            return;
        case 'm':
            arch_memorysummary();
            return;
        case 'p':
            x = arch_spllo();
            procdump();
            arch_splx(x);
            return;
        case 'q':
            scheddump();
            return;
        case 'k':
            killbig("^t ^t k");
            return;
        case 'r':
            exit(0);
            return;
        <<[[echo()]] C-t C-t special keys handler other cases>>
        }
    }
@




<<function xsummary>>=
void
xsummary(void)
{
    int i;
    Hole *h;

    for(i = 0; i < Nhole && xlists.hole[i].top != 0; i++) {
        print("|i| = %d (0x%luX), addr 0x%luX, top = 0x%luX, size = %ld, link = 0x%luX\n",
              i, &xlists.hole[i],
              xlists.hole[i].addr, xlists.hole[i].top, xlists.hole[i].size,
              xlists.hole[i].next
              );
    }
    print("flists = 0x%luX, sorted_holes = 0x%luX\n", xlists.unused_slots, xlists.sorted_holes);
    i = 0;
    for(h = xlists.unused_slots; h; h = h->next)
        i++;

    print("%d holes free", i);
    i = 0;
    for(h = xlists.sorted_holes; h; h = h->next) {
        if (0) {
            print("addr %#.8lux top %#.8lux size %lud\n",
                h->addr, h->top, h->size);
            delay(10);
        }
        i += h->size;
        if (h == h->next) {
            print("xsummary: infinite loop broken\n");
            break;
        }
    }
    print(" %d bytes free\n", i);
}
@

<<function mallosummary>>=
void
mallocsummary(void)
{
    poolsummary(mainmem);
    poolsummary(imagmem);
}
@

<<function poolsummary>>=
void
poolsummary(Pool *p)
{
    print("%s max %lud cur %lud free %lud alloc %lud\n", p->name,
        p->maxsize, p->cursize, p->curfree, p->curalloc);
}
@

<<function memorysummary(x86)>>=
void
arch_memorysummary(void)
{
  int i;
  int npallocpage = 0;

  print("\n");
  print("etext = 0x%luX, edata = 0x%luX, eend = 0x%luX, sizeof long = %d\n",
        etext, edata, end, sizeof(long));
  for(i=0; i<nelem(conf.mem); i++) {
       print("conf mem %d start = 0x%luX, npage = %ld\n", 
          i,
          conf.mem[i].base,
          conf.mem[i].npage
          );
  }
  for(i=0; i<nelem(palloc.mem); i++) {
       print("palloc mem %d start = 0x%luX, npage = %ld\n", 
          i,
          palloc.mem[i].base,
          palloc.mem[i].npage
          );
       npallocpage += palloc.mem[i].npage;
  }
  print("size of Page = %d, palloc size = %d\n", 
        sizeof(Page),
        npallocpage*sizeof(Page)
        );

  print("size of Proc = %d, procalloc size = %d\n",
        sizeof(Proc),
        conf.nproc*sizeof(Proc)
        );
  print("\n");
  memdebug();
}
@

<<function memdebug(x86)>>=
void
memdebug(void)
{
    ulong maxpa, maxpa1, maxpa2;

    maxpa = (nvramread(0x18)<<8)|nvramread(0x17);
    maxpa1 = (nvramread(0x31)<<8)|nvramread(0x30);
    maxpa2 = (nvramread(0x16)<<8)|nvramread(0x15);
    print("maxpa = %luX -> %luX, maxpa1 = %luX maxpa2 = %luX\n",
        maxpa, MB+maxpa*KB, maxpa1, maxpa2);

    mapprint(&rmapram);
    mapprint(&rmapumb);
    mapprint(&rmapumbrw);
    mapprint(&rmapupa);
}
@


<<function mapprint(x86)>>=
void
mapprint(RMap *rmap)
{
    Map *mp;

    print("%s\n", rmap->name);  
    for(mp = rmap->map; mp->size; mp++)
        print("\t%8.8luX %8.8luX (%lud)\n", mp->addr, mp->addr+mp->size, mp->size);
}
@

<<function pagersummary>>=
void
pagersummary(void)
{
    print("%lud/%lud memory %lud/%lud swap %d iolist\n",
        palloc.user-palloc.freecount,
        palloc.user, conf.nswap-swapalloc.free, conf.nswap,
        ioptr);
}
@


<<function ixsummary>>=
void
ixsummary(void)
{
    debugging ^= 1;
    iallocsummary();
    print("pad %lud, concat %lud, pullup %lud, copy %lud\n",
        padblockcnt, concatblockcnt, pullupblockcnt, copyblockcnt);
    print("consume %lud, produce %lud, qcopy %lud\n",
        consumecnt, producecnt, qcopycnt);
}
@

<<function iallocsummary>>=
void
iallocsummary(void)
{
    print("ialloc %lud/%lud\n", ialloc.bytes, conf.ialloc);
}
@

<<function scheddump>>=
void
scheddump(void)
{
    Proc *p;
    Schedq *rq;

    for(rq = &runq[Nrq-1]; rq >= runq; rq--){
        if(rq->head == 0)
            continue;
        print("rq%ld:", rq-runq);
        for(p = rq->head; p; p = p->rnext)
            print(" %lud(%lud)", p->pid, cpu->ticks - p->readytime);
        print("\n");
        delay(150);
    }
    print("nrdy %d\n", nrdy);
}
@ 

<<function procdump>>=
void
procdump(void)
{
    int i;
    Proc *p;

    if(up)
        print("up %lud\n", up->pid);
    else
        print("no current process\n");
    for(i=0; i<conf.nproc; i++) {
        p = &procalloc.arena[i];
        if(p->state == Dead)
            continue;

        dumpaproc(p);
    }
}
@ 

<<function dumpaproc>>=
void
proc_dumpaproc(Proc *p)
{
    ulong bss;
    char *s;

    if(p == nil)
        return;

    bss = 0;
    if(p->seg[BSEG])
        bss = p->seg[BSEG]->top;

    s = p->psstate;
    if(s == nil)
        s = statename[p->state];
    print("%3lud:%10s pc %8lux dbgpc %8lux  %8s (%s) ut %ld st %ld bss %lux qpc %lux nl %lud nd %lud lpc %lux pri %lud\n",
        p->pid, p->text, p->pc, arch_dbgpc(p),  s, statename[p->state],
        p->time[TUser], p->time[TSys], bss, p->qpc, p->nlocks.ref, p->delaysched, p->lastlock ? p->lastlock->pc : 0, p->priority);
}
@ 

% vs userpc?
<<function dbgpc(x86)>>=
ulong
arch_dbgpc(Proc *p)
{
    Ureg *ureg;

    ureg = p->dbgreg;
    if(ureg == nil)
        return nilptr;

    return ureg->pc;
}
@ 

% ----------------------------------------------------------------------------
% not used by C-t C-t but could, and related

<<function lockloop>>=
void
lockloop(Lock *l, ulong pc)
{
    Proc *p;

    p = l->p;
    print("lock %#p loop key %#lux pc %#lux held by pc %#lux proc %lud\n",
        l, l->key, pc, l->pc, p ? p->pid : 0);
    dumpaproc(up);
    if(p != nil)
        dumpaproc(p);
}
@ 


<<function dumpregs2(x86)>>=
/*
 *  dump registers
 */
void
dumpregs2(Ureg* ureg)
{
    if(up)
        iprint("cpu%d: registers for %s %lud\n",
            cpu->cpuno, up->text, up->pid);
    else
        iprint("cpu%d: registers for kernel\n", cpu->cpuno);
    iprint("FLAGS=%luX TRAP=%luX ECODE=%luX PC=%luX",
        ureg->flags, ureg->trap, ureg->ecode, ureg->pc);
    iprint(" SS=%4.4luX USP=%luX\n", ureg->ss & 0xFFFF, ureg->usp);
    iprint("  AX %8.8luX  BX %8.8luX  CX %8.8luX  DX %8.8luX\n",
        ureg->ax, ureg->bx, ureg->cx, ureg->dx);
    iprint("  SI %8.8luX  DI %8.8luX  BP %8.8luX\n",
        ureg->si, ureg->di, ureg->bp);
    iprint("  CS %4.4luX  DS %4.4luX  ES %4.4luX  FS %4.4luX  GS %4.4luX\n",
        ureg->cs & 0xFFFF, ureg->ds & 0xFFFF, ureg->es & 0xFFFF,
        ureg->fs & 0xFFFF, ureg->gs & 0xFFFF);
}
@ 


<<function dumpregs(x86)>>=
void
dumpregs(Ureg* ureg)
{
    vlong mca, mct;

    dumpregs2(ureg);

    /*
     * Processor control registers.
     * If machine check exception, time stamp counter, page size extensions
     * or enhanced virtual 8086 mode extensions are supported, there is a
     * CR4. If there is a CR4 and machine check extensions, read the machine
     * check address and machine check type registers if RDMSR supported.
     */
    iprint("  CR0 %8.8lux CR2 %8.8lux CR3 %8.8lux",
        getcr0(), getcr2(), getcr3());
    if(cpu->cpuiddx & (Mce|Tsc|Pse|Vmex)){
        iprint(" CR4 %8.8lux", getcr4());
        if((cpu->cpuiddx & (Mce|Cpumsr)) == (Mce|Cpumsr)){
            rdmsr(0x00, &mca);
            rdmsr(0x01, &mct);
            iprint("\n  MCA %8.8llux MCT %8.8llux", mca, mct);
        }
    }
    iprint("\n  ur %#p up %#p\n", ureg, up);
}
@ 


%//unused:
%//static void
%//dumplockmem(char *tag, Lock *l)
%//{
%//  byte *cp;
%//  int i;
%//
%//  iprint("%s: ", tag);
%//  cp = (byte*)l;
%//  for(i = 0; i < 64; i++)
%//      iprint("%2.2ux ", cp[i]);
%//  iprint("\n");
%//}

%//unused
%//static void
%//dumpmount(void)       /* DEBUGGING */
%//{
%//  Pgrp *pg;
%//  Mount *t;
%//  Mhead **h, **he, *f;
%//
%//  if(up == nil){
%//      print("no process for dumpmount\n");
%//      return;
%//  }
%//  pg = up->pgrp;
%//  if(pg == nil){
%//      print("no pgrp for dumpmount\n");
%//      return;
%//  }
%//  rlock(&pg->ns);
%//  if(waserror()){
%//      runlock(&pg->ns);
%//      nexterror();
%//  }
%//
%//  he = &pg->mnthash[MNTHASH];
%//  for(h = pg->mnthash; h < he; h++){
%//      for(f = *h; f; f = f->hash){
%//          print("head: %#p: %s %#llux.%lud %C %lud -> \n", f,
%//              f->from->path->s, f->from->qid.path,
%//              f->from->qid.vers, devtab[f->from->type]->dc,
%//              f->from->dev);
%//          for(t = f->mount; t; t = t->next)
%//              print("\t%#p: %s (umh %#p) (path %#.8llux dev %C %lud)\n", t, t->to->path->s, t->to->umh, t->to->qid.path, devtab[t->to->type]->dc, t->to->dev);
%//      }
%//  }
%//  poperror();
%//  runlock(&pg->ns);
%//}

\section{[[/bin/ktrace]] (x86)}
% rename /bin/kstracktrace?

% getcallerpc nice trick

% what to do when have panic, e.g. when I mixed some fields
% and I got a pc error, how do I fix it? how do I find the relevant code?

% first can use nm -n 9qemu and try to find the name of the function involved

% can also use ktrace!!!

% TODO: ex of dumpstack(): 

<<function dumpstack(x86)>>=
void
trap_dumpstack(void)
{
    arch_callwithureg(_dumpstack);
}
@ 

<<function _dumpstack(x86)>>=
static void
_dumpstack(Ureg *ureg)
{
    uintptr l, v, i, estack;
    extern ulong etext;
    int x;
    char *s;

    if((s = getconf("*nodumpstack")) != nil && strcmp(s, "0") != 0){
        iprint("dumpstack disabled\n");
        return;
    }
    iprint("dumpstack\n");

    x = 0;
    x += iprint("ktrace /kernel/path %.8lux %.8lux <<EOF\n", ureg->pc, ureg->sp);
    i = 0;
    if(up
    && (uintptr)&l >= (uintptr)up->kstack
    && (uintptr)&l <= (uintptr)up->kstack+KSTACK)
        estack = (uintptr)up->kstack+KSTACK;
    else if((uintptr)(&l) >= (uintptr)(cpu->stack)
    && (uintptr)(&l) <= (uintptr)(cpu+CPUSIZE))
        estack = (uintptr)(cpu+CPUSIZE);
    else
        return;
    x += iprint("estackx %p\n", estack);

    for(l = (uintptr)(&l); l < estack; l += sizeof(uintptr)){
        v = *(uintptr*)l;
        if((KTZERO < v && v < (uintptr)(&etext)) || estack-l < 32){
            /*
             * Could Pick off general CALL (((byte*)v)[-5] == 0xE8)
             * and CALL indirect through AX
             * (((byte*)v)[-2] == 0xFF && ((byte*)v)[-2] == 0xD0),
             * but this is too clever and misses faulting address.
             */
            x += iprint("%.8p=%.8p ", l, v);
            i++;
        }
        if(i == 4){
            i = 0;
            x += iprint("\n");
        }
    }
    if(i)
        iprint("\n");
    iprint("EOF\n");

    if(ureg->trap != VectorNMI)
        return;

    i = 0;
    for(l = (uintptr)(&l); l < estack; l += sizeof(uintptr)){
        iprint("%.8p ", *(uintptr*)l);
        if(++i == 8){
            i = 0;
            iprint("\n");
        }
    }
    if(i)
        iprint("\n");
}
@ 

<<function callwithureg(x86)>>=
/*
 * Fill in enough of Ureg to get a stack trace, and call a function.
 * Used by debugging interface rdb.
 */
void
arch_callwithureg(void (*fn)(Ureg*))
{
    Ureg ureg;
    ureg.pc = getcallerpc(&fn);
    ureg.sp = (ulong)&fn;
    fn(&ureg);
}
@ 


% put code of ktrace? interesting code ... and very kernel specific
% or maybe in Debuggers.nw?

\section{[[/dev/kmesg]]}

<<struct KMesg>>=
/*
 * Log console output so it can be retrieved via /dev/kmesg.
 * This is good for catching boot-time messages after the fact.
 */
struct KMesg {
    Lock lk;
    char buf[KMESGSIZE];
    uint n;
};
@ 

<<global kmesg>>=
struct KMesg kmesg;
@ 

<<constant KMESGSIZE(x86)>>=
// used in devcons.c
KMESGSIZE = (16*1024),  /* put 256*1024 if want acpi debugging */
@
% used to be 256Ko but was making the binary really big which could make it
% harder to put a kernel on a floppy; no need for that much.


<<[[echo()]] hooks>>=
kmesgputs(buf, n);
@
% when a key was pressed, need to echo it back on screen and kmesg!

<<[[putstrn0()]] kmesg handling>>=
/*
 *  how many different output devices do we need?
 */
kmesgputs(str, n);
@
% print what was written do /dev/cons (hmm really the role of kmesg?)


<<function kmesgputs>>=
static void
kmesgputs(char *str, int n)
{
    uint nn, d;

    ilock(&kmesg.lk);
    /* take the tail of huge writes */
    if(n > sizeof kmesg.buf){
        d = n - sizeof kmesg.buf;
        str += d;
        n -= d;
    }

    /* slide the buffer down to make room */
    nn = kmesg.n;
    if(nn + n >= sizeof kmesg.buf){
        d = nn + n - sizeof kmesg.buf;
        if(d)
            memmove(kmesg.buf, kmesg.buf+d, sizeof kmesg.buf-d);
        nn -= d;
    }

    /* copy the data in */
    memmove(kmesg.buf+nn, str, n);
    nn += n;
    kmesg.n = nn;
    iunlock(&kmesg.lk);
}
@ 

<<devcons.c enum Qxxx cases>>=
Qkmesg,
@

<<[[consdir]] fields>>=
"kmesg",    {Qkmesg},   0,      0440,
@

<<[[consread()]] cases>>=
case Qkmesg:
    /*
     * This is unlocked to avoid tying up a process
     * that's writing to the buffer.  kmesg.n never 
     * gets smaller, so worst case the reader will
     * see a slurred buffer.
     */
    if(off >= kmesg.n)
        n = 0;
    else{
        if(off+n > kmesg.n)
            n = kmesg.n - off;
        memmove(buf, kmesg.buf+off, n);
    }
    return n;
@

\section{[[/dev/kprint]]}
%TODO: I don't understand this

<<devcons.c enum Qxxx cases>>=
    Qkprint,
@

<<[[consdir]] fields>>=
    "kprint",   {Qkprint, 0, QTEXCL},   0,  DMEXCL|0440,
@

<<enum dirmode cases>>=
DMEXCL = 0x20000000,  /* mode bit for exclusive use files */
@
% this bit is set for this file but never checked anywhere in the kernel
% weird

<<global kprintoq>>=
Queue*  kprintoq;       /* console output, for /dev/kprint */
@ 

% why use arch_tas() on it? why not use a Ref? because core debugging?
% so don't want to rely on anything fancy?
<<global kprintinuse>>=
ulong   kprintinuse;        /* test and set whether /dev/kprint is open */
@

<<[[consopen()]] cases>>=
    case Qkprint:
        if(arch_tas(&kprintinuse) != 0){
            c->flag &= ~COPEN;
            error(Einuse);
        }
        if(kprintoq == nil){
            kprintoq = qopen(8*1024, Qcoalesce, 0, 0);
            if(kprintoq == nil){
                c->flag &= ~COPEN;
                error(Enomem);
            }
            qnoblock(kprintoq, true);
        }else
            qreopen(kprintoq);
        c->iounit = qiomaxatomic;
        break;
@

<<[[consclose()]] cases>>=
    /* close of kprint allows other opens */
    case Qkprint:
        if(c->flag & COPEN){
            kprintinuse = 0;
            qhangup(kprintoq, nil);
        }
        break;
@

<<[[consread()]] cases>>=
    case Qkprint:
        return qread(kprintoq, buf, n);
@

<<[[putstrn0()]] if kprint>>=
    /*
     *  if someone is reading /dev/kprint,
     *  put the message there.
     *  if not and there's an attached bit mapped display,
     *  put the message there.
     *
     *  if there's a serial line being used as a console,
     *  put the message there.
     */
    if(kprintoq != nil && !qisclosed(kprintoq)){
        if(usewrite)
            qwrite(kprintoq, str, n);
        else
            qiwrite(kprintoq, str, n);
    }
@

<<[[panic()]] reset kprintoq>>=
    kprintoq = nil; /* don't try to write to /dev/kprint */
@



\section{Remote debugger}
% rdb.c
% related to serial line code?
% TODO: how does it work? can make it work via qemu?

<<hook consdebug>>=
void    (*consdebug)(void) = nil; // for rdb
@ 

<<[[panic()]] run consdebug hook>>=
    if(consdebug)
        (*consdebug)();
@

<<[[echo()]] C-t C-t special keys handler other cases>>=
        case 'd':
            if(consdebug == nil)
                consdebug = rdb;
            else
                consdebug = nil;
            print("consdebug now %#p\n", consdebug);
            return;
        case 'D':
            if(consdebug == nil)
                consdebug = rdb;
            consdebug();
            return;
@

\section{Serial line}

% can demo with qemu?

<<global serialoq>>=
Queue*  serialoq;       /* serial console output */
@ 

<<function consactive>>=
int
consactive(void)
{
    if(serialoq)
        return qlen(serialoq) > 0;
    return 0;
}
@ 

<<[[echo()]] hooks>>=
if(serialoq)
    echoserialoq(buf, n);
@


<<function echoserialoq>>=
static void
echoserialoq(char *buf, int n)
{
    char *e, *p;
    char ebuf[128];
    int x;

    p = ebuf;
    e = ebuf + sizeof(ebuf) - 4;
    while(n-- > 0){
        if(p >= e){
            qiwrite(serialoq, ebuf, p - ebuf);
            p = ebuf;
        }
        x = *buf++;
        if(x == '\n'){
            *p++ = '\r';
            *p++ = '\n';
        } else if(x == 0x15){
            *p++ = '^';
            *p++ = 'U';
            *p++ = '\n';
        } else
            *p++ = x;
    }
    if(p != ebuf)
        qiwrite(serialoq, ebuf, p - ebuf);
}
@ 
% quite similar to echoscreen


<<[[putstrn0()]] serialoq handling>>=
    /*
     *   Convert \n to \r\n for serial
     *   line consoles.  Locking of the queues is left up to the screen
     *   or uart code.  Multi-line messages to serial consoles may get
     *   interspersed with other messages.
     */

    if(serialoq == nil){
        uartputs(str, n);
        return;
    }

    while(n > 0) {
        t = memchr(str, '\n', n);
        if(t && !kbd.raw) {
            m = t-str;
            if(usewrite){
                qwrite(serialoq, str, m);
                qwrite(serialoq, "\r\n", 2);
            } else {
                qiwrite(serialoq, str, m);
                qiwrite(serialoq, "\r\n", 2);
            }
            n -= m+1;
            str = t+1;
        } else {
            if(usewrite)
                qwrite(serialoq, str, n);
            else
                qiwrite(serialoq, str, n);
            break;
        }
    }
@



% dead?
<<function prflush>>=
void
prflush(void)
{
    ulong now;

    now = cpu->ticks;
    while(consactive())
        if(cpu->ticks - now >= HZ)
            break;
}
@ 

<<[[reboot()]] reset serialoq(x86)>>=
/* turn off buffered serial console */
serialoq = nil;
@




\chapter{Profiling}

% see also lockcycles, QlockStats, TaslockStats, ... in Kernel_extra.nw

\section{[[/sys/sysstat]] (x86)}

<<[[Cpu]] stat fields>>=
Perf  perf;     /* performance counters */
@ 

<<struct Perf>>=
/*
 *  performance timers, all units in perfticks
 */
struct Perf
{
    // intr-ts? interrupt time stamp?
    ulong intrts;   /* time of last interrupt */

    ulong inintr;   /* time since last clock tick in interrupt handlers */
    ulong avg_inintr; /* avg time per clock tick in interrupt handlers */

    ulong inidle;   /* time since last clock tick in idle loop */
    ulong avg_inidle; /* avg time per clock tick in idle loop */

    ulong last;   /* value of arch_perfticks() at last clock tick */
    ulong period;   /* arch_perfticks() per clock tick */
};
@ 

<<[[Cpu]] stat fields>>=
int load;
@

% called by hzclock, so every tick
<<function accounttime>>=
/*
 *  time accounting called by clock() splhi'd
 */
void
accounttime(void)
{
    Proc *p;
    ulong n, per;
    static ulong nrun;

    p = cpu->proc; // why not p = up?
    if(p) {
        nrun++;
        <<[[accountime()]] update time of current process>>
    }

    /* calculate decaying duty cycles */
    n = arch_perfticks();
    per = n - cpu->perf.last;
    cpu->perf.last = n;
    per = (cpu->perf.period*(HZ-1) + per)/HZ;
    if(per != 0)
        cpu->perf.period = per;

    cpu->perf.avg_inidle = (cpu->perf.avg_inidle*(HZ-1)+cpu->perf.inidle)/HZ;
    cpu->perf.inidle = 0;

    cpu->perf.avg_inintr = (cpu->perf.avg_inintr*(HZ-1)+cpu->perf.inintr)/HZ;
    cpu->perf.inintr = 0;

    /* only one processor gets to compute system load averages */
    if(cpu->cpuno != 0)
        return;

    /*
     * calculate decaying load average.
     * if we decay by (n-1)/n then it takes
     * n clock ticks to go from load L to .36 L once
     * things quiet down.  it takes about 5 n clock
     * ticks to go to zero.  so using HZ means this is
     * approximately the load over the last second,
     * with a tail lasting about 5 seconds.
     */
    n = nrun;
    nrun = 0;
    n = (nrdy+n)*1000;
    cpu->load = (cpu->load*(HZ-1)+n)/HZ;
}
@ 




<<global intrtimes(x86)>>=
ulong intrtimes[256][Ntimevec];
@ 
% note really used, could hide it

<<constant Ntimevec(x86)>>=
    Ntimevec = 20       /* number of time buckets for each intr */
@

<<function intrtime(x86)>>=
/*
 *  keep histogram of interrupt service times
 */
void
intrtime(Cpu*, int vno)
{
    ulong diff;
    ulong x;

    x = arch_perfticks();
    diff = x - cpu->perf.intrts;
    cpu->perf.intrts = x;

    cpu->perf.inintr += diff;
    if(up == nil && cpu->perf.inidle > diff)
        cpu->perf.inidle -= diff;

    diff /= cpu->cpumhz*100;      /* quantum = 100microsec */
    if(diff >= Ntimevec)
        diff = Ntimevec-1;
    intrtimes[vno][diff]++;
}
@ 


<<function perfticks(x86)>>=
/*  
 *  performance measurement ticks.  must be low overhead.
 *  doesn't have to count over a second.
 */
ulong
arch_perfticks(void)
{
    uvlong x;

    if(cpu->havetsc)
        arch_cycles(&x);
    else
        x = 0;
    return x;
}
@
% see cycles() below. essentially *x = cpu->ticks.


<<[[Cpu]] stat fields>>=
int cs; // context switch, sched() and sleep() call
int intr;
int syscall;
int pfault;
int tlbfault;
int tlbpurge;
ulong spuriousintr; // not really used
@
% related: Linux perf software events

% also lockcycles here?





<<devsys.c enum Qxxx cases>>=
    Qsysstat,
@
%old: used to be in devcons.c

<<[[sysdir]] fields>>=
    "sysstat",  {Qsysstat}, 0,      0666,
@

<<[[sysread()]] cases>>=
    case Qsysstat:
        b = smalloc(conf.ncpu*(NUMSIZE*11+1) + 1); /* +1 for NUL */
        bp = b;
        for(id = 0; id < MAXCPUS; id++) {
            if(active.cpus & (1<<id)) {
                mp = CPUS(id);
                readnum(0, bp, NUMSIZE, id, NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE, mp->cs, NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE, mp->intr, NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE, mp->syscall, NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE, mp->pfault, NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE, mp->tlbfault, NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE, mp->tlbpurge, NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE, mp->load, NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE,
                    (mp->perf.avg_inidle*100)/mp->perf.period,
                    NUMSIZE);
                bp += NUMSIZE;
                readnum(0, bp, NUMSIZE,
                    (mp->perf.avg_inintr*100)/mp->perf.period,
                    NUMSIZE);
                bp += NUMSIZE;
                *bp++ = '\n';
            }
        }
        if(waserror()){
            free(b);
            nexterror();
        }
        n = readstr((ulong)offset, buf, n, b);
        free(b);
        poperror();
        return n;
@
% >>

<<[[syswrite()]] cases>>=
    case Qsysstat:
        for(id = 0; id < 32; id++) {
            if(active.cpus & (1<<id)) {
                mp = CPUS(id);
                mp->cs = 0;
                mp->intr = 0;
                mp->syscall = 0;
                mp->pfault = 0;
                mp->tlbfault = 0;
                mp->tlbpurge = 0;
            }
        }
        break;

@
% >>

\section{[[/dev/kprof]]}

% put back devkprof.c?

<<hook kproftimer>>=
void (*kproftimer)(ulong);
@ 

\chapter{Error Management}

\section{[[panic()]]}

<<global panicking>>=
bool panicking;
@


<<function panic>>=
void
devcons_panic(char *fmt, ...)
{
    int n, s;
    va_list arg;
    char buf[PRINTSIZE];

    <<[[panic()]] reset kprintoq>>

    if(panicking)
        for(;;);
    panicking = true;

    s = arch_splhi();
    strcpy(buf, "panic: ");
    va_start(arg, fmt);
    n = vseprint(buf+strlen(buf), buf+sizeof(buf), fmt, arg) - buf;
    va_end(arg);
    iprint("%s\n", buf);
    <<[[panic()]] run consdebug hook>>
    arch_splx(s);
    prflush();
    buf[n] = '\n';
    putstrn(buf, n+1);
    //TODO: put in comment for now because already got some panic with
    // lapic, but it seems to work still :)
    //dumpstack();
    //exit(1);
}
@ 


<<function sysfatal>>=
/* libmp at least contains a few calls to sysfatal; simulate with panic */
// note that this is not a system call, even though it's prefixed with sys
//@Scheck: no dead, override also sysfatal from libc/9sys/sysfatal.c
void sysfatal(char *fmt, ...)
{
    char err[256];
    va_list arg;

    va_start(arg, fmt);
    vseprint(err, err + sizeof err, fmt, arg);
    va_end(arg);
    panic("sysfatal: %s", err);
}
@ 

<<function _assert>>=
void
devcons__assert(char *fmt)
{
    panic("assert failed at %#p: %s", getcallerpc(&fmt), fmt);
}
@ 

\section{[[error()]]}

<<global Exxx errors>>=
char Emount[] = "inconsistent mount";
char Eunmount[] = "not mounted";
char Eismtpt[] = "is a mount point";
char Eunion[] = "not in union";
char Emountrpc[] = "mount rpc error";
char Eshutdown[] = "device shut down";
char Enocreate[] = "mounted directory forbids creation";
char Enonexist[] = "file does not exist";
char Eexist[] = "file already exists";
char Ebadsharp[] = "unknown device in # filename";
char Enotdir[] = "not a directory";
char Eisdir[] = "file is a directory";
char Ebadchar[] = "bad character in file name";
char Efilename[] = "file name syntax";
char Eperm[] = "permission denied";
char Ebadusefd[] = "inappropriate use of fd";
char Ebadarg[] = "bad arg in system call";
char Einuse[] = "device or object already in use";
char Eio[] = "i/o error";
char Etoobig[] = "read or write too large";
char Etoosmall[] = "read or write too small";
char Ehungup[] = "i/o on hungup channel";
char Ebadctl[] = "bad process or channel control request";
char Enodev[] = "no free devices";
char Eprocdied[] = "process exited";
char Enochild[] = "no living children";
char Eioload[] = "i/o error in demand load";
char Enovmem[] = "virtual memory allocation failed";
char Ebadfd[] = "fd out of range or not open";
char Enofd[] = "no free file descriptors";
char Eisstream[] = "seek on a stream";
char Ebadexec[] = "exec header invalid";
char Etimedout[] = "connection timed out";
char Econrefused[] = "connection refused";
char Econinuse[] = "connection in use";
char Eintr[] = "interrupted";
char Enomem[] = "kernel allocate failed";
char Esoverlap[] = "segments overlap";
char Eshort[] = "i/o count too small";
char Egreg[] = "jmk added reentrancy for threads";
char Ebadspec[] = "bad attach specifier";
char Enoreg[] = "process has no saved registers";
char Enoattach[] = "mount/attach disallowed";
char Eshortstat[] = "stat buffer too small";
char Ebadstat[] = "malformed stat buffer";
char Enegoff[] = "negative i/o offset";
char Ecmdargs[] = "wrong #args in control message";
char Ebadip[] = "bad ip address syntax";
char Edirseek[] = "seek in directory";
char Echange[] = "media or partition has changed";
char Edetach[] = "device is detached";
char Enotconf[] = "endpoint not configured";
char Estalled[] = "endpoint stalled";
char Esbadstat[] = "invalid directory entry received from server";
char Enoversion[] = "version not established for mount channel";
@ 

<<global Edoesnotexist>>=
static char Edoesnotexist[] = "does not exist";
@


<<[[Proc]] error managment fields>>=
// array<Label>, error labels, poor's man exceptions in C
Label errlab[NERR];
// length(errlab) used.
int nerrlab;

// ref<string> point to errbuf0 or to syserrstr (which points to errbuf1)
char  *errstr;  /* reason we're unwinding the error stack, errbuf1 or 0 */
char  errbuf0[ERRMAX];
char  errbuf1[ERRMAX];
@ 

<<constant NERR>>=
    NERR = 64,
@

<<function error>>=
void
proc_error(char *err)
{
    arch_spllo();

    assert(up->nerrlab < NERR);
    kstrcpy(up->errstr, err, ERRMAX);
    arch_setlabel(&up->errlab[NERR-1]);
    nexterror();
}
@ 
% todo: there is a top waserror() in trap and syscall? so will
% always jump somewhere?

<<function exhausted>>=
void
exhausted(char *resource)
{
    char buf[ERRMAX];

    snprint(buf, sizeof buf, "no free %s", resource);
    iprint("%s\n", buf);
    error(buf);
}
@ 


\section{[[waserror()]], [[nexterror()]], [[poperror()]]}
% waserror(), nexterror(), etc
% =~ poor's man exn mechanism (=> improve C!!)

<<macro waserror poperror>>=
// poor's man exceptions in C
//  - waserror() =~ try  
//     * if (!waserror()) { } else { } <=> try { } catch { }
//     * if (waserror()) { }  <=> finally { }
//  - poperror() = nothing
//  - error() =~ raise
//  - nexterror() =~ re raise from exn handler
// note, arch_setlabel() return false, so the branch is never taken first
// but nexterror() is using arch_gotolabel() which returns true, see l_switch.s
#define waserror()  (up->nerrlab++, arch_setlabel(&up->errlab[up->nerrlab-1]))
#define poperror()    up->nerrlab--
@ 


<<function nexterror>>=
// raise an exception
void
proc_nexterror(void)
{
    arch_gotolabel(&up->errlab[--up->nerrlab]);
}
@ 


% different idioms:

% RAII: finally
% x = malloc();
% if(waserror() {
%   free(x);
%   nexterror();
% }
% ...

% try and swallow:
% if(!waserror() {
%   stuff_that_can_raise_error();
%   poperror();
% }
% ...

% try and catch
% if(!waserror() {
%   stuff_that_can_raise_error();
%   poperror();
% } else {
%   free??
% } 
% ...



\section{[[syserrstr()]]}

%design:
% most function returns an int value, but sometimes also can
% be error. Information could be an error return code, but then
% need convention and conversion and call to perror().
% So simpler to have error in a string accessible by another
% system call (which 
%alt: return either :) a la Erlang

<<[[Proc]] error managment fields>>=
char  *syserrstr; /* last error from a system call, errbuf0 or 1 */
@

<<syscall errstr>>=
// int errstr(char *err, uint nerr);
long
syserrstr(ulong* arg)
{
    return generrstr((char*)arg[0], arg[1]);
}
@ 

<<function generrstr>>=
static long
generrstr(char *buf, uint nbuf)
{
    char tmp[ERRMAX];

    if(nbuf == 0)
        error(Ebadarg);
    validaddr((ulong)buf, nbuf, true);
    if(nbuf > sizeof tmp)
        nbuf = sizeof tmp;
    memmove(tmp, buf, nbuf);

    /* make sure it's NUL-terminated */
    tmp[nbuf-1] = '\0';
    memmove(buf, up->syserrstr, nbuf);
    buf[nbuf-1] = '\0';
    memmove(up->syserrstr, tmp, nbuf);
    return 0;
}
@ 

<<function werrstr>>=
//@Scheck: this is also defined in libc, so it's supposed to override it? TODO
void werrstr(char *fmt, ...)
{
    va_list va;

    if(up == nil)
        return;

    va_start(va, fmt);
    vseprint(up->syserrstr, up->syserrstr+ERRMAX, fmt, va);
    va_end(va);
}
@ 

\chapter{Mini Libc}

% have a list, hash, queue, section? with simple macros?

\section{Memory areas operations}

% use malloc internally?

% ugly that memmove is actually not a move but a copy, and ugly
% that take dest first and src second ...
% actually memmove can handle when memory area overlap!
<<lib.h mem functions decl>>=
extern  void* memccpy(void*, void*, int, ulong);
extern  void* memset(void*, int, ulong);
extern  int memcmp(void*, void*, ulong);
extern  void* memmove(void*, void*, ulong);
extern  void* memchr(void*, int, ulong);
@ 

% memchr reverse?
<<function memrchr>>=
void*
memrchr(void *va, int c, long n)
{
    byte *a, *e;

    a = va;
    for(e=a+n-1; e>a; e--)
        if(*e == c)
            return e;
    return nil;
}
@

\section{String functions}

<<lib.h string functions decl>>=
extern  char* strchr(char*, int);
extern  char* strrchr(char*, int);
extern  int strcmp(char*, char*);
extern  char* strcpy(char*, char*);
extern  char* strecpy(char*, char*, char*);
extern  char* strncpy(char*, char*, long);
extern  int strncmp(char*, char*, long);
extern  long  strlen(char*);
extern  char* strstr(char*, char*);
extern  int atoi(char*);
extern  int fullrune(char*, int);
@ 
%//unused: extern  char* strcat(char*, char*);
%//unused: extern  char* strncat(char*, char*, long);


<<function kstrcpy>>=
/*
 * Rather than strncpy, which zeros the rest of the buffer, kstrcpy
 * truncates if necessary, always zero terminates, does not zero fill,
 * and puts ... at the end of the string if it's too long.  Usually used to
 * save a string in up->genbuf;
 */
void
kstrcpy(char *s, char *t, int ns)
{
    int nt;

    nt = strlen(t);
    if(nt+1 <= ns){
        memmove(s, t, nt+1);
        return;
    }
    /* too long */
    if(ns < 4){
        /* but very short! */
        strncpy(s, t, ns);
        return;
    }
    /* truncate with ... at character boundary (very rare case) */
    memmove(s, t, ns-4);
    ns -= 4;
    s[ns] = '\0';
    /* look for first byte of UTF-8 sequence by skipping continuation bytes */
    while(ns>0 && (s[--ns]&0xC0)==0x80)
        ;
    strcpy(s+ns, "...");
}
@


<<function kstrdup>>=
/*
 * Atomically replace *p with copy of s
 */
void
kstrdup(char **p, char *s)
{
    int n;
    char *t, *prev;

    n = strlen(s)+1;
    /* if it's a user, we can wait for memory; if not, something's very wrong */
    if(up){
        t = smalloc(n);
        setmalloctag(t, getcallerpc(&p));
    }else{
        t = malloc(n);
        if(t == nil)
            panic("kstrdup: no memory");
    }
    memmove(t, s, n);
    prev = *p;
    *p = t;
    free(prev);
}
@

%less: put the isdot, isfrog here

<<function emptystr>>=
bool
emptystr(char *s)
{
    if(s == nil)
        return true;
    if(s[0] == '\0')
        return true;
    return false;
}
@
% was in chan.c, but used outside, so should be in libc_extra.h

\section{Conversion functions}

<<lib.h strto functions decl>>=
extern  long  strtol(char*, char**, int);
extern  ulong strtoul(char*, char**, int);
extern  vlong strtoll(char*, char**, int);
extern  uvlong  strtoull(char*, char**, int);
@ 

<<function readnum>>=
int
readnum(ulong off, char *buf, ulong n, ulong val, int size)
{
    char tmp[64];

    snprint(tmp, sizeof(tmp), "%*lud", size-1, val);
    tmp[size-1] = ' ';
    if(off >= size)
        return 0;
    if(off+n > size)
        n = size-off;
    memmove(buf, tmp+off, n);
    return n;
}
@


<<function readstr>>=
int
readstr(ulong off, char *buf, ulong n, char *str)
{
    int size;

    size = strlen(str);
    if(off >= size)
        return 0;
    if(off+n > size)
        n = size-off;
    memmove(buf, str+off, n);
    return n;
}
@

\section{Pool allocation}

% set things from lib_core/libc/...?pool.c mainmem? imagmem?

\section{Printf and [[Fmt]]}

% see print.c which overrides functions defined in lib_core/libc/fmt/fmtlock.c 

<<lib.h printf functions decl>>=
extern  char* seprint(char*, char*, char*, ...);
extern  char* vseprint(char*, char*, char*, va_list);
extern  int snprint(char*, int, char*, ...);
extern  int sprint(char*, char*, ...);
@
%//unused: extern  int vsnprint(char*, int, char*, va_list);



<<struct Fmt>>=
struct Fmt{
  byte runes;      /* output buffer is runes or chars? */
  void  *start;     /* of buffer */
  void  *to;      /* current place in the buffer */
  void  *stop;      /* end of the buffer; overwritten if flush fails */
  int (*flush)(Fmt *);  /* called when to == stop */
  void  *farg;      /* to make flush a closure */
  int nfmt;     /* num chars formatted so far */
  va_list args;     /* args passed to dofmt */
  int r;      /* % format Rune */
  int width;
  int prec;
  ulong flags;
};
@ 

<<lib.h fmt functions decl>>=
extern  int fmtstrinit(Fmt*);
extern  int fmtinstall(int, int (*)(Fmt*));
extern  void  quotefmtinstall(void);
extern  int fmtprint(Fmt*, char*, ...);
extern  int fmtstrcpy(Fmt*, char*);
extern  char* fmtstrflush(Fmt*);
@ 

<<lib.h pragmas>>=
#pragma varargck  argpos  fmtprint  2
#pragma varargck  argpos  print   1
#pragma varargck  argpos  seprint   3
#pragma varargck  argpos  snprint   3
#pragma varargck  argpos  sprint    2

#pragma varargck  type  "lld" vlong
#pragma varargck  type  "llx" vlong
#pragma varargck  type  "lld" uvlong
#pragma varargck  type  "llx" uvlong
#pragma varargck  type  "ld"  long
#pragma varargck  type  "lx"  long
#pragma varargck  type  "ld"  ulong
#pragma varargck  type  "lx"  ulong
#pragma varargck  type  "d" int
#pragma varargck  type  "x" int
#pragma varargck  type  "c" int
#pragma varargck  type  "C" int
#pragma varargck  type  "d" uint
#pragma varargck  type  "x" uint
#pragma varargck  type  "c" uint
#pragma varargck  type  "C" uint
#pragma varargck  type  "s" char*
#pragma varargck  type  "q" char*
#pragma varargck  type  "S" Rune*
#pragma varargck  type  "%" void
#pragma varargck  type  "p" uintptr
#pragma varargck  type  "p" void*
#pragma varargck  flag  ','
@


\section{Runes, a.k.a unicode}

<<enum utf>>=
enum
{
  UTFmax    = 4,    /* maximum bytes per rune */
  Runeself  = 0x80,   /* rune and UTF sequences are the same (<) */
};
@
%//unused: Runesync  = 0x80,   /* cannot represent part of a UTF sequence (<) */
%//unused: Runeerror = 0xFFFD, /* decoding error in UTF */
%//unused: Runemax   = 0x10FFFF, /* 24 bit rune */
%//unused: Runemask  = 0x1FFFFF, /* bits used by runes (see grep) */

<<lib.h rune functions decl>>=
extern  int runetochar(char*, Rune*);
extern  int chartorune(Rune*, char*);
extern  char* utfrune(char*, long);
extern  int utfnlen(char*, long);
@ 
%//unused: extern  int utflen(char*);
%//unused: extern  int runelen(long);

% unicode input from keyboard

% see also Spec = 0xF800 in enum specialkey

% chartorune() returns number of bytes actually read to produce the rune

<<[[Kbscan]] other fields>>=
bool collecting;
int nk;
Rune    kc[5];
@
% used to be Rune kc[5]; but does not make sense; would make
% more sense with char kc[5] and change accordingly
% latin1() and unicode().

<<[[kbdputsc()]] if collecting>>=
if(kbscan->collecting){
    int i;
    // pad's additional overflow checking, just to make sure
    if(kbscan->nk >= nelem(kbscan->kc)) {
      kbscan->nk = 0;
      kbscan->collecting = false;
      print("collecting overflow, possible bug in latin1()\n");
    }
    kbscan->kc[kbscan->nk++] = c;
    c = latin1(kbscan->kc, kbscan->nk);
    if(c < -1)  /* need more keystrokes */
        return;
    if(c != -1) /* valid sequence */
        kbdputc(c);
    else    /* dump characters */
        for(i=0; i<kbscan->nk; i++)
            kbdputc(kbscan->kc[i]);
    kbscan->nk = 0;
    kbscan->collecting = false;
}
@

<<[[kbdputsc()]] start collecting>>=
/*
 * VMware and Qemu use Ctl-Alt as the key combination
 * to make the VM give up keyboard and mouse focus.
 * This has the unfortunate side effect that when you
 * come back into focus, Plan 9 thinks you want to type
 * a compose sequence (you just typed alt). 
 *
 * As a clumsy hack around this, we look for ctl-alt
 * and don't treat it as the start of a compose sequence.
 */
if(!kbscan->ctl){
    kbscan->collecting = true;
    kbscan->nk = 0;
}
@

<<latin1.h>>=
 " ", " i",	L"␣ı",
 "!~", "-=~",	L"≄≇≉",
 "!", "!<=>?bmp",	L"¡≮≠≯‽⊄∉⊅",
 "\"*", "IUiu",	L"ΪΫϊϋ",
 "\"", "\"AEIOUYaeiouy",	L"¨ÄËÏÖÜŸäëïöüÿ",
 "$*", "fhk",	L"ϕϑϰ",
 "$", "BEFHILMRVaefglopv",	L"ℬℰℱℋℐℒℳℛƲɑℯƒℊℓℴ℘ʋ",
 "\'\"", "Uu",	L"Ǘǘ",
 "\'", "\'ACEILNORSUYZacegilnorsuyz",	L"´ÁĆÉÍĹŃÓŔŚÚÝŹáćéģíĺńóŕśúýź",
 "*", "*ABCDEFGHIKLMNOPQRSTUWXYZabcdefghiklmnopqrstuwxyz",	L"∗ΑΒΞΔΕΦΓΘΙΚΛΜΝΟΠΨΡΣΤΥΩΧΗΖαβξδεφγθικλμνοπψρστυωχηζ",
 "+", "-O",	L"±⊕",
 ",", ",ACEGIKLNORSTUacegiklnorstu",	L"¸ĄÇĘĢĮĶĻŅǪŖŞŢŲąçęģįķļņǫŗşţų",
 "-*", "l",	L"ƛ",
 "-", "+-2:>DGHILOTZbdghiltuz~",	L"∓­ƻ÷→ÐǤĦƗŁ⊖ŦƵƀðǥℏɨłŧʉƶ≂",
 ".", ".CEGILOZceglz",	L"·ĊĖĠİĿ⊙Żċėġŀż",
 "/", "Oo",	L"Øø",
 "1", ".234568",	L"․½⅓¼⅕⅙⅛",
 "2", "-.35",	L"ƻ‥⅔⅖",
 "3", ".458",	L"…¾⅗⅜",
 "4", "5",	L"⅘",
 "5", "68",	L"⅚⅝",
 "7", "8",	L"⅞",
 ":", "()-=",	L"☹☺÷≔",
 "<!", "=~",	L"≨⋦",
 "<", "-<=>~",	L"←«≤≶≲",
 "=", ":<=>OV",	L"≕⋜≡⋝⊜⇒",
 ">!", "=~",	L"≩⋧",
 ">", "<=>~",	L"≷≥»≳",
 "?", "!?",	L"‽¿",
 "@\'", "\'",	L"ъ",
 "@@", "\'EKSTYZekstyz",	L"ьЕКСТЫЗекстыз",
 "@C", "Hh",	L"ЧЧ",
 "@E", "Hh",	L"ЭЭ",
 "@K", "Hh",	L"ХХ",
 "@S", "CHch",	L"ЩШЩШ",
 "@T", "Ss",	L"ЦЦ",
 "@Y", "AEOUaeou",	L"ЯЕЁЮЯЕЁЮ",
 "@Z", "Hh",	L"ЖЖ",
 "@c", "h",	L"ч",
 "@e", "h",	L"э",
 "@k", "h",	L"х",
 "@s", "ch",	L"щш",
 "@t", "s",	L"ц",
 "@y", "aeou",	L"яеёю",
 "@z", "h",	L"ж",
 "@", "ABDFGIJLMNOPRUVXabdfgijlmnopruvx",	L"АБДФГИЙЛМНОПРУВХабдфгийлмнопрувх",
 "A", "E",	L"Æ",
 "C", "ACU",	L"⋂ℂ⋃",
 "Dv", "Zz",	L"Ǆǅ",
 "D", "-e",	L"Ð∆",
 "G", "-",	L"Ǥ",
 "H", "-H",	L"Ħℍ",
 "I", "-J",	L"ƗĲ",
 "L", "&-Jj|",	L"⋀ŁǇǈ⋁",
 "M", "#48bs",	L"♮♩♪♭♯",
 "N", "JNj",	L"Ǌℕǋ",
 "O", "*+-./=EIcoprx",	L"⊛⊕⊖⊙⊘⊜ŒƢ©⊚℗®⊗",
 "P", "P",	L"ℙ",
 "Q", "Q",	L"ℚ",
 "R", "R",	L"ℝ",
 "S", "123S",	L"¹²³§",
 "T", "-u",	L"Ŧ⊨",
 "V", "=",	L"⇐",
 "Y", "R",	L"Ʀ",
 "Z", "-ACSZ",	L"Ƶℤ",
 "^", "ACEGHIJOSUWYaceghijosuwy",	L"ÂĈÊĜĤÎĴÔŜÛŴŶâĉêĝĥîĵôŝûŵŷ",
 "_\"", "AUau",	L"ǞǕǟǖ",
 "_,", "Oo",	L"Ǭǭ",
 "_.", "Aa",	L"Ǡǡ",
 "_", "AEIOU_aeiou",	L"ĀĒĪŌŪ¯āēīōū",
 "`\"", "Uu",	L"Ǜǜ",
 "`", "AEIOUaeiou",	L"ÀÈÌÒÙàèìòù",
 "a", "ben",	L"↔æ∠",
 "b", "()+-0123456789=bknpqru",	L"₍₎₊₋₀₁₂₃₄₅₆₇₈₉₌♝♚♞♟♛♜•",
 "c", "$Oagu",	L"¢©∩≅∪",
 "dv", "z",	L"ǆ",
 "d", "-adegz",	L"ð↓‡°†ʣ",
 "e", "$lmns",	L"€⋯—–∅",
 "f", "a",	L"∀",
 "g", "$-r",	L"¤ǥ∇",
 "h", "-v",	L"ℏƕ",
 "i", "-bfjps",	L"ɨ⊆∞ĳ⊇∫",
 "l", "\"$&\'-jz|",	L"“£∧‘łǉ⋄∨",
 "m", "iou",	L"µ∈×",
 "n", "jo",	L"ǌ¬",
 "o", "AOUaeiu",	L"Å⊚Ůåœƣů",
 "p", "Odgrt",	L"℗∂¶∏∝",
 "r", "\"\'O",	L"”’®",
 "s", "()+-0123456789=abnoprstu",	L"⁽⁾⁺⁻⁰ⁱ⁲⁳⁴⁵⁶⁷⁸⁹⁼ª⊂ⁿº⊃√ß∍∑",
 "t", "-efmsu",	L"ŧ∃∴™ς⊢",
 "u", "-AEGIOUaegiou",	L"ʉĂĔĞĬŎŬ↑ĕğĭŏŭ",
 "v\"", "Uu",	L"Ǚǚ",
 "v", "ACDEGIKLNORSTUZacdegijklnorstuz",	L"ǍČĎĚǦǏǨĽŇǑŘŠŤǓŽǎčďěǧǐǰǩľňǒřšťǔž",
 "w", "bknpqr",	L"♗♔♘♙♕♖",
 "x", "O",	L"⊗",
 "y", "$",	L"¥",
 "z", "-",	L"ƶ",
 "|", "Pp|",	L"Þþ¦",
 "~!", "=",	L"≆",
 "~", "-=AINOUainou~",	L"≃≅ÃĨÑÕŨãĩñõũ≈",
@
%$


\chapter{Extra Code}

\ifallcode
#include "Kernel_extra.nw"
#include "Kernel_x86.nw"
#include "Kernel_arm.nw"
\fi

\chapter{Changelog}
\label{sec:changelog}

\chapter{Glossary}
\label{sec:glossary}

\begin{verbatim}
UP   = User Process
PC   = Program Counter
SPL  = Set Priority Level
RMAP = RAM map
UMB  = Upper Memory Block
GDT  = Global Descriptor Table
PD   = Page Directory
PT   = Page Table
PDB  = Page Directory Base
PTE  = Page Table Entry
PPN  = Physical Page Number?
VPT  = Virtual Page Table
INTR = INTeRrupt (not INT, probably to avoid ambiguity with integer)
VNO  = Vector Number (interrupt)
IRQ  = Interrupt Request
ISR  = Interrupt Service Routine
NMI  = Non Maskable Interrupts (hardware error)
AP   = Application Processor
EDF  = Earliest Deadline First
RPC  = Remote Procedure Call
EGRP = Environment GRouP
FGRP = File descriptor GRouP (channels)
PGRP = Process GRouP (namespace)
QID  = uniQue IDentifier (uid is taken for user id)
TSC  = Time Stamp Counter
TOD  = Time Of Day
APIC = Advanded Programmable Interrupt Controller (a next gen 8259)
ACPI = Advanced Configuration & Power Interface
UART = Universal Asynchronous Receive/Transmitter
\end{verbatim}

\chapter*{Indexes}
\addcontentsline{toc}{chapter}{Index}

%\chapter{References} 
\addcontentsline{toc}{chapter}{References}

\bibliography{../docs/latex/Principia}
\bibliographystyle{plain}

%******************************************************************************
% Postlude
%******************************************************************************

\end{document}
